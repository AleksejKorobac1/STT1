00:00:01 the following is a conversation with Jeremy Howard he's the founder of fast AI a Research Institute dedicated to
00:00:08 making deep learning more accessible he's also a distinguished research scientist at the University of San
00:00:16 Francisco a former president of Kegel as well as the top ranking competitor there and in general he's a successful
00:00:23 entrepreneur educator researcher and an inspiring personality in the AI community when someone asked me how do I
00:00:30 get started with deep learning fast AI is one of the top places that point them to it's free it's easy to get started
00:00:38 it's insightful and accessible and if I may say so it has very little BS they can sometimes dilute the value of
00:00:45 educational content on popular topics like deep learning fast AI has a focus on practical application of deep
00:00:51 learning and hands-on exploration of the cutting edge that is incredibly both accessible to beginners and useful to
00:00:59 experts this is the artificial intelligence podcast if you enjoy it subscribe on YouTube give it five stars
00:01:06 and iTunes supported on patreon or simply connect with me on Twitter Alex Friedman spelled Fri D ma N and now
00:01:16 here's my conversation with Jeremy Howard what's the first program you've ever ridden this program I wrote that I
00:01:29 remember would be at high school I did an assignment where I decided to try to find out if there were sand like better
00:01:36 musical scales and the normal twelve tone twelve interval scale so I wrote a program on my Commodore 64 in basic
00:01:46 let's search through other scale sizes to see if you could find one where they were more accurate you know harmonies
00:01:53 like mid tone like sliding like he won an actual exactly 3 to 2 ratio where else with a 12 interval scale it's not
00:02:02 exactly 3 to 2 for example so that's in the car well tempered as I say you know and basic on a Commodore 64 yeah where
00:02:09 was the interest in music from or is it just I took music all my life so I played the phone and clarinet and piano and
00:02:18 guitar and drums and whatever so how does that threat go through your life where's music today yeah it's not where
00:02:29 I wish it was I for various reasons couldn't really keep it going particularly because I had a lot of
00:02:33 problems with RSI with my fingers and so I had to kind of like cut back anything that used hands and fingers I hope one
00:02:42 day I'll be able to get back to it health-wise so there's a love for music underlying it all yeah what's your
00:02:50 favorite instrument sex the phone sex baritone saxophone well probably bass saxophone but they're awkward well I'm I
00:03:00 always love it when music is coupled with programming there's something about a brain that utilizes those that emerges
00:03:08 with creative ideas so you've used and studied quite a few programming languages can you given an overview of
00:03:15 what you've used one of the pros and cons of each well my favorite programming environment almost certainly
00:03:25 was Microsoft Access back in like the earliest days so that was Visual Basic for applications which is not a good
00:03:31 programming language for the programming environment fantastic it's like the ability to create you know user
00:03:40 interfaces and tie data and actions to them and create reports and all that as I've never seen anything as good there's
00:03:48 things nowadays like air table which you're like small subsets of that which people love for good reason but
00:04:00 unfortunately nobody's ever achieved anything like that what is that if you could pause in there for a second no
00:04:06 access this is it a database database program that Microsoft produced part of office and the kind of wizard you know
00:04:15 but basically it lets you in a totally graphical way create tables and relationships and queries and tie them
00:04:22 to forms and set up you know event handlers and calculations and it was very plate powerful system designed for not
00:04:33 massive scalable things but fair like useful little applications that I loved so what's the connection between excel
00:04:41 and access so very close so access kind of was the relational database equivalent if you like so
00:04:51 people still do a lot of that stuff it should be an access in Excel excels they don't know what Excel is great as well
00:04:59 so but it's just not as rich a programming model as VBA combined with a relational database and so I've always
00:05:08 loved relational databases but today programming on top of a relational database is just a lot more of a
00:05:15 headache you know you generally either need to kind of you know you need something that connects that that runs
00:05:20 some kind of database server unless you use circle light which has its own issues then you can often if you want to get a
00:05:27 nice programming model you'll need to like create and add an ORM on top and then I don't know there's all these
00:05:35 pieces tie together and it's just a lot more awkward than it should be there are people that are trying to make it easier
00:05:41 so in particular I think of if sharp you know Don Syme who him and his team have done a great job of making something
00:05:50 like a database appear in the type system so you actually get like tab completion for fields and tables and
00:05:58 stuff like that anyway so that was kind of anyway so like that whole VBA office thing I guess was a starting point which
00:06:06 I still miss I got into standard Visual Basic that's interesting just to pause on them for a second it's interesting
00:06:12 that you're connecting programming languages to the ease of management of data yeah so in your use of programming
00:06:23 languages you always had a love and a connection with data I've always been interested in doing useful things for
00:06:30 myself and for others which generally means getting some data and doing something with it and putting it out
00:06:37 there again so that's been my interest throughout so I also did a lot of stuff with Apple script back in the early days
00:06:46 so it's kind of nice being able to get the computer and computers to talk to each other and to do things for you and
00:06:55 then I could think that one night the programming language I most loved then would have been Delphi which was object
00:07:05 pascal created by under sales berg who previously did to it by pascal and then went on to create dotnet and then went
00:07:12 on create typescript delphi was amazing because it was like a compiled fast language that was as easy to use as
00:07:21 Visual Basic Delphi what is it similar to in in more modern languages Visual Basic Visual Basic yeah that a compiled
00:07:34 fast version so I'm not sure there's anything quite like it anymore if you took like C
00:07:42 shop or Java and got rid of the virtual machine and replaced it with something you could compile a small type binary I
00:07:50 feel like it's where Swift could get to with the new Swift UI and the cross-platform development going on like
00:07:59 that's one of my dreams is that will hopefully get back to where Delphi was there is actually a free Pascal project
00:08:09 nowadays called Lazarus which is also attempting to kind of recreate Delphi though they're making good progress so
00:08:19 ok Delphi that's one of your favorite programming languages programming environments again I hate Pascal's not a
00:08:27 nice language if you wanted to know specifically about what languages I like they would definitely pick J there's
00:08:33 being an amazingly wonderful language well woods j.j are you aware of APL I am NOT okay so from doing a little research
00:08:46 on work you've done okay so not at all surprising you're not familiar with it cuz it's not well known but it's
00:08:54 actually one of the main families of programming languages going back to the late 50s early 60s so there was a couple
00:09:02 of major directions one was the kind of lambda calculus Alonzo Church direction which I guess kind of listens
00:09:10 game and whatever which has a history going back to the early days of computing the second was the kind of
00:09:19 imperative /o o you know algo Simula going under C C++ so forth there was a third which Accord array oriented
00:09:29 languages which started with a paper by a guy called Ken Iverson which was actually a math theory paper not a
00:09:39 programming paper it was called notation as a tool for thought and it was the development of a new way a new type of
00:09:46 math notation and the idea is that this math notation would be was was much more flexible expressive
00:09:54 and also well-defined then traditional math notation which is none of those things math notation is awful and so he
00:10:01 actually turned that into a programming language and because this was the early 50s although that's very late 50s
00:10:06 although names were available so he called his language a programming language or APL ABL APL is a
00:10:15 implementation of notation as a tool for thought by which he means math notation and Ken and his son went on to do many
00:10:23 things but eventually they actually produced you know a new language that was built on top of all the learnings of
00:10:32 APL that was called J and J is the most expressive composable language of you know beautifully designed language I've
00:10:42 ever seen this didn't have object-oriented components deserve that kind of thing there's not really it's an
00:10:48 array oriented language it's a new it's a it's an it's it's the third half using array array oriented yes so I need to be
00:10:56 a ray warrior so arranged it means that you generally don't use any loops but the whole thing is done with kind of a
00:11:06 extreme version of broadcasting if you're familiar with that none got an umpire slash Python concept so you do a
00:11:15 lot with one line of code it looks a lot like math notation basically I'll compact mm-hm and the idea is that you can kind
00:11:23 of because you can do so much with one line of code a single screen of code is very unlikely to you very rarely need
00:11:30 more than that to in the rest your program and so you can kind of keep it all in your head and you can kind of
00:11:36 clearly communicate it it's interesting that the APL created two main branches k and j j is this kind of like open source
00:11:48 niche community of crazy enthusiasts like me and then the other path k was fascinating it's an astonishingly
00:11:56 expensive programming language which many of the world's most ludicrous a rich hedge funds use so the entire
00:12:07 machine is so small it sits inside level 3 cache on your CPU and and it easily wins every benchmark I've ever seen in
00:12:15 terms of data processing speed hey you don't come across it very much because it's like $100,000 per CPU to to
00:12:23 run it yeah but it's like this this this this path of programming languages it's just so much that are not so much more
00:12:31 powerful in every way than the ones that almost anybody uses every day so though it's all about computation
00:12:38 it's really focused pretty heavily focused on computation I mean so much of programming is data processing by
00:12:46 definition and so there's a lot of things you can do with it but yeah there's not much work being done on
00:12:56 making like use user interface talking us or whatever I mean this some but it's they're not great at the same time
00:13:01 you've done a lot of stuff with Perl and Python yeah so where does that fit into the picture of J and K and APO and well
00:13:11 you know it's much more pragmatic like in the end you kind of have to end up where the where the libraries are you
00:13:19 know like because to me my my focus is on productivity I just want to get stuff done and solve problems so Perl was
00:13:28 great for I created an email company called fast mail and Perl was great cuz back in the late 90s early 2000s it just
00:13:38 had a lot of stuff it could do I still had to write my own monitoring system and my own web framework my own whatever
00:13:45 because like none of that stuff existed but it was the super flexible language to do that in and you used Perl
00:13:54 fast ball used as a back-end think so everything was written in Perl yeah yeah everything everything was fell why do
00:14:02 you think Perl hasn't succeeded or hasn't dominated the market where Python really takes over a lot yeah well I mean
00:14:10 it felt did dominate it was for time everything everywhere but then the guy that Pal Larry will kind of just didn't put
00:14:22 the time in anymore and no project can be successful if there isn't you know it's particularly
00:14:31 one that's data with a strong leader that that loses that strong leadership so then python is kind of replaced - you
00:14:42 know python is a lot less elegant language in nearly every way but it has the data science libraries and a lot of
00:14:54 them are pretty great so I kind of use it because it's the best we have but it's definitely not good enough what do
00:15:03 you think the future programming looks like what do you hope the future programming looks like if we zoom in on
00:15:09 the computational fields on data science on machine learning I hope Swift is successful because the goal is Swift the
00:15:21 way Chris Lattner describes it is to be infinitely hackable and that's what I want I want something where me and the
00:15:27 people I do research with and my students can look at and change everything from top to bottom there's
00:15:34 nothing mysterious and magical and inaccessible unfortunately with Python it's the opposite of that because
00:15:42 pythons so slow it's extremely unhackable you get to a point where it's like okay from here on down at sea so
00:15:47 your debugger doesn't works in the same way your profiler doesn't work in the same way your build system doesn't work
00:15:51 in the same way it's really not very happy ball at all what's the part you would like to be hackable is it for the
00:16:00 objective of optimizing training of neural networks inference in your networks is it performance of the system
00:16:06 or is there some non performance related just it's it's a greater thing I'm in the end I want to be productive as a
00:16:15 practitioner so that means that so like at the moment our understanding of deep learning is incredibly primitive there's
00:16:21 very little we understand most things don't work very well even though it works better than anything else out
00:16:27 there there's so many opportunities to make it so you look at any domain area like I
00:16:35 don't know speech recognition with deep learning or natural language processing classification with deep learning or
00:16:40 whatever every time I look at an area with deep learning I always see like oh it's terrible there's lots and lots of
00:16:48 obviously stupid ways to do things that need to be fixed so then I want to be able to jump in there and quickly
00:16:55 experiment and make them better using the programming language is has a role in a huge role yes so currently Python
00:17:07 has a big gap in terms of our ability to innovate particularly around recurrent neural networks and natural language
00:17:16 processing because it because it's so slow the the actual loop where we actually loop through words we have to
00:17:24 do that whole thing in CUDA C so we actually can't innovate with the kernel the heart of that most important
00:17:33 algorithm and it's just a huge problem and this happens all over the place so we hit you know research limitations
00:17:42 another example convolutional neural networks which actually the most popular architecture for lots of things maybe
00:17:49 most things in declining we almost certainly should be using space convolutional neural networks but only
00:17:56 like two people are because to do it you have to rewrite all of that CUDA sea level stuff and yeah this researchers
00:18:05 and practitioners don't so like there's just big gaps in like what people actually research on what people
00:18:11 actually implement because of the programming language problem so you think you think it's it's just too
00:18:21 difficult to write in CUDA see that a programming like a higher level programming language like Swift should
00:18:30 enable the the easier input fooling around creative stuff with RN ends or was parse convolution your noise kind of
00:18:38 who's a who's at fault who's who's a charge of making it easy for a research - player I mean no one's at fault just
00:18:45 know what he's got around to it yet or it's just it's hard right and I mean part of the fault is that we ignored
00:18:52 that whole APL kind of direction most prominently everybody did for 60 years 50 years but recently people have been
00:19:03 starting to reinvent pieces of that and kind of create some interesting new directions in the compiler technology so
00:19:10 the place where that's particularly happening right now is something called ml ir which is something that ok I'm
00:19:17 Kris lat know this rift guy is leading and because it's actually not gonna be swift on its own that solves his problem
00:19:23 because the problem is they're currently writing a acceptable fast you know GPU program is too complicated regardless of
00:19:37 what language you use no and that's just because if you have to deal with the fact that I've got you know 10,000
00:19:42 threads and I have to synchronize between them all and I have to put my thing in to grid blocks and think about
00:19:48 warps and all this stuff it's just it's just so much boilerplate to do that well you have to be a specialist at that and
00:19:55 it's going to be a year's work to you know optimize that algorithm in that way but with things like tensor
00:20:06 comprehensions and tile and ml ir and t vm there's all these various projects which are all about saying let's let
00:20:12 people create like domain-specific languages for tensor computations these are the kinds of things we do are
00:20:20 generally in on the GPU for deep learning and then have a compiler which can optimize that tensor computation a
00:20:29 lot of this work is actually sitting on top of a project called halide which was is a mind-blowing project where they
00:20:37 came up with such a domain-specific language in fact true one domain-specific language for expressing
00:20:42 this is what my tensor computation is and another domain-specific language for expressing this is the kind of the way I
00:20:51 want you to structure the compilation of that like do it block by block and do these bits in parallel
00:20:56 they were able to show how you can compress the amount of code by 10x compared to optimized GPU code and get
00:21:06 the same performance so that's like so these other things are kind of sitting on top of that kind of research and ml
00:21:13 ir is pulling a lot of those best practices together and now we're starting to see work done on making all
00:21:20 of that directly accessible through Swift so that I could use Swift to kind of write those domain-specific languages
00:21:29 and hopefully we'll get them Swift CUDA kernels written in a very expressive and concise way that looks a bit like J in
00:21:36 APL and then Swift layers on top of that and then a swift UI on top of that and you know it'll be so nice if we can get
00:21:43 to that point that does it all eventually boil down to CUDA and NVIDIA GPUs unfortunately at the moment it does
00:21:52 but one of the nice things about ml ir if AMD ever gets their act together which they probably won't is that they
00:22:01 or others could write MLA our backends for other GPUs or other or other tensor computation devices of which today there
00:22:12 are increasing number are like graph core or vertex AI or whatever so yeah being able to target lots of backends
00:22:24 would be another benefit of this and the market really needs competitions at the moment NVIDIA is massively overcharging
00:22:33 for their kind of enterprise class cards because there is no serious competition because nobody else is doing the
00:22:40 software properly in the cloud there is some competition right but not really other than TP used for heavy use are
00:22:47 almost unprogrammed well at the moment you can't the GPUs has the same problem the case is even worse so TP use the
00:22:54 Google actually made an explicit decision to make them almost entirely unprogrammed ball because they felt that
00:23:00 there was too much IP in there and if they gave people direct access to program them people would learn their
00:23:06 secrets yeah so you can't actually directly program the memory in a teepee you you can't even directly like create code
00:23:17 that runs on and that you look at on the machine that has the GPU it all goes through a virtual machine so all you can
00:23:23 really do is this kind of cookie cutter thing of like plug into high-level stuff together which is just super tedious and
00:23:34 annoying and totally unnecessary so what was the tell me if you could the origin story of fast AI what is the motivation
00:23:46 its mission its dream so I guess the founding story is heavily tied in my previous startup which is a company
00:23:54 called in lytic which was the first company to focus on deep learning for medicine and I created that because I
00:24:03 saw that was a huge opportunity to there's a there's a about a 10x shortage of the number of doctors in the world
00:24:11 and the developing world that we need expected it would take about three hundred years to train enough doctors to
00:24:18 meet that gap but I guess that maybe if we used deep learning for some of the analytics we could maybe make it so you
00:24:26 don't need as highly trained doctors diagnosis diagnosis and treatment planning where's the biggest benefit
00:24:33 just before get the first day I was where's the biggest benefit of AI in medicine DC today and not much not much
00:24:41 happening today in terms of like stuff that's actually out there it's very early but in terms of the opportunity
00:24:49 it's to take markets like India and China and Indonesia which have big populations Africa small numbers of
00:25:01 doctors and provide diagnostic particularly treatment planning and triage kind of on device so that if you
00:25:08 do a you know test for malaria or tuberculosis or whatever you immediately get something that even a health care
00:25:15 worker that's had a month of training can get a very high quality assessment of whether the
00:25:24 patient might be at risk until you know okay we'll send them off to a hospital so for example in Africa outside of
00:25:33 South Africa there's only five pediatric radiologists for the entire continent so most countries don't have any so if your
00:25:39 kid is sick and they need something diagnose your medical imaging the person even if you're able to get medical
00:25:44 imaging done the person that looks at it will be you know a nurse at best yeah but actually in India for example and in
00:25:54 China almost no x-rays are read by anybody by any trained professional because they don't have enough so if
00:26:03 instead we had a algorithm that could take the most likely high-risk 5% and say triage basically say okay somebody
00:26:14 needs to look at this it would massively change the kind of way that what's possible with medicine in the developing
00:26:21 world and remember they have increasingly they have money there the developing world they're not imported
00:26:26 Apella people so they have the money so that they're building the hospitals they're getting the diagnostic equipment
00:26:34 but they just there's no way for a very long time will they be able to have the expertise shortage of their sweeties
00:26:42 okay and that's where the deep learning systems could step in and magnify the expertise they do exactly yeah so you do
00:26:52 see just a longer it a little bit longer yeah the interaction you still see the human expert still at the core of these
00:27:00 systems yeah absolutely there's something in medicine that can be automated almost completely I don't see
00:27:06 the point of even thinking about that because we have such a shortage of people why would we not why would we
00:27:12 want to find a way not to use them like we have people so the idea of like even from an economic point of view if you
00:27:19 can make them 10x more productive getting rid of the person doesn't impact your unit economics at all and it
00:27:26 totally ignores effect that there are things people do better than machines so it's just to me that's not a useful way
00:27:35 of framing the problem I guess just to clarify I guess I meant there may be some problems where you can avoid
00:27:42 even going to the expert ever sort of maybe preventive care or some basic stuff flowing and food allowing the
00:27:49 expert to focus on the things that are that are really that well that's what the triage would do right so the triage
00:27:57 would say okay it's ninety ninety nine percent sure there's nothing here right so you know that can be done on device
00:28:06 and they can just say okay go home so the experts are being used to look at the stuff which has some chance it's
00:28:14 worth looking at which most things is it's not you know it's fine why do you think we haven't quite made progress on
00:28:24 that yet in terms of the the scale of how much AI is applied in the middle there's a lot of reasons I mean one is
00:28:30 it's pretty new I only started and let it can like 2014 and before that like it's hard to express to what degree the
00:28:39 medical world was not aware of the opportunities here so I went to iris na which is the world's largest radiology
00:28:48 conference and I told everybody I could you know like I'm doing this thing this deep learning please come and check it
00:28:56 out and no one had any idea what I was talking about and no one had any interest in it so like we've come from
00:29:06 absolute zero which is hard and then the whole regulatory framework education system everything is just set up to
00:29:13 think of doctoring in a very different way so today there is a small number of people who are deep learning
00:29:22 practitioners and doctors at the same time and that we're starting to see the first ones come out of their PhD
00:29:32 programs so that Kinane over in fostering Cambridge has a number of students now who are data data science
00:29:43 experts deep learning experts and and actual medical doctors quite a few doctors have completed
00:29:50 first day of course now and are publishing papers and creating journal reading groups in the American Council
00:29:59 of radiology and like it's just starting out but it's going to be a long process they regulators have to learn how to
00:30:05 regulate this they have to build you know guidelines and then the lawyers at hospitals have to develop a new way of
00:30:17 understanding that sometimes it makes sense for data to be you know looked at in raw form in large quantities in order
00:30:27 to create world-changing results he has a regulation around data all that it sounds it was probably the hardest
00:30:35 problem but sounds reminiscent of autonomous vehicles as well many of the same regulatory challenges meaning the
00:30:41 same data challenges yeah I mean funnily enough that problem is less their regulation and more the interpretation
00:30:47 of that regulation by by lawyers in hospital so hipper is actually was designed to its it to P and hipper is
00:30:56 not standing does not stand for privacy it stands for portability it's actually meant to be a way that data can be used
00:31:03 and it was created with lots of gray areas because the idea is that would be more practical and would help people to
00:31:10 use this this legislation to actually share data in a more thoughtful way unfortunately it's done the opposite
00:31:16 because when a lawyer sees a gray area they see oh if we don't know we won't get sued then we can't do it today
00:31:26 so hipper is not exactly the problem the problem is more than there's hospital lawyers are not incentive to make bold
00:31:36 decisions about data portability or even to embrace technology that saves lives no they more want to not get in trouble
00:31:45 for embracing the right but also it is also so slaves in a very abstract way which is like oh we've been able to
00:31:50 release these hundred thousand and on most records I can't point at the specific person whose life that's saved
00:31:57 I can say like oh we've ended up with this paper which found this result which you know diagnosed a thousand more people
00:32:04 otherwise but it's like which ones were helped it's it's very abstract and on the counter side of that you may be able
00:32:12 to point to a life that was taken because of something though yeah or or or a person whose privacy was violated
00:32:20 it was like oh this specific person you know there was de-identified so we've identified just a fascinating topic
00:32:28 we're jumping around I'll get back to fast AI but on the question of privacy data is the fuel for so much innovation
00:32:39 in deep learning what's your sense and privacy whether we're talking about Twitter Facebook YouTube just the
00:32:48 technologies like in the medical field that rely on people's data in order to create impact how do we get that right
00:32:59 respecting people's privacy and yet creating technology that just learns from data one of my areas of focus is on
00:33:12 doing more with less data which so most vendors unfortunately are strongly incented to find ways to require more
00:33:21 data and more computation so Google and IBM being the most obvious IBM yeah so Watson you know so Google and IBM both
00:33:32 strongly push the idea that you have to be you know that they have more data and more computation and more intelligent
00:33:38 people than anybody else and so you have to trust them to do things because nobody else can do it and Google's very
00:33:46 upfront about this like Geoff Dana's going out there and given talks and said our goal is to require a thousand times
00:33:55 more computation but less people our goal is to use the people that you have better and the data you have better in
00:34:03 the computation you have better so one of the things that we've discovered is or or at least highlighted is that you
00:34:11 very very very often don't need much data at all and so the data you already have in your organization
00:34:17 we'll be enough to get state-of-the-art results so like my starting point would be this going to say around privacy is a
00:34:25 lot of people are looking for ways to share data and aggregate data but I think often that's unnecessary they
00:34:31 assume that they need more data than they do because they're not familiar with the basics of transfer learning
00:34:38 which is this critical technique for needing orders of magnitude less data is your sense one reason you might want to
00:34:47 collect data from everyone is like in the recommender system context where your individual Jeremy Howard's
00:34:56 individual data is the most useful for freeing for providing a product that's impactful for you so for giving you
00:35:03 advertisements for recommending to your movies for doing medical diagnosis is your sense we can build with a small
00:35:13 amount of data general models they will have a huge impact for most people that we don't need to have data from punching
00:35:21 on the whole I'd say yes I mean they're things like you know recommender systems have this cold-start problem where you
00:35:31 know Jeremy is a new customer we haven't seen him before so we can't recommend him things based on what else he's
00:35:36 bought and liked with us and there's various workarounds to that like in a lot of music programs we'll start out by
00:35:44 saying which of these artists you like which of these albums do you like which of these songs do you like Netflix used
00:35:52 to do that nowadays they they tend not to people kind of don't like that because they think oh we don't want to
00:35:58 bother the user so you could work around that by having some kind of data sharing where you get my marketing record from
00:36:06 axiom or whatever and try to guess from that to me the the benefit to me and to society of saving me five minutes on
00:36:17 answering some questions versus the negative externalities of if the privacy issue doesn't add up so I think like a
00:36:26 lot of the time the places where people are invading our privacy in order to provide convenience is really about just trying
00:36:38 to make them more money and and they move these negative externalities and to places that they don't have to pay for
00:36:46 them so when you actually see regulations appear that actually cause the companies that create these negative
00:36:52 externalities to have to pay for it themselves they say well we can't do it anymore so the cost is actually too high right but
00:37:00 for something like medicine yeah I mean the hospital has my you know medical imaging my pathology studies my medical
00:37:11 records and also I own my medical data so you can so I I helped a startup called doc AI one of the things doc AI
00:37:20 does is that this has an app you can connect to you know Sutter Health's and webcore and Walgreens and download your
00:37:30 medical data to your phone and then upload it again at your discretion to share it as you wish so with that kind
00:37:40 of approach we can share our medical information with the people we want to yes of control I mean it really being
00:37:48 able to control who you share with us on yeah so that that has a beautiful interesting tangent but to return back
00:37:59 to  the origin story of fast they act right so so before I started fast AI I spent a year researching where the
00:38:09 biggest opportunities for deep learning because I knew from my time at Cal in particular that deep learning had kind
00:38:17 of hit this threshold point where it was rapidly becoming the state of the art approach in every areas that looked at
00:38:24 it and I've been working with neural nets for over 20 years I knew that from a theoretical point of view once it hit
00:38:29 that point it would do that in kind of just about every domain and so I kind of spent a year researching what are the
00:38:36 domains it's going to have the biggest low-hanging fruit in the shortest time period medicine but there were so many I could
00:38:44 have picked and so there was a kind of level of frustration for me of like okay I'm really glad we've opened up the
00:38:51 medical deep learning world and today is huge as you know but we can't do you know I can't do everything I don't even
00:39:00 know like it took like in medicine it took me a really long time to even get a sense of like what kind of problems to
00:39:05 medical practitioners solve what kind of data do they have who has that data so I kind of felt like I need to approach
00:39:13 this differently if I want to maximize the positive impact of deep mourning rather than me picking an area and
00:39:20 trying to become good at it and building something I should let people who are already domain experts in those areas
00:39:28 and who already have the data do it themselves mm-hmm so that was the reason for fast AI is to basically try and
00:39:39 figure out how to get deep learning into the hands of people who could benefit from it and help them to do so in as
00:39:45 quick and easy and effective way as possible god it's all sort of empowered the the domain expert yeah and like
00:39:54 partly it's because like unlike most people in this field my background is very applied and
00:40:01 industrial that my first job at MIT was at McKinsey and company I spent 10 years in management consulting I I spend a lot
00:40:10 of time with domain experts you know so I kind of respect them and appreciate them and know I know that's where the
00:40:17 value generation in society is and so I also know how most of them can't code and most of them don't have the time to
00:40:27 invest you know three years and a graduate degree or whatever so it's like how do i skill those two main experts I
00:40:35 think it would be a super powerful thing you know biggest societal impact I could have so that yeah that was the thinking
00:40:44 so so much a fast AI students and researchers and the things you teach are pragmatically minded right practically
00:40:53 minded freaking figuring out ways how to solve real problems and fast right so from your experience what's the difference
00:41:00 between theory and practice of deep learning well most of the research in the deep mining world is a total waste
00:41:10 of time all right that's what I was getting at yeah it's it's a problem in science in general scientists need to be
00:41:20 published which means they need to work on things that their peers are extremely familiar with and can recognize in
00:41:26 advance in that area so that means that they all need to work on the same thing and so it really Inc and and the thing
00:41:33 they work on there's nothing to encourage them to work on things that are practically useful so you get just a
00:41:41 whole lot of research which is minor advances and stuff that's been very highly studied and has no significant
00:41:49 practical impact where else the things that really make a difference like I mentioned transfer learning like if we
00:41:55 can do better at transfer learning then it's this like world-changing thing we're suddenly like lots more people can
00:42:04 do world-class work with less resources and less data and but almost nobody works on that or another example active
00:42:12 learning which is the study of like how do we get more out of the human beings in the loop where's my favorite topic
00:42:18 yeah so active learning is great but it's almost nobody working on it because it's just not a trendy thing right now
00:42:25 you know what somebody's suicide interrupt you're saying that nobody is publishing an active learning but there's people
00:42:34 inside companies anybody who actually has to solve a problem they're going to innovate an active learning yeah
00:42:41 everybody kind of reinvents active learning when they actually have to work in practice because they start labeling
00:42:46 things and they think gosh this is taking a long time and it's very expensive and then they start thinking
00:42:52 well why am i labeling everything I'm only the machines only making mistakes on those two classes they're the hard
00:42:57 ones maybe I ought to start labeling those two classes and then you start thinking well why did I do that manually
00:43:02 why kind of just get the system to tell me which things are going to be hardest it's an obvious thing to do but
00:43:10 yeah it's it's just like like transplant learning it's it's under studied and the academic world just has no reason to
00:43:17 care about practical results the funny thing is like I've only really ever written one paper I hate writing papers
00:43:23 and I didn't even write it it was my colleague sebastian ruder who actually wrote it I just knew did the research
00:43:29 for it but it was basically introducing transfer learning successful transfer learning to NLP for the first time the
00:43:39 algorithm is called GLM fit and it actually I actually wrote it for the course for the first day of course I
00:43:45 wanted to teach people in LP and I thought I only want to teach people practical stuff and I think the only
00:43:50 practical stuff is transfer learning and I couldn't find any examples of transfer learning and NLP so I just did it and I
00:43:57 was shocked to find that as soon as I did it was you know the basic prototype took a couple of days smashed the
00:44:03 state-of-the-art on one of the most important data sets in a field that I knew nothing about and I just thought
00:44:09 well this is ridiculous and so I spoke to the best unit and he kindly offered to write it up the
00:44:19 results and so it ended up being published in a CL which is the top link with a computational linguistics
00:44:26 conference so like people do actually care once you do it but I guess it's difficult for maybe like junior
00:44:34 researchers or like like I don't care whether I get citations or papers whatever I was right there's nothing in
00:44:39 my life that makes that important which is why I've never actually bothered to write a pic of myself now for people who
00:44:46 do I guess they have to pick the kind of safe option which is like yeah make a slight improvement on something that
00:44:55 everybody is already working on yeah nobody does anything interesting or succeeds in life or the safe option
00:45:02 speed I mean the nice thing is nowadays everybody is now working on you know a transfer learning because since that
00:45:09 time we've had GPT and GPT too and Burt and you know it's like it's so yeah once you show that something is possible if
00:45:17 nobody jumps you and I guess I hope to be a part of and I hope to see more innovation and active learning in
00:45:23 the same way I think yeah try learning an active learning are fascinating public open were I actually helped start
00:45:30 a startup called platform AI which is really all about active learning and yeah it's very interesting trying to
00:45:36 kind of see what research is out there and make the most of it and there's basically none so we've had to do all
00:45:42 our own research once again and just as easy described can you tell the story of the stanford competition dawn bench and
00:45:52 fast day eyes achievement on it sure so something which I really enjoy is that I basically teach two courses a year
00:45:59 the practical deep money for coders which is kind of the introductory course and then cutting-edge tech mining for
00:46:05 coders which is the kind of research level course and while I teach those courses I have a I basically have a big
00:46:17 office at the University of San Francisco big enough for like 30 people and I invite anybody any student who
00:46:23 wants to come and hang out with me well I built the course and so generally it's full and so we have twenty or thirty
00:46:31 people in a big office with nothing to do but study deep learning so it was during one of these times that somebody
00:46:38 in the group said oh there's a thing called Don benched it looks interesting and I was like what the hell is that is
00:46:44 it about some competition to see how quickly you can train a model seems kind of not exactly relevant to what we're
00:46:51 doing but it sounds like the kind of thing which you might be interested in I checked it out and I said oh crap
00:46:55 there's only ten days till it's over it's pretty too late and we're kind of busy trying to teach this course yeah
00:47:02 maybe like oh it would make an interesting case study for the course like it's all the stuff where you're
00:47:09 already doing why don't you just put together our current best practices and ideas so me and I guess about four
00:47:17 students just decided to give it a go and we focused on this more one called Sipho ten which is that all 32 by 32
00:47:26 pixels can you say word on benches yeah so it's a competition to train a model as fast as possible I was run by Stanford
00:47:33 as cheap as possible - that's also another one first cheap as possible and there was a couple of categories
00:47:38 imagenet and so far 10 so image nets is big 1.3 million image thing that took a couple of days to train remember a
00:47:48 friend of mine Pete worden who's now at Google I remember he told me how he trained imagenet a few years ago and he
00:47:59 basically like had this little granny flat out the back that he turned into his image net training center and he
00:48:03 figured you know after like a year of work he figured out how to train it and like ten days or something it's like
00:48:09 that was a big job well so far ten at that time you could train in a few hours you know it's much smaller and easier so
00:48:19 we thought would try so far 10 and yeah I've really never done that before like I've never really liked things like
00:48:28 using more than one gpgpu at a time was something I tried to avoid cuz to me it's like very against the whole idea of
00:48:34 accessibility is she better to do things with 1gb here I mean have you asked in the past before after having
00:48:40 accomplished something how do I do this faster much faster Oh always but it's always for me it's always how do I make
00:48:47 it much faster on a single genus you that a normal person could afford in their day-to-day life it's not how could
00:48:54 I do it faster I you know having a huge data center because up to me it's all about like as many people should be to
00:49:00 use something as possible without fussing around with infrastructure so anyway so in this case it's like well we
00:49:09 can use eight GPUs just by renting a AWS machine so we thought we'd try that and yeah basically using the stuff we were
00:49:18 already doing we were able to get you know the speed you know within a few days we had to speed down to I don't
00:49:25 know that's a very small number of minutes I can't remember exactly how many minutes it was but I might have in
00:49:32 like 10 minutes or something and so yeah we found ourselves at the top of the leaderboard easily for both time and
00:49:39 money which really shocked me because the other people competing this were like Google and Intel and stuff we're
00:49:44 like know a lot more about this stuff I think we do so that we were emboldened we thought let's try the imagenet one
00:49:54 two way out of our league but our goal was to get under 12 hours yeah and we did which was really exciting and but we
00:50:00 didn't put anything up on the leaderboard but we were down to like 10 hours but then Google put in some like 5
00:50:10 hours or something about us like oh they're so screwed but we kind of thought we'll keep trying you know if
00:50:18 Google can do it info I mean Google did on five hours on someone like a TPU pod or something like a lot of hardware but
00:50:25 we kind of like had a bunch of ideas to try like a really simple thing was why are we using these big images they're
00:50:36 like 224 256 by 256 pixels you know why don't we try smaller ones and just elaborate there's a constraint on the
00:50:42 accuracy that your training model is supposed to achieve yeah you got to achieve 93% I think it was for imagenet
00:50:50 exactly which is very tough so you have to yeah 93% like they think that they picked a good threshold it was a little
00:50:58 bit higher than what the most commonly used ResNet 50 model could achieve at that time so yeah so it's quite a
00:51:08 difficult problem to solve but yeah we realized if we actually just use 64 by 64 images it trained a pretty good model
00:51:17 and then we could take that same model and just give it a couple of epochs to learn 224 by 224 images and it was
00:51:24 basically already trained it makes a lot of sense like if you teach somebody like here's what a dog looks like and you
00:51:30 show them low res versions and then you say here's a really clear picture of a dog they already know what a dog looks
00:51:39 like so that like just we jumped to the parts of that competition we actually ended up doing a distributed version
00:51:51 over multiple machines a couple of months later and ended up at the top of the leaderboard we had 18 minutes in it
00:51:58 yeah and it was and people have just kept on blasting through again and again since then so so what's your view on
00:52:07 multi-gpu or multiple machine training in general as as a way to speed code up I think it's largely a waste of time
00:52:15 both multi-gpu on a single machine and yeah particularly multi machines because it's just clunky motogp use is less
00:52:25 clunky than it used to be but to me anything that slows down your iteration speed is a waste of time so you could
00:52:35 maybe do your very last you know perfecting of the model on Motty GPUs if you need to that so for example I think
00:52:45 doing stuff on imagenet is generally a waste of time why test things on 1.3 million images most of us don't use 1.3
00:52:51 million images and we've also done research that shows that doing things on a smaller subset of images gives you the
00:52:59 same relative answers anyway so from a research point of view why waste that time so actually I released a couple of
00:53:04 new data sets recently one is called imaginet the French image net which is a small subset
00:53:13 of image net which is designed to be easy to classify I would highly spell imaginer it's got an extra T and e at
00:53:20 the end because it's very French am i okay yeah I'm okay and then another one called image Wharf which is a subset of
00:53:28 the image net that only contains dog breeds that's a hard one right that's a hard one yeah and I've discovered that if you
00:53:35 just look at these two subsets you can train things on a single GPU in ten minutes and the results you get directly
00:53:43 transferable to imagenet nearly all the time and so now I'm starting to see some researchers start to use these holidays
00:53:50 that's so deeply love the way you think because I think you might have written a blog post saying that sort of going
00:54:01 these big data sets is encouraging people to not think creatively absolutely so you're - it's sort of
00:54:09 constrained you to Train on large resources and because you have these resources you think more research will
00:54:15 be bit better and then you start like for some somehow you kill the creativity yeah and even worse than that Lex I keep
00:54:21 hearing from people who say I decided not to get into deep learning because I don't believe it's accessible to people
00:54:28 outside of Google to do useful work so like I see a lot of people make an explicit decision to not learn this
00:54:36 incredibly valuable tool because they've they've drunk the Google kool-aid which is that only Google's big enough and
00:54:42 smart enough to do it and I just find that so disappointing and it's so wrong and I think all the major breakthroughs
00:54:51 in AI in the next twenty years will be doable on a single GPU like I would say my sense is all the big
00:54:58 sort of well let's put it this way none of the big breakthroughs of the last 20 years or acquired multiple GPUs
00:55:05 so like fetch norm well you drop out did you demonstrate to everyone of them yeah this is five multiple GPUs against
00:55:14 the original Gans didn't require multiple ups well and and we've actually recently shown that you don't even need
00:55:22 gains so we've developed gained level outcomes without knitting Gans and we can now do it with again by using
00:55:28 transfer learning we can do it in a couple of hours on a single generator might like without the other serial port yeah
00:55:36 so we've found loss functions that work super well without the adversarial part and then one of our students guy called
00:55:42 Jason antic has created Cordiale defi which uses this technique to colorize old black-and-white movies
00:55:50 you can do it on a single GPU color as a whole movie in a couple of hours and one of the things that Jason and I did
00:55:58 together was we figured out how to add a little bit of n at the very end which it turns out for colorization makes it just
00:56:06 a bit brighter and nicer and then Jason did masses of experiments to figure out exactly how much to do but it's still
00:56:13 all done on his home machine on a single GPU in his lounge room and like if you think about like colorizing Hollywood
00:56:20 movies that sounds like something a huge studio it would have to do but he has the world's best results on this there's
00:56:27 this problem of microphones we're just talking two microphones now yeah it's such a pain in the ass to have these
00:56:33 microphones to get good quality audio and I tried to see if it's possible to plop down a bunch of cheap sensors and
00:56:40 reconstruct higher quality audio from multiple sources because right now I haven't seen work from okay we can say
00:56:48 inexpensive mics automatically combining audio from multiple sources to improve the combined audio right people haven't
00:56:54 done that and that feels like a learning problem alright so hopefully somebody can well I mean it's it's eminently
00:57:00 doable and it should have been done by now I feel I felt the same way about computational photography four years ago
00:57:04 that's right why are we investing in big lenses when three cheap lenses plus actually a
00:57:13 little bit of intentional movement so like Holden you don't like take a few frames gives you enough information to
00:57:20 get excellent sub pixel resolution which particularly with deep learning you would know exactly what you meant to
00:57:27 be looking at we can totally do the same thing with audio I think there's a madness that it hasn't been done yet I
00:57:32 live in progress on the photographer tog Rafik yeah the dog photography is basically standard now so the the Google
00:57:41 picks all night light I don't know if you've ever tried it but it's it's astonishing you take a picture in almost
00:57:47 pitch black and you get back a very high quality image and it's not because of the lens same stuff is like adding the
00:57:54 bouquet to the you know the background wearing have done computationally this depicts over here
00:58:02 yeah basically the everybody now is doing most of the fanciest stuff on their phones with computational
00:58:08 photography and also increasingly people are putting more than one lens on the back of the camera so the same will
00:58:14 happen for audio for sure and there's applications in the audio side if you look at an Alexa type device most people
00:58:21 have seen especially I worked at Google before when you look at noise background removal you don't think of multiple
00:58:30 sources of audio you don't play with that as much as I would hope people I mean you can still do it even with one
00:58:35 like again it's not not much works being done in this area so we're actually going to be releasing an audio library
00:58:40 soon which hopefully will encourage development of this because it's so underused the basic approach we used for
00:58:47 our super resolution in which Jason uses video defy of generating high quality images the exact same approach would
00:58:54 work for audio no-one's done it yet but it would be a couple of months work okay are also learning rate in terms of Don
00:59:03 bench there's some magic on learning rate that you played around with yeah interesting yeah so this is all work
00:59:08 that came from a guy called Leslie Smith Leslie's a researcher who like us cares a lot about just the practicalities of
00:59:18 training neural networks quickly and accurately which i think is what everybody should care about but almost
00:59:27 nobody does and he discovered something very interesting which he calls super convergence which is there are certain
00:59:32 networks that with certain settings of high parameters could suddenly be trained ten times faster by using a ten
00:59:41 times higher learning rate now no one published that paper because it's not an area of kind of active research in the
00:59:51 academic world no academics recognized this is important and also deep learning in academia is not considered a
01:00:00 experimental science so unlike in physics where you could say like I just saw as a subatomic particle do something
01:00:07 which the theory doesn't explain you could publish that without an explanation and then in the
01:00:12 next 60 years people can try to work out how to explain it we don't allow this in the deep learning
01:00:18 world so it's it's literally impossible for Leslie to publish a paper that says I've just seen something amazing happen
01:00:25 this thing trained ten times faster than it should have I don't know why and so the reviewers were like we can't
01:00:29 publish that because you don't know why so anyway that's important to pause on because there's so many discoveries that
01:00:36 would need to start like that every every other scientific field I know of works is that way I don't know why ours
01:00:45 is uniquely disinterested in publishing unexplained experimental results but there it is so it wasn't published
01:00:55 having said that I read a lot more unpublished papers and published papers because that's where you find the
01:01:00 interesting insights so I absolutely read this paper and I was just like this is astonishingly mind-blowing and weird
01:01:11 and awesome and like why isn't everybody only talking about this because like if you can train these things ten times
01:01:16 faster they also generalized better because you're you're doing less epochs which means you look at the data less
01:01:22 you get better accuracy so I've been kind of studying that ever since and eventually Leslie kind of figured out a
01:01:31 lot of how to get it's done and we added minor tweaks and a big part of the trick is starting at a very low learning rate
01:01:38 very gradually increasing it so as you're training your model you would take very small steps at the start and
01:01:43 it gradually makes them bigger and bigger and tall eventually you're taking much bigger steps than anybody thought
01:01:49 as possible a few other little tricks to make it work but ever ever basically we can
01:01:55 reliably get super convergence and so for the dawn bench thing we were using just much higher learning rates than
01:02:02 people expected to work what do you think the future of I mean makes so much sense for that to be a critical hyper
01:02:08 parameter learning rate that you very what do you think the future of learning rate magic looks like well there's been
01:02:15 a lot of great work in the last 12 months in this area it's and people are increasingly realizing that up to might
01:02:21 like we just have no idea really how optimizers work and the combination of weight decay which is how we regularize
01:02:28 optimizers and the learning rate and then other things like the epsilon we use in in the atom optimizer they all
01:02:36 work together in weird ways and different parts of the model this is another thing we've done a lot of work
01:02:42 on is research into how different parts of the model should be trained at different rates in different ways so we
01:02:48 do something we call discriminative learning rates which is really important particularly for transfer learning so
01:02:54 really I think in the last 12 months a lot of people have realized that this all this stuff is important there's been
01:03:00 a lot of great work coming out and we're starting to see algorithms here which have very very few dials if any that you
01:03:08 have to touch selector I think what's going to happen is the idea of a learning rate well it almost already has
01:03:14 disappeared in the latest research and instead it's just like you know we we know enough about how to interpret the
01:03:23 gradients and the change of gradients we see to know how to set every parameter you can await it so you see the future
01:03:32 of of deep learning where really where's the input of a human expert needed well hopefully the input of the human expert
01:03:38 will be almost entirely unneeded from the deep learning point of view so again like Google's approach to this is to try
01:03:45 and use thousands of times more compute to run lots and lots of models at the same time and hopefully one of them is
01:03:52 good at or male CONUS yeah I don't know kind of stuff which i think is insane when you better understand the mechanics
01:04:02 of how models learn you don't have to try thousand different models to find which one happens to work the best you can
01:04:08 just jump straight to the best one which means that it's more accessible in terms of compute cheaper and also with less
01:04:15 hyper parameters to set it means you don't need deep learning experts to train your deep learning model for you
01:04:21 which means that domain experts can do more of the work which means that now you can focus the human time on the kind
01:04:27 of interpretation data gathering identifying what all errors and stuff like that yeah the data side how often
01:04:34 do you work with data these days in terms of the cleaning looking at like Darwin looked at different species while
01:04:44 traveling about do you look at data I have you in your roots and cargo always yeah good data I mean it's a key part of
01:04:52 our course it's like before we train a model in the course we see how to look at the data and then after the first
01:04:57 thing we do after we train our first model which we fine-tune an image net model for five minutes and then the
01:05:02 thing we immediately do after that is we learn how to analyze the results of the model by looking at examples of
01:05:09 misclassified images and looking at a classification matrix and then doing like research on Google to learn about
01:05:16 the kinds of things that it's misclassifying so to me one of the three cool things about machine learning
01:05:22 models in general is that you can interpret when you interpret them they tell you about things like what are the
01:05:28 most important features which groups you misclassifying and they help you become a domain expert more quickly because you
01:05:35 can focus your time on the bits that the model is telling you it is important so it lets you deal with things like data
01:05:41 leakage for example if it says all the main feature I'm looking at is customer ID you know and you're like oh customer
01:05:48 ID should be predictive and then you can talk to the people that manage customer IDs and they'll tell you like oh yes as
01:05:56 soon as a customer's application is accepted we add a one on the end of their customer arm or something you know
01:06:03 yeah so yeah model looking at data particularly from the lens of which parts of the date of the model says is
01:06:09 important is super important yeah and using kind of using the model to almost debug the data yeah you have learn more
01:06:16 about exactly what are the different cloud options for training y'all networks it's the last
01:06:22 question related to dawn bench well it's part of a lot of the work we do but from a perspective of performance I think
01:06:29 you've written this in a blog post there's AWS there's TPU from Google what's your sense what the future holds
01:06:36 what would you recommend now right there was a so from a halfway point of view Google's TP use and the best nvidia gpus
01:06:46 are similar I mean maybe the TP is like 30% faster but they're also much harder to program with there isn't a clear
01:06:54 leader in terms of hardware right now although much more importantly the GPU nvidia gpus a much more programmable
01:07:00 they've got much more written for all them so like that's the clear leader for me and where I would spend my time as a
01:07:08 researcher and practitioner millington to the platform I mean we're super lucky now with stuff
01:07:18 like Google TCP Google Cloud and AWS that you can access a GPU pretty quickly and easily but I mean for AWS it's still
01:07:31 too hard like you have to find an ami and get the instance running and then install the software you want blah blah
01:07:39 blah GCP is still is currently the the best way to get started on if the server environment because they have a
01:07:46 fantastic fast AI in pi torch ready to go instance which has all the courses pre-installed it has Jupiter notebook
01:07:54 pre running Jupiter notebook is this wonderful interactive computing system which everybody basically should be
01:08:01 using for any kind of data-driven research but then even better than there are there are platforms like salamander
01:08:11 which we own and paper space where literally you click a single button and it pops up a Jupiter notebook straight
01:08:21 away without any kind of installation or anything and all the course notebooks are all pre-installed so like for me we
01:08:28 this is one of the things we spent a lot of time kind of curating and working on because when we first started
01:08:37 our courses the biggest problem was people dropped out of lesson one because they couldn't get an AWS instance
01:08:44 running so things are so much better now and like we actually have if you got a cost up faster day I the first thing it
01:08:49 says is here's how to get started with your GPU and there's like you just click on a link and you click start and and
01:08:56 it's going it will you a go GCP I have to confess I've never used the Google DCP yeah JCP gives you three hundred
01:09:01 dollars of compute for free which is really nice that as I say a salamander and paper spacer even even easier still
01:09:14 okay so the from the perspective of deep learning frameworks you work with fast AI to go to this framework and PI torch
01:09:23 intensive flow what are the strengths of each platform your perspective so in terms of what we've done our research on
01:09:30 and taught in our course we started with Theano and care us and then we switch to tensor flow and care us and then we
01:09:40 switch to PI torch and then we switched to PI torch and fast AI and that that kind of reflects a growth and
01:09:49 development of the ecosystem of dig learning libraries siano intensive flow were great but we're much harder to
01:10:01 teach and do research and development on because they define what's called a computational graph upfront less data
01:10:07 graph well you basically have to say here are all the things that I'm going to eventually do in my model and then
01:10:14 later on you say okay do those things with this data and you can't like debug them you can't do them step-by-step you
01:10:20 can't program them interactively in a Jupiter notebook and so forth pi torch was not the first four pi torch
01:10:26 was certainly the the strongest entrant to come along and say let's not do it that way let's just use normal Python
01:10:32 and everything you know about in Python is just going to work and we'll figure out how to make that run on the GPU as
01:10:41 in when and necessary that turned out to be a huge a huge leap in terms of what we could do with our research and what
01:10:48 we could weigh with our teaching and because it was a limiting yeah I mean it was critical for us for something like
01:10:55 dawn Bench to be able to rapidly try things it's just so much harder to be a researcher and practitioner when you
01:11:00 have to do everything up front and you can inspect it problem with pay torch is it's not at all accessible to newcomers
01:11:10 because you have to like write your own training loop and manage the gradients and all their stuff and it's also like
01:11:18 not great for researchers because you're spending your time dealing with all this boilerplate and overhead rather than
01:11:24 thinking about your algorithm so we ended up writing this very multi-layered API that at the top level you can train
01:11:31 a state-of-the-art neural network in three lines of code and which kind of talks to an API which talks to an API
01:11:37 which talks from API which like you can deep dive into at any level and get progressively closer to the Machine kind
01:11:45 of levels of control and this is the first AI library that's been critical for us and for our students and for lots
01:11:54 of people that have one big learning competitions with it and written academic papers with it it's made a big
01:12:01 difference we're still limited though by Python and particularly this problem with things like recurrent neural nets a
01:12:10 where you just can't change things unless you accept it going so slowly that it's impractical so in the latest
01:12:18 incarnation of the course and with some of the research risked out now starting to do we're starting to do stuff some
01:12:23 stuff in Swift I think we're three years away from that being super practical but I'm in no
01:12:32 hurry I'm very happy to invest the time to get there but you know with with that we actually already have a nascent
01:12:40 version of the first AI library for vision running on special knowledge and so flow
01:12:46 because a Python for tensorflow is not going to cut it it's just a disaster what they did was they tried to
01:12:55 replicate the bits that people were saying they like about a torch the is kind of interactive computation but they
01:13:01 didn't actually change their foundational runtime components so they kind of added this like syntax sugar
01:13:08 they call TF eager tend to flow again which makes it look a lot like pay torch but it's 10 times slower than pi torch
01:13:17 to actually do a step so because they didn't invest the time and like retooling the foundations cuz their code
01:13:23 base is so horribly copy yeah I think it's probably very difficult to do that kind of rejoin yeah well particularly
01:13:28 the way tensorflow was written it was written by a lot of people very quickly in a very disorganized way so like when
01:13:35 you actually look in the code as I do it often I'm always just like oh god what were they thinking it's just it's pretty
01:13:45 awful so I'm really extremely negative about the potential future if it by the flaws of the fet swift for tensorflow
01:13:53 can be a different beast altogether it can be like it can basically be a layer on top of M lar that takes advantage of
01:14:02 you know all the great compiler stuff that Swift builds on with LLVM and yeah it could be a thing kit will be
01:14:10 absolutely fantastic well you're inspiring me to try evan Roo truly felt the pain of tensorflow 2.0 python it's
01:14:21 fine by me but yeah but it does the job if you're using like predefined things that somebody's already written but if
01:14:29 you actually compare you know like I've had to do because I've been having to do a lot of stuff with tensorflow recently
01:14:35 you actually compare like okay I want to write something from scratch yeah like I just kick fighting is like oh it's
01:14:41 running ten times slower than pi torch so is the biggest cost let's throw running time out the window how long it
01:14:50 takes you to program that's not too different now thanks to transfer flow eager that's not too different but
01:14:57 because because so many things take so long to run yeah you wouldn't run it at ten times slower like you just go like oh
01:15:02 this is taking so long yeah and also there's a lot of things which are just less programmable like TF
01:15:08 data which is the way they do processing works intensive flow is just this big mess it's incredibly inefficient and
01:15:14 they kind of had to write it that way because of the TPU problems I described earlier so I just you know I just feel
01:15:24 like they've got this huge technical debt which they're not gonna solve without starting from scratch so here's
01:15:30 an interesting question then if there's a new student starting today what would you recommend they use well I mean we
01:15:40 obviously recommend fast AI and pi torch because we teach new students and that's what we teach with so we would very
01:15:47 strongly recommend that because it will let you get on top of the concepts much more quickly so then you'll become an
01:15:54 extra and you'll also learn the actual state-of-the-art techniques you know so you actually get world-class results
01:16:02 honestly it doesn't much matter what library you learn because switching from China to MX net to tensorflow to PI
01:16:11 torch is going to be a couple of days work as few long as you understand the foundation as well but you think we'll
01:16:21 Swift creep in there as a thing that people start using not for a few years particularly because like Swift has no
01:16:31 data science community libraries Oh basil wing and the Swift community has a a total lack of appreciation and
01:16:41 understanding of numeric computing so like they keep on making stupid decisions you know for years they've
01:16:47 just done dumb things around performance and prioritization that's clearly changing now because the
01:16:56 developer of Chris Christie at developer of Swift Chris Latner is working at Google on the Swift Potenza flows so
01:17:04 like that's that's a priority it'll be interesting to see what happens with Apple because like Apple hasn't shown
01:17:11 any sign of caring about numeric programming in Swift so I mean hopefully they'll get off their ass and
01:17:18 start appreciating this because currently all of their low-level libraries are not written in Swift
01:17:27 they're not particularly swifty at all stuff like ml they're really pretty rubbish so yeah so there's a long
01:17:34 way to go but at least one nice thing is that Swift for tensorflow can actually directly use Python code
01:17:41 and Python libraries you know literally the entire lesson one notebook a fast AI runs in Swift right now in Python mode
01:17:50 so that's that's a nice intermediate thing how long does it take the look at the two two facile courses how long does
01:18:00 it take to get from point zero to completing both courses it varies a lot somewhere between two months and two
01:18:12 years generally so for two months how many hours a day so I sound like a somebody who is a very
01:18:25 competent coder can can do 70 hours per course and seventy seven zero yeah that's it okay but a lot of people I
01:18:36 know take a year off to study first day I full-time and say at the end of the year they feel pretty competent because
01:18:45 generally there's a lot of other things you do like they're generally they'll be entering cowgirl competitions they you
01:18:51 might be reading in Goodfellows books they might you know they'll be doing a bunch of stuff and often you know
01:18:57 particularly if they are domain expert they're coding skills might be a little on the pedestrian side so part of it's
01:19:04 just like doing a lot more writing what do you find is the bottleneck for people usually except getting started and
01:19:13 setting stuff up I would say coding just yeah I would say the best the people who are strong coders pick it up the best
01:19:20 although another bottleneck is people who have a lot of experience of classic statistics can really struggle because
01:19:30 it the intuition is so the opposite of what they used to they're very used to like trying to reduce the number of
01:19:36 parameters in their model and looking at individual coefficients and stuff like that so I find people who have a lot of
01:19:43 coding background and know nothing about statistics are generally going to be the best off so you taught several course on
01:19:52 deep learning and as Fineman says the best way to understand something is to teach it what have you learned about
01:19:59 deep learning from teaching it a lot it's a key reason for me to to teach the courses I mean obviously it's going to
01:20:05 be necessary to achieve our goal of getting two main experts to be familiar with deep learning but it was also
01:20:12 necessary for me to achieve my goal of being really familiar with deep learning I I mean to see so many domain experts
01:20:25 from so many different backgrounds it's definitely I wouldn't say taught me but convinced me something that I like to
01:20:33 believe was true which was anyone can do it so there's a lot of kind of snobbishness out there about only
01:20:40 certain people can learn to code only certain people are going to be smart enough to like do AI that's definitely
01:20:46 you know I've seen so many people from so many different backgrounds get state-of-the-art results
01:20:53 in their domain areas now the it's definitely taught me that the key differentiator between people that
01:21:00 succeed and people that fail is tenacity that seems to be basically the only thing that matters the people a lot of
01:21:10 people give up and but if the ones who don't give up pretty much everybody succeeds you know even if at first I'm
01:21:17 just kind of like thinking like wow they're really not quite getting it yet are they but eventually people get it
01:21:25 and they succeed so I think that's been any they're both things I'd like to believe was true but I don't feel like I
01:21:31 really had strong evidence with them to be true but now I can say I've seen it again and again so what advice do you
01:21:40 have for someone who wants to get started in deep learning train lots of models that's that's how you that's how
01:21:48 you learn it so like so I would you know I think it's not just me I think I think our course is very good but also lots of
01:21:55 people independently I said it's very good it recently won the cog X award for AI courses as being the best in the
01:22:01 world let's say come to our course cost up faster day I and the thing I keep on hopping on in my lessons is train models
01:22:09 print out the inputs to the models print out to the outputs to the models like study you know change change the inputs
01:22:17 of it look at how the outputs very just run lots of experiments to get a you know an intuitive understanding of
01:22:26 what's going on to get hooked do think you mentioned training do you think just running the models inference
01:22:35 like if we talk about getting started no you've got to find cheering the models so that's that's that's the critical
01:22:40 thing because at that point you now have model that's in your domain area so there's there's there's no point running
01:22:47 somebody else's model because it's not your model like so it only takes five minutes to fine-tune a model for the
01:22:52 data you care about and in lesson two of the course we teach you how to create your own data set from scratch by
01:22:58 scripting Google Image Search yeah so and we show you how to actually create a web application running online so I
01:23:04 create one in the course that differentiates between a teddy bear or grizzly bear and a brown bear and it
01:23:09 does it with basically a hundred percent accuracy took me about four minutes to scrape the images from Google search in
01:23:17 the script there's a little graphical widgets we have in the notebook that help you clean up the data set there's
01:23:23 other widgets that help you study the results to see where the errors are happening and so now we've had got over
01:23:30 a thousand replies in our share your work here thread of students saying here's the thing I built and so those
01:23:36 people who like and a lot of them are state of the art like somebody said oh I tried looking at Devon Gehry characters
01:23:41 and I couldn't believe it the thing that came out was more accurate than the best academic paper after lesson one and then
01:23:48 there's others which are just more kind of fun like somebody who's doing Trinidad and Tobago hummingbirds she
01:23:54 said that's kind of their national bird and she's got something that can now classify Trinidad and Tobago
01:24:00 hummingbirds so yeah train models fine-tune models with your data set and then study their inputs and outputs
01:24:08 how much is fast there of course is free everything we do is free we have no revenue sources of any kind it's just a
01:24:16 service to the community you're a saint okay once the person understands the basics trains a bunch of models if we
01:24:26 look at the scale of years what advice do you have for someone wanting to eventually become an expert train lots
01:24:34 of models train lots of models in your domain area so an expert what right we don't need more expert like
01:24:45 create slightly evolutionary research an area that everybody's studying we need experts at using deep learning to
01:24:53 diagnose malaria well we need experts at using deep learning to analyze language to study media bias so we need experts
01:25:09 in analyzing fisheries to identify problem areas and you know the ocean you know that that's that's what we need so
01:25:16 like become the expert in your passion area and this is a tool which you can use just about anything and you'll be
01:25:23 able to do that thing better than other people particularly by combining it with your passion and domain expertise so
01:25:29 that's really interesting even if you do want to innovate on transfer learning or active learning your thought is that
01:25:36 means one I certainly share is you also need to find a domain or dataset that you actually really care for right if
01:25:43 you're not working on a real problem that you understand how do you know if you're doing it any good you know how do
01:25:49 you know if your results so good how do you know if you're getting bad results why you're getting bad results is it a
01:25:54 problem with the data or is like how do you know you're doing anything useful yeah the only to me the only really
01:26:01 interesting research is not the only but the vast majority of interesting research is like try and solve an actual
01:26:07 problem and solve it really well so both understanding sufficient tools and the deep learning side and becoming a domain
01:26:15 expert in a particular domain I really thinks will then reach for anybody yeah I mean to me I would compare it to like
01:26:24 studying self-driving cars having never looked at a car or being in a car or turn the car on right you know which is
01:26:30 like the way it is for a lot of people they'll study some academic data set where they literally have no idea about
01:26:37 the other way I'm not sure how familiar with the thomas vehicles but that is literally you describe a large
01:26:43 percentage of robotics folks working in a self-driving cars as they actually haven't considered driving they haven't
01:26:50 actually looked at what driving looks right they haven't driven it goes and enterprise because you know when you've
01:26:54 actually driven you know like these are the things that happened to me and I was driving it so
01:26:58 there's nothing that beats the real-world examples are just experiencing them you've created many
01:27:05 successful startups what does it take to create a successful startup same thing is becoming successful deep learning
01:27:16 practitioner which is not getting up so right out of money or time or run out of something you know
01:27:28 but if you keep costs super low and try and save up some money beforehand so you can afford to have some time then just
01:27:37 sticking with it it's one important thing doing something you understand and care about is important that by
01:27:45 something I don't mean the biggest problem I see with deep whining people is they do a PhD in deep learning and
01:27:51 then they try and commercialize their PhD it is a waste of time because that doesn't solve an actual problem you
01:27:58 picked your PhD topic because it was an interesting kind of engineering or math or research exercise but yeah if you've
01:28:06 actually spent time as a recruiter and you know that most of your time was spent sifting through resumes and you
01:28:12 know that most of the time you're just looking for certain kinds of things and you can try doing that with a model for
01:28:20 a few minutes and see whether that something which your models be able to do as well as you could then you're on
01:28:26 the right track to creating a startup and then I think just yeah being just be train state
01:28:37 to capital money as long as possible preferably forever so yeah on that point do you venture capital so did you were
01:28:47 able to successfully run startups with was self-funded yeah my first two was self-funded and that was the right way
01:28:52 to do it that's scary no species startups are much more scary because you have these
01:29:01 people on your back who do this all the time and who have done it for years telling you grow grow grow grow and I
01:29:07 don't they don't care if you fail they only care if you don't grow fast enough so that's scary
01:29:13 where else doing the ones myself well with with partners who were friends is nice because like we just went along at
01:29:22 a pace that made sense and we were able to build it to something which was big enough that we never had to work again
01:29:29 but was not big enough that any VC would think it was impressive and that was enough for us to be excited you know so
01:29:38 I I thought that's a much better way to do things and most people in generally speaking that for yourself but how do
01:29:44 you make money during that process do you cut into savings if I guess so yeah so fir
01:29:50 so I started fast mail and optimal decisions at the same time in 1999 with two different friends and for fast mail
01:30:01 I guess I spent $70 a month on the server and when the server ran out of space I put a payments button on the
01:30:10 front page and said if you want more than 10 makerspace you have to pay $10 a yeah and so run low like keep your cost
01:30:20 down yes I came across town and once you know once once I needed to spend more money I asked people to spend the money
01:30:28 for me and that that was that basically from then on oh we were making money and I was profitable from then for optimal
01:30:38 decisions it was a bit harder because we were trying to sell something that was more like a 1 million dollar sale but
01:30:45 what we did was we would sell scoping projects so kind of like prototype he projects but rather than to be free we
01:30:54 would sell them 50 to $100,000 so again we were covering our costs and also making the client feel like we were
01:31:00 doing something valuable so in both cases we were profitable from six months in yeah nevertheless is scary I mean
01:31:12 yeah sure it's it's Gary before you jump in and I just I guess I was comparing it to this scariness of VC I felt like with
01:31:21 VC stuff it was more scary you kind of much more in somebody else's hands you know will they fund you or not and what
01:31:27 do they think of what you're doing I also found it very difficult with VC's bet startups to actually do the thing
01:31:34 which I thought was important for the company rather than doing the thing which I thought would make the VC happy
01:31:40 now VCS always tell you not to do the thing that makes them happy but then if you don't do the thing that makes them
01:31:46 happy they get set so and do you think optimizing for the whatever they call it they exit is 
01:31:53 as a good thing to optimize for I think I can be but not at the VC level because the VC exit needs to be you know a
01:32:02 thousand x so where else the lifestyle exit if you can sell something for ten million dollars I think you've made it
01:32:09 right so I don't it depends if you want to build something that's gonna you kind of happy to do forever
01:32:14 then fine if you want to build something you want to sell then three is time that's fine too I mean they're both
01:32:22 perfectly good outcomes so you're learning Swift now in a way I mean you were a writer and I read that you use at
01:32:32 least in some cases spaced repetition as a mechanism for learning new things yeah I used Anki quite a lot yourself sure I
01:32:40 actually don't never talk to anybody about it don't don't know how many people do it but it works incredibly
01:32:47 well for me can you talk to your experience like how did you what what do you like first of all okay let's back it
01:32:55 up what is space repetition so spaced repetition is an idea created by a psychologist named Epping house must be
01:33:06 a couple hundred years ago or something hundred and fifty years ago he did something which sounds pretty damn
01:33:13 tedious he wrote down random sequences of letters on cards and tested how well he would remember those random sequences
01:33:23 a day later or a week later whatever he discovered that there was this kind of a curve where his probability of
01:33:29 remembering one of them would be dramatically smaller the next day and then a little bit smaller the next day a
01:33:33 little bit smaller next day what he discovered is that if he revised those cards after a day the probabilities
01:33:42 would decrease at a smaller rate and then if he revised them again a week later they would decrease it a smaller
01:33:48 rate again and so he basically figured out a roughly optimal equation for when you should revise something you want to
01:33:57 remember so spaced repetition learning is using this simple algorithm just something like revise something after a
01:34:04 day and then three days and then a week and then three weeks and so forth and so if you use a program like Anki as
01:34:11 you know it will just do that for you and if you and it will say did you remember this and if you say no it will
01:34:18 reschedule it back to be up here again like ten times faster than it otherwise would have it's a kind of a way of being
01:34:27 guaranteed to learn something because by definition if you're not learning it it will be rescheduled to be
01:34:34 revised more quickly unfortunately though it's also like it doesn't let you for yourself if you not learning
01:34:41 something you you know like it your revisions will just get more and more so you have to find ways to learn things
01:34:49 productively and effectively like treat your brain well so using like mnemonics and stories and context and stuff like
01:34:59 that so yeah it's it's a super great technique is like learning how to loan is something which everybody should
01:35:04 learn before they actually learn anything but almost nobody does what have you so certainly works well for
01:35:13 learning new languages for I mean for learned like small projects almost but do you you know I started using it for
01:35:21 if you had who wrote a blog post about this inspired me I went Ben you I'm not sure is I started
01:35:30 when I read papers all all concepts and ideas I'll put them was it Michael Nelson in my Illinois muscle strains
01:35:36 that Michael started doing this recently and he's been writing about it I so the kind of today's evening house is a guy
01:35:45 called Peter was niak who developed a system called super memo and he's been basically trying to become like the
01:35:54 world's greatest Renaissance man over the last few decades he's basically lived his life with spaced repeated
01:36:04 repetition learning for everything I and sort of like Michaels only very recently got into this but he started really
01:36:09 getting excited about doing it for a lot of different things for me personally I actually don't use it for anything
01:36:18 except Chinese and the reason for that is that Chinese is specifically a thing I made a conscious decision that I want
01:36:28 to continue to remember even if I don't get much of a chance to exercise it because like I'm not often in China so I
01:36:35 I don't or else something like programming languages or papers I have a very different approach which is I try
01:36:41 not to learn anything from them but instead I try to identify the important concepts
01:36:49 and like actually ingest them so like really understand that concept deeply and study it carefully I will decide if
01:36:57 it really is important if it is like incorporated into our library you know incorporated into how I do things
01:37:08 or decide it's not worth it say so I find I find I didn't remember the things that I care about because I'm using it
01:37:18 all the time so I've fell at last 25 years I've committed to spending at least half of everyday learning or
01:37:27 practicing something new which is all my colleagues have always hated because it always looks like I'm not working I mean
01:37:32 if what I meant to be working on but it always means I do everything faster because I've been practicing a lot of
01:37:38 stuff so I kind of give myself a lot of opportunity to practice new things and so I find now I don't
01:37:47 yeah I don't often kind of find myself wishing I could remember something because if it's something that's useful
01:37:53 then I've been using it a lot that's easy enough to look it up on google fit speaking Chinese you can't look it up on
01:38:00 Google so do you have advice for people learning new things so if you what have you learned is a process does it I mean
01:38:07 it all starts is just making the hours in the day available yeah you gotta stick with it which is again the number
01:38:13 one thing that 99% of people don't do so the people I started learning Chinese with none of them were still doing it
01:38:18 twelve months later I'm still doing a ten years later I tried to stay in touch with them but they just no one did it
01:38:26 yeah for something like Chinese like study how human learning works so my every one of my Chinese flashcards is
01:38:34 associated with a story and that story is specifically designed to be memorable and we find things memorable which are
01:38:41 like funny or disgusting or sexy or related to people that we know will care about so I try to make sure all those
01:38:47 stories that are in my head have those characteristics yeah so you have to you know you won't remember things well if they don't have
01:38:56 some context and yeah you won't remember them well if you don't regularly practice them whether it be just part of
01:39:03 your day to day life or the Chinese for me flashcards I mean the other thing is I'll let yourself fail sometimes
01:39:11 so like I've had various medical problems over the last few years and basically my flashcards just stopped for
01:39:20 about three years and then they've been other times I've stopped for a few months and it's so hard because you get
01:39:26 back to it and it's like you have 18,000 cards June and so you just have to go alright well I can either stop and give
01:39:35 up everything or just decide to do this every day for the next two years until I get back to it
01:39:40 the amazing thing has been that even after three years I you know the Chinese were still in there like yeah it was so
01:39:48 much faster to relearn than it was to learn the first time yeah absolutely it's it's in there the same with with
01:39:57 guitar with music and so on it's sad because the work sometimes takes away and then you won't play for a year but
01:40:03 really if you then just get back to it every day you're right through right there again what do you think is the
01:40:08 next big breakthrough in artificial intelligence what are your hopes in deep learning or beyond that people should be
01:40:14 working on or you hope there'll be breakthroughs I don't think it's possible to predict I think yeah I think
01:40:21 what we already have is an incredibly powerful platform to solve lots of societally important problems that are
01:40:28 currently unsolved so I just hope that people will lots of people will learn this toolkit and try to use it I don't
01:40:35 think we need a lot of new technological breakthroughs to do a lot of great work right now and when do you think we're
01:40:43 going to create a human level intelligence system do you think know how hard is it how far away are we don't
01:40:50 know don't have no way to know I don't know like I don't know why people make predictions about this because there's
01:40:57 no data and nothing to go on and the Senate that's right it's just like there's so many
01:41:03 societally important problems to solve right now I just don't find it a really interesting question to even answer so
01:41:12 in terms of societally important problems what's the problem well is within reached for it
01:41:17 well I mean for example there are problems that AI creates right so most specifically labor force displacement is going to be
01:41:28 huge and people keep making this frivolous econometrics argument of being like oh there's been other things that
01:41:34 aren't AI that have come along before and haven't created massive labor force displacement therefore AI want it slow
01:41:41 so there's a serious concern for you oh yeah Andrew yang is running on it yeah it's it's it's I'm desperately concerned
01:41:50 and you see already that the changing workplace has lived to a hollowing out of the middle class you're seeing that
01:41:59 students coming out of school today have a less rosy financial future ahead of them and the parents did which has never
01:42:07 happened in recent in the last few hundred years you know we've always had progress before and you see this turning
01:42:18 into anxiety and despair and and even quite a bit about ethics too I do think that every data scientist working with
01:42:34 deep learning needs to recognize they have an incredibly high leverage tool that they're using that can influence
01:42:39 society in lots of ways and if they're doing research that that research is going to be used by people doing this
01:42:45 kind of work and they have a responsibility to consider the consequences and to think about things
01:42:53 like how will humans be in the loop here how do we avoid runaway feedback loops how do we ensure an appeals process for
01:43:01 humans that are impacted by my algorithm how do I ensure that the constraints of my algorithm are ethically explained to
01:43:08 the people that end up using them there's all kinds of human issues which only data scientists are actually in the
01:43:18 right place to educate people about but data scientists tend to think of themselves as just engineers and that
01:43:23 they don't need to be part of that process just know yeah which is wrong well you're in the perfect position to
01:43:30 educate them better to read literature to read history to learn from history well Jeremy thank you so much for
01:43:40 everything you do for inspiring huge amount of people getting them into deep learning and having the ripple effects
