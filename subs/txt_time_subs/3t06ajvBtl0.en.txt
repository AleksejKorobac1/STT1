00:00:01 the following is a conversation with Matt Botvinnik director of neuroscience research deep mind he's a brilliant
00:00:09 cross-disciplinary mind navigating effortlessly between cognitive psychology computational neuroscience
00:00:17 and artificial intelligence quick summary of the ads to sponsors the Jordan Harbinger show and magic spoon
00:00:24 cereal please consider supporting the podcast by going to Jordan Harbinger complex and also going to magic spoon
00:00:35 complex and using collects a check out after you buy all of their cereal click the links buy the stuff it's the best
00:00:43 way to support this podcast and journey I'm on if you enjoy this podcast subscribe on youtube review it with five
00:00:50 stars set up a podcast follow on Spotify support on patreon or connect with me on Twitter at Lex Friedman spelled
00:01:00 surprisingly without the e just Fri D M a.m. as usual I'll do a few minutes of ads now and never any ads in the middle that
00:01:06 can break the flow of the conversation this episode is supported by the Jordan Harbinger show go to Jordan Harbinger complex
00:01:17 it's how he knows I sent you on that page subscribe to his podcast an apple podcast Spotify and you know where to
00:01:25 look I've been binging on his podcast Jordan is a great interviewer and even a better human being
00:01:31 I recently listened to his conversation with Jack Barsky former sleeper agent for the KGB in the 80s and author of
00:01:39 deep undercover which is a memoir that paints yet another interesting perspective on the Cold War era I've
00:01:46 been reading a lot about the Stalin and then Gorbachev impudent errors of Russia but this conversation made me realize
00:01:52 that I need to do a deep dive into the Cold War era to get a complete picture of Russia's recent history again go to
00:02:01 Jordan Harbinger complex subscribe to his podcast that's how he knows I sent you it's awesome you won't regret it
00:02:09 this episode is also supported by magic spoon barb keto friendly super amazingly delicious cereal I've been on a keto or
00:02:19 very low carb diet for a long time now it helps with my mental performance it helps with my physical performance even
00:02:25 during this crazy push up pull up challenge I'm doing including the running it just feels great I used to
00:02:32 love cereal obviously I can't have it now because most cereals have a crazy amount of sugar which is terrible for
00:02:41 you so I quit eight years ago but magic spoon amazingly somehow is a totally different thing zero sugar 11 grams of
00:02:49 protein and only three net grams of carbs it tastes delicious it has a lot of flavors too new ones including peanut
00:02:57 butter but if you know what's good for you you'll go with cocoa my favorite flavor and the flavor of Champions click
00:03:07 the magic school complex link in the description and use collects a check out for free shipping and to let them know I
00:03:14 sent you they've agreed to sponsor this podcast for a long time they're an amazing sponsor and an even better
00:03:21 cereal I highly recommend it it's delicious it's good for you you won't regret it and now here's my
00:03:29 conversation with Matt Botvinnik how much of the human brain do you think we understand I think we're at a weird
00:03:39 moment in the history of neuroscience in the sense that there's a there I feel like we understand a lot about the brain
00:03:50 at a very high level but a very very coarse level when you say high level what are you thinking you thinking
00:03:58 functional yeah structurally so in other words what is what is the brain for you know what what what kinds of computation
00:04:06 does the brain do you know what kinds of behaviors would we have - would we have to explain if we were going to look down
00:04:16 at the mechanistic level and at that level I feel like we understand much much more about the brain than we did
00:04:22 when I was in high school but what but it's at a very it's almost like we're seeing it
00:04:26 a fog it's only at a very coarse level we don't really understand what the the neuronal mechanisms are that underlie
00:04:32 these computations we've gotten better at saying you know what are the functions that the brain is computing
00:04:38 that we would have to understand you know if we were going to get down to the neuronal level and at the other end of
00:04:46 the spectrum we you know in the last few years incredible progress has been made in terms of technologies that allow us to
00:04:56 see you know actually literally see in some cases what's going on at the the single unit level even the dendritic
00:05:04 level and then there's this yawning gap in between oh that's interesting so it's a high level so there's almost a
00:05:10 cognitive science yeah yeah and then at the neuronal level that's neurobiology and neuroscience
00:05:16 yeah just studying single neurons the the the the synaptic connections and all the dopamine all the kind of new
00:05:22 transmitters one blanket statement I should probably make is that as I've gotten older I have become more and more
00:05:30 reluctant to make a distinction between psychology and neuroscience to me the point of neuroscience is to study what
00:05:43 the brain is for if you if you if you're if you're a nephrologist and you want to learn about the kidney you start by at
00:05:51 by saying what is this thing for well it seems to be for taking blood on one side that has metabolites in it that are that
00:06:00 shouldn't be there sucking them out of the blood while leaving the good stuff behind and then
00:06:06 excreting that in the form of urine that's what the kidney is for it's like obvious so the rest of the work is
00:06:14 deciding how it does that and this it seems to me is the right approach to take to the brain you say well what is
00:06:20 the brain for the brain as far as I can tell is for producing behavior it's from going it's for going from perceptual
00:06:28 inputs to behavioral outputs and the behavioral output should be adaptive so that's what psychology is about it's
00:06:34 about understanding the structure of that function and then the rest of neuroscience is about figuring out how
00:06:41 those operations are actually carried out at a mechanistic level it's really interesting but so unlike the kidney the
00:06:51 the brain the the gap between the electrical signal and behavior so you truly see neuroscience as the science
00:07:01 oh that that touches behavior how the brain generates behavior or how the brain converts raw visual information
00:07:09 into understanding like and it's like you you basically see cognitive science psychology and neuroscience is all one
00:07:18 science yeah is that a personal statement I said I'm hopeful is that is that a hopeful or a realistic statement
00:07:25 so certainly you will be correct in your feeling in some number of years but that number of years could be two hundred
00:07:32 three hundred years from now oh well there's a is that aspirational or is that a pragmatic engineering feeling
00:07:41 that you have it's it's both in the sense that this is what I hope and expect will bear fruit over the coming
00:07:55 decades but it's also pragmatic in the sense that I'm not sure what we're doing in either in either psychology or
00:08:04 neuroscience if that's not the framing I don't I don't I don't know what it means to understand the brain if there's no if
00:08:16 part of the enterprise is not about understanding the behavior that's being produced I mean yeah but out I would
00:08:24 have compared to maybe astronomers looking at the movement of the planets and the stars and without any interest
00:08:32 of the underlying physics right and I would argue that there at least in the early days there are some valued is just
00:08:38 tracing the movement of the planets and the stars without thinking about the physics too much because it's such a
00:08:45 to start thinking about the physics before you even understand even the basic structural elements of oh I agree
00:08:50 with that I agree what you're saying in the end the goal should be yeah deeply
00:08:57 understand well right and I I think so I thought about this a lot when I was in grad school because a lot of what I
00:09:01 studied in grad school was psychology and I found myself a little bit confused about what it meant to it seems like
00:09:10 what we were talking about a lot of the time were virtual causal mechanisms like oh well you know attentional selection
00:09:21 then selects some object in the environment and that is then passed on to the motor you know information about
00:09:27 that is passed on to the motor system but these are these are virtual mechanisms these are you know they're
00:09:32 metaphors they're you know that there's no they're not there's no reduction - there's no reduction going on in that
00:09:39 conversation to some physical mechanism that you know or which is really what it would take to fully understand you know
00:09:47 how how behavior is arising but the causal mechanisms are definitely neurons interacting I'm willing to say that at
00:09:52 this point in history so in psychology at least for me personally there was this strange
00:10:00 insecurity about trafficking in these metaphors you know which we're supposed to explain the the function of the mind
00:10:08 if you can't ground them in physical mechanisms then what you know you know what is the what is the explanatory
00:10:17 validity of these explanations and I I managed to I managed to soothe my own nerves by thinking about the history of
00:10:31 genetics research so I'm very far from being an expert on the history of this field but I know enough to say that you
00:10:41 know Mendelian genetics preceded you know Watson and Crick and so there was a significant period of time during which
00:10:49 people were you know continued productively investigating the structure of inheritance using what was
00:10:57 essentially a metaphor of gene you know and no genes do this and genes do that but you know where the
00:11:03 genes they're they're sort of an explanatory thing that we made up and we we ascribed to them these causal
00:11:09 property so there's a dominant there's a recessive and then then they recombine and and and then later there was a kind
00:11:18 of blank there that was filled in with it with a with a physical mechanism that connection was made in but it was worth
00:11:27 having that metaphor because that's that gave us a good sense of what kind of cause what kind of causal mechanism we
00:11:35 were looking for and the fundamental metaphor of cognition you said is the interaction of neurons is that what is
00:11:44 the metaphor no no the metaphor the the metaphors we use in in in cognitive psychology are you know things like
00:11:55 attention way that memory works you know I I retrieve something from memory right you know a memory retrieval occurs what
00:12:05 is the Hat you know that's not that's not a physical mechanism that I can examine in its own right but if we if
00:12:12 but it's still worth having that that metaphorical level yeah so yeah I misunderstood actually so the higher
00:12:18 level abstractions is the metaphor that's most useful yes but but what the idea that that arises from
00:12:34 interaction of neurons well even it is the interaction of neurons also not a metaphor to you is or is it literally
00:12:42 like that's no longer a metaphor that's that's already that's already the lowest level of abstractions that could
00:12:51 actually be directly studied well I'm hesitating because I think what I want to say could end up being controversial
00:13:00 so what I want to say is yes the interaction of the interactions of neurons that's not metaphorical that's a
00:13:05 physical fact that's that's where that's where the causal interactions actually occur now I suppose you could say well
00:13:11 you know even is metaphorical relative to the quantum events that underlie yes you know I
00:13:17 don't want to go down that rabbit hole so is turtles on top potatoes but there is it there isn't there's a reduction
00:13:23 that you can do you can say these psychological phenomena are can be explained through a very different kind
00:13:29 of causal mechanism which has to do with neurotransmitter release and and so what we're really trying to do in
00:13:36 neuroscience writ large you know as I say which for me includes psychology is to take these psychological phenomena
00:13:49 and map them on to neural events I think remaining forever at the level of description that is natural for
00:14:01 psychology for me personally would be disappointing I want to understand how mental activity arises from neural
00:14:11 neural activity but the converse is also true studying neural activity without any sense of what you're trying to
00:14:24 explain to me feels like at best groping around you know at random now you've kind of talked about this bridging at
00:14:31 the gap between psychology in neuroscience but do you think it's possible like my love is like I fell in
00:14:39 love with psychology and psychiatry in general with Freud and when I was really young and I hope to understand the mind
00:14:45 and for me understanding the mind at least at a young age before I discovered AI and even neuroscience was to his
00:14:54 psychology and do you think it's possible to understand the mind without getting into all the messy details of
00:15:00 neuroscience like you kind of mentioned to you it's appealing to try to understand the mechanisms at the lowest
00:15:07 level but do you think that's needed that's required to understand how the mind works
00:15:12 that's an important part of the whole picture but I would be the last person on earth to suggest that that reality
00:15:30 unproductive I trained as a psychologist I I am fond of saying that I have learned much more from psychology than I
00:15:40 have from neuroscience to me psychology is a hugely important discipline and and ways of ways of investigating behavior
00:15:57 that have been native to cognitive psychology since its you know dawn in the 60s are starting to become they're
00:16:06 starting to become interesting to AI researchers for a variety of reasons and that's been exciting for me to see can
00:16:13 you maybe talk a little bit about what's what you see is beautiful aspects of psychology maybe limiting aspects of psychology
00:16:23 I mean maybe just started off as a science as a field to me was when I understood what psychology is analytical
00:16:31 psychology like the way it's actually carried out is really disappointing to see two aspects one is how few how small
00:16:40 the end is how many how small the number of subject is in the studies and two was disappointing to see how controlled the
00:16:49 entire how how much it was in the lab how it wasn't studying humans in the wild there's no mechanism for studying
00:16:55 humans in a while so that's where I became a little bit disillusioned into psychology and then the modern world of
00:17:03 the Internet is so exciting to me the Twitter data or YouTube daily data of human behavior on the Internet becomes
00:17:10 exciting because then the N grows and then in the wild girls but that's just my narrow sense they give us optimistic
00:17:17 or pessimistic cynical view of psychology how do you see the field broadly when I was in graduate school it was
00:17:26 early enough that there was still a thrill in seeing that there were ways of doing there were ways of doing
00:17:37 experimental science that provided insight to the structure of the mind one thing that impressed me most when I was
00:17:44 at that stage in my education was neuropsychology looking at looking at the analyzing the behavior of
00:17:54 populations who had brain damage of different kinds and trying to understand what what the what the specific deficits
00:18:05 were that arose from a lesion in a particular part of the brain and the the kind of experimentation that was done
00:18:10 and that's still being done to get answers in that context was so creative and it was so deliberate you know the it
00:18:22 was good science an experiment answered one question but raised another and somebody would do an experiment that
00:18:27 answered that question and you really felt like you were narrowing in on some kind of approximate understanding of
00:18:34 what this part of the brain was for do you have an example of the memory of what kind of aspects of the mind could
00:18:41 be studied in this kind of way oh sure I mean the very detailed neuropsychological studies of language
00:18:50 language function looking at production and reception and the relationship between you know visual function you
00:18:59 know reading and auditory and semantic and I mean there were these beauty and still are these beautiful models that
00:19:05 came out of that kind of research that really made you feel like you understood something that you hadn't understood
00:19:12 stood before about how you know language processing is organized in the brain but having said all that you know I I think
00:19:24 you know I think you are I mean I agree with you that the cost of doing highly controlled experiments is that you
00:19:36 by construction miss out on the richness and complexity of the real world one thing that so I I was drawn into science
00:19:44 by what in those days was called connectionism which is of course that you know what we now called deep
00:19:50 learning and at that point in history neural networks were primarily being used in order to model human cognition
00:19:58 they weren't yet really useful for industrial applications so you always fall in neural networks in biological
00:20:05 form beautiful Oh neural networks were very concretely the thing that drew me into science I was handed are you
00:20:13 familiar with the the PDP books from from the 80s some when I was in I went to medical school before I went into
00:20:21 science and really yeah this thing Wow I also I also did a graduate degree in art history so I'm I kind of explored
00:20:28 well art history I understand there's just a curious creative mind but medical school with the dream of what if we take
00:20:37 that slight tangent what did you what did you want to be a surgeon I actually was quite interested in
00:20:42 surgery I was I was interested in surgery and psychiatry and I thought that must be I must be the only person
00:20:51 on the planet who had who was torn between those two fields and III said exactly that to my advisor in medical
00:20:59 school who turned out I found out later to be a famous psychoanalyst and and he said to me no no it's actually not so
00:21:06 uncommon to be interested in surgery and psychiatry and he conjectured that the reason that people develop these these
00:21:13 two interests is that both fields are about going beneath the surface and kind of getting into the kind of secret yeah
00:21:20 I mean maybe you understand this as someone who was interested in psychoanalysis and or the stage there's
00:21:25 sort of a this you know there's a cliche phrase that people use now on you know like an NPR The Secret Life of Bees like
00:21:32 right yeah you know and that was part of the thrill of surgery was seeing you know the secret
00:21:38 you know the secret activity that's inside everybody is abdomen and thorax it's a very poetic way to connect it to
00:21:45 disciplines that are very practically speaking different each other that's for sure that's for
00:21:51 sure yes so so how do we get on to medical school so so I was in medical school and I I was doing a psychiatry
00:22:00 rotation and my kind of advisor in that rotation asked me what I was interested in and I said well maybe psychiatry he
00:22:10 said why and I said well I've always been interested in how the brain works I'm pretty sure that nobody's doing
00:22:18 scientific research that addresses my interests which are I didn't have a word for it then but I would have said about
00:22:26 cognition and he said well you know I'm not sure that's true you might you might be interested in
00:22:30 these books and he pulled down the the PDB books from his shelf and they were still shrink-wrapped
00:22:36 he hadn't read them but he handed to me a hint that inform you said he you can you feel free to borrow these and that
00:22:41 was you know I went back to my dorm room and I just you know read them cover to cover and what's PDP parallel
00:22:47 distributed processing which was the one of the original names for deep learning and so I apologize for the romanticized
00:22:57 question but what what idea in the space of neural size in the space of the human brain is to use the most beautiful
00:23:04 mysterious surprising what what had always fascinated me even when I was a pretty young kid I think was the the the
00:23:23 paradox that lies in the fact that the brain is so mysterious and so it seems so distant but at the same time it's
00:23:36 responsible for the the the the full transparency of everyday life it's the brain is literally what makes everything
00:23:45 obvious and familiar and and and there's always one in the room with you yeah I I used to teach when I taught at Princeton
00:23:52 I used to teach a cognitive neuroscience course and the very last thing I would say to the students was you know
00:24:01 people often when people think of scientific inspiration the the metaphor is often we'll look to the stars you
00:24:09 know the stars will inspire you to wonder at the universe and and you know think about your place in it and how
00:24:17 things work and and I'm all for looking at the stars but I've always been much more inspired and my sense of wonder
00:24:26 comes from the not from the distant mysterious stars but from the extremely intimately close brain yeah there's
00:24:38 something just endlessly fascinating to me about that the like just like you said the the one is close and yet
00:24:46 distant in in terms of our understanding of it do you are you all so captivated by the the fact that this very
00:24:56 conversation is happening because two brains are communicating the I guess what I mean is the subjective nature of
00:25:05 the experience if can take a small taejun into the the mystical of it the unconsciousness or or when you are
00:25:13 saying you're captivated by the idea of the brain you are you talking about specifically the mechanism of cognition
00:25:22 or are you also just like at least for me it's almost like paralyzing the beauty and the mystery of the fact that
00:25:28 it creates the entirety of the experience not just the reasoning capability but the experience well I I
00:25:38 definitely resonate with that that latter thought and I I often find discussions of artificial intelligence
00:25:50 to be disappointingly narrow you know speaking of someone who has always had an interest in in in art great it was
00:25:58 just gonna go there cuz it sounds like somebody who has an interest in art yeah I mean I there there there
00:26:05 there are many layers to you know to full-bore him and experience and and in some ways it's not enough to say oh well
00:26:14 don't worry you know we're talking about cognition but we'll add emotion you know yeah there's there's there's an
00:26:23 incredible scope to what humans go through in in every moment and and yes so it's that's part of what fascinates
00:26:36 me is that is that our brains are producing that but at the same time it's so mysterious to us how we literally our
00:26:48 brains are literally in our heads producing mystics and yet there and yet there's there it's so mysterious to us
00:26:56 and so and in the scientific challenge of getting at the the the actual explanation for that is so overwhelming
00:27:04 it's not that's just i don't know that certain people have fixations on particular questions and that's always
00:27:11 that's just always been mine yeah I would say the poetry that is fascinating and I'm really interested in natural
00:27:17 language as well and when you look at our personal intelligence community it always saddens me how much when you try
00:27:26 to create a benchmark for the community together around how much of the magic of language is lost when you create that
00:27:34 benchmark that there's something would we talk about experience the the music of the language the wit the something
00:27:41 that makes a rich experience something that would be required to pass the spirit of the Turing test is lost in
00:27:49 these benchmarks and I wonder how to get it back in because it's very difficult the moment you tried to do like real
00:27:55 good rigorous science you lose some of that magic when you try to study cognition in a rigorous scientific way
00:28:03 it feels like you're losing some of the magic mm-hmm-hmm the the seen cognition in a mechanistic way that AI vote at
00:28:10 this stage in our history well okay I I agree with you but at the same time one one thing that I found really exciting
00:28:20 about that first wave of deep learning models in cognition was there was the the fact that the people
00:28:29 who were building these models were focused on the richness and complexity of human cognition so an early debate in
00:28:40 cognitive science which I sort of witnessed as a grad student was about something that sounds very dry which is
00:28:47 the formation of the past tense but there were these two camps one said well the the mind encodes certain rules and
00:28:58 it also has a list of exceptions because of course you know the rule is a DB but that's not always what you do so you
00:29:03 have to have a list of exceptions and and then there were the connectionists who you know evolved into the deep
00:29:11 learning people who said well well you know if you look carefully at the data if you look at actually look at corpora
00:29:19 like language corpora it's it turns out to be very rich because yes there are there are there's a you know the there
00:29:26 most verbs that and you know you just tack on e d and then there are exceptions but there are also there's
00:29:32 also there are there are rules that in you know there's the exceptions aren't just random they there are certain clues
00:29:40 to which which which verbs should be exceptional and then there are some exceptions to the exceptions and there
00:29:47 was a word that was kind of deployed in order to capture this which was quasi regular in other words there are rules
00:29:55 but it's it's messy and there there's their structure even among the exceptions and and it would be yeah you
00:30:01 could try to write down you could try to write down the structure in some sort of closed form but really the right way to
00:30:08 understand how the brain is handling all this and by the way producing all of this is to build a deep neural network
00:30:15 and trained it on this data and see how it ends up representing all of this richness so the way that deep learning
00:30:23 was deployed in cognitive psychology was that was the spirit of it it was about that richness and that's something that
00:30:31 I always found very very compelling still do is it is there something especially
00:30:37 interesting and profound to you in terms of our current deep learning neural network artificial neural network
00:30:45 approaches and the whatever we do understand about the biological neural networks in our brain is there there's
00:30:52 some there's quite a few differences are some of them to you either interesting or perhaps profound in terms
00:31:02 of in terms of the gap we might want to try to close in trying to create a human level intelligence what I would say here
00:31:09 is something that a lot of people are saying which is that one seeming limitation of the systems that we're
00:31:20 building now is that they lack the kind of flexibility the readiness to sort of turn on a dime when this when the
00:31:27 context calls for it that is so characteristic of human behavior so is that connected to you to the like
00:31:36 which aspect of the neural networks in our brain is that connected to is that now again see like my natural
00:31:48 inclination is to separate into three disciplines of neuroscience cognitive science and psychology and you've
00:31:56 already kind of shut that down by saying you you're kind of see them as separate but just to look at those layers I guess
00:32:04 where is there something about the lowest layer of the way the neural neurons interact and that is profound to
00:32:13 you in terms of this difference to the artificial neural networks or is all the difference the key difference is at a
00:32:21 higher level of abstraction one thing I often think about is that you know if you take an introductory
00:32:27 computer science course and they are introducing you to the notion of Turing machines one way of articulating what
00:32:38 the significance of a Turing machine is is that it's a machine emulator it's it can emulate any other machine and that
00:32:52 that to me you know that that and it was that way of looking at a deterring machine you know it really sticks with
00:33:02 me I think of humans as maybe sharing in some of that character we're capacity limited we're not Turing
00:33:09 machines obviously but we have the ability to adapt behaviors that are very much unlike anything we've done before
00:33:17 but there's some basic mechanism that's implemented in our brain that allows us to run run software but you're just in
00:33:24 that point you mentioned into a machine but nevertheless it's fundamentally our brains are just computational devices in
00:33:30 your view is that what you're getting like is it I was a little bit unclear to this line you drew mmm is is is there
00:33:38 any magic in there or is it just basic computation I'm happy to think of it as just basic computation but mind you I
00:33:46 won't be satisfied until somebody explains to me how what the basic computations are that are leading to the
00:33:54 full richness of human cognition yes I mean it's not gonna be enough for me to you know understand what the
00:33:59 computations are that allow people to you know do arithmetic or play chess I want I want the whole whole you know
00:34:07 the whole thing in a small tangent because you kind of mentioned coronavirus the this group behavior oh
00:34:14 sure I is that is there something interesting to your search of understanding the human mind where law
00:34:21 behavior of large groups of just behavior of groups is interesting you know seeing that as a collective mind as
00:34:27 a collective intelligence perhaps seeing the groups of people as a single intelligent organisms especially looking
00:34:34 at the reinforcement learning work mm-hm even done recently well yeah I can't I can't I mean I
00:34:41 I have the I have the the honor of working with a lot of incredibly smart people and I wouldn't want to take any
00:34:47 credit for for leading the way on the the multi-agent work that's come out of out of my group or deep mine lately but
00:34:56 I do find it fascinating and I mean I think there you know I think it it can't be debated you know the human behavior
00:35:06 arises within communities that just seems to me self-evident but to me so it is self-evident but that seems to be a
00:35:15 profound aspects of something that created that was like if you look at like 2001 Space Odyssey when that well
00:35:22 the monkeys touch the yeah like that's the magical moment I think Eva Hari argues that the ability of our large
00:35:30 numbers of humans to hold an idea to converge towards idea together like you said shaking and bumping elbows somehow
00:35:38 converge like without even like like without you know without being in a room all together just kind of this like
00:35:44 distributed convergence towards an idea yeah over a particular period of time seems to be fundamental to to just every
00:35:52 aspect of our cognition of our intelligence because humans I will talk about reward but it seems like we don't
00:36:00 really have a clear objective function under which we operate but we all kind of converge towards one somehow and that
00:36:06 that to me has always been a mystery that I think is somehow productive for also understanding AI systems but I
00:36:16 guess I guess that's the next step the first step is trying to understand the mind well I don't know I mean I think
00:36:22 there's something to the argument that that kind of bottom like strictly bottom-up approach is wrongheaded in
00:36:32 other words you know there are there are basic phenomena that you know you know basic aspects of human intelligence that
00:36:40 you know can only be understood in in the context of groups I'm perfectly open to that I've never been particularly
00:36:50 convinced by the notion that we should be we should consider intelligence to in here at the
00:36:57 level of communities I I don't know why I just I'm sort of stuck on the notion that the basic unit that we want to
00:37:03 understand is individual humans and if if we have to understand that in the context of other humans fine but for me
00:37:12 intelligence is just I'm stubbornly I stubbornly defined it as something that is you know an aspect of an individual human
00:37:21 that's just my time with you with us that could be the reduction is dream of a scientist because you can understand a
00:37:27 single human it also is very possible that intelligence can only arise when there's multiple intelligences when
00:37:36 there's multiple sort of it's a sad thing if that's true because it's very difficult to study but if it's just one
00:37:44 human that one human will not be Homo Sapien would not become that intelligent that's a real that's a possibility I I'm
00:37:51 with you well one thing I will say along these lines is that I think I think a serious effort to understand human
00:38:08 intelligence and maybe to build a human-like intelligence needs to pay just as much attention to the structure
00:38:15 of the environment as to the structure of the you know the the cognizing system whether it's a brain or an AI system
00:38:24 that's one thing I took away actually from my early studies with the pioneers of neural network research people like
00:38:32 Jay McClelland and John Cohen you know the the structure of cognition is really it's only a only partly a function of
00:38:43 the the you know the the architecture of the brain and the learning algorithms that it implements what it's really a
00:38:49 function what what what really shapes it is the interaction of those things with the structure of the world in which
00:38:56 those things are embedded right and that's especially important for this made most clear and reinforcement
00:39:02 learning where I simulate an environment as you can only learn as much as you can simulate and that's what made well deep
00:39:09 mine made very clear well the other aspect of the environment which is the self play mechanism of the other agent
00:39:17 of the competitive behavior which the other agent becomes the environment essentially yeah and that's I mean one
00:39:24 of the most exciting ideas in AI is the self play mechanism that's able to learn successfully so there you go there's a
00:39:30 there's a thing where competition is essential for yeah earning yeah at least in that context so if we can step back
00:39:38 into another beautiful world which is the actual mechanics the dirty mess of it of the human brain is is there
00:39:48 something for people who might not know is there something in common or describe the key parts of the brain that are
00:39:55 important for intelligence or just in general what are the different parts of the brain that you're curious about that
00:40:03 you've studied and that are just good to know about when you're thinking about cognition well my area of expertise if I
00:40:15 have one is prefrontal cortex so what's that or do we it depends on who you ask the the the the the technical definition
00:40:27 is has is anatomical it there are there are parts of your brain that are responsible for motor behavior and
00:40:37 they're very easy to identify and the region of your cerebral cortex they out needs sort of outer crust of your brain
00:40:47 that lies in front of those is defined as the prefrontal cortex and when you say anatomical sorry to interrupt
00:40:55 so that's referring to sort of the geographic region yeah as opposed to some kind of functional definition
00:41:02 exactly so that it this is kind of the coward's way out and I'm telling you what the prefrontal cortex is just in
00:41:07 terms of like what part of the real-estate it occupies the thing in the front of them yeah exactly and and in
00:41:16 fact the early history of you know the neuroscientific investigation of what this like front
00:41:25 part of the brain does is sort of funny to read because you know it was really it was really World War one that started
00:41:35 people down this road of trying to figure out what different parts of the brain the human brain do in the sense
00:41:41 that there were a lot of people with brain damage who came back from the war with brain damage and it that provided
00:41:48 as tragic as that was it provided an opportunity for scientists to try to identify the functions of different
00:41:54 brain regions and it wasn't actually incredibly productive but one of the frustrations that neuropsychologist face
00:42:01 was they couldn't really identify exactly what the deficit was that arose from damage to this these most you know
00:42:08 kind of frontal parts of the brain it was just a very difficult thing to you know to you know to pin down there were
00:42:16 a couple of neuropsychologists who identified through through a large amount of clinical experience in close
00:42:24 observation they started to put their finger on a syndrome that was associated with frontal damage actually one of them
00:42:30 was a russian neuropsychologist named Gloria who you know students of cognitive psychology still read and and
00:42:40 what he started to figure out was that the frontal cortex was somehow involved in flexibility the in in in guiding
00:42:52 behaviors that required someone to override a habit or to do something unusual or to change what they were
00:43:01 doing in a very flexible way from one moment to another so focused on like new experiences and so the so the way your
00:43:09 brain processes and acts in new experiences yeah what later helped bring this function into better focus was a
00:43:18 distinction between controlled and automatic behavior or - in in other literature's this is referred to as
00:43:26 habitual behavior versus goal directed behavior so it's very very clear that the human brain has
00:43:36 pathways that are dedicated to habits to things that you do all the time and they need to be autumn at they don't require
00:43:45 you to concentrate too much so the that leaves your cognitive capacity freed you do other things just think about the
00:43:54 difference between driving when you're learning to drive versus driving after you're fairly expert there are brain
00:44:03 pathways that slowly absorb those frequently performed behaviors so that they can be habits so that they can be
00:44:12 automatic for that that's kind of like the purest form of learning I guess it's happening there which is
00:44:19 why I mean this is kind of jumping ahead which is why that perhaps is the most useful for us to focusing on and trying
00:44:25 to see how artificial intelligent systems can learn is that the way it's interesting I I do think about this
00:44:30 distinction between controlled and automatic or goal directed and habitual behavior a lot in thinking about where
00:44:43 we are in AI research but but just to finish to finish the the kind of dissertation here the the the role of
00:44:51 the front of the prefrontal cortex is generally understood these days sort of in in Contra distinction to that
00:45:01 habitual domain in other words the prefrontal cortex is what helps you override those habits it's what allows
00:45:09 you to say well what I usually do in this situation is acts but given the context I probably should do why I mean
00:45:17 the elbow bump is a great example right if you know reaching out and shaking hands is a probably habitual behavior
00:45:25 and it's the prefrontal cortex that allows us to bear in mind that there's something unusual going on right now
00:45:32 and in this situation I need to not do the usual thing the kind of behaviors that Luria reported and he built tests
00:45:41 for you know detect these kinds of things we're exactly like this so in other words when I stick out
00:45:49 my hand I want you instead to present your elbow a patient with frontal damage would have great deal of trouble with
00:45:54 that you know somebody preferring their hand would elicit you know a handshake the prefrontal cortex is what allows us
00:46:02 to say oh no hold on that's the usual thing but I'm I have the ability to bear in mind even very unusual contexts and
00:46:11 to reason about what behavior is appropriate there just to get a sense is our us humans special in the presence of
00:46:21 the prefrontal cortex do mice have a prefrontal cortex do other mammals that we can study if you if no then how do
00:46:30 they integrate new experiences yeah that's a that's a really tricky question and a very timely question because we
00:46:45 have revolutionary new technologies for monitoring measuring and also causally influencing neural behavior in mice and
00:46:59 fruit flies and these techniques are not fully available even for studying brain function in in monkeys let alone humans
00:47:12 and so it's a it's a very sort of for me at least a very urgent question whether the kinds of things that we want to
00:47:18 understand about human intelligence can be pursued in these other organisms and you know to put it briefly there's disagreement
00:47:31 you know people who study fruit flies will often tell you hey root flies are smarter than you think
00:47:36 and they'll point to experiments where fruit flies were able to learn new behaviors we're able to generalize from
00:47:44 one stimulus to another in a way that suggests that they have abstractions that guide their generalization I've had
00:47:54 many conversations in which I will start by observing you know recounting some some observation about
00:48:07 Mouse behavior where it seemed like mice were taking an awfully long time to learn a task that for a human would be
00:48:15 profoundly trivial and I will conclude from that that mice really don't have the cognitive flexibility that we want
00:48:21 to explain and that a mouse researcher will say to me well you know hold on that experiment may not have worked
00:48:30 because you asked a mouse to deal with stimuli and behaviors that were very unnatural for the mouse if instead you
00:48:38 kept the logic of the experiment the same but put you know kind of put it in a you know presented it the information
00:48:46 in a way that aligns with what mice are used to dealing with in their natural habitats you might find that a mouse
00:48:51 actually has more intelligence than you think and then they'll go on to show you videos of mice doing things in their
00:48:58 natural habitat which seem strikingly intelligent you know dealing with you know physical problems you know I have
00:49:05 to drag this piece of food back to my you know back to my lair but there's something in my way and how do I get rid
00:49:12 of that thing so I think I think these are open questions to put it you know to sum that up and then taking a small step
00:49:19 back so related to that is you kind of mentioned we're taking a little shortcut by saying it's a geographic geographic
00:49:26 part of the the prefrontal cortex is a region of the brain but if we what's your sense in a bigger philosophical
00:49:35 view prefrontal cortex and the brain in general do you have a sense that it's a set of subsystems in the way we've kind
00:49:42 of implied that are they're pretty distinct or to what degrees of that or to what degree is it a giant
00:49:50 interconnected mess where everything kind of does everything and is impossible to disentangle them I think
00:49:57 there's overwhelming evidence that there's functional differentiation that it's clearly not the case that all parts
00:50:06 of the brain are doing the same thing this follows immediately from the kinds of studies of brain damage that we were
00:50:17 chatting about before it's obvious from what you see if you stick an electrode in the brain and measure what's going on
00:50:25 at the level of you neural activity having said that there are two other things to add which kind of I don't know
00:50:34 maybe tug in the other direction one is that it's when you look carefully at functional differentiation in the
00:50:44 brain what you usually end up concluding at least this is my observation of the literature is that the the differences
00:50:53 between regions are graded rather than being discrete so it doesn't seem like it's easy to divide the brain up into
00:51:04 true modules where you know that are you know that have clear boundaries and that have you know like like clear channels
00:51:16 of communication between them instead lies to the prefrontal cortex yeah oh yeah yeah the prefrontal cortex is made
00:51:22 up of a bunch of different sub regions the you know the functions of which are not clearly defined and which then the
00:51:31 borders of which seem to be quite vague and then then there's another thing that's popping up in very recent
00:51:40 research which you know which involves application of these new techniques which there are a number of studies that
00:51:50 suggest that parts of the brain that we would have previously thought were quite focused in their function are actually
00:52:00 carrying signals that we wouldn't have thought would be there for example looking in the primary visual cortex
00:52:06 which is classically thought of as basically the first cortical way station for processing visual information
00:52:12 basically what it should care about is you know where are the edges in this scene that I'm viewing
00:52:18 it turns out that if you have enough data you can recover information from primary visual cortex about all sorts of
00:52:24 things like you know what what behavior the animal is engaged in right now and what what how much reward is on offer in
00:52:32 the task that it's pursuing so it's clear that even even regions whose function is pretty well defined at a
00:52:41 course brain are nonetheless carrying some information about information from very different domains so you know the
00:52:50 history of neuroscience is sort of this oscillation between the two views that you articulated you know the kind of
00:52:56 modular view and then the big you know mush view and you know I think I guess we're gonna end up somewhere in the
00:53:04 middle which is which is unfortunate for our understanding because the mod there's something about our you know
00:53:10 conceptual system that finds it's easy to think about a modular AI system and easy to think about a completely
00:53:15 undifferentiated system but something that kind of lies in between is confusing but we're gonna have to get
00:53:22 used to it I think unless we can understand deeply the lower-level mechanism and you're all communicating
00:53:27 yeah so yeah on that on that topic you kind of mention information just to get a sense I imagine something that there's
00:53:35 still mystery and disagreement on is how does the brain carry information and signal like what in your sense is the
00:53:45 basic mechanism of communication in the brain well I I guess I'm old-fashioned in that I consider the networks that we
00:53:54 use in deep learning research to be a reasonable approximation to you know the the mechanisms that carry information in
00:54:04 the brain so the the the usual way of articulating that is to say what really matters is a rate code it what matters
00:54:12 is how how how quickly is an individual neuron spiking how you know what's the frequency at which it's spiking is the
00:54:18 timing of the spike yeah is it is it firing fast or slow let's you know let's put a number on that and that number is
00:54:25 enough to capture what what neurons are doing there's you know there's still uncertainty about whether that's
00:54:34 an an adequate description of how information is is transmitted within the brain there you know there are there are
00:54:43 studies that suggest that the precise timing of spikes matters there are studies that suggest that there are
00:54:52 computations that go on within the dendritic tree within a neuron that are quite rich and structured and that
00:54:59 really don't equate to anything that we're doing in our artificial neural networks having said that I feel like we
00:55:07 can get I feel like I feel like we're getting somewhere by sticking to this high level of
00:55:13 abstraction just the rate and by the way we're talking about the electrical signal that I remember reading some
00:55:20 vague paper somewhere recently where the mechanical signal like the vibrations or something of the of the neurons also
00:55:29 communicates and if I haven't seen that but this is there somebody was arguing that the the electrical signal this is
00:55:37 in nature paper something like that where the electrical signal is actually a side effect of the mechanical signal
00:55:45 but I don't think they changes the story but it's almost the interesting idea that there could be a deeper it's like
00:55:53 it's always like in physics with quantum mechanics there's always a deeper story that could be underlying the whole thing
00:55:59 but you think is basically the rate of spiking that gets us that's like the lowest hanging fruit that can get us
00:56:06 really far this is a this is a classical view I mean this is this is this is not the only way in which this stance would
00:56:13 be controversial is it you know in the sense that there are there are members of the neuroscience community who are
00:56:19 interested in alternatives but this is really a very mainstream view the way that neurons communicate is that
00:56:28 neurotransmitters arrive or you know at a at you know they they wash up on a neuron the neuron has receptors for
00:56:37 those transmitters the the the the the meeting of the transmitter with these receptors changes the voltage of the neuro
00:56:45 and if enough voltage change occurs then a spike occurs right one of these like discrete events and it's that spike that
00:56:53 is conducted down the axon and leads to neuroses this is just this is just like neuroscience 101 this is like the way
00:57:00 the brain is supposed to work now what we do when we build artificial neural networks of the kind that are now
00:57:08 popular in the AI community is that we don't worry about those individual spikes we just worry about the frequency
00:57:15 at which those spikes are being generated and the you know we consider people talk about that as the activity
00:57:23 of a neuron and you know so the the activity of units in a deep learning system is you know broadly analogous to
00:57:33 the spike rate of a neuron there there are people who who believe that there are other forms of communication in the
00:57:40 brain in fact I've been involved in some research recently that suggests that the voltage the voltage fluctuations that
00:57:49 occur in populations of neurons that aren't you know that are sort of below the level of a spike production may be
00:57:58 important for for communication but I'm still pretty old-school in the sense that I think that the the things that
00:58:05 we're building in AI research constitute reasonable models of how a brain would work let me ask just for fun a crazy
00:58:15 question because I can do you think it's possible were completely wrong about the way this basic mechanism of your
00:58:23 neuronal communication that the information is thought is some very different kind of way in the brain oh
00:58:28 heck yes you know I would look I wouldn't be a scientist if I didn't think there was any chance we were wrong
00:58:35 but but I mean if you look if you look at the history of deep learning research as it's been applied to neuroscience of
00:58:42 course the vast majority of deep learning research these days isn't about neuroscience but you know if you go back
00:58:50 to the 1980s there's a you know sort of an unbroken chain of research in in which a particular strategy is taken
00:58:55 which is hey let's train a deep a deep learning system let's train a multi-layer neural
00:59:07 network on this task that we trained our you know backbone or our monkey on or this human being on and then let's look
00:59:16 at what the units deep in the system are doing and let's ask whether what they're doing resembles what we know about what
00:59:24 neurons deep in the brain are doing and over and over and over and over that strategy works in the sense that the
00:59:34 learning algorithms that we have access to which typically send our own back propagation they give rise to you know
00:59:42 patterns of activity patterns of response patterns of like neuronal behavior and these in these artificial
00:59:50 models that look haunting Lisa hauntingly similar to what you see in the brain and you know is that a commune
00:59:58 yes incidences at a certain point it starts looking like such coincidence is unlikely to not be deeply meaningful
01:00:05 yeah yeah that's yeah the circumstantial evidence is overwhelming but it could be always open to a total
01:00:11 of flipping a table yeah of course so you have co-authored several recent papers that sort of weave beautifully
01:00:19 between the world of neuroscience and artificial intelligence and this maybe if we could can we just try to dance
01:00:27 around and talk about some of them maybe tried to pick up the interesting idea as a jump to your mind from memory so maybe
01:00:34 looking at we're talking about the prefrontal cortex the 2018 I believe paper called the prefrontal cortex as a
01:00:41 matter of reinforcement learning system what is there a key idea that you can speak to from that paper yeah the I mean
01:00:53 the key idea is about meta learning so what is meta learning meta learning is by definition a situation in which you
01:01:06 have a learning algorithm and the learning algorithm operates in such a way that it gives rise to another
01:01:14 learning algorithm in the in the earliest applications with this idea you had one learning algorithm sort of
01:01:21 adjusting the parameters on another learning algorithm but the case that we're interested in this paper is one
01:01:28 where you start with just one learning algorithm and then another learning algorithm kind of emerges out of the
01:01:35 kind of thin air I can say more about what I mean by that I don't mean to be you know your entities but that's the
01:01:44 idea of meta learning you you it relates to the old idea and psychology of learning to learn situations where you
01:01:54 you you have experiences that make you better at learning something new like a group a familiar example would be
01:02:01 learning a foreign language the first time you learn a foreign language it may be you know quite laborious and
01:02:08 disorienting and a novel but if you let's say you've learned to two foreign languages the third foreign language
01:02:15 obviously is going to be much easier to pick up and why because you've learned how to learn you know how this goes you
01:02:21 know okay I'm gonna have to learn how to conjugate I'm gonna happen that's a that's a simple form of meta learning
01:02:27 right in the sense that there's some slow learning mechanism that's giving that's helping you kind of update your
01:02:35 fast learning mechanism that that that makes you so how from from our understand from the psychology world
01:02:42 from neuroscience honor our understanding how meta learning works might work in the human brain what what
01:02:50 lessons can we draw from that that we can bring into the artificial intelligence world well yeah so we the
01:02:58 origin of that paper was in AI work that that we were doing in my group we were we were looking at what happens when you
01:03:06 train a recurrent neural network using standard reinforcement learning algorithms but but you train that
01:03:12 network not just in one task but you train it in a bunch of interrelated tasks and then you ask what happens when
01:03:19 you give it yet another task in that sort of line of interrelated tasks and and what we started to realize
01:03:30 is that a form of meta learning spontaneously happens in in recurrent neural networks and and the simplest way
01:03:40 to explain it is to say a recurrent a recurrent neural network has a kind of memory in its activation patterns it's
01:03:47 recurrent by definition in the sense that you have units that connect to other units that connect to other units
01:03:52 so you have sort of loops of connectivity which allows activity to stick around and be updated over time in
01:03:59 psychology we call in neuroscience we call this working memory it's like actively holding something in mind and
01:04:09 and and so that memory gives the recurrent neural network of dynamics right the way that the activity pattern
01:04:19 evolves over time is inherent to the connectivity of the recurrent neural network okay so that's that's idea
01:04:25 number one now the dynamics of that network are shaped by the connectivity by the synaptic weights and those
01:04:31 synaptic weights are being shaped by this reinforcement learning algorithm that you're you know training the
01:04:39 network with so the punchline is if you train a recurrent neural network with a reinforcement learning algorithm that's
01:04:44 adjusting its weights and you do that for long enough the activation dynamics will become very interesting right so
01:04:53 imagine imagine I give you a task where you have to press one button or another left button or right button and some
01:05:00 time in and there's some probability that I'm going to give you an M&M if you press the left button and there's some
01:05:06 probability I'll give you an M&M if you press the other button and you have to figure out what those probabilities are
01:05:13 just by trying things out but as I said before instead of just giving you one of these tasks I give you a whole sequence
01:05:18 you know I give you two buttons and you figure out which one's best and I go good job here's here's a new box two new
01:05:23 buttons you have to figure out which one's best good job here's a new box and every box
01:05:27 has its own probabilities and you have to figure so if you train a neural net a recurrent neural network on that kind of
01:05:32 sequence of tasks the what happens it seemed almost magical to us when we first started kind
01:05:41 of realizing what was going on the slow learning algorithm that's justing the the synaptic weights though those slow
01:05:49 synaptic changes give rise to a network dynamics that them cell that you know the dynamics themselves turn into a
01:05:57 learning algorithm so in other words you can you can tell this is happening by just freezing the synaptic weights
01:06:02 saying okay no more learning you're done here's a new box figure out which button is best and the recurrent neural network
01:06:10 will do this just fine there's no like it figures out which which button is best it train it kind of transitions
01:06:17 from exploring the two buttons to just pressing the one that it likes best in a very rational way how is that happening
01:06:23 it's happening because the activity of the day the activity dynamics of the network have been shaped by this slow
01:06:28 learning process that's occurred over many many boxes and so what's happened is that this slow learning algorithm
01:06:37 that's slowly adjusting the weights is changing the dynamics of the network the activity dynamics into its own learning
01:06:45 algorithm and as we were as we were kind of realizing that this is the thing it just so happened that the group that was
01:06:54 working on this included a bunch of neuroscientists and it started kind of ringing a bell for us which is to say
01:07:02 that we thought this sounds a lot like the distinction between synaptic learning and activity synaptic memory
01:07:09 and activity based memory in the brain and it also reminded us of recurrent connectivity that's very characteristic
01:07:20 of prefrontal function so there this is this is kind of why it's good to have people working on AI that know a little
01:07:27 bit about neuroscience and vice-versa because we started thinking about whether we could apply this principle to
01:07:32 neuroscience and that's where the paper came from so the kind of principle of the the recurrence they can see in the
01:07:40 prefrontal cortex then you start to realize that is possible too for something like an idea of a learning to learn emerging
01:07:51 from this learning process as long as you keep varying the environment sufficient zactly so so the kind of
01:07:59 metaphorical transition we made to neuroscience was to think okay well we know that the prefrontal cortex is
01:08:05 highly recurrent we know that it's an important locus for working memory for active activation based memory so maybe
01:08:14 the prefrontal cortex supports reinforcement learning in other words you what is reinforcement learning you
01:08:20 take an action you see how much reward you got you update your policy of behavior maybe the prefrontal cortex is
01:08:26 doing that sort of thing strictly in its activation patterns it's keeping around a memory in its activity
01:08:34 patterns of what you did how much reward you got and it's using that that activity based memory as a basis for
01:08:41 updating behavior but then the question is well how did the prefrontal cortex get get so smart in other words how did
01:08:47 it where did these activity dynamics come from how did that program that's implemented in the recurrent dynamics of
01:08:55 the prefrontal cortex arise and one answer that became evident in this work was well maybe maybe the mechanisms that
01:09:03 operate on the synaptic level which we believe are mediated by dopamine are responsible for shaping those dynamics
01:09:12 so this may be a silly question but because this kind of several temporal of classes of learning are happening and so
01:09:24 the learning to learn is emerges can it just can you keep building stacks of learning to learn to learn learning to
01:09:31 learn to learn to learn to learn because it keeps I mean basically abstractions of more powerful abilities to generalize
01:09:41 of learning complex rules yeah or is this that's over stretching the this kind of mechanism well what at one of the
01:09:51 one of the people in AI who started thinking about meta learning from there very early on your ganancia tuber sort
01:10:00 of cheekily suggested I think it is it may have been in his PhD thesis that we should think about meta meta meta meta
01:10:08 meta meta learning you know that that's really that's really what's going to get us to true intelligence certainly
01:10:15 there's a poetic aspect to it and it seems interesting and correct that that kind of level of abstraction would be
01:10:22 powerful but is that something you see in the brain this kind of is it useful to think of learning in these meta meta
01:10:31 meta way or is it just meta learning well one thing that really fascinated me about this mechanism that we were
01:10:39 starting to look at and you know other groups started talking about very similar things at the same time and and
01:10:47 then a kind of explosion of interest in metal learning happened in the AI community shortly after that I don't
01:10:51 know if we had anything to do with that but but I was gratified to see that a lot of people started talking about meta
01:10:58 learning one of the things that I like about the kind of flavor of meta learning that we were studying was that
01:11:06 it didn't require anything special it was just if you took a system that had some form of memory that the function of
01:11:15 which could be shaped by picture RL algorithm then this would just happen yes right I mean there there there are a
01:11:22 lot of forms of there are a lot of meta learning algorithms that have been proposed since then that are fascinating
01:11:27 and effective in in their you know in their domains of application but they're you know they're engineered they're
01:11:33 they're things that you had to say well see if we wanted meta learning to happen how would we do that here's an algorithm
01:11:37 that would but there's something about the kind of meta learning that we were studying that seemed to me special in
01:11:45 the sense that it wasn't an algorithm it was just something that automatically happened if you had a system that had
01:11:52 memory and it was trained with a reinforcement learning algorithm in and in that sense it can be as meta as it
01:12:00 wants to be right it there's no limit on how abstract the the meta-learning can get because it's not reliant on the human
01:12:09 engineering a particular metal learning algorithm to get there and and that's I I also I don't know I guess I hope that
01:12:18 that's relevant in the brain I think there's a kind of beauty in the in in the ability of this emergent the
01:12:25 emergent aspect of it yeah it's engineered exactly it's something that just it just happens in in in a sense in
01:12:33 a sense you can't avoid this happening if you have a system that has memory and the function of that memory is shaped by
01:12:42 reinforcement learning and this system is trained in a series of interrelated tasks this is gonna happen you can't
01:12:49 stop it as long as you have certain properties maybe like of a current structure too you have to have memory it
01:12:54 actually doesn't have to be a recurrent neural network when a paper that I was honored to be involved with even earlier
01:13:02 used a kind of slot based memory you remember the title just it was memory augmented neural networks I think it
01:13:11 what I too was meta learning in memory augmented neural networks and and you know it was the same exact story you
01:13:20 know if you have a system with memory here it was a different kind of memory but the function of that memory is
01:13:30 shaped by reinforcement learning here it was the root you know the reads and writes that occurred on this slot based
01:13:37 memory this yeah this will just happen and and and so this but this brings us back to something I was saying earlier
01:13:44 about the importance of the environment the this this will happen if the system is being trained in a setting where
01:13:53 there's like a sequence of tasks that all share some abstract structure you know sometimes talk about tasks
01:14:00 distributions and that's something that's very obviously true of the world that humans inhabit we're we're
01:14:10 constantly like if you just kind of think about what you do every day you never you never do exactly the same
01:14:17 thing that you did the day before but everything that you do is sort of has a family resemblance it shares structure
01:14:23 with something that you did before and so you know the the real world is sort of you know saturated with this kind of
01:14:34 this property it's an endless variety with endless redundancy and that's the setting in which this kind of meta
01:14:41 learning happens and it does seem like we're just so good at finding just like in this emergent phenomena you describe
01:14:49 we're really good at finding that redundancy finding those similarities the family resemblance some people call
01:14:56 it sort of what is it Melanie Mitchell was talking about analogies so we were able to connect
01:15:03 concepts together in in this kind of way in in this same kind of automated emergent way which if there's so many
01:15:10 echoes here of psychology neuroscience and obviously now with reinforcement learning with recurrent neural networks
01:15:18 at the core if we could talk a little bit about dopamine you have really you're a part of co-authoring really
01:15:26 exciting recent paper very recent in terms of release on dopamine and temporal difference learning can you
01:15:34 describe the key ideas of that paper sure yeah I mean one thing I want to pause to do is acknowledge my co-authors
01:15:41 on actually both of the papers we're talking about so the this dopamine I'll just I'll certainly post all their names
01:15:48 okay wonderful yeah as I you know I I'm sort of abashed to be the spokesperson for these papers when I had such amazing
01:15:56 collaborators on both so it's a it's a comfort to me to know that you all have you all acknowledge that yeah it's not
01:16:00 an incredible team there but yeah so yeah it's such a it's so much fun and and in the case of the the dopamine
01:16:08 paper we also collaborated with now ochite at Harvard who you know what a paper simply wouldn't happened without
01:16:15 him but so so you were asking for like a thumbnail sketch of yes thumbnail sketch or key ideas or you know things the
01:16:23 insights that no continued on our kind of discussion here between euros and yeah yeah I mean this was another a
01:16:30 lot of the work that we've done so far is taking ideas that have bubbled up in AI and you know asking the question of
01:16:40 whether the brain might be doing something related which I think on the surface sounds like something that's
01:16:49 really mainly of use to neuroscience we see it also as a way of validating what we're doing on the AI side if we can
01:16:58 gain some evidence that the brain is using some technique that we've been trying out in our AI work that gives us
01:17:06 confidence that you know it may be a good idea that it'll you know scale to rich complex tasks that it'll interface
01:17:15 well with other mechanisms so you see is a two-way Road yeah for just because a particular paper is a little bit focused
01:17:22 on from one to the from a yeah from you'll network's to neuroscience ultimately the discussion the thinking
01:17:30 the productive long-term aspect of it is the the two-way Road nature of the whole and yeah I mean we we've talked about
01:17:37 the notion of a virtuous circle between AI and neuroscience and you know the way I see it that's always been there since
01:17:46 the two fields you know jointly existed there have been some phases in that history when AI was
01:17:54 sort of ahead there are some phases when neuroscience was sort of ahead I feel like given the bursts of innovation
01:18:02 that's happened recently on the AI side AI is kind of ahead in the sense that they're all of these ideas that we you
01:18:11 know we you know for which it's exciting to consider that there might be neural analogs and neuroscience
01:18:21 you know in a sense has been focusing on approaches to studying behavior that come from you know that are kind of
01:18:27 derived from this earlier era of cognitive psychology and you know so in some ways fail to connect with some of
01:18:35 the issues that we're you know grappling with in AI like how do we deal with you know you know complex environments but I've
01:18:45 you know I think it's inevitable that this circle will keep turning and there will be a moment in the not too
01:18:51 different distant future when neuroscience is pelting AI researchers with insights that may change the
01:18:58 direction of our work just as just a quick human question is it you have parts of your brain this is very meta
01:19:08 but they're able to both think about neuroscience and AI you know I don't often meet people like that do you do
01:19:18 you think let me ask a meta plasticity question you think a human being can be both good at AI and neuroscience is like
01:19:26 what on the team at deep mind what kind of human can occupy these two realms and is that something you see everybody
01:19:35 should be doing can be doing or is it a very special few can kind of jump just like we thought about our history I
01:19:41 would think it's a special person that can major in art history and also consider being a surgeon otherwise known
01:19:51 as a dilettante yeah easily distracted no I I think it does take a special kind of person to be truly world-class at
01:20:03 both AI and neuroscience and I am not on that list I happen to be someone who whose interest in neuroscience and
01:20:16 psychology involved using the kinds of modeling techniques that are now very central in AI and that sort of I guess
01:20:25 bought me a ticket to be involved in all of the amazing things that are going on in AI research right now I do know a few
01:20:33 people who I would consider pretty expert on both fronts and I won't embarrass them by naming them but you
01:20:38 know there are there are like exceptional people out there who are like this the the one the one thing that
01:20:47 I find is a is a barrier to being truly world-class on both fronts is is the just the
01:20:55 the complexity of the technology that's involved in both disciplines now so the the engineering expertise that it takes
01:21:04 to to do you know truly frontline hands-on AI research is really really considerable
01:21:12 the learning curve of the tools just like the specifics of just whether it's programming or the kind of tools
01:21:18 necessary to collect the data to manage the data to distribute to compute all that kind of stuff yeah and on the
01:21:22 neuroscience I guess side there'll be all different sets of tools exactly especially with the recent explosion in
01:21:29 you know in neuroscience methods so but but how you know so having said all that I I think I think the rule I think the
01:21:40 best scenario for both neuroscience and AI is to have people who interacting who live at every point on this spectrum
01:21:52 from exclusively focused on neuroscience to exclusively focused on the engineering side of AI but but to have
01:22:01 those people you know inhabiting a community where they're talking to people who live elsewhere on the on the
01:22:07 spectrum and I be I may be someone who's very close to the center in in the sense that I have one foot in the neuroscience
01:22:14 world and one foot in the AI world in and and that central position I will admit prevents me at least someone with
01:22:22 my limited cognitive capacity from being a truly you know true having true technical expertise in any you know
01:22:30 either domain but at the same time I at least hope that it's worthwhile having people around who can kind of you know
01:22:37 see the connections if the community the yeah the the emergent intelligence of the community yeah yeah that's nicely
01:22:44 distributed is useful okay exactly yeah so hopefully but I mean I've seen that work I've seen that work out well at D
01:22:51 mind there there are there are people who I mean even if you just focus on the AI work that happens a deep mind it's
01:22:59 been a good thing to have some people around doing that kind of work whose PhDs are in neuroscience or psychology
01:23:08 every every academic discipline has its kind of blind spots and kind of unfortunate obsessions and it's
01:23:18 metaphors and it's reference points and having some intellectual diversity is is really healthy people get each other
01:23:29 unstuck I think I see it all the time at deep mind and you know I like to think that the people who bring some
01:23:36 neuroscience background to the table are helping with that so one of the one of them I like probably the deepest passion
01:23:42 for me what I would say maybe who kind of spoke off mic a little bit about it but that that I think is a blind spot
01:23:51 for at least robotics and AI folks is human robot interaction human agent interaction maybe idea of thoughts about
01:24:02 how we reduce the size of that lines but do you also share the feeling that not enough folks are studying this aspect of
01:24:12 interaction well I I'm I'm actually pretty intensively interested in this issue now and there are people in my
01:24:19 group who've actually pivoted pretty hard over the last few years from doing more traditional cognitive psychology
01:24:26 and cognitive neuroscience to doing experimental work on human agent interaction and there are a couple of
01:24:34 reasons that I'm pretty passionately interested in this one is it's kind of the outcome of having thought for a few
01:24:47 years now about what we're up to like what were you like what are we doing like what what is this what is this aid
01:24:55 AI research for so what does it mean to make the world a better place I think I'm pretty sure that means making life
01:25:01 better for humans yeah and so how do you make life better for humans that's that's a proposition that
01:25:10 when you look at it carefully and honestly is rather horrendously complicated especially when the AI
01:25:19 systems that your that your building our learning systems they're not you're not you know
01:25:29 programming something that you then introduce to the to the world and it just works as programmed like Google
01:25:37 Maps or something we're building systems that that learn from experience so you know that that typically leads to AI
01:25:43 safety questions how do we keep these things from getting out of control how do we keep them from doing things that
01:25:51 harm humans and I mean I hasten to say I consider those hugely important issues and there are large sectors of the
01:26:00 research community a deep mind and of course elsewhere who are dedicated to thinking hard all day every day about
01:26:07 that but there's a there's I guess I guess I would say a positive side to this too which is to say well what would
01:26:16 it mean to make human life better oh and and how how can we imagine learning systems doing that and and in talking to
01:26:24 my colleagues about that we reached the initial conclusion that it's not sufficient to philosophize about that
01:26:31 you actually have to take into account how humans actually work and what humans want and the difficulties of knowing
01:26:43 what humans want and the difficulties that arise when humans want different things and and so human agent
01:26:52 interaction has become you know a quite a quite intensive focus of my group lately if for no other reason that in
01:27:02 order to really address that that issue in an adequate way you have to I mean psychology becomes part of the picture
01:27:09 yeah and then so there's a few elements there so if you focus on solving into like the if you focus on the robotics
01:27:17 problem let's say a GI without humans in the picture is you're missing fundamentally the final step you when
01:27:24 you do want to help human civilization you eventually have to interact with humans and when you create a learning
01:27:30 system just as you said that will eventually have to interact with humans the interaction itself has
01:27:39 to be become has to become part of the learning process right so you can't just watch well my sense is it sounds like
01:27:46 your senses you can't just watch humans to learn about humans yeah you have to also be part of the human world you have
01:27:52 to interact with humans yeah exactly and I mean then questions arise that start imperceptibly but inevitably to slip
01:28:02 beyond the realm of engineering so questions like if you have an agent that can do something that you can't do under
01:28:12 what conditions do you want that agent to do it so you know if you know if I if Beethoven sonatas better than any human
01:28:29 in the sense that the you know the the sensitivity the express the expression is just beyond what any human do I do I
01:28:36 want to listen to that do I want to go to a concert and hear a robot play these are these are these are an engineering
01:28:43 questions these are questions about human preference and human culture and psychology bordering and philosophy yeah
01:28:50 and then and then you start asking well well even if we knew the answer to that is it our place as AI engineers to build
01:29:00 that into these agents probably the agents should interact with humans beyond the population of AI engineers
01:29:07 and figure out what those humans want yeah and then you know when you start I referred this the moment ago but even
01:29:15 that becomes complicated be quote what if what if 2-8 what if two humans want different
01:29:20 things and and you have only one agent that's able to interact with them and try to satisfy their preferences then
01:29:29 you're into the realm of of of like economics and social choice theory and and even politics so there's a sense in
01:29:36 which if you if you kind of follow what we're doing to its logical conclusion then it goes beyond questions of
01:29:45 engineering and technology and you know starts to shade and perceptibly into questions about what
01:29:52 kind of society do you want and actually that once once that dawned on me I actually felt I don't know what the
01:30:01 right word is quite refreshed in my in my involvement in AI research it's almost like this building this kind of
01:30:08 stuff is gonna lead us back to asking really fundamental questions about what's you know what is this like look
01:30:15 what's the good life and yeah who gets to decide and and you know you know bringing in viewpoints from multiple sub
01:30:25 communities to help us you know shape the way that we live this it's it's there's something it it started making
01:30:33 me feel like doing a a I research in you know fully responsible away would you know could potentially lead to a kind of
01:30:44 like cultural renewal yeah it's it's the way done it's the it's the way to understand human beings at the
01:30:50 individual at the societal level it may become a way to answer all the silly human questions of the meaning of life
01:30:56 and all the all those kinds of things but if it doesn't even if it doesn't give us a way of answering those
01:31:01 questions it may force us back to thinking about thinking about you know and it might bring it it might bring it
01:31:07 might restore a certain I don't know a certain depth to or even dare I say spirituality to the way that you know to
01:31:18 to to the world I don't think maybe that you crann do switch well I don't think I I'm with you I think it's a it's a I
01:31:25 will be that's one of the philosophy of the 21st century the way which will open the door I think a lot of a I
01:31:31 researchers are afraid to open that door of exploring the view beautiful richness of the human agent interaction human AI
01:31:40 interaction I'm really happy that somebody like you have opened to that door and I think one thing I often think
01:31:48 about is you know the the the usual the usual schema for thinking about human human agent interaction is this kind of dystopian
01:31:58 you know oh you know where our robot overlords and and again I hasten to say AI safety is usually working and I you
01:32:06 know I'm not saying we shouldn't be thinking about those risks totally on board for that
01:32:13 but there's a what having said that there's a there's a I what often follows for me is the thought that you know
01:32:22 there's another there's another kind of narrative that might be relevant which is when we think of when we think of
01:32:30 humans gaining more and more information about you know like human life the the narrative there is usually that they've
01:32:39 gained more and more wisdom and more you know they get closer to enlightenment and you know and they become more
01:32:44 benevolent and you know like the Buddha is like the like that's that's a totally different narrative and why isn't it the
01:32:51 case that we we imagine that the the AI systems that we're creating and just kind of like they're gonna figure out
01:32:55 more and more about the way the world works and the way that humans interact and they'll they'll become beneficent
01:33:01 I'm not saying that will happen I'm not you know III I'm I don't honestly expect that to happen without some careful
01:33:08 setting things up very carefully but it's another way things could go right and yeah and I would even push back on
01:33:19 that I believe that the most trajectory's natural human trajectories will lead us towards progress so for me
01:33:28 there is a kind of sense that most trajectories in AI development will lead us into trouble you mean and and we over
01:33:37 focus on the worst case it's like in computer science theoretical computer science has been this focus on
01:33:42 worst-case analysis there's something appealing to our human mind at some lowest level to be mean we don't want to
01:33:50 be eaten by the tiger I guess so we want to do the worst-case analysis but the reality is that shouldn't stop us from
01:33:57 actually building out all the other trajectories which are potentially leading to all the positive world's all
01:34:05 the all the Enlightenment this book in language now with Steven Pinker and so on this
01:34:09 looking generally at human progress and there's so many ways the human progress can happen with AI it's and I think you
01:34:16 have to do that research you have to do that work you have to do the not just AI safety work of the one worst case
01:34:23 analysis how do we prevent that but the the actual tools and the glue and the mechanisms of human AI interaction that
01:34:33 would lead to all the positive yeah isn't go yes super exciting area right yeah you know we should be spending we
01:34:39 should be spending a lot of our time saying what can go wrong I think it's harder to see that there's work to be
01:34:49 done to bring into focus the question of what what it would look like for things to go right yeah that it's you know
01:34:58 that's not obvious there and we wouldn't be doing this if we didn't have the sense there was huge potential right
01:35:04 we're not doing this you know you know for no reason we we have a sense that AG I would be a major boom to humanity but
01:35:13 I think I think it's worth starting now even when our technology is quite primitive asking well exactly what would
01:35:20 that mean we can start now with applications that are already gonna make the world a better place like you know
01:35:25 solving protein folding you know I I think this deep mind has gotten heavy into science applications lately which i
01:35:32 think is you know you know a wonderful wonderful move for us to be making but when we think about AGI when we think
01:35:39 about building you know fully intelligent agents that are gonna be able to in a sense do whatever they want
01:35:46 you know we should start thinking about what do we want them to want what what what kind of world do we want to live in
01:35:55 that's not an easy question and if you think we just need to start working on it and even on the path to sort of it
01:36:00 doesn't have to be AG I was just intelligent agents that interact with us and help us enrich our own existence on
01:36:07 social networks for example on recommender systems and various intelligence there's so much interesting
01:36:11 interaction that's yet to be understood and studied and you know how how do you create I mean Twitter's is
01:36:19 struggling with this very idea how do you create AI systems that increase the quality in the health of a conversation
01:36:26 for sure it's a beautiful beautiful human psychology question and how do you do that without without deception being
01:36:36 involved without manipulation being involved you know maximizing human autonomy and how do you how do you make
01:36:46 these choices in a democratic way how do you how do we how do we face the how do we again I'm speaking for myself here
01:36:57 how do we face the fact that it's a small group of people who have the skill set to build these kinds of systems but
01:37:06 the you know what it means to make the world a better place is something that we all have to be
01:37:12 talking about yeah the kind of the world the that we're trying to make a better place includes a huge variety of
01:37:20 different kinds of people yeah how do we cope with that this is this is a problem that has been discussed you know in in
01:37:29 Gori extensive detail in social choice theory you know there one thing I'm really enjoying about the recent
01:37:35 direction work has taken in some parts of my team is that yeah we're reading the IEEE literature
01:37:39 we're reading the neuroscience literature but we've also started reading like economics and as I
01:37:45 mentioned social choice Theory even some political theory because it turns out that it's you know it all becomes
01:37:53 relevant it all becomes relevant and but you know at the same time we've been trying not to write philosophy papers
01:38:01 right we've been trying not to write position papers we're trying to figure out ways of doing
01:38:06 actual empirical research that kind of take the first small steps to thinking about what it really means for humans
01:38:13 with all of their complexity and contradiction and you know paradox and you know to be bought and to be brought
01:38:22 into contact with these API systems in a way that then it really makes the world a better place often reinforcement
01:38:28 learning frameworks actually kind of allow you to to do that machine learning and so that
01:38:33 that's the exciting thing about AI is allows you to reduce the unsolvable problem philosophical problem into
01:38:40 something more concrete that you can get ahold of yeah and it allows you to kind of define the problem in some way that
01:38:50 allows for growth in the system that sort of beat you know you're not responsible for the details right you
01:38:56 say this is generally what I want you to do and then learning takes care of the rest of course the safety issues are you know
01:39:04 arise in that context but I think also some of these positive issues arise in that context what would it mean for an
01:39:10 AI system to really come to understand what humans want and you know in if you know in with all of the subtleties of
01:39:22 that right you know humans humans want help with certain things but they don't want everything done for them right
01:39:29 there is part of part of the satisfaction that humans get from life is in accomplishing things so if there
01:39:34 were devices around that did everything for him you know I often think of the movie wall-e yeah that's like dystopian
01:39:40 in a totally different ways like the machines are doing everything for us that's that's not what we want it you
01:39:46 know anyway I just I find this you know this kind of this opens up a whole landscape of research that feels
01:39:53 affirmative yeah and it's not to me it's one of the most exciting and it's wide open yeah we have to because it's a cool
01:39:59 paper talk about dopamine oh yeah okay so I can let's we were gonna we were gonna I was gonna give you
01:40:05 a quick summary here's a quick summary of  what's the title of the paper I I think we called it a distributional
01:40:15 distributional code for value in dopamine based reinforcement learning yes so that's another project that grew
01:40:26 out of pure AI research a number of people that deep mind and a few other places had started working on a new
01:40:34 version of reinforcement learning it would the which was defined by taking something in
01:40:41 traditional reinforcement learning and just tweaking it so the thing that they took from traditional reinforcement
01:40:48 learning was a value signal so that the at the center of reinforcement learning at least most algorithms is some
01:40:54 representation of how well things are going your expected cumulative future reward and that's usually represented as
01:41:03 a single number so if you imagine a gambler in a casino and the gamblers thinking well I have this probability of
01:41:10 winning such and such an amount of money and I have this probability of losing such and such an amount of money the
01:41:15 that situation would be represented as a single number which is like the expected the the weighted average of all those
01:41:23 outcomes and this new form of reinforcement learning said well what if we what if we generalize that to
01:41:28 distributional representation so now we think of the gambler as literally thinking well there's this probability
01:41:34 that I'll win this amount of money and there's this probability that I'll lose that amount of money and we don't reduce
01:41:40 that to a single number and it had been observed through experiments through you know just trying this out that that rep
01:41:46 that kind of distributional representation really accelerated reinforcement learning and led to better
01:41:55 policies what's your intuition about so we're talking about rewards yeah so what's the intuition why that is why
01:42:01 what is it well it's an it's kind of a surprising historical note at least surprised me when I learned it that this
01:42:08 had been tried out in a kind of heuristic way people thought well gee what would happen if we tried and then
01:42:15 it had this empirically it had this striking effect and it was only then that people started thinking well gee
01:42:22 why wait why wait why why is this working and and that's led to a series of studies just trying to figure out why
01:42:29 it works it which is ongoing but one thing that's already clear from that research is that one reason that it
01:42:36 helps is that it drives richer representation learning so if you imagine imagine two situations that have
01:42:45 the same expected value they're the same kind of weighted average value Stan deep reinforcement learning algorithms
01:42:52 are going to take those two situations and kind of in terms of the way they're represented internally dozen ex-squeeze
01:42:59 them together because the the thing that you're trying to represent which is their expected value is the same so all
01:43:06 the way through the system things are going to be mushed together but what if in what if what if those two situations
01:43:12 actually have different value distributions they have the same average value but they have different
01:43:20 distributions of value in that situation distributional learning will will maintain the distinction between these
01:43:26 two things so to make a long story short distribution of learning can keep things separate in the internal representation
01:43:34 that might otherwise be conflated or squished together and maintaining those distinctions can be useful in in when
01:43:40 the system is now faced with some other task where the distinction is important if we look at the optimistic and
01:43:47 pessimistic dopamine neurons so first of all what is dopamine why is this why is it all useful to to think about in the
01:44:01 artificial intelligence sense but what do we know about dopamine in the human brain what is what is it why is it
01:44:07 useful why is it interesting what does have to do with the prefrontal cortex and learning in general yeah so well
01:44:14 there's this hint this is also some a case where there is a huge amount of detail and debate but one one one
01:44:26 currently prevailing idea is that the function of this neurotransmitter dopamine resembles a particular
01:44:36 component of standard reinforcement learning algorithms which is called the reward prediction error so I was talking
01:44:43 a moment ago about these value representations how do you learn them how do you update them based on
01:44:49 experience well if you if you made some prediction about a future reward and then you get more reward than you were
01:44:55 expecting then probably retrospectively you want to go back and increase the value representation that you attached
01:45:02 to the earlier situation if you got less reward than you were expecting
01:45:07 you should probably decrement that estimate and that's the process of temporal difference exactly this is the
01:45:12 central mechanism of temporal difference learning which is one of several kind of you know kind of back them sort of the
01:45:19 backbone of our armamentarium in in RL and it was this connection between the world prediction error and dopamine was
01:45:31 was made you know in the in the 1990s and there's been a huge amount of research that you know seems to back it
01:45:36 up dopamine made to be doing other things but this is clearly at least roughly one of the things that it's
01:45:44 doing but the usual idea was that dopamine was representing these reward prediction errors again in this like
01:45:52 kind of single number way that representing your surprise you know it with a single number and in distribution
01:45:59 ilaria forcement learning this this kind of new elaboration of the standard approach it's not only the value the
01:46:07 value function that's represented as a single number it's also the reward prediction error and so what happened
01:46:16 was that will Dabney one of my collaborators who was one of the first people to work on distributional
01:46:22 temporal difference learning talked to a guy in my group will Chris Nelson who's a computational neuroscientist and said
01:46:29 gee you know is it possible that dopamine might be doing something like this distributional coding thing and
01:46:35 they started looking at what was in the literature and then they brought me in we started talking to now ochita and we
01:46:40 came up some with some specific predictions about you know if the brain is using this kind of distributional
01:46:46 coding then in the tasks that now has studied you should see this this this and this and that's where the paper came
01:46:52 from we kind of enumerated a set of predictions all of which ended up being fairly clearly confirmed and all of
01:46:59 which leads to at least some initial indication that the brain might be doing something like this distributional
01:47:04 coding that dopamine might be representing surprise signals in a way that is not just collapsing everything
01:47:11 to a single number but instead it's kind of respecting the the variety of future outcomes if that
01:47:17 makes sense so yeah so that's we're showing suggesting possibly that dopamine has a really interesting
01:47:25 representation scheme for for in in the human brain for its reward signal exactly that's fascinating it's just
01:47:31 that's another beautiful example of AI revealing something that's about neuroscience potentially suggesting
01:47:37 possibilities well you never know so a minute you published paper like that the next thing you think is I hope that
01:47:43 replicates like I hope I hope we see that same thing in other datasets but of course several labs now are doing the
01:47:49 follow-up experiment so we'll know soon but it has been it has been a lot of fun for us to you know to take these ideas
01:47:56 from AI and kind of bring them into neuroscience and and you know see how far we can get so we kind of talked
01:48:01 about it a little bit but where do you see the field of neuroscience and artificial intelligence heading broadly
01:48:11 like what are the possible exciting areas that you can see breakthroughs in the next let's get crazy not just three
01:48:19 or five years but the next 10 20 30 years that would make you excited and perhaps you'd be part of on the
01:48:33 neuroscience side there's a great deal of interest now in what's going on in AI and and at the same time I feel like so
01:48:49 the neuroscience especially the part of neuroscience that's focused on circuits and and systems you know kind of like
01:48:58 really mechanism focused there's been this explosion in new technology and up until recently the experiments that have
01:49:11 exploited this technology have have not involved a lot of interesting behavior and this is for a variety of reasons you
01:49:18 know one of which is in order to employ some of these technologies you actually have to if you're if you're studying a
01:49:23 mouse you have to head fix the mouse in other words you know you have to like immobilize the mouse
01:49:28 and so it's been it's been tricky to come up with ways of eliciting interesting behavior from a mouse that's
01:49:34 that's restrained in this way but people have begun to you know create very interesting solutions to this like
01:49:41 virtual reality environments where the animal can kind of move a trackball and and and and as people have kind of begun
01:49:49 to explore what you can do with these technologies I feel like more and more people are asking well let's try to bring behavior
01:49:56 into the picture let's try to like reintroduce behavior which was supposed to be what this whole thing was about
01:50:06 and I'm hoping that those two trends the the kind of growing interest in behavior and the widespread widespread interest
01:50:15 in what's going on in AI will come together to kind of open a new chapter in neuroscience research where there's a
01:50:25 kind of rebirth of interest in the structure of behavior and its underlying substrates but that that research is
01:50:33 being informed by computational mechanisms that were coming to understand in AI you know if we can do
01:50:39 that then we might be taking a step closer to this utopian future that we were talking about earlier where there's
01:50:46 really no distinction between psychology and neuroscience night neuroscience is about studying the mechanisms that
01:50:54 underlie whenever it is the brain is for and you know what is the brain for it's for behavior now I feel like we could I
01:51:01 feel like we could maybe take a step toward that now if people are motivated in the right way you also ask Betty I so
01:51:10 that is very science question you said neuroscience that's right and especially place like deep mind are interested in
01:51:16 both branches sort of what what about the engineering or intelligence systems I think I think the one of the key
01:51:26 challenges that a lot of people are seeing now in AI is to build systems that have the kind of
01:51:36 flexibility and the kind of flexibility that humans have in two senses one is that humans can be good at many things
01:51:43 they're not just expert at one thing and they're also flexible in the sense that they can switch between things very
01:51:50 easily and they can pick up new things very quickly because they they very they very able see what a new task has in
01:51:58 common with other things that they've done and and that's something that our AI systems to you know blatantly do not
01:52:10 have there are some people who like to argue that deep learning and deep RL are simply wrong for getting that kind of
01:52:19 flexibility I don't share that belief but the simpler fact of the matter is we're not building things yet that do
01:52:26 have that kind of flexibility and and I think the the attention of a large part of the AI community is starting to pivot
01:52:32 to that question how do we get that that's going to lead to a focus on abstraction it's gonna lead to a focus
01:52:42 on what in psychology we call cognitive control which is the ability to switch between tasks the ability to quickly put
01:52:49 together a program of behavior that you've never executed before but you know makes sense for a particular set of
01:52:56 demands it's very closely related to what the prefrontal cortex does on the neuroscience side so I think it's going
01:53:03 to be an interesting and interesting new chapter so that's the reasoning side and cognition side but let me ask the over
01:53:10 romanticize question do you think we'll ever engineer an AGI system that we humans would be able to love and that
01:53:20 would love us back so I have that level and depth of connection I love that question and it it it relates closely to
01:53:32 things that I've been thinking about a lot lately you know in the context of this human AI research there there's
01:53:42 social psychology research in particular by Susan Fiske at Princeton in the department I used to
01:53:49 where I used to work where she she dissects human attitudes toward other humans into a sort of two-dimensional
01:53:58 you know a two-dimensional two-dimensional scheme and one dimension is about ability you know how able how
01:54:10 capable is is this other person and the but the other dimension is warmth so you can imagine another person who's very
01:54:18 skilled and capable but it's very cold right and you wouldn't you wouldn't really like highly you might have some
01:54:25 reservations about that other person right but there's also a kind of reservation that we might have about
01:54:33 another person who who elicits in us or displays a lot of human warmth but is you know not good at getting things done
01:54:41 right that that like the the greatest esteem that we we reserved our greatest esteem really for people who are both
01:54:51 highly capable and also quite warm right that that's that's like the best of the best this is I mean I'm just this isn't
01:54:57 a normative statement I'm making this is just an empirical it's an empirical statement this is what humans seem this
01:55:02 is these are the two dimensions that people seem to kind of like along which people size other people up in an in AI
01:55:09 research we really focus on this capability thing you like we want our agents to be able to do stuff you know
01:55:14 this thing can play go at a superhuman level that's awesome and but that's only one dimension what's the what about the
01:55:19 other dimension what would it mean for Nai system to be warm and you know I don't know maybe there are easy
01:55:27 solutions here like we can put them put a face on rei systems it's cute it has big years I mean that's probably part of
01:55:34 it but I think it also has to do with a pattern of behavior a pattern of you know what would it mean for an AI system
01:55:42 to display caring compassionate behavior in a way that actually made us feel like it was for real yeah that we didn't feel
01:55:50 like it was simulated we didn't feel like we were being duped to me that you know people talk about the Turing test
01:55:58 or some some descendant of it I feel like that's the ultimate Turing test you know is there is there an AI system that can
01:56:06 not only convince us that it knows how to reason and it knows how to interpret language but that we're comfortable
01:56:14 saying yeah that AI system is a good guy you know like I'm the warmth scale yeah whatever warmth is we kind of
01:56:21 intuitively understand it but we also want to be able to yeah we don't even understand it explicitly enough yet to
01:56:31 be able to engineer it exactly and that's and that's an open scientific question you kind of alluded it several
01:56:37 times in the human AI interaction that's the question that should be studied and probably one of the most important
01:56:43 questions and usually and human to AG we humans are so good at it yeah you know it's not just weird it's not just that
01:56:50 we're born warm you know like I suppose some people are are warmer than others given you know whatever genes they
01:56:57 manage to inherit but there's also there's also there are also learned skills involved right I mean there are
01:57:04 ways of communicating to other people that you care that they matter to you that you're enjoying interacting with
01:57:12 them yeah right and we learn these skills from one another and it's not out of the question that we could build
01:57:19 engineered systems I think it's hopeless as you say that we could somehow hand design these sorts of
01:57:26 these sorts of behaviors but it's not out of the question that we could build systems that kind of we-we-we in instill
01:57:34 in them something that sets them out in the right direction so that they they end up learning what it is to interact
01:57:42 with humans in a way that's gratifying to humans I mean honestly if that's not I think it's exciting as a scientific
01:57:56 problem just as he described I I honestly don't see a better way to enter than talking about warmth and love and
01:58:04 Matt I don't think I've ever had such a wonderful conversation where my questions were so bad and your answers
01:58:09 was so beautiful so I deeply appreciate it I really do very fun I don't know I as you can
01:58:16 probably tell I'm I really you know I there's something I like about kind of thinking outside the box and like yeah
01:58:22 I'm so it's good having fun to do that awesome thanks so much for doing it thanks for listening to this
01:58:28 conversation with Matt bah panic and thank you to our sponsors the Jordan Harbinger show and magic spoon low carb
01:58:37 keto cereal please consider supporting this podcast by going to Jordan Harbinger complex and also going to
01:58:46 magic spoon complex and using code Lex a check out click the links buy all the stuff it's the best way to support this
01:58:54 podcast and the journey I'm on in my research and the startup if you enjoy this thing subscribe on youtube review
01:59:02 it with the five stars in a podcast the port on patreon follow on Spotify or connect with me on Twitter at Lex
01:59:10 Friedman again spelled miraculously without the e just Fri DM a.m. and now let me leave you with some words from
01:59:21 urologists vs amachandran hannah three pound mass of jelly that you can hold in your palm imagine angel's contemplate
01:59:29 the meaning of infinity even question its own place in cosmos especially all inspiring it's the fact that any single
01:59:37 brain including yours is made up of atoms that were forged in the hearts of countless far-flung stars billions of
01:59:44 years ago these particles drifted for eons and light years until gravity and change
01:59:53 brought them together here now these atoms now form a conglomerate your brain I can not only ponder the very stars
02:00:01 they gave it birth but can also think about its own ability to think and wonder about its own ability to wander
02:00:09 with the arrival of humans it has been said the universe has suddenly become conscious of itself this
