00:00:01 the following is a conversation with Chris flattener currently he's a senior director of Google working on several
00:00:08 projects including CPU GPU TPU accelerators for tensorflow swift for tensorflow and all kinds of
00:00:14 machine learning compiler magic going on behind the scenes he's one of the top experts in the world on compiler
00:00:21 technologies which means he deeply understands the intricacies of how hardware and software come together to
00:00:28 create efficient code he created the LLVM compiler infrastructure project and the clang compiler he led major
00:00:36 engineering efforts at Apple including the creation of the Swift programming language he also briefly spent time at
00:00:43 Tesla as vice president of auto pilot software during the transition from autopilot Hardware 1 to hardware 2 when
00:00:50 Tesla essentially started from scratch to build an in-house software infrastructure for autopilot I could
00:00:56 have easily talked to Chris for many more hours compiling code down across the levels abstraction is one of the
00:01:04 most fundamental and fascinating aspects of what computers do and he is one of the world experts in this process it's
00:01:10 rigorous science and it's messy beautiful art this conversation is part of the artificial intelligence podcast
00:01:18 if you enjoy it subscribe on youtube itunes or simply connect with me on twitter at Lex Friedman spelled Fri D
00:01:27 and now here's my conversation with Chris Ladner what was the first program you've ever written my first program
00:01:36 back and when was it I think I started as a kid and my parents got a basic programming book and so when I started
00:01:44 it was typing out programs from a book and seeing how they worked and then typing them in wrong and trying to
00:01:50 figure out why they were not working right that kind of stuff so basic what was the first language that you remember
00:01:58 yourself maybe falling in love with like really connecting with I don't know I mean I feel like I've learned a lot
00:02:03 along the way and each of them have a different special thing about them so I started in basic and then went like
00:02:10 gw-basic which was the thing back in the DOS days and then upgrade to QBasic and eventually quick
00:02:17 basic which are all slightly more fancy versions of Microsoft basic made the jump to Pascal and start doing machine
00:02:24 language programming and assembly in Pasco which was really cool through Pascal was amazing for its day
00:02:31 eventually going to C C++ and then kind of did lots of other weird things I feel like you took the dark path which is the
00:02:39 you could you could have gone Lisp yeah you've got a higher-level sort of functional philosophical hippy route
00:02:46 instead you went into like the dark arts of the straight straight in the machine straight to toys so started with basic
00:02:54 task element assembly and then wrote a lot of assembly and why eventually I eventually did small talk and other
00:03:00 things like that but that was not the starting point but so what what is this journey to see is that in
00:03:07 high school is that in college that was in high school yeah so and then that was it was really about trying to be able to
00:03:16 do more powerful things than what Pascal could do and also to learn a different world so he was really confusing me with
00:03:21 pointers and the syntax and everything and it took a while but Pascal is much more principled in various ways sees
00:03:33 more I mean it has its historical roots but it's it's not as easy to learn with pointers there's this memory management
00:03:41 thing that you have to become conscious of is that the first time you start to understand that there's resources that
00:03:46 you're supposed to manage well so you have that in Pascal as well but in Pascal these like the carrot instead of
00:03:52 the star and there's some small differences like that but it's not about pointer arithmetic and and and see it
00:03:58 you end up thinking about how things get laid out in memory a lot more and so in Pascal you have allocating and
00:04:05 deallocating and owning the the memory but just the programs are simpler and you don't have to well for example
00:04:13 Pascal has a string type and so you can think about a string instead of an array of characters which are consecutive in
00:04:18 memory so it's a little bit of a higher level abstraction so let's get into it let's talk about LLVM si Lang and compilers
00:04:28 sure so can you tell me first what I love the a messy laying our and how is it that you find yourself the creator
00:04:36 and lead developer one of the most powerful compiler optimization systems than used today sure so I guess they're
00:04:45 different things so let's start with what is a compiler it's a is that a good place to start
00:04:50 what are the phases of a compiler where the parts yeah what is it so what does even a compiler are used for so the way
00:04:56 the way I look at this is you have a two sided problem of you have humans that need to write code and then you have
00:05:02 machines that need to run the program that the human wrote and for lots of reasons the humans don't want to be
00:05:07 writing in binary and want to think about every piece of hardware and so at the same time that you have lots of
00:05:13 humans you also have lots of kinds of hardware and so compilers are the art of allowing humans to think of the level of
00:05:19 abstraction that they want to think about and then get that program get the thing that they wrote to run on a
00:05:27 specific piece of hardware and the interesting and exciting part of all this is that there's now lots of
00:05:32 different kinds of hardware chips like x86 and PowerPC and arm and things like that but also high-performance
00:05:38 accelerators for machine learning and other things like that or also just different kinds of hardware GPUs these
00:05:43 are new kinds of hardware and at the same time on the programming side of it you have your basic UFC you have
00:05:50 JavaScript you have Python you so if you have like lots of other languages that are all trying to talk to the human in a
00:05:55 different way to make them more expressive and capable and powerful and so compilers are the thing that goes
00:06:04 from one to the other no and then from the very beginning end to end and so you go from what the human wrote and
00:06:10 programming languages end up being about expressing intent not just for the compiler and the hardware but the
00:06:18 programming languages job is really to to capture an expression of what the programmer wanted that then can be
00:06:25 maintained and adapted and evolved by other humans as well as by the interpreter by the compiler so so when
00:06:32 you look at this problem you have on one hand humans which are complicated and you have hardware which is complicated
00:06:38 until compilers typically work in multiple phases and so the software engineering challenge that you have here
00:06:45 is try to get maximum reuse out of the the amount of code that you write because this these compilers are very
00:06:50 complicated and so the way it typically works out is that you have something called a front-end or a parser that is
00:06:57 language specific and so you'll have a C parser and that's what clang is or C++ or JavaScript or Python or whatever
00:07:05 that's the front-end then you'll have a middle part which is often the optimizer and then you'll have a late part which
00:07:14 is hardware specific and so compilers end up there's many different layers often but these three big groups are
00:07:21 very common in compilers and what LLVM is trying to do is trying to standardize that middle and last part and so one of
00:07:28 the cool things about LLVM is that there are a lot of different languages that compile through to it and so things like
00:07:37 swift but also julia rust clang for C C++ objective-c like these are all very different languages and they can all use
00:07:43 the same optimization infrastructure which gets better performance and the same code generation for structure for
00:07:50 hardware support and so LVM is really that that layer that is common that all these different specific compilers can
00:07:58 use and is that is it a standard like a specification or is it literally an implementation it's an implementation
00:08:05 and so it's I think there's a couple different ways of looking at write because it depends on what which angle
00:08:09 you're looking at it from LVM ends up being a bunch of code okay so it's a bunch of code that people
00:08:16 reuse and they build compilers with we call it a compiler infrastructure because it's kind of the underlying
00:08:20 platform that you build a concrete compiler on top of but it's also a community and the LVM community is
00:08:27 hundreds of people that all collaborate and one of the most fascinating things about LVM over the course of time is
00:08:34 that we've managed somehow to successfully get harsh competitors in the commercial space to collaborate on
00:08:41 shared infrastructure and so you have Google and Apple you have AMD and Intel you've Nvidia and
00:08:50 d on the graphics side you have prey and everybody else doing these things and like all these companies are
00:08:56 collaborating together to make that shared infrastructure really really great and they do this not other
00:09:01 businesses or heart but they do it because it's in their commercial interests of having really great
00:09:05 infrastructure that they can build on top of and facing the reality that it's so expensive that no one company even
00:09:12 the big companies no one company really wants to implement it all themselves expensive or difficult both that's a
00:09:19 great point because it's also about the skill sets right and these the skill sets are very hard hard to find how big
00:09:29 is the LLVM it always seems like with open-source projects the kind you know LLVM open source yes it's open source
00:09:36 it's about it's 19 years old now so it's fairly old it seems like the magic often happens within a very small circle of
00:09:44 people yes I'd like at least the early birth and whatever yes so the LVM came from a university project and so I was
00:09:52 at the University of Illinois and there it was myself my advisor and then a team of two or three research students in the
00:09:59 research group and we built many of the core pieces initially I then graduated went to Apple and Apple brought it to
00:10:07 the products first in the OpenGL graphics stack but eventually to the C compiler realm and eventually built
00:10:13 clang and eventually built Swift in these things along the way building a team of people that are really amazing
00:10:19 compiler engineers that helped build a lot of that and so as it was gaining momentum and as Apple was using it being
00:10:25 open source in public and encouraging contribution many others for example at Google came in and started contributing
00:10:32 and some cases Google effectively owns clang now because it cares so much about C++ and the evolution of that that
00:10:39 ecosystem and so it's a vesting a lot in the C++ world and the tooling and things like that
00:10:47 and so likewise Nvidia cares a lot about CUDA and so CUDA uses clang and uses LVM for for graphics and GPGPU and so when
00:10:58 you first started as a master's project I guess did you think is gonna go as far as it went
00:11:06 were you  crazy ambitious about it no seems like a really difficult undertaking a brave one yeah no it was
00:11:12 nothing like that so I mean my goal when I went to University of Illinois was to get in and out with the non thesis
00:11:18 masters in a year and get back to work so I was not I was not planning to stay for five years and and build this
00:11:26 massive infrastructure I got nerd sniped into staying and a lot of it was because Elvin was fun I was building cool stuff
00:11:33 than learning really interesting things and facing will suffer engineering challenges but also learning how to work
00:11:40 in a team and things like that I had worked at many companies as interns before that but it was really a
00:11:46 different a different thing to have a team of people that were working together and try and collaborate in
00:11:51 version control and it was it was just a little bit different like I said I just talked to Don Knuth and he believes that
00:11:56 2% of the world population have something weird with their brain that they're geeks they understand computers
00:12:02 to connect with computer he put it exactly 2 percent okay so this specific guy is very specific he says I can't
00:12:11 prove it but it's very empirical II there is there something that attracts you to the idea of optimizing code and
00:12:18 he seems like that's one of the biggest coolest things about oh yeah that's one of the major things it does so I got
00:12:26 into that because of a person actually so when I was in my undergraduate I had an advisor or a professor named Steve
00:12:34 Bechtel and he I went to this little tiny private school we there were like seven or nine people in my computer
00:12:42 science department students in my in my class so it was a very tiny very very small school it was a kind of a wart on
00:12:50 the side of the math department kind of a thing at the time I think it's evolved a lot in the many years since then but
00:12:57 but Steve egg Dahl was a compiler guy and he was super passionate and he his passion rubbed off on me and one of the
00:13:05 things I like about compilers is that they're large complicated software pieces and so one of the culminating classes
00:13:14 is that many computer science departments at least at the time did was to say that you take algorithms and data
00:13:19 structures in all these core classes but then the compilers class was one of the last classes you take because it pulls
00:13:25 everything together and then you work on one piece of code over the entire semester and and so you keep building on
00:13:32 your own work which is really interesting it's also very challenging because in many classes if you don't get
00:13:38 a project done you just forget about it and move on to the next one and get your you know your B or whatever it is but
00:13:43 here you have to live with the decisions you make and continue to reinvest in it and I really like that and and so I did
00:13:51 a extra study project within the following semester and he was just really great and he was also a great
00:13:58 mentor in a lot of ways and so from from him and from his advice he encouraged me to go to graduate school I wasn't super
00:14:03 excited about going grad school I wanted the master's degree but I didn't want to be in academic and but like I said I
00:14:11 kind of got tricked into saying and was having a lot of fun and I definitely do not regret it what aspects of compilers
00:14:18 were the things you connected with so LVM there's also the other part this is really interesting if you're interested
00:14:26 in languages is parsing and you know just analyzing like yeah analyzing language breaking it out parsing so on
00:14:32 was that interesting to you were you more engine optimization for me it was more so I'm I'm not really a math person
00:14:39 I can do math I understand some bits of it when I get into it but math is never the thing that that attracted me and so
00:14:46 a lot of the parser part of the compiler has a lot of good formal theories that dawn for example knows quite well still
00:14:54 waiting for his book on that but but the but I just like building a thing and and seeing what it could do and exploring
00:15:00 and getting it to do more things and then setting new goals and reaching for them and and with in the case of
00:15:07 component in the case of LVM when I start work on that my research advisor that I was working for was a compiler
00:15:15 guy and so he and I specifically found each other because we're both interested in compilers and so I started working
00:15:19 with them and taking his class and a lot of LLVM initially was it's fun implementing all the standard algorithms
00:15:25 and all the all the things that pea have been talking about and were well-known and they were in the the
00:15:30 curricula for Advanced Studies and compilers and so just being able to build that was really fun and I was
00:15:37 learning a lot by instead of reading about it just building and so I enjoyed that so he said compositor these complicated
00:15:45 systems can you even just with language tried to describe you know how you turn a C++ program yes into code like what
00:15:54 are the hard parts why is this hard so I'll give you examples of the hard parts Illinois so C++ is a very complicated
00:16:01 programming way which is something like 1400 pages in the spec so people as possible as crazy complicated paas what
00:16:09 makes a language complicated in terms of what's syntactically like us so it's what they call syntax so the actual how
00:16:17 the character is arranged yes it's also semantics how it behaves it's also in the case of C++ there's a huge amount of
00:16:24 history C was supposed to build on top of C you play that forward and then a bunch of suboptimal in some cases
00:16:30 decisions were made and they compound and then more and more and more things keep getting added to C++ and it will
00:16:37 probably never stop but the language is very complicated from that perspective and so the interactions between
00:16:42 subsystems is very complicated there's just a lot there and when you talk about the front end one of the major
00:16:48 challenges which clang as a project the the C C++ compiler that I built I and many people built one of the challenges
00:16:58 we took on was we looked at GCC ok GCC at the time was like a really good industry standardized compiler that had
00:17:05 really consolidated a lot of the other compilers in the world and was was a standard but it wasn't really great for
00:17:11 research the design was very difficult to work with and it was full of global variables and other other things that
00:17:18 made it very difficult to reuse in ways that it wasn't originally designed for and so with claying one of the things
00:17:24 what we wanted to do is push forward on better user interface so make error messages that are just better than GCC's
00:17:29 and that that's actually hard because you have to do a lot of bookkeeping in an efficient way
00:17:33 today I'll do that we want to make compile-time better and so compile-time is about making it efficient which is
00:17:38 also really hard when you're keeping track of extra information we wanted to make new tools available so refactoring
00:17:46 tools and other analysis tools the the GCC never supported also leveraging the extra information we kept but enabling
00:17:54 those new classes the tools that then get built into IDs and so that's been one of the one of the areas that clang
00:18:01 has really helped push the world forward in the tooling for C and C++ and things like that but C++ and the front-end
00:18:08 piece is complicated and you have to build syntax trees and you have to check every rule in the spec and you have to
00:18:14 turn that back into an error message to the humor humor that the human can understand when they do something wrong
00:18:19 but then you start doing the what's called lowering so going from C++ in the way that it represents code down to the
00:18:25 machine and when you do that there's many different phases you go through often there are I think LLVM something
00:18:34 like 150 different what are called passes in the compiler that the code passed passes through and these get
00:18:41 organized in very complicated ways which affect the generated code in performance and compile time and many of the things
00:18:47 what are they passing through so after you do the clang parsing what's what's the graph what does it look like what's
00:18:57 the data structure here yeah so in in the parser it's usually a tree and it's called an abstract syntax tree and so
00:19:04 the idea is you you have a node for the plus that the human wrote in their code or the function call you'll have a node
00:19:10 for call with the function that they call and the arguments they pass things like that this then gets lowered into
00:19:17 what's called an intermediate representation and intermediate representations are like LVM has one and
00:19:25 there it's a it's what's called a control flow graph and so you represent each operation in the program as a very
00:19:33 simple like this is gonna add two numbers this is gonna multiply two things maybe we'll do a call but then
00:19:39 they get put in what are called blocks and so you get blocks of these straight line operations or instead of being
00:19:46 nested like in a tree it's straight line operation and so there's a sequence and ordering to these operations and then in the
00:19:52 block we're outside the block that's within the block and so it's a straight line sequence of operations within the
00:19:57 block and then you have branches like conditional branches between blocks and so when you write a loop for example in
00:20:06 a syntax tree you would have a four node like for a for statement and I see like language you'd out a four node and you
00:20:12 have a pointer to the expression for the initializer a pointer to the expression for the increment a pointer to the
00:20:17 expression for the comparison a pointer to the body okay and these are all nested underneath it in a control flow
00:20:24 graph you get a block for the code that runs before the loop so the initializer code then you have a block for the body
00:20:32 of the loop and so the the body of the loop code goes in there but also they increment and other things like that and
00:20:36 then you have a branch that goes back to the top and a comparison and branch that goes out and so it's more of a assembly
00:20:44 level kind of representation but the nice thing about this level of representation is it's much more
00:20:49 language independent and so there's lots of different kinds of languages with different kinds of you know JavaScript
00:20:56 has a lot of different ideas of what is false for example and all that can stay in the front end but then that middle
00:21:04 part can be shared across all those how close is that intermediate representation to ten yuan that works
00:21:12 for example is they are they because everything described as a kind of neural network graph right yeah that's all we
00:21:18 need a neighbor's or what they're they're quite different in details but they're very similar and idea so one of
00:21:24 the things that normal networks do is they learn representations for data at different levels of abstraction right
00:21:31 and then they transform those through layers right so the compiler does very similar things but one of the things the
00:21:38 compiler does is it has relatively few different representations or a neural network often as you get deeper for
00:21:43 example you get many different representations in each you know layer or set of ops is transforming between
00:21:50 these different representations and compiler often you get one representation and they do many
00:21:55 transformations to it and these transformations are often applied iteratively and for programmers there's familiar
00:22:03 types of things for example trying to find expressions inside of a loop and pulling them out of a loop so if they
00:22:09 execute four times or a fine redundant computation or find constant folding or other simplifications turning
00:22:18 you know 2 times X into X shift left by one and and things like this or all all all the examples of the things that
00:22:24 happen but compilers end up getting a lot of theorem proving and other kinds of algorithms that try to find
00:22:29 higher-level properties of the program that then can be used by the optimizer cool so what's like the biggest bang for
00:22:38 the buck with optimization what's there yeah well no not even today at the very beginning the 80s I don't know but yeah
00:22:44 so for the 80s a lot of it was things like register allocation so the idea of in in a modern like a microprocessor
00:22:51 what you'll end up having is you're having memory which is relatively slow and then you have registers relatively
00:22:58 fast but registers you don't have very many of them ok and so when you're writing a bunch of code you're just
00:23:04 saying like compute this put it in temporary variable compute those compute this compute this put in temporary well
00:23:08 I have a loop I have some other stuff going on well now you're running on an x86 like a
00:23:14 desktop PC or something well it only has in some cases some modes eight registers right and so now the compiler has to
00:23:22 choose what values get put in what registers at what points in the program and this is actually a really big deal
00:23:28 so if you think about you have a loop and then an inner loop to execute millions of times maybe if you're doing
00:23:33 loads and stores inside that loop then it's gonna be really slow but if you can somehow fit all the values inside that
00:23:39 loop and registers now it's really fast and so getting that right requires a lot of work because there's many different
00:23:46 ways to do that and often what the compiler ends up doing is it ends up thinking about things in a different
00:23:51 representation than what the human wrote all right you wrote into X well the compiler thinks about that as four
00:23:57 different values each which have different lifetimes across the function that it's in and each of those could be
00:24:03 put in a register or memory or different memory or maybe in some parts of the code recomputed instead of stored and
00:24:09 reloaded and there are many of these different kinds of techniques that can be used so it's adding almost like a
00:24:16 time-dimension - it's trying to trying to optimize across time so considering when when you're programming you're not
00:24:22 thinking and yeah absolutely and so the the RISC era made thing this so so RISC chips Ras see the the risks
00:24:33 risk chips as opposed to sisk chips the risk chips made things more complicated for the compiler because what they ended
00:24:41 up doing is ending up adding pipelines to the processor where the processor can do more than one thing at a time but
00:24:46 this means that the order of operations matters a lot and so one of the classical compiler techniques that you
00:24:53 use is called scheduling and so moving the instructions around so that the processor can act like keep its
00:24:58 pipelines full instead of stalling and getting blocked and so there's a lot of things like that that are kind of bread
00:25:03 and butter a compiler techniques have been studied a lot over the course of decades now but the engineering side of
00:25:09 making them real is also still quite hard and you talk about machine learning this is this is a huge opportunity for
00:25:15 machine learning because many of these algorithms are full of these like hokey hand-rolled heuristics which work well
00:25:21 on specific benchmarks we don't generalize and full of magic numbers and you know I hear there's some techniques
00:25:28 that are good at handling that so what would be the if you were to apply machine learning to this what's the
00:25:34 thing you try to optimize is it ultimately the running time you can pick your metric and there's there's running
00:25:43 time there's memory use there's there's lots of different things that you can optimize for code code size is another
00:25:47 one that some people care about in the embedded space is this like the thinking into the future or somebody actually
00:25:56 been crazy enough to try to have machine learning based parameter tuning for optimization of compilers so this is
00:26:03 something that is I would say research right now there are a lot of research systems that have been applying search
00:26:10 in various forums and using reinforcement learning is one form but also brute force search has been tried
00:26:15 for a quite a while and usually these are in small small problem spaces so find the optimal way to code generate a
00:26:23 matrix multiply for a GPU write something like that where we say there there's a lot of
00:26:30 design space of do you unroll uppsala do you execute multiple things in parallel and there's many different confounding
00:26:36 factors here because graphics cards have different numbers of threads and registers and execution ports and memory
00:26:42 bandwidth and many different constraints to interact in nonlinear ways and so search is very powerful for that and it
00:26:50 gets used in in certain ways but it's not very structured this is something that we need we as an industry need to
00:26:58 fix these set ATS but like so have there been like big jumps and improvement and optimization yeah yeah yes since then
00:27:06 what's yeah so so it's largely been driven by hardware so hartwell hardware and software so in the mid-90s Java
00:27:14 totally changed the world right and and I'm still amazed by how much change was introduced by the way or in a good way
00:27:21 so like reflecting back Java introduced things like it all at once introduced things like JIT compilation
00:27:27 none of these were novel but it pulled it together and made it mainstream and and made people invest in it JIT
00:27:33 compilation garbage collection portable code safe code say like memory safe code like a very dynamic dispatch execution
00:27:42 model like many of these things which had been done in research systems and had been done in small ways and various
00:27:47 places really came to the forefront really changed how things worked and therefore changed the way people thought
00:27:53 about the problem javascript was another major world change based on the way it works but also on the hardware side of
00:28:03 things multi-core and vector instructions really change the problem space and are very they don't remove any
00:28:11 of the problems that composers faced in the past but they they add new kinds of problems of how do you find enough work
00:28:20 to keep a four-wide vector busy right or if you're doing a matrix multiplication how do you do different columns out of
00:28:26 that matrix in at the same time and how do you maximally utilize the the arithmetic compute that one core has and
00:28:32 then how do you take it to multiple cores and how did the whole virtual machine thing change the compilation
00:28:39 pipeline yeah so so what what the java virtual machine does is it splits just like I've talked about
00:28:45 before where you have a front-end that parses the code and then you have an intermediate representation that gets
00:28:50 transformed what Java did was they said we will parse the code and then compile to what's known as Java bytecode and
00:28:57 that bytecode is now a portable code representation that is industry-standard and locked down and can't change and
00:29:04 then the the back part of the compiler the the does optimization and code generation can now be built by different
00:29:11 vendors okay and Java bytecode can be shipped around across the wire its memory safe and relatively trusted and
00:29:18 because of that it can run in the browser and that's why it runs in the browser yeah right and so that way you
00:29:23 can be in you know again back in the day you would write a Java applet and you use as a little as a web developer you'd
00:29:30 build this mini app that run a web page well a user of that is running a web browser on their computer you download
00:29:36 that that Java bytecode which can be trusted and then you do all the compiler stuff on your machine so that you know
00:29:42 that you trust that that was that a good idea a bad idea it's great idea I mean it's great idea for certain problems and
00:29:48 I'm very much believe for the technologies itself neither good nor bad it's how you apply it you know this
00:29:55 would be a very very bad thing for very low levels of the software stack but but in terms of solving some of these
00:30:00 software portability and transparency your portability problems I think it's been really good now Java ultimately
00:30:07 didn't win out on the desktop and like there are good reasons for that but it's been very successful on servers and in
00:30:13 many places it's been a very successful thing over over decades so what has been ll VMs and ceilings improvements in
00:30:28 optimization that throughout its history what are some moments we get set back I'm really proud of what's been
00:30:34 accomplished yeah I think that the interesting thing about LLVM is not the innovations in compiler research it has
00:30:42 very good implementations of various important algorithms no doubt and and a lot of really smart people have worked
00:30:49 on it but I think that the thing was most profound about LLVM is that through standardization it made things possible too
00:30:55 otherwise wouldn't have happened okay and so interesting things that have happened with LVM for example sony has
00:31:02 picked up lv m and used it to do all the graphics compilation in their movie production pipeline and so now they're
00:31:07 able to have better special effects because of LVN that's kind of cool that's not what it was designed for
00:31:14 right but that's that's the sign of good infrastructure when it can be used in ways it was never designed for because
00:31:20 it has good layering and software engineering and it's composable and things like that just where as you said
00:31:27 it differs from GCC yes GCC is also great in various ways but it's not as good as a infrastructure technology it's
00:31:34 it's you know it's really a C compiler or it's or it's a fortunate compiler it's not it's not infrastructure in the
00:31:40 same way is it now you can tell I don't know what I'm talking about because I'm sick eep saying si Lang you can you
00:31:47 could always tell when a person is close by the way pronounce something I'm I don't think have I ever used Clank
00:31:54 entirely possible have you well so you've used code it's generated probably so clang is an Alabama used to compile
00:32:03 all the apps on the iPhone effectively and the OS is it compiles Google's production server applications let's use
00:32:13 to build my GameCube games and PlayStation 4 and things like that I was a user I have but just everything I've
00:32:21 done that I experienced for Linux has been I believe always GCC yeah I think Linux still defaults to GCC and is there
00:32:29 a reason for that there's a big it's a combination of technical and social reasons many GC likes developers do you
00:32:38 do use clang but the distributions for lots of reasons use GCC historically and they've not
00:32:45 switched yeah that and it's just anecdotally online it seems that LLVM has either reached the level GCC or
00:32:52 superseded on different features or whatever the way I would say it is that there was there so close it doesn't
00:32:57 matter yeah exactly like there's a slightly better in some way slightly worse than otherwise but it doesn't
00:33:01 actually really matter anymore that level so in terms of optimization breakthroughs it's just been solid
00:33:09 incremental work yeah yeah which which is which describes a lot of compilers there are the hard thing about
00:33:15 compilers in my experience is the engineering the software engineering making it so that you can have hundreds
00:33:21 of people collaborating on really detailed low-level work and scaling that and that's that's really hard and that's
00:33:29 one of the things I think Alabama's done well and that kind of goes back to the original design goals with it to be
00:33:36 modular and things like that and incidentally I don't want to take all the credit for this right I mean some of
00:33:42 the the best parts about LLVM is that it was designed to be modular and when I started I would write for example a
00:33:47 register allocator and then some a much smarter than me would come in and pull it out and replace it with something
00:33:52 else that they would come up with and because it's modular they were able to do that and that's one of the challenges
00:33:59 with what GCC for example is replacing subsystems is incredibly difficult it can be done but it wasn't designed for
00:34:05 that and that's one of the reasons the LVM has been very successful in the research world as well but in the in the
00:34:12 community sense Widow van rossum right from Python just retired from what is it benevolent dictator for life right so in
00:34:23 managing this community of brilliant compiler folks is there that did it at for a time at least following you to
00:34:32 approve things oh yeah so I mean I still have something like an order of magnitude more patches in LVM than
00:34:41 anybody else and many of those I wrote myself but he's still right I mean you still he's still close to the two though
00:34:49 I don't know what the expression is to the metal you still write code yes alright good not as much as I was able
00:34:55 to in grad school but that's important part of my identity but the way the LLVM has worked over time is that when I was
00:35:01 a grad student I could do all the work and steer everything and review every patch and make sure everything was done
00:35:08 exactly the way my opinionated sense felt like it should be done and that was fine but I think scale you can't do that
00:35:15 right and so what ends happening as LVM has a hierarchical system of what's called code owners
00:35:22 these code owners are given the responsibility not to do all the work not necessarily to review all the
00:35:27 patches but to make sure that the patches do get reviewed and make sure that the right things happening
00:35:32 architectural e in their area and so what you'll see is you'll see that for example hardware manufacturers end up
00:35:40 owning the the the hardware specific parts of their their their hardware that's very common leaders in the
00:35:47 community that have done really good work naturally become the de facto owner of something and then usually somebody
00:35:54 else's like how about we make them the official code owner and then and then we'll have somebody to make sure the
00:35:59 whole patch does get reviewed in a timely manner and then everybody's like yes that's obvious and then it happens
00:36:04 right and usually this is a very organic thing which is great and so I'm nominally the top of that stack still
00:36:10 but I don't spend a lot of time reviewing patches what I do is I help negotiate a lot of the the technical
00:36:17 disagreements that end up happening and making sure that the community as a whole makes progress and is moving in
00:36:23 the right direction and and doing that so we also started a non-profit and six years ago seven years ago it's times
00:36:32 gone away and the nonprofit the the LVM foundation nonprofit helps oversee all the business sides of things and make
00:36:38 sure that the events that the Elven community has are funded and set up and run correctly and stuff like that
00:36:44 but the foundation is very much stays out of the technical side of where where the project was going right sounds like
00:36:53 a lot of it is just organic just yeah well and this is Alabama is almost twenty years old which is hard to
00:36:57 believe somebody point out to me recently that LVM is now older than GCC was when Olivia started right so time
00:37:07 has a way of getting away from you but the good thing about that is it has a really robust
00:37:12 really amazing community of people that are in their professional lives spread across lots of different companies but
00:37:19 it's a it's a community of people that are interested in similar kinds of problems and have been working together
00:37:25 effectively for years and have a lot of trust and respect for each other and even if they don't always agree that you
00:37:29 know we're we'll find a path forward so then in a slightly different flavor of effort you
00:37:37 started at Apple in 2005 with the task of making I guess LLVM production ready and then eventually 2013 through 2017
00:37:46 leading the entire developer tools department we were talking about LLVM Xcode Objective C to Swift so in a quick
00:37:58 overview of your time there what were the challenges first of all leading such a huge group of developers what was the
00:38:06 big motivator dream mission behind creating Swift the early birth of it's from objective-c and so on and Xcode
00:38:15 well yeah so these are different questions yeah I know what about the other stuff I'll stay I'll stay on the
00:38:21 technical side then we could talk about the big team pieces yeah that's okay sure so he has to really oversimplify
00:38:30 many years of hard work via most started joined Apple became a thing we became successful and became deployed but then
00:38:37 there was a question about how how do we actually purse the source code so LVM is that back part the optimizer and the
00:38:43 code generator and Alvin was really good for Apple as it went through a couple of hundred transitions I joined right at
00:38:48 the time of the Intel transition for example and 64-bit transitions and then the transition to almost the iPhone and
00:38:55 so LVM was very useful for some of these kinds of things but at the same time there's a lot of questions around
00:39:00 developer experience and so if you're a programmer pounding out at the time of objective-c code the error message you
00:39:06 get the compile time the turnaround cycle the the tooling and the IDE were not great we're not as good as it could
00:39:17 be and so you know as as I occasionally do I'm like well okay how hard is it to write a C compiler and so I I'm not
00:39:22 gonna commit to anybody I'm not gonna tell anybody I'm just gonna just do it on nice and weekends and start working
00:39:29 on it and then you know I built up in C there's a thing called the preprocessor which people don't like but it's
00:39:35 actually really hard and complicated and includes a bunch of really weird things like try graphs and other stuff like
00:39:40 that that are they're really nasty and it's the crux of a bunch of the perform issues in the compiler and I'm started
00:39:47 working on the parser and kind of got to the point where I'm like ah you know what we could actually do this this
00:39:50 everybody saying that this is impossible to do but it's actually just hard it's not impossible and eventually told my
00:39:58 manager about it and he's like oh wow this is great we do need to solve this problem oh this is great we can like get
00:40:03 you one other person to work with you on this you know and slowly a team is formed and it starts taking off and c++
00:40:11 for example huge complicated language people always assume that it's impossible to implement and it's very
00:40:17 nearly impossible but it's just really really hard and the way to get there is to build it one piece at a time
00:40:24 incrementally and and there that was only possible because we were lucky to hire some really exceptional engineers
00:40:29 that that knew various parts of it very well and and could do great things Swift was kind of a similar thing so
00:40:38 Swift came from we were just finishing off the first version of C++ support in M clang and C++ is a very formidable and
00:40:47 very important language but it's also ugly in lots of ways and you can't influence C++ without thinking there has
00:40:54 to be a better thing right and so I started working on Swift again with no hope or ambition that would go anywhere
00:41:00 just  let's see what could be done let's play around with this thing it was you know me in my spare time not telling
00:41:08 anybody about it kind of a thing and it made some good progress I'm like actually it would make sense to do this
00:41:12 at the same time I started talking with the senior VP of software at the time a guy named Burt Ron stole a and Burt Ron
00:41:19 was very encouraging he was like well you know let's let's have fun let's talk about this and he was a little bit of a
00:41:24 language guy and so he helped guide some of the the early work and encouraged me and like got things off the ground and
00:41:32 eventually I've told other to like my manager and told other people and and it started making progress the the
00:41:41 complicating thing was Swift was that the idea of doing a new language is not obvious to anybody including myself
00:41:49 and the tone at the time was that the iPhone was successful because of objective-c right Oh interesting in a
00:41:56 practice site of or just great because it and and you have to understand that at the time
00:42:03 Apple was hiring software people that loved Objective C right and it wasn't that they came despite Objective C they
00:42:09 loved Objective C and that's why they got hired and so you had a software team that the leadership and in many cases
00:42:15 went all the way back to next where Objective C really became real and so they quote-unquote grew up writing
00:42:24 Objective C and many of the individual engineers all were hired because they loved Objective C and so this notion of
00:42:31 okay let's do new language was kind of heretical in many ways right meanwhile my sense was that the outside community
00:42:37 wasn't really in love with Objective C some people were and some of the most outspoken people were but other people
00:42:43 were hitting challenges because it has very sharp corners and it's difficult to learn and so one of the challenges of
00:42:50 making Swift happen that was totally non-technical is the the social part of what do we do like if we do a new
00:43:00 language which at Apple many things happen that don't ship right so if we if we ship it what what what is the metrics
00:43:06 of success why would we do this why wouldn't we make Objective C better if object C has problems let's file off
00:43:12 those rough corners and edges and one of the major things that became the reason to do this was this notion of safety
00:43:20 memory safety and the way Objective C works is that a lot of the object system and everything else is built on top of
00:43:28 pointers and C Objective C is an extension on top of C and so pointers are unsafe and if you get rid of the
00:43:35 pointers it's not Objective C anymore and so fundamentally that was an issue that you could not fix safety or memory
00:43:44 safety without fundamentally changing the language and so once we got through that part of the mental process and the
00:43:52 thought process it became a design process of saying okay well if we're gonna do something new what what is good
00:43:57 like how do we think about this and what do we like and what are we looking for and that that was a very different phase
00:44:03 of it so well what are some design choices early on and Swift like we're talking about braces are you making a
00:44:12 type language or not all those kinds of things yeah so some of those were obvious given the context so a types
00:44:18 language for example objective sees a typed language and going with an untyped language wasn't really seriously
00:44:25 considered we wanted we want the performance and we wanted refactoring tools and other things like that to go
00:44:30 with type languages quick dumb question yeah was it obvious I think it would be a dumb question but
00:44:36 was it obvious that the language has to be a compiled language not and yes that's not a dumb question earlier I
00:44:44 think late 90s Apple is seriously considered moving its development experience to Java but this was started
00:44:53 in 2010 which was several years after the iPhone it was when the iPhone was definitely on an upward trajectory and
00:44:59 the iPhone was still extremely and is still a bit memory constrained right and so being able to compile the code and
00:45:06 then ship it and then have having standalone code that is not JIT compiled was is a very big deal and it's very
00:45:15 much part of the apple value system now javascript is also a thing right I mean it's not it's not that this is exclusive
00:45:21 and technologies are good depending on how they're applied right but in the design of Swift saying like how can we
00:45:28 make Objective C better right Objective C is statically compiled and that was the contiguous natural thing to do just
00:45:34 skip ahead a little bit now go right back just just as a question as you think about today in 2019 yeah in your
00:45:42 work at Google if tons of phone so on is again compilations static compilation the right there's still the right thing
00:45:51 yes so the the funny thing after working on compilers for a really long time is that and one of this is one of the
00:45:59 things that LVM has helped with is that I don't look as comp compilations being static or dynamic or interpreted or not
00:46:08 this is a spectrum okay and one of the cool things about Swift is that Swift is not just statically compiled
00:46:13 it's actually dynamically compiled as well and it can also be interpreted that nobody's actually done that and so what
00:46:20 what ends up happening when you use Swift in a workbook for example in Calabria and Jupiter is it's actually
00:46:26 dynamically compiling the statements as you execute them and so let's gets back to the software engineering problems
00:46:34 right where if you layer the stack properly you can actually completely change how and when things get compiled
00:46:40 because you have the right abstractions there and so the way that a collab workbook works with Swift is that we start typing
00:46:49 into it it creates a process a UNIX process and then each line of code you type in it compiles it through the Swift
00:46:55 compiler there's the front end part and then sends it through the optimizer JIT compiles machine code and then injects
00:47:04 it into that process and so as you're typing new stuff it's putting it's like squirting a new code and overriding and
00:47:10 replacing an updating code in place and the fact that it can do this is not an accident like Swift was designed for
00:47:17 this but it's an important part of how the language was set up and how it's layered and and this is a non-obvious
00:47:22 piece and one of the things with Swift that was for me a very strong design point is to make it so that you can
00:47:30 learn it very quickly and so from a language design perspective the thing that I always come back to is this UI
00:47:36 principle of progressive disclosure of complexity and so in Swift you can start by saying print quote hello world quote
00:47:46 right and there's no /n just like Python one line of code no main no no header files no header files no public static
00:47:53 class void blah blah blah string like Java has right so one line of code right and you can teach that and it works
00:47:59 great they can say well let's introduce variables and so you can declare a variable with far so VAR x equals four
00:48:05 what is a variable you can use xx plus one this is what it means then you can say we'll have a control flow well this
00:48:11 is what an if statement is this is what a for statement is this is what a while statement is then you can say let's
00:48:18 introduce functions right and and many languages like Python have had this this kind of notion of let's introduce small
00:48:23 things and they can add complex then you can introduce classes and then you can add generics I'm against the
00:48:29 Swift and then you can in modules and build out in terms of the things that you're expressing but this is not very
00:48:36 typical for compiled languages and so this was a very strong design point and one of the reasons that Swift in general
00:48:42 is designed with this factoring of complexity in mind so that the language can express powerful things you can
00:48:48 write firmware in Swift if you want to but it has a very high-level feel which is really this perfect blend because
00:48:56 often you have very advanced library writers that want to be able to use the the nitty-gritty details but then other
00:49:02 people just want to use the libraries and work at a higher abstraction level it's kind of cool that I saw that you
00:49:09 can just enter a probability I don't think I pronounced that word enough but you can just drag in Python it's just a
00:49:18 string you can import like I saw this in the demo yeah I'm pointing out but like how do you make that happen
00:49:23 yeah what's what's up yeah say is that as easy as it looks or is it yes that's not that's not a
00:49:29 stage magic hack or anything like that then I I don't mean from the user perspective I mean from the
00:49:33 implementation perspective to make it happen so it's it's easy once all the pieces are in place the way it works so if you
00:49:39 think about a dynamically typed language like Python right you can think about it as in two different ways you can say it
00:49:46 has no types right which is what most people would say or you can say it has one type right and you could say has one
00:49:52 type and it's like the Python object mm-hmm and the Python object gets passed around and because there's only one type
00:49:59 its implicit okay and so what happens with Swift and Python talking to each other Swift has lots of types right has
00:50:05 a raise and it has strings and all like classes and that kind of stuff but it now has a Python object type right so
00:50:12 there is one Python object type and so when you say import numpy what you get is a Python object which is the numpy
00:50:22 module then you say NPRA it says okay hey hey Python object I have no idea what you are give me your array member
00:50:29 right okay cool it just it just uses dynamic stuff talks to the Python interpreter and says hey Python what's
00:50:34 the daughter a member in the that Python object it gives you back another Python object and now you say
00:50:39 parentheses for the call and the arguments are gonna pass and so then it says hey a Python object that is the
00:50:46 result of NPR a call with these arguments right again calling into the Python interpreter to do that work and
00:50:53 so right now this is all really simple and if you if you dive into the code what you'll see is that the the Python
00:50:58 module and Swift is something like twelve hundred lines of code or something is written in pure Swift it's
00:51:05 super simple and it's and it's built on top of the c interoperability because just talks to the Python interpreter but
00:51:11 making that possible required us to add two major language features to Swift to be able to express these dynamic calls
00:51:17 and the dynamic member lookups and so what we've done over the last year is we've proposed implement standardized
00:51:24 and contributed new language features to the Swift language in order to make it so it is really trivial right and this
00:51:32 is one of the things about Swift that is critical to this but for tens flow work which is that we can actually add new
00:51:38 language features and the bar for adding those is high but it's it's what makes it possible so you know Google doing
00:51:45 incredible work on several things including tensorflow the test flow 2.0 or whatever leading up
00:51:55 to 2.0 has by default in 2.0 has eager execution in yet in order to make code optimized for GPU or TP or some of these
00:52:04 systems computation needs to be converted to a graph so what's that process like what are the challenges
00:52:10 there yeah so I I'm tangentially involved in this but the the way that it works with autograph is that
00:52:20 you mark your your function with the decorator and when Python calls that that decorator is invoked and then it
00:52:28 says before I call this function you can transform it and so the way autograph works is as far as I understand as it
00:52:34 actually uses the Python parser to go parse that turn into a syntax tree and now apply compiler techniques to again
00:52:41 transform this down into tensor photographs and so it you can think of it as saying hey I have an if statement
00:52:47 I'm going to create an if node in the graph like you say TF conned you have a multiply well I'll turn that into
00:52:55 multiply node in the graph and that becomes the street transformation so word is the Swift for tensor for come in
00:53:05 which is you know parallels you know for one swift is a interface like Python is an interface test flow but it seems like
00:53:11 there's a lot more going on in just a different language interface there's optimization methodology yeah so so the
00:53:17 tensor float world has a couple of different what I'd call front-end technologies and so Swift and Python and
00:53:25 go and rust and Julia and all these things share the tensor flow graphs and all the runtime and everything that's
00:53:35 later again and so vertex flow is merely another front end for tensor flow I'm just like any of these other systems are
00:53:42 there's a major difference between I would say three camps of technologies here there's Python which is a special
00:53:48 case because the vast majority of the community efforts go into the Python interface and python has its own
00:53:53 approaches for automatic differentiation it has its own api's and all this kind of stuff
00:53:59 there's Swift which I'll talk about in a second and then there's kind of everything else and so the everything
00:54:04 else are effectively language bindings so they they call into the tense flow runtime but they're not they usually
00:54:10 don't have automatic differentiation or they usually don't provide anything other than API is that call the C API is
00:54:16 intensive flow and so they're kind of wrappers for that Swift is really kind of special and it's a very different
00:54:24 approach Swift 4/10 below that is is a very different approach because there we're saying let's look at all the
00:54:29 problems that need to be solved in the fullest of the tensorflow compilation process if you think about it that way because
00:54:37 tensorflow is fundamentally a compiler it takes models and then it makes them go faster on hardware that's what a
00:54:46 compiler does and it has a front end it has an optimizer and it has many backends and so if you think about it
00:54:51 the right way or in in if you look at it in a particular way like it is a compiler
00:55:01 okay and and so Swift is merely another front-end but it's saying in the the design principle is saying let's look at
00:55:08 all the problems that we face as machine learning practitioners and what is the best possible way we can do that given
00:55:13 the fact that we can change literally anything in this entire stack and python for example where the vast majority of
00:55:21 the engineering and an effort has gone into its constrained by being the best possible thing you can do with the
00:55:28 Python library like there are no Python language features that are added because of machine learning that I'm aware of
00:55:34 they added a matrix multiplication operator with that but that's as close as you get and so with Swift you can you
00:55:41 it's hard but you can add language features to the language and there's a community process for that and so we
00:55:48 look at these things and say well what is the right division of labor between the human programmer and the compiler
00:55:54 and Swift has a number of things that shift that balance so because it's a because it has a type system for example
00:56:01 it makes certain things possible for analysis of the code and the compiler can automatically build graphs for you
00:56:08 without you thinking about them like that's that's a big deal for a programmer you just get free performance
00:56:13 you get clustering infusion and optimization and things like that without you as a programmer having to
00:56:18 manually do it because the compiler can do it for you automatic to frenchie ation there's another big deal and it's
00:56:25 I think one of the key contributions of the Swift for tensorflow project is that there's this entire body of work on
00:56:32 automatic differentiation that dates back to the Fortran days people doing a tremendous amount of numerical computing
00:56:38 and Fortran used to write these what they call source-to-source translators where you where you take a bunch of code
00:56:45 shove it into a mini compiler and push out more Fortran code but it would generate the backwards passes for your
00:56:54 functions for you the derivatives and so in that work in the 70s a true master of optimizations a tremendous number of
00:57:02 techniques for fixing numerical instability and other other kinds of problems were developed but they're very
00:57:08 difficult to port into a world where in eager execution you get an opt by op at a time like you need to be able to look
00:57:13 at an entire function and be able to reason about what's going on and so when you have a language integrated automatic
00:57:20 differentiation which is one of the things that the Swift project is focusing on you can open open all these
00:57:26 techniques and reuse them and in familiar ways but the language integration piece has a bunch of design
00:57:33 room in it and it's also complicated the other piece of the puzzle here that's kind of interesting is TP use at Google
00:57:39 yes so you know we're in a new world with deep learning it's constantly changing and I imagine without
00:57:46 disclosing anything I imagine you know you're still innovating on the TP you front - indeed so how much sort of
00:57:53 interplay xur between software and hardware in trying to figure out how to gather move towards at an optimal
00:57:57 solution there's an incredible amount so our third generation of TP use which are now 100 petaflop syn a very large liquid
00:58:05 cooled box in a virtual box with no cover and as you might imagine we're not out of ideas yet the the great thing about
00:58:15 TP use is that they're a perfect example of hardware/software co.design and so it's a bet it's about saying what
00:58:20 hardware do we build to solve certain classes of machine learning problems well the algorithms are changing like
00:58:28 the hardware it takes you know some cases years to produce right and so you have to make bets and decide what is
00:58:35 going to happen and so and what is the best way to spend the transistors to get the maximum you know performance per
00:58:42 watt or area per cost or like whatever it is that you're optimizing for and so one of the amazing things about TP use
00:58:50 is this numeric format called b-flat 16b float16 is a compressed 16-bit floating-point format but it puts the
00:58:56 bits in different places in numeric terms it has a smaller mantissa and a larger exponent that means that it's
00:59:04 less precise but it can represent larger ranges of values which in the machine learning context is really important and
00:59:10 useful because sometimes you have very small gradients you want to accumulate and very very small numbers that are
00:59:19 important to to move things as you're learning but sometimes you have very large magnitude numbers as well and be
00:59:27 float16 is not as precise the mantissa is small but it turns out the machine learning algorithms actually want to
00:59:33 generalize and so there's you know theories that this actually increases generate the ability for the network to
00:59:38 generalize across data sets and regardless of whether it's good or bad is much cheaper at the hardware level to
00:59:47 implement because the area and time of a multiplier is N squared in the number of bits in the mantissa but it's linear
00:59:54 with size of the exponent connected to solar big deal efforts here both on the hardware and the software side yeah and
00:59:59 so that was a breakthrough coming from the research side and people working on optimizing network transport of weights
01:00:08 across a network originally and trying to find ways to compress that but then it got burned into silicon and it's a
01:00:14 key part of what makes CPU performance so amazing and and and great TPS have many different aspects of the
01:00:23 important but the the co.design between the low-level compiler bits and the software bits and the algorithms is all
01:00:30 super important and it's a this amazing try factor that only Google do yeah that's super exciting so can you tell me
01:00:40 about MLI our project previously this the secretive one yeah so EMA lair is a project that we announced at a compiler
01:00:47 conference three weeks ago or something at the compilers for machine learning conference basically if again if you
01:00:53 look at tensorflow as a compiler stack it has a number of compiler algorithms within it it also has a number of
01:00:58 compilers that get embedded into it and they're made by different vendors for example Google has xla which is a great
01:01:06 compiler system NVIDIA has tensor RT Intel has n graph there's a number of these different compiler systems and
01:01:13 they're very hardware specific and they're trying to solve different parts of the problems but they're all kind of
01:01:19 similar in a sense of they want to integrate with tensorflow no test flow has an optimizer and it has these
01:01:25 different code generation technologies built in the idea of NLR is to build a common infrastructure to support all
01:01:32 these different subsystems and initially it's to be able to make it so that they all plug in together and they can share
01:01:38 a lot more code and can be reusable but over time we hope that the industry will start collaborating and sharing code and
01:01:43 instead of reinventing the same things over and over again that we can actually foster some of that that you know
01:01:50 working together to solve common problem energy that has been useful in the compiler field before beyond that mor is
01:01:57 some people have joked that it's kind of LVM to it learns a lot about what LVM has been good and what LVM has done
01:02:06 wrong and it's a chance to fix that and also there are challenges in the LLVM ecosystem as well where LVM is very good
01:02:13 at the thing was designed to do but you know 20 years later the world has changed and people are trying to solve
01:02:18 higher-level problems and we need we need some new technology and what's the future of open source in this context
01:02:27 very soon so it is not yet open source but it will be hopefully you still believe in the value of open source in
01:02:32 kazakh oh yeah absolutely and I that the tensorflow community at large fully believes an open-source so I mean
01:02:39 that's there is a difference between Apple where you were previously in Google now in spirit and culture and I
01:02:45 would say the open sourcing intensive floor was a seminal moment in the history of software because here's this
01:02:52 large company releasing a very large code base as the open sourcing what are your thoughts on that
01:03:00 I'll happy or not were you to see that kind of degree of open sourcing so between the two I prefer the Google
01:03:06 approach if that's what you're saying the Apple approach makes sense given the historical context that Apple came from
01:03:16 but that's been 35 years ago and I think the Apple is definitely adapting and the way I look at it is that there's
01:03:22 different kinds of concerns in the space right it is very rational for a business to to care about making money that
01:03:30 fundamentally is what a business is about right but I think it's also incredibly realistic to say it's not
01:03:36 your string library that's the thing that's going to make you money it's going to be the amazing UI product
01:03:42 differentiating features and other things like that that you built on top of your string library and so keeping
01:03:49 your string library proprietary and secret and things like that isn't maybe not the the important thing anymore
01:03:57 right or before platforms were different right and even 15 years ago things were a little bit different but the world is
01:04:04 changing so Google strikes very good balance I think and I think the tensorflow being open source really
01:04:10 changed the entire machine learning field and it caused a revolution in its own right and so I think it's amazing
01:04:18 for amazingly forward-looking because I could have imagined and I was an at Google time but I could imagine the
01:04:23 different contacts and different world where a company says machine learning is critical to what we're doing we're not
01:04:28 going to give it to other people right and so that decision is a profound a profoundly brilliant insight that I
01:04:37 think has really led to the world being better and better for Google as well and has all kinds of ripple effects I think
01:04:45 it is really I mean you can't understate Google does adding that how profound that is for
01:04:51 software is awesome well and it's been in again I can understand the concern about if we release our machine learning
01:04:59 software are our competitors could go faster from the other hand I think that open sourcing test flow has been
01:05:05 fantastic for Google and I'm sure that obvious was that that that decision was very non obvious at the time
01:05:10 but I think it's worked out very well so let's try this real quick yeah you were at Tesla for five months as the VP of
01:05:18 auto pilot software you led the team during the transition from each hardware one hardware to I have a couple
01:05:25 questions so one first of all to me that's one of the bravest engineering decisions undertaking
01:05:33 so like undertaking really ever in the automotive industry to me software wise starting from scratch it's a really
01:05:40 brave a decision so my one question is there's always that like what was the challenge of that do you mean the career
01:05:46 decision of jumping from a comfortable good job into the unknown or that combined so the at the individual level
01:05:55 you making that decision and then when you show up you know it's a really hard engineering process so you could just
01:06:04 stay maybe slow down say hardware one or that those kinds of decisions just taking it full-on let's let's do
01:06:10 this from scratch what was that like well so I mean I don't think Tesla has a culture of taking things slow insights
01:06:15 how it goes and one of the things that attracted me about Tesla is it's very much a gung-ho
01:06:20 let's change the world let's figure it out kind of a place and so I have a huge amount of respect for that
01:06:28 Tesla has done very smart things with hardware one in particular and the harder one design was originally
01:06:36 designed to be very simple automation features in the car for like traffic aware cruise control and things like
01:06:41 that and the fact that they were able to effectively feature creep it into lane holding and and a very useful driver
01:06:48 assistance features is pretty astounding particularly given the details of the hardware hardware to built on that a lot
01:06:55 of ways and the challenge there was that they were transitioning from a third party provided vision stack to an
01:07:03 in-house built vision stack and so for the first step which I mostly helped with was getting onto that new vision
01:07:11 stack and that was very challenging and there were it was time critical for various reasons and it was a big leap
01:07:17 but it was fortunate that built on a lot of the knowledge and expertise and the team that had built harder ones driver
01:07:23 assistance features so you spoke in a collected and kind way about your time at Tesla but it was ultimately not a
01:07:31 good fit Elon Musk we've talked on his podcast several guests the course he almost continues to do some of the most
01:07:37 bold and innovative engineering work in the world at times at the cost some of the members
01:07:42 of the test the team what did you learn about this working in this chaotic world Leon yeah so I guess I would say that
01:07:51 when I was at Tesla I experienced and saw vert the highest degree of turnover I'd ever seen in a company my which was
01:07:59 a bit of a shock but one of the things I learned and I came to respect is that Elon is able to attract amazing talent
01:08:05 because he has a very clear vision of the future and he can get people to buy into it because they want that future to
01:08:11 happen right and the power of vision is something that I have a tremendous amount of respect for and I think that
01:08:17 Elon is fairly singular in the world in terms of the things he's able to get people to believe in and it's it's a
01:08:26 very it's very there many people who stay on the street corner and say ah we're gonna go to Mars right but then
01:08:31 but then there are a few people that can get other others to buy into it and believe in build the path and make it
01:08:38 happen and so I respect that I don't respect all of his methods but but I have a huge amount of respect for
01:08:46 that you've mentioned in a few places including in this context working hard what does it mean to work hard and when
01:08:54 you look back at your life what are what were some of the most brutal periods of having to really sort of put everything
01:09:03 you have into something yeah good question so working hard can be defined a lot of different ways so a lot of hours and so
01:09:13 that's that is true the thing to me that's the hardest is both being short-term focused on delivering and
01:09:19 executing and making a thing happen while also thinking about the longer-term and trying to balance that
01:09:26 right because if you are myopically focused on solving a task and getting that done and only think about that
01:09:33 incremental next step you will miss the next big hill you should jump over - right and so I've been really fortunate
01:09:40 that I've been able to kind of oscillate between the two and historically at Apple for example that was made possible
01:09:47 because I was able to work some really amazing people and build up teams and leadership structures and and allow them
01:09:55 to grow in their careers and take on responsibilities thereby freeing up me to be a little bit crazy and thinking
01:10:04 about the next thing and so it's it's a lot of that but it's also about you know with the experience you make connections
01:10:09 that other people don't necessarily make and so I think that is that's a big part as well but the bedrock is just a lot of
01:10:18 hours and you know that's that's okay with me there's different theories on work-life
01:10:23 balance and my theory for myself which I do not project on to the team but my theory for myself is that you know I I
01:10:29 wanted love what I'm doing and work really hard and my purpose I feel like and my goal is to change the world and
01:10:37 make it a better place and that's that's what I'm really motivated to do so last question LLVM logo is a dragon
01:10:45 you know you explain that this is because dragons have connotations of power speed intelligence it can also be
01:10:52 sleek elegant and modular till you remove them the modular part what is your favorite
01:10:59 dragon-related character from fiction video or movies so those are all very kind ways of explaining it that you
01:11:05 wanna know the real reason it's a dragon well yeah so there is a seminal book on compiler design called the dragon book
01:11:15 and so this is a really old now book on compilers and so the the dragon logo for LVM came about because at Apple we kept
01:11:24 talking about LLVM related technologies and there's no logo to put on a slide it's sort of like what do we do and
01:11:29 somebody's like well what kind of logo should a compiler technology have and I'm like I don't know I mean the Dragons
01:11:35 or the dragon is the best thing that that we've got and you know Apple somehow magically came up with the logo
01:11:42 and and it was a great thing and the whole community rallied around it and and then it got better as other graphic
01:11:48 designers got involved but that's that's originally where it came from story is they're dragons from fiction
01:11:55 that you connect with for that Game of Thrones Lord of the Rings that kind of thing Lord of the Rings is great I also like
01:12:00 role-playing games and things like in computer role-playing games and so Dragons often show up in there but but
01:12:07 really comes back to to to the book oh no we need we need a thing yeah and hilariously one of the one of the the
01:12:15 funny things about LLVM is that my wife who's amazing runs the the LVM foundation and she goes to Grace Hopper
01:12:21 and it's trying to get more women involved in the she's also compiler engineer so she's trying to get other
01:12:26 other women to get interested in compilers and things like this and so she hands out the stickers and people
01:12:32 like the LVM sticker because a game of thrones and so sometimes culture has this whole effect to like get the next
