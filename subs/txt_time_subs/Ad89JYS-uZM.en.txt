00:00:01 the following is a conversation with raha Prasad he's the vice president and head scientist of Amazon Alexa and one
00:00:09 of its original creators the Alexa team embodies some of the most challenging incredible impactful and inspiring work
00:00:17 that is done in a high today the team has to both solve problems at the cutting edge of natural language
00:00:23 processing and provide a trustworthy secure and enjoyable experience to millions of people this is where
00:00:29 state-of-the-art methods in computer science meet the challenges of real-world engineering in many ways
00:00:37 Alexa and the other voice assistants are the voices of artificial intelligence to millions of people and an introduction
00:00:44 to AI for people who have only encountered it in science fiction this is an important and exciting opportunity
00:00:51 so the work that Rohit and the Alexa team are doing is an inspiration to me and to many researchers and engineers in
00:01:00 the AI community this is the artificial intelligence podcast if you enjoy it subscribe on YouTube give it five stars
00:01:07 an apple podcast supported on patreon or simply connect with me on Twitter Alex Friedman spelled Fri D ma n if you leave
00:01:16 a review on an apple podcast especially but also cast box or comment on youtube consider mentioning topics people ideas
00:01:24 questions quotes in science tech or philosophy that you find interesting and I'll read them on this podcast I won't
00:01:31 call out names but I love comments with kindness and thoughtfulness in them so I thought I'd share them someone on
00:01:37 YouTube highlighted a quote from the conversation with Ray Dalio where he said that you have to
00:01:43 appreciate all the different ways that people can be a player's this connected me to on teams of engineers it's easy to
00:01:50 think that raw productivity is the measure of excellence but there are others I've worked with people who
00:01:56 brought a smile to my face every time I got to work in the morning their contribution to the team is immeasurable
00:02:03 I recently started doing podcast ads at the end of the introduction I'll do one or two minutes after introducing the
00:02:08 episode and never any ads in the middle that break the flow of the conversation I hope that works for you it doesn't
00:02:16 hurt the listening experience this show is presented by cash app the number one finance app in the App Store I
00:02:22 personally use cash app to send money to friends but you can also use it to buy sell and deposit a big coin in just
00:02:28 seconds cash app also has a new investing feature you can buy fractions of a stock say $1 worth no matter what
00:02:36 the stock price is brokerage services are provided by cash up investing a subsidiary of square and member at CIBC
00:02:44 I'm excited to be working with cash app to support one of my favorite organizations called first best known
00:02:49 for their first robotics and Lego competitions they educate and inspire hundreds of thousands of students in
00:02:56 over 110 countries and have a perfect rating at Charity Navigator which means the donated money is used to maximum
00:03:04 effectiveness when you get cash app from the App Store Google Play and use code Lex podcast you'll get $10 and cash app
00:03:13 will also donate $10 to 1st which again is an organization that I've personally seen inspire girls and boys the dream of
00:03:23 engineering better world this podcast is also supported by a zip recruiter hiring great people is hard and to me is one of
00:03:30 the most important elements of successful mission driven team I've been fortunate to be a part of and lead
00:03:37 several great engineering teams the hiring I've done in the past was mostly through tools we built ourselves but
00:03:44 reinventing the wheel was painful sip recruiters a tool that's already available for you it seeks to make
00:03:50 hiring simple fast and smart for example codable co-founder gretchen nner use zip recruiter to find a
00:03:57 new game artist to join our education tech company by using sip recruiters screening questions to filter candidates
00:04:03 Gretchen found it easier to focus on the best candidates and finally hiring the perfect person for the role in less than
00:04:10 two weeks from start to finish zip recruiter the smartest way to hire CY zip recruiters effective for
00:04:19 businesses of all sizes by signing up as I did for free at zip recruiter comm / Lex pod that
00:04:30 zipper Kirkham / Lex pod and now here's my conversation with Rohit Prasad in the movie her I'm not sure if you ever seen
00:04:39 a human falls in love with a voice of an AI system let's start at the highest philosophical level before we get too
00:04:45 deep learning and some of the fun things do you think this what the movie her shows is within our reach
00:04:55 I think not specifically about her but I think what we are seeing is a massive increase in adoption of AI assistants
00:05:05 Rai and all parts of our social fabric and I think it's what I do believe is that the utility these areas provide
00:05:15 some of the functionalities that are shown are absolutely within reach so the some of the functionality in terms of
00:05:25 the interactive elements but in terms of the deep connection that's purely voice based do you think such a close
00:05:32 connection as possible with voice alone it's been a while since I saw her but I would say in terms of the in terms of
00:05:40 interactions which are both human-like and in these AI assistants you have to value what is also super human we as
00:05:49 humans can be in only one place AI assistance can be in multiple places at the same time one with you on your
00:05:56 mobile device one at your home one at work so you have to respect these superhuman capabilities to Plus as
00:06:05 humans we have certain attributes we are very good at where you're at reasoning AI assistance not yet there but in
00:06:12 Terrell mauve AI assistance what they're great at is computation memory it's infinite and pure these are the
00:06:17 attributes you have to start respecting so I think the comparison with human-like versus the other aspect which
00:06:23 is also super human has to be taken into consideration so I think we need to elevate the discussion to not just human
00:06:30 like so there's certainly elements we just mentioned Alexa's everywhere computation is
00:06:36 speaking so this is a much bigger infrastructure than just the thing that sits there
00:06:40 in the room with you but it certainly feels to us mere humans that there's just another little creature there when
00:06:50 you're interacting with it you're not interacting with the entirety of the infrastructure you're interacting with
00:06:56 the device the feeling is okay sure we anthropomorphize things but that feeling is still there so what do you think we
00:07:05 as humans the purity of the interaction with a smart assistant what do you think we look for in that interaction I think
00:07:12 in the certain interactions I think will be very much where it does feel like a human because it has a persona of its
00:07:20 own and in certain ones it wouldn't be so I think a simple example to think of it is if you're walking through the
00:07:26 house and you just want to turn on your lights on and off and you're issuing a command that's not very much like a
00:07:32 human-like interaction and that's where the AI shouldn't come back and have a conversation with you just it should
00:07:38 simply complete that command so those I think the blend of we have to think about this is not human human alone it
00:07:45 is a human machine interaction and certain aspects of humans are needed and certain aspects are in situations demand
00:07:52 it to be like a machine so I told you it's gonna be full soft cause in parts what was the difference between human
00:07:58 and machine in that interaction when we interact to humans especially those our friends and loved ones versus you and a
00:08:09 machine that you also are close with I think they you have to think about the roles the AI plays right so and it
00:08:15 differs from different customer to customer different situation to situation especially I can speak from
00:08:23 Alexis perspective it is a companion a friend at times an assistant an advisor down the line so I think most a eyes
00:08:31 will have this kind of attributes and it will be very situational in nature so where is the boundary I think the
00:08:37 boundary depends on exact context in which you are interacting what they are so the depth and the richness of natural
00:08:45 language conversation is been by Alan Turing being used to try to define what it means to be intelligent you know
00:08:51 there's a lot of criticism of that kind of but what do you think it's a good test of intelligence in your view in the
00:08:59 context of the Turing test and Alexa or the elect surprise this whole realm do you think about this human intelligence
00:09:08 what it means to define it what it means to reach that level I do think the ability to converse is an sign of an
00:09:16 ultimate intelligence I think that is no question about it so if you think about all aspects of humans there are sensors
00:09:25 we have and those are basically a data collection mechanism and based on that we make some decisions with our sensory
00:09:32 brains right and from that perspective I think that there are elements we have to talk about how we sense the world and
00:09:39 then how we act based on what we sense those elements clearly machines have but then there's the other aspects of
00:09:48 computation that is way better I also mentioned about memory again in terms of being near infinite depending on the
00:09:54 storage capacity you have and the retrieval can be extremely fast and pure in terms of like there's no ambiguity of
00:10:02 who did I see when right I mean if your machine scan remember that quite well so it again on a philosophical level I do
00:10:09 subscribe to the fact that to can be able to converse and as part of that to be able to reason based on the world
00:10:15 knowledge you've acquired and the sensory knowledge that is there is definitely very much the essence of
00:10:25 indulgence but indulgence can go beyond human level intelligence based on what machines are getting capable of so what
00:10:32 do you think maybe stepping outside of Alexa broadly as an AI field what do you think is a good test of intelligence put
00:10:41 it another way outside of Alexa because so much of Alexa is a product is an experience for the customer on the
00:10:47 research side what would impress the heck out of you if you saw you know what is the test what he said wow this thing
00:10:57 is now starting to encroach into the realm of what we loosely think of as human intelligence so well we think of
00:11:03 it as a GI and human intelligence all together right so in some sense and I think we are quite
00:11:10 far from that I think an unbiased view I have is that the Alexus intelligence capability is a great test I think of it
00:11:20 as there are many other proof points like self-driving cars game playing like go or chess let's take those two for as
00:11:30 an exemption clearly requires a lot of data-driven learning and intelligence but it's not as hard a problem as
00:11:39 conversing with as an AI is with it humans to accomplish certain tasks or open domain chat as you mentioned like a
00:11:46 surprise in those settings the key difference is that the end goal is not defined unlike game playing you also do not know
00:11:55 exactly what state you are in in a particular goal completion scenario in certain times sometimes you can if it is
00:12:03 a simple goal but if you're even certain examples like planning a weekend or you can imagine how many things change along
00:12:11 the way you look for whether you make change your mind and you you change their destination or you want to catch a
00:12:18 particular event and then you decide no I want this other event I want to go to so these dimensions of how many
00:12:25 different steps are possible when you're conversing as a human with a machine makes it an extremely daunting problem
00:12:31 and I think it is the ultimate test for intelligence and don't you think the natural language is enough to prove that
00:12:40 conversation your conversation from a scientific standpoint natural language is a great test but I would go beyond I
00:12:48 don't want to limit it to as natural language as simply understanding an intent or parsing for entities and so
00:12:53 forth we are really talking about dialogue so so I would say human machine dialogue is definitely one of the best tests of intelligence
00:13:06 so can you briefly speak to the Alexa prize for people who are not familiar with it and and also just maybe were
00:13:13 things stand and what have you learned what's surprising what have you seen the surprising from this incredible
00:13:19 competition absolutely it's a very competition like surprise is essentially Grand Challenge in conversational
00:13:27 artificial intelligence where we threw the gauntlet to the universities who do active research in the field to say can
00:13:34 you build what we call a social board that can converse with you coherently and engagingly for 20 minutes that is an
00:13:42 extremely hard challenge talking to someone in a who you're meeting for the first time or even if you're you've met
00:13:51 them quite often to speak at 20 minutes on any topic an evolving nature of topics is super hard we have completed
00:14:00 two successful years of the competition the first was one with the industry of Washington's second industry of
00:14:06 California we are in our third instance we have an extremely strong team of 10 cohorts and the third instance of the of
00:14:15 the lexer prizes underway now and we are seeing a constant evolution first year was definitely learning it was a lot of
00:14:21 things to be put together we had to build a lot of infrastructure to enable these you know STIs to be able to build
00:14:30 magical experiences and and do high quality research just a few quick questions sorry for the interruption
00:14:36 what is failure look like in the 20-minute session so what does it mean to fail not to reach the twenty minimum
00:14:42 awesome question so there are one first of all I forgot to mention one more detail it's not just 20 minutes but the
00:14:48 quality of the conversation too that matters and the beauty of this competition before I answer that
00:14:54 question on what failure means is first that you actually converse with millions and millions of customers as these
00:15:02 social BOTS so during the judging phases there are multiple phases before we get to the finals which is a very controlled
00:15:09 judging in a situation where we have we bring in judges and we have interactors who interact with these social BOTS that
00:15:16 is a much more controlled setting but till the point we get to the finals all the judging is essentially by the
00:15:23 customers of Alexa and there you basically rate on a simple question how good your experience was so that's where
00:15:30 we are not testing for a 20 minute boundary being claw across because you do want
00:15:36 to be very much like a clear-cut winner be chosen and and it's an absolute bar so did you really break that 20-minute
00:15:44 barrier is why we have to test it in a more controlled setting with actors essentially in tractors and see how the
00:15:51 conversation goes so this is why it's a subtle difference between how it's being tested in the field with real customers
00:16:00 versus in the lab to award the prize so on the latter one what it means is that essentially the that there are three
00:16:09 judges and two of them have to say this conversation is stalled essentially got it and the judges the human experts
00:16:17 judges or human experts okay great so this is in the third year so what's been the evolution how far it's in the DARPA
00:16:24 challenge in the first year the autonomous vehicles nobody finished in the second year a few more finished in
00:16:32 the desert so how far along within this I would say much harder challenge are we this challenge has come a long way do
00:16:40 they extend that we've definitely not close to the 20-minute barrier being with coherence and engaging conversation
00:16:46 I think we are still five to ten years away in that horizon to complete that but the progress is immense like what
00:16:54 you're finding is the accuracy in what kind of responses these social BOTS generate is getting better and better
00:17:01 what's even amazing to see that now there's humor coming in the bots are quite you know you're talking about
00:17:08 ultimate science of intial and signs of intelligence I think humor is a very high bar in terms of what it takes to
00:17:15 create humor and I don't mean just being goofy I really mean good sense of humor is also a sign of intelligence in my
00:17:23 mind and something very hard to do so these social BOTS are now exploring not only what we think of natural language
00:17:29 abilities but also personality attributes and aspects of when to inject an appropriate joke went to when you
00:17:38 don't know the question the domain how you come back with something more intelligible so that you can continue
00:17:44 the conversation if if you and I are talking about AI and we are domain experts we can speak to it but if you
00:17:49 suddenly switch the topic to that I don't know how do I change the conversation so you're starting to
00:17:55 notice these elements as well and that's coming from partly by by the nature of the 20 minute challenge that people are
00:18:04 getting quite clever on how to really converse and essentially masks some of the
00:18:09 understanding defects if they exist so some of this this is not a Lex of the products this is somewhat for fun for
00:18:18 research for innovation and so on I have a question sort of in this modern era there's a lot of you look at Twitter and
00:18:25 Facebook and so on there's there's discourse public discourse going on and some things are a little bit too edgy
00:18:31 people get blocked and so on I'm just out of curiosity are people in this context pushing the limits is anyone
00:18:39 using the f-word is anyone sort of pushing back sort of you know arguing I guess I should say in as part of the
00:18:48 dialogue to really draw people in first of all let me just back up a bit in terms of why we're doing this right so
00:18:56 you said it's fun I think fun is more part of the engaging part for customers it is one of the most used skills as
00:19:05 well in our skill store but up that apart the real goal was essentially what was happening is with lot of AI research
00:19:13 moving to industry we felt that academia has the risk of not being able to have the same resources at disposal that we
00:19:20 have which is loss of beta massive computing power and a clear ways to test these AI advances with real customer
00:19:29 benefits so we brought all these three together in the like surprise that's why it's one of my favorite projects and
00:19:37 Amazon and with that the secondary fact is yes it has become engaging for our customers as well we're not there in
00:19:43 terms of where we want to it to be right but it's a huge progress but coming back to your question on how do the
00:19:49 conversations evolve yes there is some natural attributes of what you said in terms of argument and some amount of
00:19:56 swearing the way we take care of that is that there is a sensitive filter we have built that show you see words and so
00:20:02 it's more than keywords a little more in terms of of course there's key word base to but there's more in terms of these
00:20:09 words can be very contextual as you can see and also the topic can be something that you don't want a conversation to
00:20:16 happen because this is a criminal device as well a lot of people use these devices so we have put
00:20:22 lot of guardrails for the conversation to be more useful for advancing AI and not so much of these these other issues
00:20:31 you attributed what's happening in there I feel as well right so this is actually a serious opportunity I didn't use the
00:20:39 right word fun I think it's an open opportunity to do some some of the best innovation in conversational agents in
00:20:47 in the world absolutely why just universities why just you know streets because as I said I really felt young
00:20:55 minds young minds it's also - if you think about the other aspect of where the whole industry is moving with AI
00:21:03 there's a dearth of talent in in given the demands so you do want the universities to have a clear place where
00:21:11 they can invent and research and not fall behind with that they can't motivate students imagine all grad
00:21:19 students left - to industry like us or or faculty members which has happened - so this is in a way that if you're so
00:21:25 passionate about the field where you feel industry and academia need to work well this is a great example and a great
00:21:35 way for universities to participate so what do you think it takes to build a system that wins the allow surprise I
00:21:43 think you have to start focusing on aspects of reasoning that it is there are still more lookups of what intense
00:21:54 customers asking for and responding to those are rather than really reasoning about the elements of the of the
00:22:04 conversation for instance if you have if you're playing if the conversation is about games and it's about a recent
00:22:12 sports event there's so much context in war and you have to understand the entities that are being mentioned so
00:22:19 that the conversation is coherent rather than you suddenly just switch to knowing some fact about a sports entity and
00:22:26 you're just relating that rather than understanding the true context of the game like you if you just said I learned
00:22:33 this fun fact about Tom Brady rather than really say how he played the game the previous night then
00:22:41 the conversation is not really that intelligent so you have to go to more reasoning elements of understanding the
00:22:50 context of the dialogue and giving more appropriate responses which tells you that we are still quite far because a
00:22:56 lot of times it's more facts being looked after and something that's close enough as an answer but not really the
00:23:03 answer so that is where the research needs to go more an actual true understanding and reasoning and that's
00:23:10 why I feel it's a great way to do it because you have an engaged set of users working to make help these AI advances
00:23:18 happen in this case item actually customers they're there quite a bit and there's a skill what is the experience
00:23:26 for the for the user that is helping so just to clarify this isn't as far as I understand the Alexa so this skill is to
00:23:33 stand alone for the art surprise I mean it's focused on the elect surprise it's not you ordering certain things and I
00:23:38 was on the comet trait checking the weather or you're playing Spotify right separate skills directly and so you're
00:23:46 focused on helping not well I don't know how do people how do customers think of it are they having fun are they helping
00:23:52 teach the system what's the experience like I think it's both actually and let me tell you how they how you invoke this
00:23:59 skill so you all you have to say Alexa let's chat and then the first time you say Alexa let's chat it comes back with
00:24:05 a clear message that you're interacting with one of those you know three social BOTS and there's a fear so he's know
00:24:12 exactly how you interact right and that is why it's very transparent you are being asked to help right and and we
00:24:21 have lot of mechanisms where as the we are in the first phase of feedback phase then you send a lot of emails to our
00:24:29 customers and then this they know that this the team needs a lot of interactions to improve the accuracy of
00:24:35 the system so we know we have lot of customers who really want to help be zeros to bots and they are conversing
00:24:41 with that and some are just having fun with just saying Alexa let's chat and also some adversarial behavior to see whether
00:24:49 how much do you understand as a social bot so I think we have a good healthy mix of all three situations so what is
00:24:56 the if we talk about solving the Alexa challenge they like surprise what's the data set of really engaging pleasant
00:25:07 conversations look like is if we think of this as a supervised learning problem I don't know if it has to be but if it
00:25:15 does maybe you can comment on that do you think there needs to be a data set of what it means to be an engaging
00:25:23 successful fulfilling copy that's part of the research question here this was I think it's we at least got the first
00:25:31 part right which is have a way for universities to build and test in a real-world setting now you're asking in
00:25:38 terms of the next phase of questions which we are still we're also asking by the way what does success look like from
00:25:45 a optimization function that's what you're asking in terms of we as researchers are used to having a great
00:25:52 corpus of annotated data and then making a Rob then you know sort of tune our algorithms on those right and
00:26:01 fortunately and unfortunately in this world of a lexer prize that is not the way we are going after it so you have to
00:26:09 focus more on learning based on live feedback that is another element that's unique we're just not I started with
00:26:17 giving you how you ingress and experience this capability as a customer what happens when you're done so they
00:26:26 ask you a simple question on a scale of one to five how likely are you to interact with this social bot again that
00:26:34 is a good feedback and customers can also leave more open-ended feedback and I think partly that to me is one part of
00:26:42 the question you're asking which I'm saying is a mental model shift that as researchers also you have to change your
00:26:49 mindset that this is not a dart by evaluation or NSF funded study and you have a nice corpus this is where it's
00:26:59 real world you have real data the scale is amazing is this beautiful thing then and then the
00:27:05 customer the user can quit the conversation in exactly the user game that is also a signal for how good you
00:27:13 were at that point so and then on a scale of one to five one two three do they say how likely are you or is it
00:27:19 just a binary Allah one two five one two five Wow okay that's such a beautifully constructed challenge okay you said the
00:27:28 only way to make a smart assistant really smart to give it eyes and let explore the world I'm not sure he might
00:27:37 been taken out of context but can you a comment and I can you elaborate and that idea is that I personally also find that
00:27:43 ideas super exciting from a social robotics personal robotics perspective yeah a lot of things do get taken out of
00:27:50 context my this particular one was just as philosophically discussion we were having on terms of what does
00:27:56 intelligence look like and the context was in terms of learning I think just we said we as humans are empowered with
00:28:05 many different sensory abilities I do believe that eyes are an important aspect of it in terms of if you think
00:28:15 about how we as humans learn it is quite complex and it's also not unimodal that you are fed a ton of text or audio and
00:28:24 you just learn that way no you are you learn by experience you learn by seeing you're taught by humans and we're very
00:28:33 efficient and how we learn machines on the contrary are very inefficient on how they learn especially these AI is I
00:28:41 think the next wave of research is going to be with less data not just less human not just with less label data but also
00:28:51 with a lot of week supervision and where you can increase the learning rate I don't mean less data in terms of not
00:28:58 having a lot of data to learn from that we are generating so much data but it is more about from a aspect of how fast can
00:29:06 you learn so improving the quality of the data that's the quality data and learning process I think more on the
00:29:12 learning process I think we have to we as humans learn with a lot of noisy data right and and I think that's
00:29:20 the part that I don't think should change what should change is how we learn right so if you look at you
00:29:26 mentioned supervised learning we have making transformative shifts from moving to more unsupervised more week
00:29:33 supervision those are the key aspects of how to learn and I think in that setting you I hope you agree with me that having
00:29:42 other senses is very crucial in terms of how you learn so absolutely and from a machine learning perspective which I
00:29:49 hope we get a chance to talk to a few aspects that are fascinating there but just stick on the point a sort of a body
00:29:56 you know an embodiment so Alexa has a body is a very minimalistic beautiful interface or there's a ring and so on I
00:30:04 mean I'm not sure of all the flavors of the devices that Alyssa lives on but there's a minimalistic basic interface
00:30:15 and nevertheless we humans so I have a Roomba of all kinds of robots and all over everywhere so what do you think the
00:30:25 Alexa the future looks like if it begins to shift what his body looks like what  what may be beyond the Alexa what do
00:30:32 you think are the different devices in the home as they start to embody their intelligence more and more what do you
00:30:39 think that looks like philosophically a future what do you think that looks I think let's look at what's happening
00:30:45 today you mentioned I think all our devices as an Amazon devices we also wanted to point out Alexa is already
00:30:51 integrated a lot of third-party devices which also come in lots of forms and shapes some in robots right some and
00:31:00 microwaves some in appliances of that you use in everyday life so I think it is it's not just the shape Alexa takes
00:31:09 in terms of form factors but it's also where all it's available it's getting in cars it's getting in different
00:31:17 appliances in homes even toothbrushes right so I think you have to think about it is not a physical assistant it will
00:31:27 be in some embodiment as you said we already have these nice devices but I think it's also important
00:31:34 to think of it it is a virtual assistant it does superhuman in the sense that it is in multiple places at the same time
00:31:43 so I think the the actual embodiment in some sense to me doesn't matter I think you have to think of it as not as
00:31:54 human-like and more of what its capabilities are that derive a lot of benefit for customers and how there are
00:32:01 different ways to delighted and delight customers and different experiences and I think I am a big fan of it not being
00:32:09 in just human like it should be human-like in certain situations Alexa Frye social bot in terms of conversation
00:32:15 is a great way to look at it but there are other scenarios where human like I think is underselling the abilities of
00:32:25 this AI so if I could trivialize what we're talking about so if you look at the way Steve Jobs thought about the
00:32:32 interaction with the device that Apple produced there was a extreme focus on controlling the experience by making
00:32:38 sure there's only the Apple produced devices you see the voice of Alexa being taking all kinds of forms depending on
00:32:47 what the customers want and that means that means it could be anywhere from the microwave to a vacuum cleaner to the
00:32:55 home and so on the voice is the essential elrom to the interaction I think voice is an essence it's not all
00:33:03 but it's a key aspect I think to your question in terms of you should be able to recognize Alexa and that's a huge
00:33:11 problem I think in terms of a huge scientific problem I should say like what are the traits what makes it look
00:33:16 like Alexa especially in different settings and especially if it's primarily voice what it is but LX is not
00:33:22 just voice either right I mean we have devices with a screen now you're seeing just other behaviors of Alexa so I think
00:33:30 they're in very early stages of what that means and this will be an important profit for the following years but I do
00:33:38 believe that being able to recognize and tell when it's Alexa versus it's not as going to be important from an Alexa
00:33:44 perspective I'm not speaking for the entire AI Thank You Marie but from but I think attribution and as we go into more
00:33:55 of understanding who did what that identity of the AI is crucial in the coming world I think from the broad AI
00:34:01 community perspective that's also a fascinating problem so basically if I close my eyes and listen to the voice
00:34:07 what would it take for me to recognize that this is Alexa exactly or at least the Alexa that I've come to known from
00:34:13 my personal experience in my home through my interactions that Korea and the Alexa here in the u.s. is very
00:34:19 different the Alexa and UK and Alexa India even though they are all speaking English or the Australian version so
00:34:26 again we're so now think about when you go into a different culture different community but you travel there
00:34:32 what do you recognize Alexa I think these are super hard questions actually so there's a Tina works on personality
00:34:39 so if we talk about those different flavours or what it means culturally speaking India UK u.s. what does it mean
00:34:46 to add so the problem that we just stated which is fascinating how do we make it purely recognizable that it's
00:34:55 Alexa assuming that the qualities of the voice are not sufficient it it's also the content of what is being said how do
00:35:03 how do we do that how does the personality kind of come into play what's what's that researching would
00:35:08 look like it's such a fascinating we have some very fascinating folks who from both the UX background and human
00:35:15 factors are looking at these aspects and these exact questions but I'll definitely say it's not just how it
00:35:24 sounds the choice of words the tone not just I mean the voice identity of it but the tone matters the speed matters how
00:35:33 you speak how you enunciate words how what choice of words are using how tours are you or how lending in your
00:35:41 explanations you are all of these are factors and you also you mentioned something crucial that it's may have you
00:35:49 may have personalized it Alexa to some extent in your homes or in the devices you are interacting with so
00:35:58 you as your individual how you prefer Alexa sounds can be different than how I prefer and we may and the amount of
00:36:04 customizability you want to give is also a key debate we always have but I do want to point out it's more than the
00:36:11 voice actor that recorded and you'd sounds like that actor it is more about the choices of words the attributes of
00:36:20 tonality the volume in terms of how you raise your pitch and so forth all of that matters this is a fascinating
00:36:27 problem from a product perspective I could see those debates just happening inside of the Alexa team of how much
00:36:33 personalization do you do for the specific customer because you're taking a risk if you over personalized because
00:36:39 you don't I if you create a personality for a million people you can test that better
00:36:47 you can create a rich fulfilling experience that will do well but if the more you personalize it the less you can
00:36:54 test it the less you can know that it's it's a great experience so how much personalization what's the right balance
00:37:01 I think the right balance depends on the customer give them the control so I'd say I think the more control you give
00:37:08 customers the better it is for everyone and I'll give you some key personalization features I think we have
00:37:16 a feature called remember this which is where you can tell Alexa to remember something there you have an explicit
00:37:23 sort of control in customers hand because they have to say like I remember XYZ what kind of things would that be
00:37:29 used for so you can respond or something I have stored my tire specs for my car nice because it's so hard to go and find
00:37:37 and see what it is right when you're having some issues I store my mileage plan numbers for all the frequent-flyer
00:37:44 ones where sometimes just looking at it and it's not handy so and so those are my own personal choices army for Alexa
00:37:52 to remember something on my behalf right so again I think the choice was be explicit about how you provide that to a
00:38:00 customer as a control so I think these are the aspects of what you do like think about
00:38:07 where we can use speaker recognition capabilities that it's if you taught Alexa that you are Lex and this person
00:38:16 you're householders person to then you can personalize the experiences again these are very in this and the CX
00:38:23 customer experience patterns are very clear about and transparent when a personalization action is happening and
00:38:32 then you have other ways like you go through explicit control right now through your app that your multiple
00:38:37 service providers let's say for music which one is your preferred one so when you say place ting depend on your
00:38:43 whether you have preferred Spotify or Amazon music or Apple music that the decision is made where to play it from
00:38:51 so what's Alexis backstory from her perspective this is there I remember just asking as probably a lot of us are
00:39:00 just the basic questions about love and so on of Alexa just to see what the answer would be just as a it feels like
00:39:07 there's a little bit of a back like there's a feels like there's a little bit of personality but not too much is
00:39:18 Alexa have a metaphysical presence in this human universe we live in or is it something more ambiguous is there a past
00:39:27 is there birth is there family kind of idea even for joking purposes and so on I think well it does tell you if I think
00:39:36 you should double-check this but if you said when were you born I think we do respond I need to double check that but
00:39:41 I'm pretty positive about it I think you do it because I think I've too soon but that's like that's like hell like I was
00:39:49 born in your brand of champagne and whatever the year good thing yeah so in terms of the metaphysical I think it's
00:39:58 early does it have the historic knowledge about herself to be able to do that maybe have we
00:40:04 crossed that boundary not yet right in terms of being thank you have you thought about it quite a bit but I
00:40:10 wouldn't say that we have come to a clear decision in terms of what it should look like but you can imagine
00:40:17 though and I bring this back to the Alexa prize social BOTS one there you will start seeing some of that
00:40:23 like you these bots have their identity and in terms of that you may find you know this is such a great research topic
00:40:31 that some academia team may think of these problems and start solving them - so let me ask a question it's kind of
00:40:41 difficult I think but it feels fascinating to me because I'm fascinated with psychology it feels that the more
00:40:49 personality you have the more dangerous it is in terms of a customer perspective of products if you want to create a
00:40:57 product that's useful by dangerous I mean creating an experience that upsets me and so what how do you get that right
00:41:09 because if you look at the relationships maybe I'm just a screwed-up Russian but if you look at the real human to human
00:41:15 relationship some of our deepest relationships have fights have tension have the push and pull have a little
00:41:25 flavor in them do you want to have such flavor in an interaction with Alexa how do you think about that so there's one
00:41:32 other common thing that you didn't say but is we think of it as paramount for any deep relationship that's trust trust
00:41:40 yeah so I think if you trust every attribute you said mm-hmm a fight some tension yeah is or healthy but the
00:41:49 waters sort of unknowable in this instance is trust and I think the bar to earn customer trust for AI is very high
00:41:58 in some sense more than a human it's it's not just about personal information or your data it's also about your
00:42:07 actions on a daily basis how trustworthy are you in terms of consistency in terms of how accurate are you in understanding
00:42:14 me like if if you're talking to a person on the phone if you have a problem with your let's say your internet or
00:42:18 something if the person is not understanding you lose trust right away you don't want to talk to that person
00:42:25 that whole example gets amplified by a factor of 10 because as when you're a human interacting with an AI you have a
00:42:32 certain expectation either you expect it to be very intelligent and then you get upset
00:42:36 why is it behaving this way more you expect it to be not so intelligent and when it surprises you're like really
00:42:42 you're trying to be too small so I think we grapple with these hard questions as well but I think the key is actions need
00:42:50 to be trustworthy from these a is not just about data protection your personal information protection but also from how
00:42:59 accurate it accomplishes all commands are all interactions well it's tough to hear because Trust you're absolutely
00:43:06 right but Trust is such a high bar with AI systems because people and I see this because I work with autonomous vehicles
00:43:12 I mean the bar this placed on AI system is unreasonably high yeah that is going to be as I agree with you and I think of
00:43:21 it is it's it's a challenge and it's also keeps my job so from that perspective that I totally I think of it
00:43:30 at both sides as a customer and as a researcher I think as a researcher yes occasionally it will frustrate me that
00:43:38 why is the bar so high for these AIS and as a customer then I say absolutely it has to be that high right so I think
00:43:44 that's the trade-off we have to balance but doesn't change the fundamentals that trust has to be own and the question
00:43:53 then becomes is are we holding the AIS to a different bar and accuracy and mistakes then we hold humans that's
00:43:58 going to be a great societal questions for years to come I think for us well one of the questions that we grapple as
00:44:06 a society now that I think about a lot I think a lot of people know I think about a lot and Alexis taking on head-on is
00:44:16 privacy is the reality is us giving over data to any AI system can be used to enrich our lives in in in profound ways
00:44:27 so if maybe basically any product that does anything awesome for you would the more data has the more awesome things it
00:44:37 can do and yet at the other side people imagine the worst case possible scenario of what can you possibly do with that data
00:44:44 people it's it goes down to trust as you said for there's a fundamental distrust of in certain groups of governments and so on
00:44:51 and depending on the government depending on who is in power depending on all these kinds of factors and so
00:44:57 here's the lux in the middle of all of it in the home trying to do good things for the customers so how do you think
00:45:05 about privacy in this context the smart assistants in the home how do you maintain how do you earn trust
00:45:11 absolutely so as you said Trust is the key here so you start with trust and then privacy is a key aspect of it it
00:45:18 has to be designed from very beginning about that and we believe in two fundamental principles one is
00:45:27 transparency and second is control so if by transparency I mean when we build what is now called smart speaker or the
00:45:35 first echo we were quite judicious about making these right trade-offs on customers behalf that it is pretty clear
00:45:43 when when the audio is being sent the cloud the light ring comes on when it has heard you say the word wake word and
00:45:49 then the streaming happens right so and the light ring comes up we also had we put a physical mute button on it just so
00:45:57 you're if you didn't want it to be listening even for the weak word then you turn the power button on the mute
00:46:03 button on and that disables the microphones that's just the first decision on essentially transparency and
00:46:11 control over then even when we launched we gave the control in the hands of the customers that you can go and look at
00:46:16 any of your individual utterances that is recorded and delete them anytime and we have cut to true to that promise
00:46:25 right so and that is super again a great instance of showing how you have the control then we made it even easier you
00:46:32 can say lecture delete what I said today so that is now making it even just just more control in your hands with what's
00:46:40 most convenient about this technology is voice you delete it with your voice now so these are the types of decisions we
00:46:48 continually make we just recently launched this feature called what we think of it as if you wanted humans not
00:46:57 to review your data because smile you mentioned supervised so you in supervised learning humans
00:47:04 have to give some annotation and that also is now a feature where you can essentially if you selected that flag
00:47:10 your data will not be reviewed by a human so these are the types of controls that we have to constantly offer with
00:47:21 customers so why do you think about as people so much that so that so everything you just said is really
00:47:27 powerful to the control the ability to leak because we collect we have studies here running at MIT that collects huge
00:47:33 amounts of data and people consent and so on the ability to delete that data is really empowering and almost nobody ever
00:47:41 asked to delete it but the ability to have that control is really powerful but still you know there's these popular
00:47:48 anecdotes anecdotal evidence that people say they like to tell that them and a friend were talking about something I
00:47:56 don't know sweaters for cats and all sudden they'll have advertisements for cat sweaters on Amazon there's that
00:48:02 that's a popular anecdote as if something is always listening what can you explain that anecdote that
00:48:09 experience that people have what's the psychology of that what's that experience and can you you've answered
00:48:16 it but let me just ask is Alexa listening no Alexa listens only for the wake word on the device right and awake
00:48:26 word is the words like Alexa Amazon echo and you but do you only choose one at a time so you choose one and it listens
00:48:34 only for that on our devices so that's first from a listening perspective we have to be very clear that it's just the
00:48:39 wake word so you said why is there this anxiety if you make yeah it's because there's a lot of confusion what it
00:48:46 really listens to right and you and I think it's partly on us to keep educating our customers and the general
00:48:53 media more in terms of like how what really happens and we've done a lot of it and with our pages on information are
00:49:03 clear but still people have to have more there's always a hunger for information and clarity and will constantly look at
00:49:09 how best to communicate if you go back and read everything yes it states exactly that
00:49:15 and then people could still question it and I think that's absolutely okay to question what we have to make sure is
00:49:22 that we are because our fundamental philosophy is customer first customer obsession is our leadership principle if
00:49:31 you put as researchers I put myself in the shoes of the customer and all decisions in Amazon are made with that
00:49:37 and I throw and Trust has to be earned and we have to keep earning the trust of our customers in this setting and to
00:49:44 your other point on like is there something showing up based on your conversations no I think the answer is
00:49:50 like you a lot of times when those experiences happen you have to also be know that okay maybe a winter season
00:49:56 people are looking for sweaters right and it shows up on your amazon.com because it is popular so there are many
00:50:04 of these you mentioned that personality or personalization turns out we are not that unique either right so those things
00:50:12 we we as humans start thinking oh must be because something was heard and that's why this other thing showed up
00:50:19 the answer is no probably it is just the season for sweaters I'm not gonna ask you this question because it's just cuz
00:50:26 your doll so because people have so much paranoia but for Milan as you say from my perspective I hope there's a day when
00:50:33 customer can ask Alexa to listen all the time to improve the experience to improve because I personally don't see
00:50:41 the negative because if you have the control and if you have the trust there's no reason why I shouldn't be
00:50:46 listening all the time to the conversations to learn more about you because ultimately as long as you have
00:50:55 control and Trust every data you provide to the device that the device wants is going to be useful and that's it
00:51:05 to me I as a machine learning person I think it worries me how sensitive people are about their data relative to how
00:51:20 empowering it could be for the devices around them how enriching it could be for their own life to improve
00:51:27 the product so I just it's something I think about sort of a lot how do we make that devices obviously Lux that thinks
00:51:32 about it a lot as well I don't know if you want to comment on that sort of okay have you seen them in the form of a
00:51:39 question okay I have have you seen an evolution in the way people think about their private data in the previous
00:51:47 several years so as we as a society a more more comfortable to the benefits we get by sharing more data first let me
00:51:55 answer that part and then I'll want to go back to the other aspect you were mentioning so as a society on a general
00:52:02 we are getting more comfortable as a society doesn't mean that everyone is and I think we have to respect that
00:52:10 I don't think one-size-fits-all is always gonna be the answer for all right by definition so I think that's is
00:52:17 something to keep in mind in these going back to your on what more magical experiences can be launched in these
00:52:27 kind of AI settings I think again if you give the control we it's possible certain parts of it so if you have a
00:52:34 feature called follow-up mode where you if you turn it on and Alexa after you've spoken to it will open the mics again
00:52:44 thinking you lanced something again yeah like if you're adding lists to your shopping items so right or a shopping
00:52:49 list or to-do list you're not done you want to keep so in that setting it's awesome that it opens
00:52:56 the mic for you to say eggs and milk and then bread right so these are the kind of things which you can empower so I and
00:53:02 then another feature we have which is called Alexa guard I said it only listens for the wake word all right but
00:53:10 if you have a let's say you're going to say Lex you leave your home and you want a lexer to listen for a couple of sound
00:53:16 events like smoke alarm going off or someone breaking your glass right so it's like just to keep your peace of
00:53:24 mind so you can say Alexa on guard or I'm away or and then it can be listening for these sound events and when you're
00:53:32 home it you come out of that mode right so this is another one where you again gave controls in the hands of the user
00:53:37 or the custom and to enable some experience that is you higher utility and maybe even more
00:53:44 delightful in the certain settings like follow up more and so forth again this general principle is the same
00:53:52 control in the hands of the Castro so I know we kind of started with a lot of philosophy and a lot of interesting
00:53:57 topics and we'll just jumping all over the place but really some of the fascinating things at the alexa team and
00:54:04 Amazon's doings in the the algorithm side the data side the technology at the deep learning machine learning and and
00:54:11 so on so can you give a brief history of Alexa from the perspective of just innovation the algorithms the data of
00:54:19 how I was born how it came to be how is grown where it is today yeah start with in Amazon everything starts with the
00:54:28 customer and we have a process called working backwards Alexa and more specifically then the product echo there
00:54:36 was a working backwards document essentially that reflected what it would be started with a very simple vision
00:54:45 statement for instance that morphed into a full-fledged document along the way changed into what all it can do right
00:54:53 you can but the inspiration was the Star Trek computer so when you think of it that way you know everything is possible
00:54:58 but when you launch a product you have to start with someplace and when I joined we the product was already in
00:55:07 conception and we started working on the far field speech recognition because that was the first thing to solve by
00:55:12 that we mean that you should be able to speak to the device from a distance and in those days that wasn't a common
00:55:21 practice and even in the previous research world I was in was considered to an unsolvable problem then in terms
00:55:27 of whether you can converse from a length and here I'm still talking about the first part of the problem where you
00:55:34 say get the attention of the device as in by saying what we call the wake word which means the word Alexa has to be
00:55:41 detected with a very high accuracy because it is a very common word it has sound units that map with words like I
00:55:50 like you or Alec Alex right so it's a undoubtably hard problem to detect the right mentions of Alexa's
00:56:01 address to the device versus I like Alexa you have to pick up that signal when there's a lot of noise not only
00:56:08 noise north conversation they are in the house while you remember on the device you are simply listening for the wake
00:56:14 word Alexa and there's a lot of words being spoken in the house how do you know it's Alexa and directed at Alexa
00:56:23 because I could say I love my Alexa I hate my Alex I want a lecture to do this and in all these three sentences I said
00:56:30 Alexa I didn't want it to wake up yeah so can I just pause on a second what would be your device that I should
00:56:37 probably in the introduction of this conversation give to people in terms of with them turning off their Lutz a
00:56:45 device if they're listening to this podcast conversation out loud like what's the probability that an Alexa
00:56:52 device will go off because we mention Alexa like a million times so it will we have done a lot of different things
00:57:02 where we can figure out that there is the device the speech is coming from a human versus over there also I mean in
00:57:11 terms of like also it is think about ads or so we have also launched a technology for watermarking kind of approaches in
00:57:19 terms of filtering it out but yes if this kind of a podcast is happening it's possible your device will wake up a few
00:57:26 times it's an unsolved problem but it is definitely something we care very much about but the idea is you wanna detect
00:57:36 Alex were meant for the device or just even hearing Alexa versus I like yeah something I mean that's the fascinating
00:57:43 part so that was the first relief that's the first of the world's best detector of course
00:57:47 yeah the FIR world's best wait word detector yeah in the far field setting not like something where the phone is
00:57:54 sitting on the table this is like people have devices 40 feet away like in my house or 20 feet away and you still get
00:58:02 an answer so that was the first part the next is you're speaking to the device of course
00:58:07 you're gonna issue many different requests some may be simple some may be extremely hard but it's a large
00:58:13 vocabulary speech recognition problem essentially where the audio is now not coming on to your phone or a handheld
00:58:22 mic like this or close talking my but it's from 20 feet away where if you're in a busy household your son may be
00:58:29 listening to music your daughter may be running around with something and asking your mom something and so forth
00:58:35 right so this is like a common household setting where the words you're speaking to Alexa
00:58:41 need to be recognized with very high accuracy yes right now we are still just in the recognition problem you haven't
00:58:47 yet come to the understanding one writes in if a possum so I once again what year was this is this before neural networks
00:58:57 began to start to seriously prove themselves in audio space yeah this is around so I joined in 2013 in April
00:59:07 right so the early research in neural networks coming back and showing some promising results in speech recognition
00:59:13 space had started happening but it was very early yeah but we just took now build on that on the very first thing we
00:59:22 did when when I join and we with the team and remember it was a very smudge of a start-up environment which is great
00:59:30 about Amazon and we double down on deep learning right away and we we knew will have to improve accuracy fast and
00:59:39 because of that we worked on and the scale of data once you have a device like this if it is successful will
00:59:45 improve big time like you'll suddenly have large volumes of data to learn from to make the customer experience better
00:59:52 so how do you scale deep learning so we did are one of the first works in in training with distributed GPUs and where
01:00:00 the training time was you know was linear in terms of like in the amount of data so that was quite important work
01:00:08 where it was algorithmic improvements as well as a lot of engineering improvements to be able to train on
01:00:14 thousands and thousand of speech and that was an important factor so the if you ask me like
01:00:20 back in 2013 and 2014 when we launched echo the combination of large scale data deep learning progress near infinite GPX
01:00:33 we had available on AWS even then was all came together for us to be able to solve the far field speech recognition
01:00:39 to the extent it could be useful to the customers it still not solved like I mean it's not that we are perfect at
01:00:45 recognizing speech but we are great at it in terms of the settings that are in homes right so and that was important
01:00:51 even in the early stages the first even I'm trying to look back at that time if I remember correctly that it was it
01:01:00 seems like the task will be pretty daunting so like so we kind of take it for granted that it works now yes right
01:01:10 so let me like how first time you mentioned startup I wasn't familiar how big the team was I kind of because I
01:01:15 know there's a lot of really smart people working on looks and I was very very large team how big was the team how
01:01:23 likely were you to fail in the highs of everyone else like what I'll give you a very interesting anecdote on that when I
01:01:34 joined the team the speech recognition team was six people my first meeting and we had hired a few more people it was 10
01:01:44 people 9 out of 10 people thought it can't be done who was the one the one was me and actually I should say and one
01:01:57 was say my optimistic yeah and and 8th we're trying to convince let's go to the management and say let's not work on
01:02:04 this problem let's work on some other problem like either telephony speech for customer service calls and so forth but
01:02:11 this was the kind of belief you must have and I had experience with far-field speech recognition and I my eyes lit up
01:02:17 and I saw a problem like that saying okay we have been in speech recognition always looking for that killer app and
01:02:26 this was a killer use case to bring something delightful in the hands of customers you mentioned you the way kind
01:02:31 of think of the product way in the future have a press release and an FAQ and you think
01:02:37 backwards that's did you have that the team have the echo and mind so this far-field speech recognition
01:02:44 actually putting a thing in the home that works it's able to interact with was that the press release what was the
01:02:51 way close I would say in terms of the as I said the vision was started computer right or the inspiration and from there
01:02:59 I can't divulge all the exact specifications but one of the first things that was magical on a lexer was
01:03:10 music it brought me to back to music because my taste was still and when I was an undergrad right so I still listen
01:03:18 to those songs and I it was too hard for me to be a music fan with a phone right so I and I don't I hate things in my
01:03:26 ears so from that perspective it was quite hard and and and music was part of the at least the documents I have seen
01:03:35 right so so from that perspective I think yes in terms of our how far are we from the original vision I can't reveal
01:03:44 that words that's why I have done a fun at work because every day we go in and thinking like these are the new set of
01:03:49 challenges to solve yeah that's a great way to do great engineering is you think of the product press release I like that idea
01:03:56 maybe we'll talk about it a bit later was just a super nice way to have focused I'll tell you this you're a
01:04:02 scientist and a lot of my scientists have adopted that they they have now they love it as a process because it was
01:04:10 very a scientist you're trained to write great papers but they are all after you've done the research or you're
01:04:15 proven lie and your PhD dissertation proposal is something that comes closest or a DARPA proposal or NSF proposal is
01:04:23 the closest that comes to a press release but that process is now ingrained in our scientists which is
01:04:31 like delightful for me to see you write the paper first then make it happen that's right in fact that's not
01:04:36 state-of-the-art results or you leave the results section open well you have a thesis about here's what I expect right
01:04:43 and here's what it will change Yeah right so I think it is a great thing it works for researchers as well
01:04:51 they're so far field recognition yeah what was the big leap what what were the breakthroughs and yeah what was that
01:04:59 journey liked it today yeah I think the as you said first there was a lot of skepticism on whether far-field speech
01:05:04 recognition will ever work to be good enough right and what we first did was got a lot of training data in a far
01:05:13 field setting and that was extremely hard to get because none of it existed so how do you collect data in far field
01:05:21 set up right with no customer bases there's no customer base right so that was first innovation and once we had
01:05:28 that the next thing was ok you if you have the data first of all we didn't talk about like what would magical mean
01:05:35 in this kind of a setting what is good enough for customers right that's always since you've never done this before what
01:05:43 would be magical so so it wasn't just a research problem you had to put some in terms of accuracy and customer
01:05:50 experience features some stakes on the ground saying here is where I think should it should get to so you
01:05:56 established a bar and then how do you measure progress toward is given you have no customer right now so from that
01:06:04 perspective we went so first was the data without customers second was doubling down on deep learning as a way
01:06:13 to learn and I can just tell you that the combination of the two cut our error rates by a factor of five from where we
01:06:23 were when I started to within six months of having that data we at that point and I got the conviction that this will work
01:06:31 right so because that was magical in terms of when it started working and that reached them who came close to the
01:06:39 magical bar back to the bar right that we felt would be where people will use it that was critical because you you
01:06:49 really have one chance at this if we had launched in November 2014 years when we launched and if it was below the bar I
01:06:56 don't think this category exists if you don't need the bar yeah and just having looked at
01:07:02 voice-based interactions like in the car or earlier systems it's a source of huge frustration for people in fact we use
01:07:10 voice based interaction for collecting data on subjects to measure frustration so as a training set for computer vision
01:07:19 for face data so we can get a data set of frustrated people that's the best way to get frustrated people is having them
01:07:24 interact with a voice based system in the car so this is that bar I imagine it's pretty high it was very high and we
01:07:32 talked about how also errors are perceived from a eyes versus errors by humans but we are not done with the
01:07:40 problems that ended up we had to solve to get it to launch so do you want the next one so the next one was what I
01:07:50 think of as multi-domain natural language understanding it's very I wouldn't say easy but it is during
01:08:00 those days solving it understanding in one domain and narrow domain was doable but for these multiple domains like
01:08:10 music like information other kinds of household productivity alarms time errors even though it wasn't as big as
01:08:16 it is in terms of the number of skills alexa has and the confusion space has like grown by three orders of magnitude
01:08:24 it was still daunting even those days and again no customer base here again no customer base so now you're looking at
01:08:30 meaning understanding and intent understanding and taking actions on behalf of customers based on their
01:08:37 request and that is the next hard problem even if you have gotten the words recognized how do you make sense
01:08:47 of them in those days there was still a lot of emphasis on rule-based systems for writing grammar patterns to
01:08:54 understand the intent but we had a statistical first approach even then where for a language understanding we
01:09:02 had in even those starting days and an entity recognizer and an intent classifier which was all trained
01:09:09 statistically in fact we had to build the deterministic matching as follow-up to fix bugs that statistical models have
01:09:17 right so it was just a different mindset where we focused on data-driven statistical understanding wins in the
01:09:25 end if you have a huge dataset yes it is contingent on that and that's why it came back to how do you get the data
01:09:31 before customers the fact that this is why data becomes crucial to get a to the point that you have the understanding
01:09:41 system built in build up and notice that for here we were talking about human machine dialogue even those early days
01:09:49 even it was very much transactional do one thing one shot a transition great way there was a lot of debate on how
01:09:55 much should Alex our talk back in terms of if you misunderstood you or you said play songs by the stones and let's say
01:10:04 it doesn't know you know early days knowledge can be sparse who were the stones right I the Rolling Stones right
01:10:14 so our and you don't want them match to be Stone Temple Pilots or Rolling Stones right so you don't know which one it is
01:10:22 so these kind of other signals to know there we had great assets right from Amazon in terms of you acts like what is
01:10:30 it what kind of yeah hurry solve that problem in terms of what we think of it as an entity resolution problem right so
01:10:37 is one is it right I mean the even if you figured out the stones is an entity you have to resolve it to whether it's
01:10:43 the stones or the temple violence or some other stones maybe I misunderstood is the resolution the job of the
01:10:50 algorithm or is the job of UX communicating with the human to help there as well there is both right it is
01:10:58 law you want 90 percent or high 90s to be done without any further questioning or UX right so but that it's absolutely
01:11:06 okay just like as humans we asked the question I didn't understand your likes yeah it's fine for a lecture to
01:11:11 occasionally say I did not understand you right and and that's a important way to learn and I'll talk about where we
01:11:17 have come with more self learning with these kind of feedback signals but in those days just solving the
01:11:24 ability of understanding the intent and resolving to an action where action could be play a particular artist or a
01:11:32 particular song was super hot again - the bar was high as as you're talking about right so while we launched it in
01:11:41 sort of 13 big domains I would say in terms of or thing we think of it as 13 the big skills we had like music is a
01:11:48 massive one when we launched it and now we have 90,000 plus skills on Alexa so what are the big skills can you just go
01:11:56 is the only thing I use it for is music weather and shopping haha so we think of it as music information right so it's
01:12:05 all whether it's a part of information right so then we launched we didn't have smart home but within spikes bottom I
01:12:12 mean you connect your smart devices you control them with watch if you haven't done it it's worth it will change your
01:12:16 signing on the lights yeah you like to do anything that's connected and has a it's just what your
01:12:25 favorite smart device for you and now you've the smart plug with and you don't we also have this echo plug which is oh
01:12:33 yeah and now you can turn on that one on and off this conversation motivation in Kevin's garage door you can check your
01:12:40 status of the garage door and things like and we have gone may collect some more and more proactive where it even
01:12:46 have a hunt has on chores now that all those hunches like you left your light on or let's say you've gone to your bed
01:12:53 and you left the garage light on so yeah it will help you out in these settings right so that smart devices right
01:13:00 information smart devices said music yeah so I don't remember everything we had big ones like that was you know the
01:13:08 timers were very popular right away music also like you could play song artist album everything and so that was
01:13:17 like a clear win in terms of the customer experience so that's again this is language understanding now things
01:13:25 have evolved right so where we want a lecture definitely to be more accurate competent and trustworthy based on how
01:13:33 well it does these core things but we have in many different dimensions first is what I think of her doing more
01:13:39 conversational for high-utility not just for chat right and there we a tree Mars this year which is our AI conference we
01:13:46 launched what is called Alexa conversations that is providing the ability for developers to author
01:13:55 multi-tone experiences on Alexa with no code essentially in terms of the code dialogue code initially it was like you
01:14:03 know all these IVR systems you have to fully author if the customer says this do that right so the whole dialogue flow
01:14:12 is hand author and with Alexa conversations the way it is that you just provide a sample interaction data
01:14:18 with your service or an API let's say you're Adam take its that provides a service for buying movie tickets you
01:14:25 provide a few examples of how your customers will interact with your api's and then the dialogue flow is
01:14:30 automatically constructed using a recurrent neural network a train on that beta so that simplifies the developer
01:14:37 experience we just launched our preview for the developers to try this capability out and then the second part
01:14:44 of it which shows even increased utility for customers is you and I when we interact with Alexa or any customer as I
01:14:52 coming back to our initial part of the conversation the goal is often unclear or unknown to the AI if I say Alexa what
01:15:04 movies are playing nearby am i trying to just buy movie tickets am I actually even do you think I'm looking for just
01:15:13 movies for curiosity whether the Avengers are still in theater or when it's maybe it's gone and maybe it will
01:15:19 come on my mr. so I may watch it on prime which happened to me so so from that perspective now you're looking into
01:15:29 what is my goal and let's say I now complete the movie ticket purchase maybe I would like to get dinner nearby so
01:15:41 what is really the goal here is it night out or is it movies as and just go watch a movie here the answer is we don't know
01:15:51 so can Alexa now figure we have the intelligence that I think this metal goal is really night or at least say to
01:15:58 the customer when you have completed the purchase of movie tickets from Adam tickets or Fandango or picture anyone
01:16:06 then the next thing is do you want to get to get an uber to the theater right or do you want to book a restaurant next
01:16:17 to it and and then not ask the same information over and over again what time what how many people in your party
01:16:26 right so so this is where you shift the cognitive burden from the customer to the AI where it's thinking the of what
01:16:35 is your it anticipates your goal and takes the next best action to complete it now that's the machine learning
01:16:43 problem but essentially you're the way we solve this first instance and we have a long way to go to make it scale to
01:16:50 everything possible in the world but at least for this situation it is from at every instance Alexa is making the
01:16:56 determination whether it should stick with the experience with Adam tickets or offer or you based on what you say
01:17:05 whether either you have completed the interaction or you said no get me an uber now so it will shift context into
01:17:12 another experience or skill on another service so that's a dynamic decision-making that's making Alexa you
01:17:18 can say more conversational for the benefit of the customer rather than simply complete transactions which are
01:17:25 well thought through if you as a customer has fully specified what you want to be accomplished its
01:17:31 accomplishing that so it's kind of as I would do this with pedestrians like intent modeling is predicting what your
01:17:40 possible goals are most likely going and switching that depending on the things you say so my question is there it seems
01:17:47 maybe it's a dumb question but it would help a lot of elects remembered me what I said previously right
01:17:57 it is it's trying to use some memory for the custom year it is using a lot of memory within that so right now not so
01:18:03 much in terms of okay which restaurant do you prefer right that is a more long-term memory but within the
01:18:09 short-term memory within the session it is remembering how many people did you so if you said buy four tickets not has
01:18:17 made an implicit assumption that you were gonna have you need for at least four seats at a restaurant right so
01:18:23 these are the kind of context its preserving between these skills but within that session what are you asking
01:18:30 the right question in terms of for it to be more and more useful it has to have more long-term memory and that's also an
01:18:36 open question and again this is still early days so for me I mean everybody is different but yeah I'm definitely not
01:18:44 representative of the general population the sense that I do the same thing every day like I eat the same that I do
01:18:52 everything the same the same thing we're the same thing clearly this or the black shirt so it's frustrating when it looks
01:18:59 it doesn't get what I'm saying because I had to correct her every time the exact same way this has to do with certain
01:19:07 songs like she doesn't know certain weird songs only and doesn't know I've complained to Spotify about this talked
01:19:13 to the Rd head of our idea Spotify stairway to heaven I have to correct it every time it really doesn't play Led
01:19:23 Zeppelin correctly so I should figure you should send me or next time it fails the seat for you to send it to me we'll
01:19:30 take care of it okay well let's Apple it is one of my favorite it works for me so I'm like shocked it doesn't work for you
01:19:36 this is an official public port I'll put it I'll make it public retweet it we're gonna fix this there would have impairment
01:19:43 anyway but the point is you know I'm pretty boring and do the same thing but I'm sure most people do the same set of
01:19:49 things do you see Alexa sort of utilizing that in the future for improving the experience yes and not
01:19:55 only utilizing it's already doing some of it we call it where Alexa is becoming more self learning so Alexa is now auto
01:20:05 correcting millions and millions of car trances in US without any human supervision the way desert is let's take an example
01:20:14 of a particular song didn't work for you what do you do next you either it played the wrong song and you said
01:20:20 Alexa no that's not the song I want or you say likes a play that you try it again and that is a signal to Alexa that she
01:20:30 may have done something wrong and from that perspective we can learn if there's that failure pattern or that action of
01:20:39 song a was played when song B was requested yes it's very common with station names because play NPR you can
01:20:47 have n be confused as an M and then you for a certain accent like mine people confuse my n and M all the time
01:20:57 and because I will Indian accent there confusable to humans it is for Alexa too and in that part but it starts auto
01:21:08 correcting and we collect we correct a lot of these automatically without a human looking at the failures so the one
01:21:16 of the things that's for me missing in Alessa I don't know from a representative customer but every time I
01:21:24 correct it it would be nice to know that that made a difference yes you know I mean like that yeah sort of like I I
01:21:32 heard you like some acknowledgement of that we worked a lot with with Tesla study the autopilot and so on and a
01:21:39 large amount of the customers they used Tesla autopilot they feel like they're always teaching the system -huh
01:21:43 they're almost excited by the possibility teaching I don't know if Alexa customers generally think of it as
01:21:50 they're teaching to improve the system I think and that's a really powerful thing against I would say it's a spectrum some
01:21:57 customers do think that way and some would be annoyed by Alexa acknowledging that or so there's a again no one you
01:22:05 know while there are certain patterns not everyone is the same in this way but we believe that again customers helping
01:22:15 Alexa is a tenet for us in terms of improving it dancing more self learning is by again this is like fully
01:22:21 unsupervised right there is no you in the loop and no labeling happening and based on your actions as a customer
01:22:29 Alexa becomes smarter again it's early days but I think this whole area of teachable AI is gonna get bigger and
01:22:39 bigger in the whole space especially in the AI assistant space so that's the second part where I mentioned more
01:22:45 conversational this is more self learning the third is more natural and the way I think of more natural is we
01:22:54 talked about how Alexa sounds and there are and we have done lot of advances in our text to speech by using again neural
01:23:01 network technology for it to sound very human like an individual texture the sound to the the the timing the tonality
01:23:09 tone of everything I would think in terms of there's a lot of controls in each of the places for
01:23:16 how I mean the speed of the voice the prosthetic patterns the the actual smoothness of how it sounds all of those
01:23:25 are factored and we do ton of listening tests to make sure is that what naturalness how it sounds should be very
01:23:32 natural how it understands requests is also very important like and in terms of like we have 95,000 skills or and if we
01:23:40 have imagined that and many of these skills you have to remember the skin Ling and say Alexa asked they're tied
01:23:51 skill to tell me X right or now if you have to remove the skill name that means the discovery and the interaction is
01:23:57 unnatural and we're trying to solve that by what we think of as again this was you don't have to have the app metaphor
01:24:07 here these are not individual apps right even though they're so you cut you're not sort of opening one at a time and
01:24:12 interacting so yeah it should be seamless because it's voice and when it's voice you have to be able to
01:24:18 understand these requests independent of the specificity like a scale name and to do that what we have done is again built
01:24:24 a deep learning based capability where we shot list a bunch of skills when you say Alexa get me a car and then we
01:24:30 figure it out okay it may it's meant for a nubile skill versus a left or they on your preferences and then you can
01:24:38 rank the responses from the scale and then choose the best response for the customer so that's on the more natural
01:24:45 other examples of more natural is like we were talking about lists for instance and you wanna you don't want to say
01:24:54 Alexa add milk likes to add eggs Alexa hired cookies you know Alexa add cookies milk and eggs and that in one shot right
01:25:00 so that works that helps with the naturalness we talked about memory like if you said you can say like so remember
01:25:09 I have to go to Mom's house or you may have entered a calendar event through your calendar that's linked or like so
01:25:15 you don't remember whether it's in my calendar or did I tell you how to remember something or some other
01:25:22 reminder right so you have to now independent of how customers create these events it should just say Alexa
01:25:29 when do I have to go to Mom's house and it tells you when you have to go to Mom's house that's the fascinating
01:25:35 problem who's that problem on so the these people create skills who's who's tasked with integrating all of
01:25:43 that knowledge together so if the skills becomes seamless is it the creators of the skills sewer system the
01:25:50 infrastructure that Alexa provides problem it's both I think the large problem in terms of making sure your
01:25:59 skill quality is high we that has to be done by our tools because it's just so these skills just to put the context
01:26:06 they are built through Alexa skill scale which is a self-serve way of building an experience on Alexa this is like any
01:26:13 developer in the world could go to Alexa scale skate and build an experience on Alex like if you're a dominoes you can
01:26:20 build a domino skills for instance that does pizza ordering when you've authored that you do want to now if people say
01:26:30 like so open Domino's or Alexa ask dominoes dominoes to get a particular type of pizza that will work but the
01:26:38 discovery is harder you can't just say like so get me a pizza and then Alexa figures out what to do that latter part
01:26:45 is definitely our responsibility in terms of when the request is not Feliz how do you figure out what's the best
01:26:53 skill or a service that can fulfill the customer's request and it can keep evolving imagine going to the situation
01:27:00 I said which was the night out planning that it the goal could be more than that individual request that came a Pizza
01:27:09 ordering could mean a night in event with your kids in the house and your so this is welcome to the world of
01:27:17 conversational yeah this is this is super exciting because it's not the academic problem of NLP of natural
01:27:22 language processing understanding dialogue this is like real world the stakes are high in a sense that
01:27:30 customers get frustrated quickly people get frustrated quickly so you have to get it right if to get that interaction
01:27:37 right so it's I love it but so from that perspective what what are the challenges today what what are the problems that
01:27:45 really need to be solved and yes here's I think first and foremost as I mentioned that get the basics right are
01:27:56 still true basically even the one-shot requests which we think of as transactional requests needs to work
01:28:01 magically no question about that lee if it doesn't turn your light on and off you'll be super frustrated even if I can
01:28:07 complete the night out for you and not do that that is unacceptable for as a customer right so that you have to get
01:28:14 the foundational understanding going very well the second aspect when I said more conversational is as you imagine is
01:28:21 more about reasoning it is really about figuring out what the latent goal is of the customer based on what I have the
01:28:29 information now and the history and what's the next best thing to do so that's a complete reasoning and
01:28:35 decision-making problem just like your self-driving car but the goal is still more finite here it
01:28:41 Evos your environment is super hard and self-driving and the cost of a mistake is huge here but there are certain
01:28:50 similarities but if you think about how many decisions Alexa is making or evaluating at any given time it's a huge
01:28:57 hypothesis space and we're only talked about so far about what I think of reactive to
01:29:03 in terms of you asked for something and Alexis reacting to it if you bring the proactive part which is Alexa having
01:29:11 hunches so any given instance then your it's really a decision at any given point based on the information Alexa has
01:29:19 to determine what's the best thing it needs to do so these are the ultimate AI problem well decisions based on the
01:29:26 information you have do you think my prospectus a lot I work a lot with sensing of the human face do you think
01:29:33 they'll and we touch this topic a little bit earlier but do you think it'll be a day soon when Alexa can also look at you
01:29:41 to help improve the quality of the hunch it has or at least detect frustration or detects you know improve the quality of
01:29:53 its perception of what you what you're trying to do I mean let me again bring back to what it already does we talked
01:30:00 about how based on you bargain over Alexa clearly it's a very high probability it must have done something
01:30:08 wrong that's why you understand the next extension of whether frustration is a signal or not of course is a natural
01:30:16 thought in terms of how that should be in a signal to egg you can get that from voice you can get from voice but it's
01:30:23 very hard like I mean a frustration as a signal historically if you think about emotions of different kinds you know
01:30:30 there's a whole field of affective computing something that MIT has also done a lot of research and is super hot
01:30:38 and you are now talking about a far field device as in you're talking to a distance noisy environment and in that
01:30:45 environment it needs to have a good sense for your emotions this is a very very hard problem very hard problem but
01:30:51 you haven't shadow voice from hard problems well you know so deep learning has been at the core of a lot of this
01:30:58 technology are you optimistic about the current deep learning approaches to solving the hardest aspects of what
01:31:03 we're talking about or do you think there will come a time where new ideas need to for this you know if you look at
01:31:10 reasoning so opening eye deep mind a lot of folks are now starting to work in reasoning trying to see how can make
01:31:17 neural networks a reason do you see that new approaches need to be invented to take the next big leap absolutely I
01:31:26 think there has to be a lot more investment and I think in many different ways and there are these I would say
01:31:33 nuggets of research forming in a good way like learning with less data or like zero short learning one-shot learning
01:31:40 and the active learning stuff you've talked about is yes incredible since so transfer learning is also super critical
01:31:46 especially when you're thinking about applying knowledge from one task to another or one language to another right
01:31:54 it's really ripe so these are great pieces deep learning has been useful too and now we are sort of marrying deep
01:32:01 learning with with transfer learning an active learning of course that's more straightforward in terms of applying
01:32:06 deep learning and an active learning set up but but I do think in terms of now looking into more reasoning based
01:32:17 approaches is going to be key for our next wave of the technology but there is a good news the good news is that I
01:32:23 think for keeping on to delight customers that a lot of it can be done by prediction tasks yes so and so we
01:32:33 haven't exhausted that so we don't need to give up on the deep learning approaches for that so that's just I
01:32:40 wanted sort of the query on our rich fulfilling amazing experience that makes Amazon a lot of money and a lot of
01:32:46 everybody a lot of money because it does awesome things deep learning is enough the the point the point I don't think I
01:32:54 would say deep learning is enough I think for the purposes of Alexa accomplish the task for customers I'm
01:33:00 saying there are still a lot of things we can do with prediction based approaches that do not reason right I'm
01:33:06 not saying that and we haven't exhausted those but for the kind of high utility experiences
01:33:14 that I'm personally passionate about of what Alexa needs to do reasoning has to be solved today to the same extent as
01:33:22 you can think of naturally understanding and a speech recognition to the extent of
01:33:29 understanding intents has been how accurate it has become but reasoning we are very very early days the nest
01:33:35 another way how hard of a problem do you think that is hardest of them I would say hardest of them because again the
01:33:45 hypothesis space of is really really large and when you go back in time like you were saying I wanna I want Alexei to
01:33:54 remember more things that once you go beyond a session of interaction which is my session I mean a a time span which is
01:34:02 today two versus remembering which restaurant I like and then when I'm planning a night out to say do you want
01:34:08 to go to the same restaurant now you're up the steaks big time and and this is where the reasoning dimension also goes
01:34:16 very very big so you think the space will be elaborating that a little bit just philosophically speaking do you
01:34:24 think when you reason about trying to model what the goal of a person is in the context of interacting with Alexa
01:34:31 you think that space is huge it's huge absolutely you think so like another a devil's advocate would be that we human
01:34:39 beings are really simple and we all want like just a small set of things and they're so do you think you think it's
01:34:46 possible cuz we're not talking about a fulfilling general conversation perhaps actually the Alexa prize is a little bit
01:34:54 after that creating a customer like there's so many of the interactions it feels like are clustered in groups that
01:35:06 are don't require general reasoning I think you're you right in terms of the head of the distribution of all the
01:35:12 possible things customers may want to accomplish but the tail is long and it's diverse right so from many many long
01:35:24 tails from that perspective I think you have to solve that problem otherwise and everyone's very different like I mean we
01:35:31 see this already in terms of the skills right I mean if you if you're an average surfer which I am now
01:35:39 right but somebody is asking Alexa about surfing conditions right and there's a skill that is there for them to get to
01:35:47 right that tells you that the tail is massive like in terms of like what kind of skills people have created it's
01:35:54 humongous in terms of it and which means there are these diverse needs and and when you start looking at the
01:36:01 combinations of these right even if your pairs of skills and and 90000 choose two it's still a big concept of combination
01:36:10 so I'm saying there's a huge to do here now and I think customers are you know wonderfully frustrated with things and
01:36:20 then I'm gonna keep getting to do better things for that so and they're not known to be super patient so you have to do it
01:36:27 fast you have to do it fast yeah so you've mentioned the idea of a press release the research and development
01:36:35 Amazon Alexa and Amazon in general you kind of think of what the future product will look like and you kind of make it
01:36:39 happen you work backwards so can you draft for me you probably have one paquim makeup on for 10 20 30
01:36:51 40 years out that you see the Alexa team putting out just in broad strokes something that you dream about I think
01:36:59 let's start with the five years first okay so and I'll get to the Fortius through in broad strokes this term I
01:37:11 think the five year is where I mean I think of in these spaces it's hard especially if you're in thick of things
01:37:17 to think beyond the five year space because a lot of things change right I mean if you ask me five years back will
01:37:25 Alexa will be here I wouldn't have I think it has surpassed my imagination of that time right so I think then from the
01:37:33 next five years perspective from a AI perspective what we're gonna see is that notion which you said goal-oriented
01:37:41 dialogues and open domain like Alec surprised I think that bridge is gonna get closed they won't be different and
01:37:47 I'll give you why that's the case you mentioned shop how do you shop do you shop in in one
01:37:58 shot sure your double-a batteries paper towels yes how much how long does it take for you to buy a camera you do ton
01:38:06 of research yeah then you make a decision so is there is that a goal oriented a lot dialogue when I like
01:38:15 somebody says Alexa find me a camera is it simply in cue sitive ness right so even in this something that you think of
01:38:21 it as shopping which you said you yourself use a lot off if you go beyond where it's reorders or items where you
01:38:32 sort of not brand conscious and so forth that was just in shock just to comment quickly I've never bought in you think
01:38:39 through Alexa there haven't bought before on Amazon on a desktop after I clicked in a bunch you read a much
01:38:45 reviews that kind of stuff so it's repurchase so now you think in even for something that you felt like is is a
01:38:52 finite goal I think the space is huge because even products the attributes are many like and you want to look at
01:39:00 reviews some on Amazon some outside some you want to look at what Zenit is saying or another consumer forum is saying
01:39:06 about even a product for instance right so that's just that's just shopping where you could you could argue the
01:39:14 ultimate goal is sort of known and we haven't talked about Alexa what's the weather in Cape Cod this weekend right
01:39:21 so why am I asking that weather question right so I think I think of it as how do you complete goals with minimum steps
01:39:30 for our customers right and when you think of it that way the distinction between goal-oriented and conversations
01:39:39 for open domain say goes away I may want to know what happened in the presidential debate right and is it I'm
01:39:46 seeking just information on I'm looking at who's winning winning the debates right so these are all quite hard
01:39:54 problems so even the five-year horizon problem I'm like I sure hope we'll solve these new year you're optimistic because
01:40:02 that's the hard problem which part the reasoning you know enough to be able to help explore complex goals
01:40:11 that are beyond something simplistic that feels like it could be well five years is a nice it's a nice bar form
01:40:19 right I think you will it's a like nice ambition and do we have press releases for that absolutely can I
01:40:26 tell you what specifically the roadmap will be no right and what and will be solve all of it in the five-year space
01:40:34 now this is we will work on this forever actually if we this is the hardest of the eye problems and I don't see if that
01:40:41 being solved even in a 40 year horizon because even if you limit to the human intelligence we know we are quite far
01:40:49 from that in fact every aspects of our sensing to do neural processing to how brain stores information and how it
01:40:57 processes it we don't yet know how to represent knowledge all right so we're and still in those are early stages so I
01:41:05 wanted to start that's why at the five-year yeah because the five-year success would look like that and solving
01:41:12 these complex goals and the forty year would be where it's just natural to talk to these in terms of more of these
01:41:19 complex goals right now we've already come to the point where these transactions you mentioned of asking for
01:41:25 weather or reordering something or listening to your favorite tune it's natural for you to actually say it's
01:41:32 it's now unnatural to pick up your phone right and that I think is the first five-year transformation the next five
01:41:39 your transformation would be okay I can plan my weekend with Alexa or I can plan my next meal with Alexa or my next night
01:41:48 out with seamless effort so just to pause and look back at the big picture of it all
01:41:54 it's a you're part of a large team that's creating a system that's in the home that's not human that gets to
01:42:02 interact with human beings so we human beings we these descendants of apes have created an artificial
01:42:09 intelligence system that's able to have conversations I mean that that to me the two most
01:42:20 transformative robots of this century I think will be autonomous vehicles but they're a little bit transforming from a
01:42:30 more boring way it's like a tool I think conversational agents in the home is I can experience how does that make you
01:42:37 feel the year at the center of creating that as its do you sit back and awe sometimes what what it what is your what
01:42:47 is your feeling about the whole mess of it can you even believe that we're able to create something like this I think
01:42:53 it's a privilege I'm so fortunate like where where I ended up right and and it's been a long journey like I've been
01:43:02 in this space for a long time in Cambridge right and it's it's so heartwarming to see the kind of adoption
01:43:11 conversational agents are having now five years back it was almost like should I move out of this because we are
01:43:19 unable to find this killer application that customers would love that would not simply be good to have thing in research
01:43:28 labs and it's so fulfilling to see it make a difference to millions and billions of people a worldwide the good
01:43:34 thing is they're still very early so I have another 20 years of job security doing what I love like so I think from
01:43:42 that perspective I feel I tell every researcher this that joins or every member of my team this is a unique
01:43:49 privilege like I think and we have and I would say not just launching a lecture in 2014 which was first of its kind
01:43:56 along the way we have when we launch a lecture skills get it become became democratizing AI when before that there
01:44:03 was no good evidence often SDK for speech and language now we are coming to this very you and I'm having this
01:44:09 conversation where I'm not saying Oh legs planning a night out with an AI agent impossible I'm saying it's in the
01:44:17 realm of possibility and not only possible we will be launching this right so some elements of that every and it
01:44:24 will keep getting better we know that is a universal truth once you have these kind of agents out there being
01:44:31 use they get better for your customers and I think that's where I think the amount of research topics we are
01:44:39 throwing out at our budding researchers is just gonna be exponentially hard and the great thing is you can now get
01:44:46 immense satisfaction by having costumers use it not just a paper and new reps or another conference I think everyone
01:44:54 myself included are deeply excited about that future so that I don't think there's a better place to and Rohit
01:45:00 thank you thank you so much this was fun thank you same here thanks for listening to this conversation with rohit prasad
01:45:07 and thank you to our presenting sponsor cash app downloaded use coal export cast you'll get ten dollars and $10 will go
01:45:16 to first stem education nonprofit and inspires hundreds of thousands of young minds to learn and to dream of
01:45:23 engineering our future if you enjoy this podcast subscribe on youtube give it five stars an apple podcast supported on
01:45:30 patreon or connect with me on twitter and now let me leave you with some words of wisdom from the great alan turing
