00:00:02 the following is a conversation with Ian good fellow he's the author of the popular textbook on deep learning simply
00:00:09 titled deep learning he coined the term of generative adversarial networks otherwise known as Ganz and with his
00:00:18 2014 paper is responsible for launching the incredible growth of research and innovation in this subfield of deep
00:00:26 learning he got his BS and MS at Stanford his PhD at University of Montreal with yoshua bengio and Erin
00:00:34 Kerrville he held several research positions including an open AI Google brain and now at Apple as the director
00:00:42 of machine learning this recording happened while Ian was still a Google brain but we don't talk about anything
00:00:49 specific to Google or any other organization this conversation is part of the artificial intelligence podcast
00:00:56 if you enjoy it subscribe on YouTube iTunes or simply connect with me on Twitter at lex friedman spelled fri d
00:01:05 and now here's my conversation with Ian good fellow you open your popular deep learning book with a Russian doll type
00:01:14 diagram that shows deep learning is a subset of representation learning which in turn is a subset of machine learning
00:01:23 and finally a subset of AI so this kind of implies that there may be limits to deep learning in the context of AI so
00:01:30 what do you think is the current limits of deep learning and are those limits something that we can overcome with time
00:01:36 yeah I think one of the biggest limitations of deep learning is that right now it requires really a lot of
00:01:44 data especially labeled data there's some unsupervised and semi-supervised learning algorithms that can reduce the
00:01:49 amount of labeled data you need but they still require a lot of unlabeled data reinforcement learning algorithms they
00:01:54 don't need labels but they need really a lot of experiences as human beings we don't learn to play pong by failing at
00:02:03 pong two million times so just getting the generalization ability better is one of the most important bottlenecks and
00:02:09 the capability of the technology today and then I guess I'd also say deep learning is like a
00:02:17 of a bigger system so far nobody is really proposing to have only what you'd call deep learning as the entire
00:02:26 ingredient of intelligence you use deep learning as sub modules of other systems like alphago has a deep learning model
00:02:35 that estimates the value function most reinforcement learning algorithms have a deep learning module that estimates
00:02:40 which action to take next but you might have other components here basically as building a function estimator do you
00:02:49 think it's possible you said nobody is kind of in thinking about this so far but do you think neural networks could
00:02:55 be made to reason in the way symbolic systems did in the 80s and 90s to do more create more like programs as
00:03:02 opposed to functions yeah I think we already see that a little bit I already kind of think of neural nets as a kind
00:03:10 of program I think of deep learning as basically learning programs that have more than one step so if you draw a
00:03:18 flowchart or or if you draw a tensor flow graph describing your machine learning model I think of the depth of
00:03:24 that graph is describing the number of steps that run in sequence and then the width of that graph is the number of
00:03:31 steps that run in parallel now it's been long enough that we've had deep learning working that it's a little bit silly to
00:03:35 even discuss shallow learning anymore but back when I first got involved in AI when we used machine learning we were
00:03:41 usually learning things like support vector machines you could have a lot of input features to the model and you
00:03:46 could multiply each feature by a different weight but all those multiplications were done in parallel to
00:03:52 each other there wasn't a lot done in series I think what we got with deep learning was really the ability to have
00:03:59 steps of a program that run in sequence and I think that we've actually started to see that what's important with deep
00:04:06 learning is more the fact that we have a multi-step program rather than the fact that we've learned a representation if
00:04:13 you look at things like res nuts for example they take one particular kind of representation and they update it
00:04:22 several times back when deep learning first really took off in the academic world in 2006 when Geoff Hinton
00:04:28 showed that you could train deep belief networks everybody who was under ested in the idea thought of it as each layer
00:04:35 learns a different level of abstraction but the first layer trained on images learn something like edges and the
00:04:40 second layer learns corners and eventually you get these kind of grandmother's cell units that recognize
00:04:46 specific objects today I think most people think of it more as a computer program where as you add more layers you
00:04:53 can do more updates before you output your final number but I don't think anybody believes the layer 150 of the
00:05:02 resin it is a grand grandmother cell and you know layer 100 is contours or something like that okay so you think
00:05:08 you're not thinking of it as a singular representation that keeps building you think of it as a program sort of almost
00:05:16 like a state the representation is a state of understanding and yeah I think of it as a program that makes several
00:05:22 updates and arrives it better and better understandings but it's not replacing the representation at each step its
00:05:30 refining it and in some sense that's a little bit like reasoning it's not reasoning in the form of deduction but
00:05:36 it's reasoning in the form of taking a thought and refining it and refining it carefully until it's good enough to use
00:05:43 do you think and I hope you don't mind we'll jump philosophical every once in a while do you think of you know a
00:05:50 cognition human cognition or even consciousness as simply a result of this kind of cincuenta sequential
00:05:58 representation learning do you think that can emerge cognition yes I think so consciousness it's really hard to even
00:06:07 define what we mean by that I guess there's consciousness is often defined as things like having self-awareness and
00:06:15 that's relatively easy to turn into something actionable for a computer scientists the reason about people also
00:06:20 defined consciousness in terms of having qualitative states of experience like qualia and there's all these
00:06:25 philosophical problems like could you imagine jambe who does all the same information processing as a human but
00:06:32 doesn't really have the qualitative experiences that we have that sort of thing I have no idea how to formalize or
00:06:40 turn it into a scientific question I don't know how you could run in experiment to tell whether a person is a
00:06:44 zombie or not and similarly I don't know how you could run an experiment to tell whether an
00:06:51 advanced AI system had become conscious in the sense of qualia or not but in the more practical sense like almost like
00:06:56 self attention you think consciousness and cognition can in an impressive way emerge from
00:07:04 current types of architectures though yes yeah or or if if you think of consciousness in terms of self-awareness
00:07:12 and just making plans based on the fact that the agent itself exists in the world reinforcement learning algorithms
00:07:20 are already more or less forced to model the agents effect on the environment so that that more limited version of
00:07:28 consciousness is already something that we get limited versions of with reinforcement learning algorithms if
00:07:37 they're trained well but you say limited so the the big question really is how you jump from limited to human level
00:07:46 yeah right and whether it's possible you know the even just building common-sense reasoning seems to be exceptionally
00:07:52 difficult so K if we scale things up forget much better on supervised learning if we get better at labeling
00:07:59 forget bigger datasets and the more compute do you think we'll start to see really impressive things that go from
00:08:08 limited to you know something echoes of human level cognition I think so yeah I'm optimistic about what can happen
00:08:15 just with more computation and more data I do think it'll be important to get the right kind of data today most of the
00:08:22 machine learning systems we train our mostly trained on one type of data for each model but the human brain we get
00:08:31 all of our different senses and we have many different experiences like you know riding a bike driving a car talking to
00:08:39 people reading I think when you get that kind of integrated data set working with a machine learning model that can
00:08:47 actually close the loop and interact we may find that algorithms not so different from what we have today learn
00:08:53 really interesting things when you scale them up a lot and a large amount of multimodal data so
00:08:59 multimodal is really interesting but within like you're working adversarial examples so selecting within modal
00:09:11 within up one mode of data selecting better at what are the difficult cases from which are most useful to learn from
00:09:18 oh yeah like could we could you get a whole lot of mileage out of designing a model that's resistant to adverse fare
00:09:24 examples or something like that right yeah question but my thinking on that has evolved a lot over the last few
00:09:30 years one nice thing when I first started to really invest in studying adversarial examples I was thinking of
00:09:35 it mostly as that versus aryl examples reveal a big problem with machine learning and we would like to close the
00:09:43 gap between how machine learning models respond to adversarial examples and how humans respond after studying the
00:09:49 problem more I still think that adversarial examples are important I think of them now more of as a security
00:09:56 liability then as an issue that necessarily shows there something uniquely wrong with machine learning as
00:10:03 opposed to humans also do you see them as a tool to improve the performance of the system not not on the security side
00:10:11 but literally just accuracy I do see them as a kind of tool on that side but maybe not quite as much as I used to
00:10:17 think we've started to find that there's a trade-off between accuracy on adversarial examples and accuracy on
00:10:25 clean examples back in 2014 when I did the first adversary trained classifier that showed resistance to some kinds of
00:10:33 adversarial examples it also got better at the clean data on M NIST and that's something we've replicated several times
00:10:39 an M NIST that when we train against weak adversarial examples Emnes classifiers get more accurate so far
00:10:46 that hasn't really held up on other data sets and hasn't held up when we train against stronger adversaries it seems
00:10:53 like when you confront a really strong adversary you tend to have to give something up interesting this is such a
00:11:02 compelling idea because it feels it feels like that's how us humans learn yeah the difficult cases we we try to
00:11:08 think of what would we screw up and then we make sure we fix that yeah it's also in a lot of branches of
00:11:15 engineering you do a worst case analysis and make sure that your system will work in the worst case and then that
00:11:21 guarantees that it'll work in all of the messy average cases that happen when you go out into a really randomized world
00:11:28 you know with driving with autonomous vehicles there seems to be a desire to just look for think I'd viscerally tried
00:11:36 to figure out how to mess up the system and if you can be robust to all those difficult cases then you can it's a hand
00:11:44 waving empirical way to show that your system is yeah yes today most adverse early example
00:11:50 research isn't really focused on a particular use case but there are a lot of different use cases where you'd like
00:11:57 to make sure that the adversary can't interfere with the operation of your system like in finance if you have an
00:12:03 algorithm making trades for you people go to a lot of an effort to obfuscate their algorithm that's both to protect
00:12:09 their IP because you don't want to research and develop a profitable trading algorithm then have somebody
00:12:16 else capture the gains but it's at least partly because you don't want people to make adversarial examples that fool you
00:12:23 our algorithm into making bad trades or I guess one area that's been popular in the academic literature is speech
00:12:30 recognition if you use speech recognition to hear an audio waveform and then in turn that into a command
00:12:40 that a phone executes for you you don't want and a malicious adversary to be able to produce audio that gets
00:12:45 interpreted as malicious commands especially if a human in the room doesn't realize that something like that
00:12:52 is happening in speech recognition has there been much success in in being able to create adversarial examples that fool
00:13:01 the system yeah actually I guess the first work that I'm aware of is a paper called hidden voice commands that came
00:13:08 out in 2016 I believe and they were able to show that they could make sounds that are not understandable by a human but
00:13:18 are recognized as the target phrase that the attacker wants the phone to recognize it as since then things have
00:13:24 gotten a little bit better on the attacker side when worse on the defender side it's become possible to make sounds
00:13:35 that sound like normal speech but are actually interpreted as a different sentence than the human here's the level
00:13:43 of perceptibility of the adversarial perturbation is still kind of high the when you listen to the recording it
00:13:50 sounds like there's some noise in the background just like rustling sounds but those rustling sounds are actually the
00:13:56 adversarial perturbation that makes the phone hear a completely different sentence yeah that's so fascinating
00:14:01 Peter Norvig mention that you're writing the deep learning chapter for the fourth edition of the artificial intelligence
00:14:08 the modern approach book so how do you even begin summarizing the field of deep learning in a chapter well in my case I
00:14:17 waited like a year before I actually read anything is it even having written a full length
00:14:24 textbook before it's still pretty intimidating to try to start writing just one chapter that covers everything
00:14:33 one thing that helped me make that plan was actually the experience of having ridden the full book before and then
00:14:39 watching how the field changed after the book came out I realized there's a lot of topics that were maybe extraneous in
00:14:46 the first book and just seeing what stood the test of a few years of being published and what seems a little bit
00:14:52 less important to have included now helped me pare down the topics I wanted to cover for the book it's also really
00:14:59 nice now that the field is kind of stabilized to the point where some core ideas from the 1980s are still used
00:15:05 today when I first started studying machine learning almost everything from the 1980s had been rejected and now some
00:15:12 of it has come back so that stuff that's really stood the test of time is what I focused on putting into the book there's
00:15:21 also I guess two different philosophies about how you might write a book one philosophy is you try to write a
00:15:26 reference that covers everything and the other philosophy is you try to provide a high level summary that gives people the
00:15:32 language to understand a field and tells them what the most important concepts are the first deep learning book that I
00:15:38 wrote with Yahshua and Aaron was somewhere between the the two philosophies that it's trying to be both
00:15:45 a reference and an introductory guide writing this chapter for Russell and Norvig book I was able to focus more on
00:15:53 just a concise introduction of the key concepts and the language you need to read about them more and a lot of cases
00:15:57 actually just wrote paragraphs that said here's a rapidly evolving area that you should pay attention to it's it's
00:16:03 pointless to try to tell you what the latest and best version of a you know learn to learn model is right you know I
00:16:12 can I can point you to a paper that's recent right now but there isn't a whole lot of a reason to delve into exactly
00:16:20 what's going on with the latest learning to learn approach or the latest module produced by learning to learn algorithm
00:16:26 you should know that learning to learn is a thing and that it may very well be the source of the latest and greatest
00:16:33 convolutional net or recurrent net module that you would want to use in your latest project but there isn't a
00:16:37 lot of point in trying to summarize exactly which architecture in which learning approach got to which level of performance
00:16:47 so you maybe focus more on the basics of the methodology so from back propagation to feed-forward to recur in your
00:16:54 networks convolutional that kind of thing yeah yeah so if I were to ask you I remember I took algorithms and data
00:17:02 structures algorithm there of course remember the professor asked what is an algorithm and yelled at everybody in a
00:17:13 good way that nobody was answering it correctly everybody knew what the alkyl it was graduate course everybody knew
00:17:18 what an algorithm was but they weren't able to answer it well let me ask you in that same spirit what is deep learning I
00:17:28 would say deep learning is any kind of machine learning that involves learning parameters of more than one consecutive
00:17:39 step so that I mean shallow learning is things where you learn a lot of operations that happen in parallel you
00:17:45 might have a system that makes multiple steps like you might have had designed feature extractors but really only one
00:17:53 step is learned deep learning is anything where you have multiple operations in sequence and that includes
00:17:59 the things that are really popular today like convolutional networks and recurrent networks but it also includes
00:18:05 some of the things that have died out like Bolton machines where we weren't using back propagation today I hear a
00:18:14 lot of people define deep learning as gradient descent applied to these differentiable functions and I think
00:18:24 that's a legitimate usage of the term it's just different from the way that I use the term myself so what's an example
00:18:32 of deep learning that is not gradient descent on differentiable functions in your I mean not specifically perhaps but
00:18:40 more even looking into the future what's your thought about that space of approaches yeah so I tend to think of
00:18:46 machine learning algorithms as decomposed into really three different pieces there's the model which can be
00:18:53 something like a neural nut or a Bolton machine or a recurrent model and I basically just described
00:19:00 how do you take data and how do you take parameters and you know what function do you use to make a prediction given the
00:19:07 data and the parameters another piece of the learning algorithm is the optimization algorithm or not every
00:19:14 algorithm can be really described in terms of optimization but what's the algorithm for updating the parameters or
00:19:20 updating whatever the state of the network is and then the the last part is the the data set like how do you
00:19:29 actually represent the world as it comes into your machine learning system so I think of deep learning as telling us
00:19:37 something about what does the model look like and basically to qualify as deep I say that it just has to have multiple
00:19:46 layers that can be multiple steps in a feed-forward differentiable computation that can be multiple layers in a
00:19:52 graphical model there's a lot of ways that you could satisfy me that something has multiple steps that are each
00:19:58 parameterised separately I think of gradient descent as being all about that other piece the how do you
00:20:04 actually update the parameters piece so you can imagine having a deep model like a convolutional net and training it with
00:20:10 something like evolution or a genetic algorithm and I would say that still qualifies as deep learning and then in
00:20:16 terms of models that aren't necessarily differentiable I guess Boltzmann machines are probably the main example of something where you
00:20:25 can't really take a derivative and use that for the learning process but you you can still argue that the model has
00:20:33 many steps of processing that it applies when you run inference in the model so that's the steps of processing that's
00:20:40 key so geoff hinton suggests that we need to throw away back prop back propagation and start all over what do
00:20:47 you think about that what could an alternative direction of training nil networks look like I don't know that
00:20:53 back propagation is going to go away entirely most of this time when we decide that a machine learning algorithm
00:21:01 isn't on the critical path to research for improving AI the algorithm doesn't die it just becomes used for some
00:21:08 specialized set of things a lot of algorithms like logistic regression don't seem that exciting to
00:21:14 AI researchers who are working on things like speech recognition or autonomous cars today but there's still a lot of
00:21:21 use for logistic regression and things like analyzing really noisy data and medicine and finance or making really
00:21:29 rapid predictions in really time-limited contexts so I think I think back propagation and gradient descent are
00:21:36 around to stay but they may not end up being everything that we need to get to real human level or superhuman AI are
00:21:45 you optimistic about us discovering you know back propagation has been around for a few decades
00:21:53 so I optimistic bus about us as a community being able to discover something better yeah I am I think I
00:22:00 think we likely will find something that works better you could imagine things like having stacks of models where some
00:22:07 of the lower level models predict parameters of the higher level models and so at the top level you're not
00:22:13 learning in terms of literally calculating gradients but just predicting how different values will
00:22:18 perform you can kind of see that already in some areas like Bayesian optimization where you have a Gaussian process that
00:22:24 predicts how well different parameter values will perform we already used those kinds of algorithms for things
00:22:30 like hyper parameter optimization and in general we know a lot of things other than back prep that work really well for
00:22:35 specific problems the main thing we haven't found is a way of taking one of these other non back based algorithms
00:22:42 and having it really advanced the state-of-the-art on an AI level problem right but I wouldn't be surprised if eventually we
00:22:50 find that some of these algorithms that even the ones that already exists not even necessarily a new one we might find
00:22:58 some way of customizing one of these algorithms to do something really interesting at the level of cognition or
00:23:07 or the the level of I think one system that we really don't have working quite right yet is like short-term memory we
00:23:14 have things like LST M's they're called long short-term memory they still don't do quite what a human
00:23:22 does with short-term memory like gradient descent to learn a specific fact has to do multiple steps
00:23:31 on that fact like if I I tell you the meeting today is at 3 p.m. I don't need to say over and over again it's at 3
00:23:37 p.m. it's not 3 p.m. it's at 3 p.m. it's a 3 p.m. right for you to do a gradient step on each one you just hear it once
00:23:43 and you remember it there's been some work on things like self attention and attention like mechanisms like the
00:23:51 neural Turing machine that can write to memory cells and update themselves with facts like that right away but I don't
00:23:56 think we've really nailed it yet and that's one area where I'd imagine that new optimization algorithms are
00:24:03 different ways of applying existing optimization algorithms could give us a way of just lightning-fast updating the
00:24:11 state of a machine learning system to contain a specific fact like that without needing to have it presented
00:24:17 over and over and over again so some of the success of symbolic systems in the 80s is they were able to assemble these
00:24:27 kinds of facts better but dude there's a lot of expert input required and it's very limited in that sense do you ever
00:24:34 look back to that as something that will have to return to eventually sort of dust off the book from the shelf and
00:24:41 think about how we build knowledge representation knowledge place well we have to use graph searches searches
00:24:47 right and like first-order logic and entailment and things like that a thing yeah exactly
00:24:51 in my particular line of work which has mostly been machine learning security and and also generative modeling I
00:24:59 haven't usually found myself moving in that direction for generative models I could see a little bit of it could be
00:25:06 useful if you had something like a differentiable knowledge base or some other kind of knowledge base where it's
00:25:14 possible for some of our fuzzier machine learning algorithms to interact with the knowledge base immanuel Network is kind
00:25:19 of like that it's a differentiable knowledge base of sorts yeah but if if we had a really easy way of giving
00:25:29 feedback to machine learning models that would clearly helped a lot with with generative models and so you could
00:25:33 imagine one way of getting there would be get a lot better at natural language processing but another way of
00:25:39 getting there would be take some kind of knowledge base and figure out a way for it to actually interact with a neural
00:25:45 network being able to have a chat within y'all network yes so like one thing in generative models we see a lot today is
00:25:52 you'll get things like faces that are not symmetrical like like people that have two eyes that are different colors
00:25:59 and I mean there are people with eyes that are different colors in real life but not nearly as many of them as you
00:26:04 tend to see in the machine learning generated data so if if you had either a knowledge base that could contain the
00:26:11 fact people's faces are generally approximately symmetric and eye color is especially likely to be the same on both
00:26:19 sides being able to just inject that hint into the machine learning model without it having to discover that
00:26:25 itself after studying a lot of data it would be a really useful feature I could see a lot of ways of getting there
00:26:31 without bringing back some of the 1980s technology but I also see some ways that you could imagine extending the 1980s
00:26:38 technology to play nice with neural nets and have it help get there awesome so you talked about the story of
00:26:45 you coming up with idea of Gans at a bar with some friends you were arguing that this you know Gans would work Jenner of
00:26:53 adversarial networks and the others didn't think so then he went home at midnight coated up and it worked so if I
00:27:01 was a friend of yours at the bar I would also have doubts it's a really nice idea but I'm very skeptical that it would
00:27:07 work what was the basis of their skepticism what was the basis of your intuition why he should work I don't
00:27:15 want to be someone who goes around promoting alcohol for the science in this case I do actually think that
00:27:22 drinking helped a little bit mm-hmm when your inhibitions are lowered you're more willing to try out things that you
00:27:31 wouldn't try out otherwise so I I have noticed it in general that I'm less prone to shooting down some of my own
00:27:36 ideas when I'm when I have had a little bit to drink I think if I had had that idea at lunch time yeah I probably would
00:27:43 have thought it it's hard enough I mean one neural net you can't train a second neuron that in the inner loop of the
00:27:48 outer neural net that was basically my friends action was that trying to train two neural nets at the same time would be
00:27:55 too hard so it was more about the training process unless so my skepticism would be you know I'm sure you could
00:28:03 train it but the thing would converge to would not be able to generate anything reasonable and any kind of reasonable
00:28:10 realism yeah so so part of what all of us were thinking about when we had this conversation was deep Bolton machines
00:28:16 which a lot of us in the lab including me were a big fan of deep bolts and machines at the time they involved two
00:28:23 separate processes running at the same time one of them is called the positive phase where you load data into the model
00:28:32 and tell the model to make the data more likely the owners called the negative phase where you draw samples from the
00:28:38 model and tell the model to make those samples less likely in a deep Bolton machine it's not trivial to generate a
00:28:45 sample you have to actually run an iterative process that gets better and better samples coming closer and closer to the
00:28:52 distribution the model represents so during the training process you're always running these two systems at the
00:28:58 same time one that's updating the parameters of the model and another one that's trying to generate samples from
00:29:03 the model and they worked really well on things like Amnesty a lot of us in the lab including me had tried to get the
00:29:09 Boltzmann machines to scale past em inist to things like generating color photos and we just couldn't get the two
00:29:17 processes to stay synchronized so when I had the idea for Gans a lot of people thought that the discriminator would
00:29:22 have more or less the same problem as the negative phase in the Boltzmann machine that trying to train the
00:29:28 discriminator in the inner loop you just couldn't get it to keep up with the generator and the outer loop and that
00:29:33 would prevent it from converging to anything useful yeah I share that intuition yeah what turns out to not be
00:29:42 the case a lot of the time with machine learning algorithms it's really hard to predict ahead of time how well they'll
00:29:47 actually perform you have to just run the experiment and see what happens and I would say I still today don't have
00:29:54 like one factor I can put my finger on it say this is why ganz worked for photo generation and deep Boltzmann machines don't
00:30:03 there are a lot of theory papers showing that under some theoretical settings the the gun algorithm does actually converge
00:30:13 but those settings are restricted enough that they don't necessarily explain the whole picture in terms of all the
00:30:20 results that we see in practice so taking a step back can you in the same way as we talked about deep learning can
00:30:27 you tell me what generative adversarial networks are yeah so generative adversarial networks are a particular
00:30:34 kind of generative model a generative model is a machine learning model that can train on some set of data like so
00:30:40 you have a collection of photos of cats and you want to generate more photos of cats or you want to estimate a
00:30:47 probability distribution over cats so you can ask how likely it is that some new image is a photo of a cat ganzar one
00:30:55 way of doing this some generative models are good at creating new data other generative
00:31:01 models are good at estimating that density function and telling you how likely particular pieces of data are to
00:31:08 come from the same distribution as a training data gans are more focused on generating samples rather than
00:31:15 estimating the density function there are some kinds of games like flow gun that can do both but mostly guns are
00:31:22 about generating samples of generating new photos of cats that look realistic and they do that completely from scratch
00:31:32 it's analogous to human imagination when again creates a new image of a cat it's using a neural network to produce a cat
00:31:41 that has not existed before it isn't doing something like compositing photos together you're not you're not literally
00:31:47 taking the eye off of one cat on the ear off of another cat it's it's more of this digestive process where the the
00:31:53 neural net trains on a lot of data and comes up with some representation of the probability distribution and generates
00:32:00 entirely new cats there are a lot of different ways of building a generative model what's specific against is that we
00:32:06 have a two-player game in the game theoretic sense and as the players in this game compete
00:32:12 one of them becomes able to generate realistic data the first player is called the generator it produces output
00:32:20 data such as just images for example and at the start of the learning process it'll just produce completely random
00:32:26 images the other player is called the discriminator the discriminator takes images as input and guesses whether
00:32:33 they're real or fake you train it both on real data so photos that come from your training set actual photos of cats
00:32:39 and you try to say that those are real you also train it on images that come from the generator network and you train
00:32:47 it to say that those are fake as the two players compete in this game the discriminator tries to become better at
00:32:52 recognizing where their images are real or fake and the generator becomes better at fooling the discriminator into
00:32:59 thinking that its outputs are are real and you can analyze this through the language of game theory and find that
00:33:07 there's a Nash equilibrium where the generator has captured the correct probability distribution so in the cat
00:33:13 example it makes perfectly realistic cat photos and the discriminator is unable to do better than random guessing
00:33:20 because all the all the samples coming from both the data and the generator look equally likely to have come from
00:33:28 either source so do you ever do sit back and does it just blow your mind that this thing works so from very so it's
00:33:35 able to estimate that density function enough to generate generate realistic images I mean does it yeah do you ever
00:33:44 sit back yeah how does this even why this is quite incredible especially where Gant's have gone in terms of
00:33:50 realism yeah and and not just to flatter my own work but generative models all of them have this property that if they
00:33:58 really did what we asked them to do they would do nothing but memorize the training data right some models that are
00:34:05 based on maximizing the likelihood the way that you obtain the maximum likelihood for a specific training set
00:34:12 is you assign all of your probability mass to the training examples and nowhere else
00:34:17 forgets the game is played using a training set so the way that you become unbeatable in the game is you literally
00:34:24 memorize training examples one of my former interns wrote a paper his name is a Vaishnav nagarajan and he
00:34:33 showed that it's actually hard for the generator to memorize the training data hard in a statistical learning theory
00:34:40 sense that you can actually create reasons for why it would require quite a lot of learning steps and and a lot of
00:34:51 observations of of different latent variables before you could memorize the training data that still doesn't really
00:34:57 explain why when you produce samples that are new why do you get compelling images rather than you know just garbage
00:35:03 that's different from the training set and I don't think we really have a good answer for that especially if you think
00:35:09 about how many possible images are out there and how few images the generative model sees during training it seems just
00:35:18 unreasonable that generative models create new images as well as they do especially considering that we're
00:35:23 basically training them to memorize rather than generalize I think part of the answer is there's a paper called
00:35:31 deep image prior where they show that you can take a convolutional net and you don't even need to learn the parameters
00:35:34 of it at all you just use the model architecture and it's already useful for things like in
00:35:42 painting images I think that shows us that the convolutional network architecture captures something really
00:35:47 important about the structure of images and we don't need to actually use learning to capture all the information
00:35:55 coming out of the convolutional net that would that would imply that it would be much harder to make generative models in
00:36:02 other domains so far we're able to make reasonable speech models and things like that but to be honest we haven't
00:36:07 actually explored a whole lot of different data sets all that much we don't for example see a lot of deep
00:36:17 learning models of like biology datasets where you have lots of microarrays measuring the amount of different
00:36:23 enzymes and things like that so we may find that some of the progress that we've seen for images and speech turns
00:36:28 out to really rely heavily on the model architecture and we were able to do what we did for vision by trying to
00:36:35 reverse-engineer the human visual system and maybe it'll turn out that we can't just use that same trick for arbitrary kinds
00:36:44 of data all right so there's aspects of the human vision system the hardware of it that makes it without learning
00:36:51 without cognition just makes it really effective at detecting the patterns we've seen the visual world yeah that's
00:37:00 yeah that's really interesting what in a big quick overview in your view in your view what types of Gans are there and
00:37:08 what other generative models besides games are there yeah so it's maybe a little bit easier to start with what
00:37:14 kinds of generative models are there other than Gans so most generative models are likelihood
00:37:23 based where to train them you have a model that tells you how how much probability it assigns to a particular
00:37:30 example and you just maximize the probability assigned to all the training examples it turns out that it's hard to
00:37:38 design a model that can create really complicated images or really complicated audio waveforms and still have it be
00:37:47 possible to estimate the the likelihood function from a computational point of view most interesting models that you
00:37:54 would just write down intuitively it turns out that it's almost impossible to calculate the amount of probability they
00:38:01 assign to a particular point so there's a few different schools of generative models in the likelyhood family one
00:38:09 approach is to very carefully design the model so that it is computationally tractable to measure the density it
00:38:15 assigns to a particular point so there are things like auto regressive models like pixel CN n those basically break
00:38:26 down the probability distribution into a product over every single feature so for an image you estimate the probability of
00:38:33 each pixel given all of the pixels that came before it there's tricks where if you want to measure the density
00:38:40 function you can actually calculate the density for all these pixels more or less in parallel generating the image
00:38:47 still tends to require you to go one pixel at a time and that can be very slow but there again tricks for doing this in
00:38:54 a hierarchical pattern where you can keep the runtime under control or the quality of the images it generates
00:39:01 putting runtime aside pretty good they're reasonable yeah the I would say a lot of the best results are from Gans
00:39:10 these days but it can be hard to tell how much of that is based on who's studying which type of algorithm if that
00:39:18 makes sense the amount of effort invest in it but yeah or like the kind of expertise so a lot of people who've
00:39:23 traditionally been excited about graphics or art and things like that have gotten interested in Gans and to
00:39:29 some extent it's hard to tell our Gans doing better because they have a lot of graphics and art experts behind them or
00:39:36 our Gans doing better because they're more computationally efficient or our Gans doing better because they
00:39:43 prioritize the realism of samples over the accuracy of the density function I think I think all of those are
00:39:48 potentially valid explanations and it's it's hard to tell so can you give a brief history of Gans from 2014 we paid
00:40:01 for 13 yeah so a few highlights in the first paper we just showed that Gans basically work if you look back at the
00:40:07 samples we had now they looked terrible on the CFR 10 dataset you can't even recognize objects in them your papers I
00:40:16 will use CFR 10 we use em NIST which is little handwritten digits we used the Toronto face database which is small
00:40:22 grayscale photos of faces we did have recognizable faces my colleague Bing Xu put together the first
00:40:30 again face model for that paper we also had the CFR 10 dataset which is things like very small 32 by 32 pixels of cars
00:40:41 and cats and dogs for that we didn't get recognizable objects but all the deep learning people back then we're really
00:40:48 used to looking at these failed samples and kind of reading them like tea leaves right and people who are used to reading
00:40:54 the tea leaves recognize that our tea leaves at least look different right maybe not necessarily better but there
00:41:00 was something unusual about them and that got a lot of us excited one of the next really big steps was lap gown
00:41:08 by Emily Denton and seemeth chintala at Facebook AI research where they actually got really good high-resolution photos
00:41:15 working with gans for the first time they had a complicated system where they generated the image starting at low res
00:41:23 and then scaling up to high res but they were able to get it to work and then in 2015 I believe later that same year
00:41:34 palek Radford and sumh intelli and Luke Metz published the DC gain paper which it stands for deep convolutional again
00:41:44 it's kind of a non unique name because these days basically all gans and even some before that were deep in
00:41:49 convolutional but they just kind of picked a name for a really great recipe where they were able to actually using
00:41:56 only one model instead of a multi-step process actually generate realistic images of faces and things like that
00:42:05 that was sort of like the beginning of the Cambrian explosion of gans like you know once once you got animals that had
00:42:10 a backbone you suddenly got lots of different versions of you know like fish and right they have four-legged animals
00:42:16 and things like that so so DC Gann became kind of the backbone for many different models that came out used as a
00:42:24 baseline even still yeah yeah and so from there I would say some interesting things we've seen are there's a lot you
00:42:30 can say about how just the quality of standard image generation ganz has increased but what's also maybe more
00:42:36 interesting on an intellectual level is how the things you can use guns for has also changed one thing is that you can
00:42:44 use them to learn classifiers without having to have class labels for every example in your your training set so
00:42:50 that's called semi-supervised learning my colleague at open AI Tim Solomon's who's at at brain now wrote a paper
00:42:58 called improved techniques for training guns I'm a co-author on this paper but I can't claim any credit for this
00:43:04 particular part one thing he showed in the paper is that you can take the gun discriminator and use it as a classifier
00:43:11 that actually tells you you know this image is a cat this image is a dog this image is a car
00:43:16 this image is a truck and so and not just to say whether the image is real or fake but if it is real to say
00:43:21 specifically what kind of object it is and he found that you can train these classifiers with far fewer labeled
00:43:29 examples learn traditional classifiers so a few supervised based on also not just your discrimination ability but
00:43:37 your ability to classify you're going to do much you're going to convert much faster to being effective at being a
00:43:45 discriminator yeah so for example for the emne status set you want to look at an image of a handwritten digit and say
00:43:53 whether it's a 0 a 1 or 2 and so on to get down to less than 1% accuracy required around 60,000 examples until
00:44:04 maybe about 2014 or so in 2016 with this semi-supervised degan project tim was able to get below 1% error using only a
00:44:14 hundred labeled examples so that was about a 600 X decrease in the amount of labels that he needed he's still using
00:44:21 more images in that but he doesn't need to have each of them labeled as you know this one's a 1 this one's a 2 this one's
00:44:28 a 0 and so on then to be able to for Ganz to be able to generate recognizable objects so object for a particular class
00:44:37 you still need labelled data because you need to know what it means to be a particular class cat dog how do you
00:44:44 think we can move away from that yeah some researchers at brain Zurich actually just released a really great
00:44:51 paper on semi-supervised de Gans whether their goal isn't to classify its to make recognizable objects despite not having
00:44:59 a lot of label data they were working off of deep minds big gun project and they showed that they can match the
00:45:08 performance of began using only 10% I believe of the of the labels big gun was trained on the image net dataset which
00:45:14 is about 1.2 million images and had all of them labelled this latest project from brain Zurich shows that they're
00:45:21 able to get away with only having about 10% of the of the images labeled and they do that essentially using a
00:45:30 clustering algorithm where the discriminator learns to assign the objects to groups and then this
00:45:36 understanding that objects can be grouped into you know similar types helps it to form more realistic ideas of
00:45:45 what should be appearing in the image because it knows that every image it creates has to come from one of these
00:45:50 archetypal groups rather than just being some arbitrary image if you train again with no class labels you tend to get
00:45:57 things that look sort of like grass or water or brick or dirt but but without necessarily a lot going on in them and I
00:46:06 think that's partly because if you look at a large image net image the object doesn't necessarily occupy the whole
00:46:13 image and so you learn to create realistic sets of pixels but you don't necessarily learn that the object is the
00:46:20 star of the show and you want it to be in every image you make yeah you've heard you talk about the the horse the
00:46:28 zebra cycle Gann mapping and how it turns out again thought provoking that horses are usually on grass and zebras
00:46:36 are usually on drier terrain so when you're doing that kind of generation you're going to end up generating
00:46:44 greener horses or whatever so those are connected together it's not just yeah yeah be able to you're not able to segment
00:46:51 yeah it's generating the segments away so there are other types of games you come across in your mind that neural
00:47:02 networks can play with each other to to to be able to solve problems yeah the the one that I spend most of my time on
00:47:11 is insecurity you can model most interactions as a game where there's attackers trying to break your system
00:47:17 and you order the defender trying to build a resilient system there's also domain adversarial learning which is an
00:47:25 approach to domain adaptation that looks really a lot like Ganz the the author's had the idea before the game paper came
00:47:32 out their paper came out a little bit later and you know they they're very nice and sighted again paper but
00:47:40 I know that they actually had the idea before I came out domain adaptation is when you want to train a machine
00:47:47 learning model in 1:1 setting called a domain and then deploy it in another domain later and he would like it to
00:47:52 perform well in the new domain even though the new domain is different from how it was trained so for example you
00:47:59 might want to train on a really clean image data set like image net but then deploy on users phones where the user is
00:48:06 taking you know pictures in the dark or pictures while moving quickly and just pictures that aren't really centered or
00:48:15 when you take a normal machine learning model it often degrades really badly when you move to the new domain because
00:48:20 it looks so different from what the model was trained on domain adaptation algorithms try to smooth out that gap
00:48:27 and the domain adverse oral approach is based on training a feature extractor where the features have the same
00:48:33 statistics regardless of which domain you extracted them on so in the domain adversarial game you have one player
00:48:39 that's a feature extractor and another player that's a domain recognizer the domain recognizer wants to look at
00:48:45 the output of the feature extractor and guess which of the two domains oh the features came from so it's a lot like
00:48:51 the real versus fake discriminator and ends and then the feature extractor you can think of as loosely analogous to the
00:48:58 generator in games except what's trying to do here is both fool the domain recognizer and two not knowing which
00:49:05 domain the data came from and also extract features that are good for classification so at the end of the day
00:49:13 you can in in the cases where it works out you can actually get features that work about the same in both domains
00:49:22 sometimes this has a drawback where in order to make things work the same in both domains it just gets worse at the
00:49:27 first one but there are a lot of cases where it actually works out well on both do you think gas being useful in the
00:49:36 context of data augmentation yeah one thing you could hope for with Kenz is you could imagine I've got a limited
00:49:43 training set and I'd like to make more training data to train something else like a classifier you could train Magan
00:49:51 on the training set and then create more data and then maybe the classifier would perform better on the test set after
00:49:57 training on those big ERG and generated data set so that's the simplest version of of something you might hope would
00:50:04 work I've never heard of that particular approach working but I think there's some there's some closely related things
00:50:11 that that I think could work in the future and some that actually already have worked so if you think a little bit
00:50:16 about what we'd be hoping for if we use the gun to make more training data we're hoping that again we'll generalize to
00:50:23 new examples better than the classifier would have generalized if it was trained on the same buddy at us
00:50:27 and I don't know of any reason to believe that the Gann would generalize better than the classifier would but
00:50:33 what we might hope for is that the Gann could generalize differently from a specific classifier so one thing I think
00:50:39 is worth trying that I haven't personally tried but someone could try is what have you trained a whole lot of
00:50:45 different generative models on the same training set create samples from all of them and then train a classifier on that
00:50:52 because each of the generative models might generalize in a slightly different way they might capture many different
00:50:57 axes of variation that one individual model wouldn't and then the classifier can capture all of those ideas by
00:51:03 training in all of their data so we'd be a little bit like making an ensemble of classifiers and I say oh of gans
00:51:09 yeah in a way I think that could generalize better the other thing that gans are really good for is not
00:51:17 necessarily generating new data that's exactly like what you already have but by generating new data that has
00:51:24 different properties from the data you already had one thing that you can do is you can create differentially private
00:51:30 data so suppose that you have something like medical records and you don't want to train a classifier on the medical
00:51:35 records and then publish the classifier because someone might be able to reverse-engineer some of the medical
00:51:41 records you trained on there's a paper from Casey greens lab that shows how you can train again using differential
00:51:48 privacy and then the samples one again still have the same differential privacy guarantees as the parameters that again
00:51:55 so you can make fake patient data for other researchers to use and they can do almost anything they want with that data
00:52:01 because it doesn't come from real people and the differential privacy mechanism gives you clear guarantees on how much
00:52:08 the original people's data has been protected that's really interesting actually I haven't heard you talk about
00:52:15 that before in terms of fairness I've seen from triple AI your talk how can an adversarial machine learning
00:52:23 help models be more fair with respect to sensitive variables yeah there was a paper from Amos Torquay's lab about how
00:52:31 to learn machine learning models that are incapable of using specific variables so to say for example you
00:52:37 wanted to make predictions that are not affected by gender it isn't enough to just leave gender out
00:52:43 of the input to the model you can often infer gender from a lot of other characteristics like say that you have
00:52:48 the person's name but you're not told their gender well right if if their name is Ian they're kind of obviously a man
00:52:54 so what you'd like to do is make a machine learning model that can still take in a lot of different attributes
00:53:01 and make a really accurate informed prediction but be confident that it isn't reverse engineering gender or
00:53:07 another sensitive variable internally you can do that using something very similar to the domain adversarial
00:53:14 approach where you have one player that's a feature extractor and another player that's a feature analyzer and you
00:53:20 want to make sure that the feature analyzer is not able to guess the value of the sensitive variable that you're
00:53:27 trying to keep private right that's yeah I love this approach so we'll yeah with the with the feature you're not able to
00:53:35 infer right this sensitive variables yeah brilliant it's quite quite brilliant and simple actually another
00:53:42 way I think that Ganz in particular could be used for fairness would be to make something like a cycle again where
00:53:49 you can take data from one domain and convert it into another we've seen cycle again turning horses into zebras we've
00:53:57 seen other unsupervised gains made by Ming Yue Lu doing things like turning day photos into night photos I think for
00:54:06 fairness you could imagine taking records for people in one group and transforming them into analogous people
00:54:12 in another group and testing to see if they're they're treated equitably across those two groups there's a lot of things
00:54:18 that be hard to get right to make sure that the conversion process itself is fair and I don't think it's anywhere
00:54:24 near something that we could actually use yet but if you could design that conversion process very carefully it
00:54:29 might give you a way of doing audits where you say what if we took people from this group converted them into
00:54:35 equivalent people in another group does the system actually treat them how it ought to that's also really interesting
00:54:45 you know in a popular in popular press and in general in our imagination you think well gangs are able to generate
00:54:52 data and use to think about deep fakes or being able to sort of maliciously generate data
00:55:00 that fakes the identity of other people is this something of a concern to you is this something if you look 10 20 years
00:55:08 into the future is that something that pops up in your work in the work of the community that's working on generating
00:55:15 models I'm a lot less concerned about 20 years from now than the next few years I think there will be a kind of bumpy
00:55:22 cultural transition as people encounter this idea that there can be very realistic videos and audio that aren't
00:55:28 real I think 20 years from now people will mostly understand that you shouldn't believe something is real just
00:55:34 because you saw a video of it people will expect to see that it's been cryptographically signed or or have some
00:55:42 other mechanism to make them believe the the content is real there's already people working on this like there's a
00:55:48 startup called true pic that provides a lot of mechanisms for authenticating that an image is real there they're
00:55:55 maybe not quite up to having a state actor try to to evade their their verification techniques but it's
00:56:02 something people are already working on and I think we'll get right eventually so you think authentication will will
00:56:08 eventually went out so being able to authenticate that this is real and this is not yeah as opposed to gas just
00:56:16 getting better and better or generative models being able to get better and better to where the nature of what is
00:56:22 real I don't think we'll ever be able to look at the pixels of a photo and tell you for sure that it's real or not real
00:56:31 and I think it would actually be somewhat dangerous to rely on that approach too much if you make a really
00:56:37 good fake detector and then someone's able to fool your fake detector and your fake detector says this image is not
00:56:43 fake then it's even more credible than if you've never made a fake detector in the first place
00:56:50 what I do think we'll get to is systems that we can kind of use behind the scenes for to make estimates of what's
00:56:57 going on and maybe not like use them in court for a definitive analysis I also think we will likely get better
00:57:05 authentication systems where you know if a match every phone cryptographically signs
00:57:10 everything that comes out of it you wouldn't go to conclusively tell that an image was real but you would be able to
00:57:18 tell somebody who knew the appropriate private key for this phone was actually able to sign this image and upload it to
00:57:29 this server at this timestamp so you could imagine maybe you make phones that have the private keys Hardware embedded
00:57:37 in them if like a State Security Agency really wants to infiltrate the company they could probably you know plant a
00:57:43 private key of their choice or break open the chip and learn the private key or something like that but it would make
00:57:49 it a lot harder for an adversary with fewer resources to fake things most of us yeah okay okay so you mentioned the
00:57:58 beer and the bar and the new ideas you were able to implement this or come up with this new idea pretty quickly and
00:58:04 implement it pretty quickly do you think there are still many such groundbreaking ideas and deep learning that could be
00:58:11 developed so quickly yeah I do think that there are a lot of ideas that can be developed really quickly guns were
00:58:17 probably a little bit of an outlier on the whole like one-hour timescale right but just in terms of a like low resource
00:58:24 ideas where you do something really different on the algorithm scale and get a big payback I think it's not as likely
00:58:33 that you'll see that in terms of things like core machine learning technologies like a better classifier or a better
00:58:38 reinforcement learning algorithm or a better generative model if I had the gun idea today it would be a lot harder to
00:58:45 prove that it was useful than it was back in 2014 because I would need to get it running on something like image net
00:58:54 or celibate high resolution you know those take a while to train you couldn't you couldn't train it in an hour and
00:58:59 know that it was something really new and exciting back in 2014 shredding an amnesty was enough but there are other
00:59:07 areas of machine learning where I think a new idea could actually be developed really quickly with low resources what's
00:59:15 your intuition about what areas of machine learning are ripe for this yeah so I think
00:59:22 fairness and interpretability our areas where we just really don't have any idea how anything should be
00:59:28 done yet like for interpretability I don't think we even have the right definitions and
00:59:34 even just defining a really useful concept you don't even need to run any experiments could have a huge impact on
00:59:41 the field we've seen that for example in differential privacy that  Cynthia Dworkin her collaborators made this
00:59:48 technical definition of privacy where before a lot of things are really mushy and then with that definition you could
00:59:54 actually design randomized algorithms for accessing databases and guarantee that they preserved individual people's
01:00:00 privacy in a in like a mathematical quantitative sense right now we all talk a lot about how interpretable different
01:00:08 machine learning algorithms are but it's really just people's opinion and everybody probably has a different idea
01:00:13 of what interpretability means in their head if we could define some concept related to interpretability that's
01:00:19 actually measurable that would be a huge leap forward even without a new algorithm that increases that quantity
01:00:27 and also once once we had the definition of differential privacy it was fast to get the algorithms that guaranteed it so
01:00:32 you could imagine once we have definitions of good concepts and interpretability we might be able to provide the
01:00:38 algorithms that have the interpretability guarantees quickly to what do you think it takes to build a
01:00:48 system with human level intelligence as we quickly venture into the philosophical so artificial general
01:00:57 intelligence what do you think I I think that it definitely takes better environments than we currently have for
01:01:04 training agents that we want them to have a really wide diversity of experiences I also think it's going to
01:01:11 take really a lot of computation it's hard to imagine exactly how much so you're optimistic about simulation
01:01:18 simulating a variety of environments is the path forward I think it's a necessary ingredient yeah I don't think
01:01:26 that we're going to get to artificial general intelligence by training on fixed datasets or by thinking really
01:01:32 hard about the problem I think that the the agent really needs to interact and have a variety of
01:01:41 experiences within the same lifespan and today we have many different models that can each do one thing and we tend to
01:01:48 train them on one data set or one RL environment sometimes they're actually papers about getting one set of
01:01:54 parameters to perform well in many different RL environments but we don't really have anything like an agent that
01:02:01 goes seamlessly from one type of experience to another and and really integrates all the different things that
01:02:08 it does over the course of its life when we do see multi agent environments they tend to be there are so many multi
01:02:15 environment agents they tend to be similar environments like all of them are playing like an action based video
01:02:21 game we don't really have an agent that goes from you know playing a video game to like reading The Wall Street Journal
01:02:30 to predicting how effective a molecule will be as a drug or something like that what do you think is a good test for
01:02:37 intelligence in you view it's been a lot of benchmarks started with the with Alan Turing a natural conversation being good
01:02:45 being a good benchmark for intelligence what what are what would you and good fellows sit back and be really damn
01:02:54 impressed if a system was able to accomplish something that doesn't take a lot of glue from human engineers so
01:03:03 imagine that instead of having to go to the CFR website and download CFR 10 and then write a Python script to parse it
01:03:12 and all that you could just point an agent at the CFR 10 problem and it downloads and extracts the data and
01:03:20 trains a model and starts giving you predictions I feel like something that doesn't need to have every step of the
01:03:29 pipeline assembled for it it definitely understands what it's doing is Auto ml moving into that direction are you
01:03:35 thinking wave and bigger autosomal has mostly been moving toward once we've built all the glue can the machine
01:03:42 learning system to design the architecture really well so I'm we're saying like
01:03:48 if something knows how to pre-process the data so that it successfully accomplishes the task then it would be
01:03:54 very hard to argue that it doesn't truly understand the task in some fundamental sense and I don't necessarily know that that's
01:04:01 like the philosophical definition of intelligence but that's something that would be really cool to build that would
01:04:05 be really useful and would impress me and would convince me that we've made a step forward in real AI so you give it
01:04:15 like the URL for Wikipedia and then next day expected to be able to solve CFR 10 or like you type in a paragraph
01:04:22 explaining what you want it to do and it figures out what web searches it should run and downloads all the whole
01:04:31 unnecessary ingredients so you have a very clear calm way of speaking no arms easy to edit I've seen comments for both
01:04:42 you and I have been identified as both potentially being robots if you have to prove to the world that you are indeed
01:04:51 human how would you do it but I can understand thinking that I'm a robot it's the flipside yeah touring test I
01:04:59 think yeah yeah the proof prove your human test I mean I lecture so you have to is there something that's truly
01:05:09 unique in your mind I suppose it doesn't go back to just natural language again just being able to so proving proving
01:05:15 that I'm not a robot with today's technology yeah that's pretty straightforward too like my conversation today hasn't veered
01:05:23 off into you know talking about the stock market or something because in my training data but I think it's more
01:05:28 generally trying to prove that something is real from the content alone it was incredibly hard that's one of the main
01:05:32 things I've gotten out of my can research that you can simulate almost anything and so you have to really step
01:05:41 back to a separate channel to prove that slang is real so like I guess I should have had myself stamped on a blockchain
01:05:47 when I was born or something but I didn't do that so according to my own research methodology there's just no way
01:05:53 to know at this point so what last question problem stands all for you that you're really excited about
01:06:00 challenging in the near future so I think resistance to adversarial examples figuring out how to make machine
01:06:06 learning secure against an adversary who wants to interfere it in control with it is one of the most important things
01:06:12 researchers today could solve in all domains in image language driving in I guess I'm most concerned about domains
01:06:22 we haven't really encountered yet like like imagine twenty years from now when we're using advanced day eyes to do
01:06:28 things we haven't even thought of yet like if you ask people what are the important problems in security of phones
01:06:38 in in like 2002 I don't think we would have anticipated that we're using them for you know nearly as many things as
01:06:43 we're using them for today I think it's going to be like that with AI that you can kind of try to speculate about where
01:06:48 it's going but really the business opportunities that end up taking off would be hard to predict ahead of time
01:06:55 well you can predict ahead of time is that almost anything you can do with machine learning you would like to make
01:07:02 sure that people can't get it to do what they want rather than what you want just by showing it a funny QR code or
01:07:09 a funny input pattern and you think that the set of methodology to do that can be bigger than you want domain and that's I
01:07:16 think so yeah yeah like one methodology that I think is not not a specific methodology but like a category of
01:07:23 solutions that I'm excited about today is making dynamic models that change every time they make a prediction so
01:07:31 right now we tend to train models and then after they're trained we freeze them and we just use the same rule to
01:07:36 classify everything that comes in from then on that's really a sitting duck from a security point of view if you
01:07:43 always output the same answer for the same input then people can just run inputs through until they find a mistake
01:07:50 that benefits them and then they use the same mistake over and over and over again I think having a model that
01:07:57 updates its predictions so that it's harder to predict what you're going to get will make it harder for the for an
01:08:04 adversary to really take control of the system and make it do what they want it to do yeah models that maintain a bit of
01:08:10 a sense of mystery and bought them because they always keep changing yeah and thanks so much for talking today it
