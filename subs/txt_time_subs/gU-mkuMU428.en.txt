00:00:01 the following is a conversation with Alex garland writer and director of many imaginative and philosophical films from
00:00:10 the dreamlike exploration of human self-destruction in the movie annihilation to the deep questions of
00:00:16 consciousness and intelligence raised in the movie ex machina which to me is one of the greatest movies and artificial
00:00:24 intelligence ever made I'm releasing this podcast to coincide with the release of his new series called devs
00:00:30 that will premiere this Thursday March 5th on Hulu as part of FX on Hulu it explores many of the themes this very
00:00:39 podcast is about from quantum mechanics to artificial life to simulation to the modern nature of power in the tech world
00:00:48 I got a chance to watch a preview and loved it the acting is great Nick Offerman especially is incredible in it
00:00:58 the cinematography is beautiful and the philosophical and scientific ideas explored are profound and for me as an
00:01:05 engineer and scientist were just fun to see brought to life for example if you watch the trailer for the series
00:01:11 carefully you'll see there's a programmer with a Russian accent looking at a screen with Python like code on it
00:01:17 that appears to be using a library that interfaces with a quantum computer this attention and technical detail on
00:01:25 several levels is impressive and one of the reasons I'm a big fan of how Alex weave science and philosophy together in
00:01:33 his work meeting Alex for me was unlikely but it was life changing in ways I may only be able to articulate in
00:01:40 a few years just as meeting spot many of Boston Dynamics for the first time planted a
00:01:47 seed of an idea in my mind so did meeting Alex garland he's humble curious intelligent and to me and
00:01:56 inspiration plus he's just really a fun person to talk with about the biggest possible questions in our universe this
00:02:04 is the artificial intelligence podcast if you enjoy it subscribe on YouTube give it five stars
00:02:10 on Apple podcast supported on patreon or simply connect with me on Twitter and Lex Friedman spelled Fri D M am as usual
00:02:19 I'll do one or two minutes of ads now and never any ads in the middle that can break the flow of the conversation I
00:02:25 hope that works for you and doesn't hurt the listening experience this show is presented by cash app the number one
00:02:32 finance app in the App Store when you get it you just code Lex podcast cash app lets you send money to friends buy
00:02:40 Bitcoin and invest in the stock market with as little as one dollar since cash app allows you to buy Bitcoin let me
00:02:47 mention that cryptocurrency in the context of the history of money is fascinating I recommend a cent of money
00:02:55 as a great book on this history debits and credits on Ledger's started thirty thousand years ago the US dollar was
00:03:03 created about two hundred years ago a Bitcoin the first decentralized cryptocurrency was released just over
00:03:10 ten years ago so given that history cryptocurrency still very much in its early days of development but it still
00:03:17 is aiming to and just might redefine the nature of money so again if you get cash up from the App
00:03:24 Store Google Play and use collects podcast you'll get ten dollars in cash Apple also donate ten dollars the first
00:03:32 one of my favorite organizations that is helping advanced robotics and STEM education for young people around the
00:03:39 world and now here's my conversation with Alex garland you describe the world inside the shimmer in the movie
00:03:47 annihilation as dreamlike I mean that it's internally consistent but detached from reality that leads me to ask do you
00:03:55 think a philosophical question I apologize do you think we might be living in a dream or in a simulation like the kind
00:04:03 that the shimmer creates we human beings here today yeah I want to sort of separate that out into two
00:04:13 things yes I think we're living in a dream of sorts no I don't think we're living in a simulation I think we're
00:04:22 living on a planet with a very thin layer of atmosphere and the planet is in a very large space and the space is full
00:04:30 of other planets and stars and quasars and stuff like that and I don't think I don't think those physical objects I
00:04:37 don't in the matter in that universe is simulated I think it's there we are definitely Soho problem is saying
00:04:48 definitely but in my opinion just about that we I think it seems very like we're living in a dream state I'm pretty sure
00:04:55 we are and I think that's just to do with the nature of how we experience the world we experience in a subjective way
00:05:04 and the the thing I've learned most as I've got older in some respects is is the degree to which reality is
00:05:11 counterintuitive and that the things that are presented to us as objective turn out not to be objective and quantum
00:05:17 mechanics is full of that kind of thing but actually just day-to-day life is full of that kind of thing as well so so
00:05:25 my understanding of the way the way the brain works is you you get some information hit your optic nerve and
00:05:32 then your brain makes its best guess about what it's seeing or what it's saying it's seeing it may or may not be
00:05:39 an accurate best guess it might be an inaccurate best guess and that that gap the best guess gap means that we are
00:05:48 essentially living in a subjective state which means that we're in a dream state so I I think you could enlarge on the
00:05:55 dream state in all sorts of ways but so yes dream state no simulation would be where I'd come down said going further
00:06:03 deeper into that direction you've also described that world as psychedelia so on that topic I'm curious
00:06:12 about that world on the topic of psychedelic drugs do you see those kinds of chemicals that modify our
00:06:21 option as a distortion of our perception reality or a window into another reality no I think what I'd be saying is that we
00:06:29 live in a distorted reality and then those kinds of drugs give us a different kind of distorted active yeah exactly
00:06:35 they just give an alternate Distortion and I think that what they really do is they give they give a distorted
00:06:42 perception which is a little bit more halide to daydreams or unconscious interests so if for some reason you're
00:06:51 feeling unconsciously anxious at that moment and you take a psychedelic drug you'll have a more pronounced unpleasant
00:06:57 experience and if you're feeling very calm or or happy my have a good time but but yeah so if I'm saying we're starting
00:07:06 from a premise our starting point is or we were already in the slightly psychedelic state you what those drugs
00:07:13 do is help you go further down an avenue or it may be a slightly different Avenue but that's what so in in a movie
00:07:22 annihilation the the shimmer this alternate dreamlike state is created by I believe perhaps an alien entity of
00:07:30 course everything is up to interpretation right but do you think there's in our world in our universe do
00:07:37 you think there's intelligent life out there and if so how different is it from us humans well one of the things I was
00:07:49 trying to do in annihilation was to to offer up a form of alien life that was actually alien because it would often
00:07:59 seem to me that in the way we would represent aliens in in books or cinema or television or well you know any one
00:08:08 of the sort of storytelling mediums is we would always give them very human-like qualities so they wanted to
00:08:14 teach us about galactic federations or they wanted to eat us or they wanted our resources like our water or they want to
00:08:21 enslave us or whatever it happens to be but all of these are incredibly human-like motivations and I was
00:08:30 interested in the idea of an alien that was not in any way like us it didn't share it maybe it had a
00:08:39 completely different clock speed maybe it's way so what we're talking about we're looking at each other we're
00:08:46 getting information like hits our optic nerve our brain makes the best guess of what we're doing sometimes it's right
00:08:50 something you know the thing we were talking about before what if this alien doesn't have an optic nerve maybe its
00:08:57 way of encountering the space it's in is wholly different maybe it has a different relationship with gravity the
00:09:03 basic laws of physics that operates under might be fundamentally different it could be a different timescale and so
00:09:10 on yeah or it could be the same laws it could be the same underlying laws of physics you know it's a machine created
00:09:17 it where it's it's a creature creating a quantum mechanical way it just ends up in a very very different place to the
00:09:24 one we end up in so so part of the preoccupation with annihilation was to come up with an alien that was really
00:09:34 alien and didn't give us and it didn't give us and we didn't give it any kind of easy connection between human and the
00:09:41 alien because I think it was to do with the idea that you could have an alien that landed on this planet that wouldn't
00:09:47 even know we were here and we might only glancingly know it was here that just be this strange point where the Venn
00:09:54 diagrams connected where we could sense each other or something like that so in the movie
00:10:00 first of all incredibly original view of what an alien life would be and she said in that sense it's a huge success let's
00:10:08 go inside your imagination did the alien that alien entity know anything about humans when it landed No so the idea is
00:10:18 you're both you're basically an alien life is trying to reach out to anything that might be able to hear its mechanism
00:10:28 of communication or was it simply was it just basically they're biologists exploring different kinds of stuff they
00:10:33 compete you see but this is the interesting thing as as soon as you say they're biologists you've done the thing
00:10:40 of attributing human type motivations to it I I was trying to free myself from anything yes like that
00:10:50 so all sorts of questions you might answer about this notion or alien I wouldn't be able to answer because I
00:10:57 don't know what it was or how it works you know yeah I had I gave it some I had some rough ideas like it had a very very
00:11:04 very slow clock speed and I thought maybe the way it is interacting with this environment is a little bit like
00:11:12 the way an octopus will change its color forms around the space that it's in so it's sort of reacting to what it's in to
00:11:20 an extent but the reason it's reacting in that way is indeterminate but it's Sobers Clark speed was slower
00:11:29 than our human life Clark speed are inter but it's faster than evolution first Laura then our solution yeah give
00:11:37 him the four billion years it took us to get here then yes maybe it started eight if you look at the human soul ization is
00:11:44 a single organism yeah in that sense you know this evolution could be us you know the evolution of the living organisms on
00:11:51 earth could be just a single organism and it's kind of that's its life is the evolution process that eventually will
00:12:00 lead to probably the the heat death of the universe already something before that I mean that's that's just an
00:12:06 incredible idea so you almost don't know you've created something that you don't even know how it works like yeah because
00:12:17 anytime I tried to look into how it might work I would then inevitably be attaching my
00:12:23 kind of thought processes into it and I wanted to try and put a bubble around it oh so no this is this is alien in its
00:12:32 most alien form I have no real point of contacts so unfortunately I can't talk to Stanley Kubrick so I'm really
00:12:41 fortunate to get a chance to talk to you on this particular notion I'd like to ask it a bunch of different ways and
00:12:49 we'll explore in different ways but do you ever consider human imagination your imagination as a window into a possible future
00:12:59 and that what you're doing you're putting that imagination on paper as a writer and then on screen as a director
00:13:06 and that plants the seeds in the minds of millions of future and current scientists and so your imagination you
00:13:14 putting it down actually makes it as a reality so it's almost like a first step of the scientific method that you
00:13:20 imagining what's possible in your new series with ex machina is actually inspiring you know thousands of
00:13:30 twelve-year-olds millions of scientists and actually creating the future of you've imagined well all I could say is
00:13:37 that from my point of view it's almost exactly the reverse because I I see that pretty much everything I do is a
00:13:49 reaction to what scientists are doing I am I'm an interested layperson and I I feel you know this individual I feel
00:14:02 that the most interesting area that humans are involved in is science I think art is very very interesting but
00:14:10 the most interesting is science and science is in a weird place because maybe around the time Newton was a alive
00:14:20 if a very very interested lay person said to themselves I want to really understand what Newton is saying about
00:14:27 the way the world works with a few years of dedicated thinking they would be able to understand that the sort of
00:14:34 principles he was laying out I don't think that's true anymore I think that stopped being true now so I'm a pretty
00:14:44 smart guy and if I said to myself I want to really really understand what is currently the state of quantum mechanics
00:14:53 or string theory or or any of the sort of branching areas of it I wouldn't be able to I'd be intellectually incapable
00:15:01 of doing it because because to work in those fields at the moment is a bit like being an athlete I suspect you need to
00:15:07 start when you're 12 you know and if you if you start in your mid-20s start trying to understand
00:15:12 in your mid-twenties then you're just never gonna catch up that's the way it feels to me so so what I do is I try to
00:15:20 make myself open so the people that you're implying maybe I would influence it to me it's exactly the other way around
00:15:27 these people are strongly influencing me I'm thinking they're doing something fascinating I'm concentrating and
00:15:33 working as hard as I can to try and understand the implications of what they say and in some ways often what I'm
00:15:41 trying to do is disseminate their ideas into a means by which it can enter a public conversation so so X Makana
00:15:54 contains lots of name checks all sorts of existing thought experiments you know shadows on you know Plato's cave and
00:16:03 Mary in the black white room and all sorts of different long-standing thought processes about sentience or
00:16:13 consciousness or subjectivity or gender or whatever it happens to be and then and then I'm trying to marshal that into
00:16:18 a narrative to say look this stuff is interesting and it's also relevant and this is my best shot at it so so I'm the
00:16:26 one being influenced in my construction that that's fascinating of course you would say that because you're not even
00:16:33 aware of your own that's probably what Kubrick will say too right is in describing why Hal 9000
00:16:41 is greater the way how 9000 is created as you're just studying what's but the reality when it when the specifics of
00:16:48 the knowledge passes through your imagination I would argue that you're in incorrect in thinking that you're just
00:16:57 disseminating knowledge that the the very act of your imagination consuming that science it creates something that
00:17:09 creates the next step potentially creates the next step I certainly think that's true with 2001 a
00:17:17 Space Odyssey I think at its best and if it fails prove that that's true of that it is best it plans something it's hard
00:17:28 describe it it inspires the the next generation and it could be feel dependent so your new series is more a
00:17:35 connection to physics quantum physics quantum quantum mechanics quantum computing and yet ex machina is more
00:17:40 artificial intelligence I know more about AI my sense that AI is much much earlier in its in the depth of
00:17:52 its understanding I would argue nobody understands anything to the depth that physicists do about physics in AI nobody
00:18:01 understands AI that there is a lot of importance and role for imagination which they think you know we're in that
00:18:08 what were Freud imagine the subconscious we're in that stage of of AI where there's a lot of imagination you didn't
00:18:14 thinking outside the box yeah it's interesting the spread of discussions and the spread of my anxieties that
00:18:25 exists about AI fascinate me the way in which some people are some people seem terrified about it what whilst also
00:18:34 pursuing it and I've never shared that fear about AI personally but it but the the way in which it educates people and
00:18:45 also the people who it agitates I find I find kind of fascinating are you afraid are you excited I use sad by the
00:18:56 possibility let's take the existential risk of artificial intelligence by the possibility an artificial intelligence
00:19:05 system becomes our offspring and makes us obsolete I mean it's a huge huge subject to talk about I suppose but but
00:19:13 one of the things I think is that humans are actually very experienced at creating new life-forms because that's
00:19:23 why you and I are both here and it's why everyone on the planet is here and so so something in the process of having a
00:19:30 living thing that exists that didn't exist previously it's very much encoded into the structures of our life and the
00:19:37 structures of our societies doesn't mean always get it right but it does mean we've learned quite a lot about that
00:19:44 we've learned quite a lot about what the dangers are of allowing things to be unchecked and it's why we then create
00:19:52 systems of checks and balances in our government and and so on and so forth I mean it's not say the other thing is it
00:20:00 seems like there's all sorts of things that you could put into a machine that you would not be so with us we sort of
00:20:07 roughly try to give some rules to live by and some of us then live by those rules to some don't and with a machine
00:20:13 it feels like you could enforce those things so so partly because of our previous experience and partly because
00:20:19 the different nature of a machine I just don't feel anxious about it I I'm more I just see all the good you know broadly
00:20:27 speaking the good that can come from it but that that's just my that's just where I am on that anxiety spectrum you
00:20:34 know it's kind of there's a sadness so we as humans give birth to other humans right petition in their generations and
00:20:41 there's often in the older generation a sadness about what the world has become now I mean that's kind of yeah there is
00:20:47 but there's a counterpoint as well which is the most parents would wish for a better life for their children so there
00:20:56 may be a regret about some things about the past but broadly speaking what people really want is that things will
00:21:01 be better for the future generations not worse and so a and then it's a question about what constitutes a future
00:21:09 generation a future generation could involve people it also could involve machines and it could involve a sort of
00:21:15 cross pollinated version of it too or any but but none of those things make me feel anxious and doesn't give you
00:21:23 anxiety it does excite you like anything that does not anything that's new I I don't think for example I've got I my
00:21:31 anxieties relate to things like social media that so I've got plenty of anxieties about that which is also
00:21:38 driven by artificial intelligence in the sense that there's too much information to be able to do is that an algorithm
00:21:45 has to filter that information and present to you so ultimately the algorithm a simple oftentimes simple
00:21:51 algorithms can trolling the flow of information on social media so that's another it is
00:21:58 yeah his but but at least my sense of it I might be wrong but my sense of it is that the algorithms have an either
00:22:06 conscious or unconscious bias which is created by the people who are making the algorithms and and sort of delineating
00:22:14 the areas to which those algorithms are going to lean and so for example the kind of thing I'd be worried about is
00:22:21 that it hasn't been thought about enough how dangerous it is to allow algorithms to create echo chambers say but that
00:22:30 doesn't seem to me to be about the AI or the algorithm it's it's the my IVA T of the people who are constructing the
00:22:38 algorithms to do that thing if you see what I mean yes so a new series does then we could speak more broadly there's
00:22:47 a let's talk about the people constructing those algorithms which be our modern society Silicon Valley those
00:22:53 algorithms happen to be a source of a lot of income because of advertisements okay so let me ask sort of a question
00:23:02 about those people are there current concerns and failures on social media they are naivety I can't pronounce that
00:23:14 word well are they naive are they I use that word carefully but evil and intent or misaligned and intent I think that's
00:23:25 a do they mean well and just go have a unintended consequence or is there something dark in them that that results
00:23:34 in them creating a company results in that super competitive drive to be successful and those are the people that
00:23:40 will end up controlling the algorithms at a guess I'd say there are instances of all those things so so sometimes I
00:23:48 think it's naivety sometimes I think it's extremely dark and sometimes I think people are are not being naive or
00:24:00 dark and and then in those instances are sometimes generating things that are very benign and and other times
00:24:06 generating things that despite their best intentions are not very benign it's something I think the reason why I don't
00:24:16 get anxious about AI high in terms of or at least hey is that have I don't know a relationship with some sort of
00:24:25 relationship with humans is that I think that's the stuff we're quite well equipped to understand how to mitigate
00:24:36 the problem is is is issues that relate actually to the power of humans or the wealth of humans and that's where that's
00:24:47 where it's dangerous here and now so so what I see I'll tell you what I sometimes feel about Silicon Valley is
00:24:58 that it's like Wall Street in the 80s it it's rabidly capitalistic absolutely rabidly capitalistic and it's rabidly
00:25:11 greedy but whereas in the 80s the sense one had of Wall Street was that these people kind of knew they were sharks and
00:25:17 in a way relished in being sharks and dressed in sharp suits and and and kind of lauded over other people and felt
00:25:26 good about doing it Silicon Valley has managed to hide its voracious Wall Street like capitalism behind hipster
00:25:35 t-shirts and you know cool cafes in the place where they set up their and and so that obfuscates what's really going on
00:25:42 what's really going on is the absolute voracious pursuit of money and power so so that that's where I get shaky for me
00:25:51 so that veneer and you explore that brilliantly that veneer of virtue that Silicon Valley has which they believe
00:26:03 themselves I'm sure so okay I I hope to be one of those people and I believe that so as a maybe a devil's advocate
00:26:18 term poorly used in this case what if some of them really are trying to build a better world
00:26:23 I can't I'm sure I think some of them are I think I've spoken to once who I believe in their heart feel they're
00:26:28 building a better work are they not able to no no no they may or may not be but it's just a zone with a lot of
00:26:36 flying about and there's also another thing which is that this actually goes back to I always thought about some
00:26:45 sports that later turned out to be corrupt in the way that the sport like who won the boxing match or how a
00:26:53 football match got thrown or cricket match or whatever happened to me and I used to think well look if there's a lot
00:27:00 of money and there really is a lot of money people stand to make millions or even billions you will find a corruption
00:27:08 that's gonna happen so so it's it's in the nature of its of its voracious appetite that some people will be
00:27:16 corrupt and some people will exploit and some people will exploit whilst thinking they're doing something good but there
00:27:22 are also people who I think are very very smart and very benign and actually very self-aware and so I'm not I'm not
00:27:31 trying to I'm not trying to wipe out the motivations of this entire area but I do it there are people in that world who
00:27:40 scare the hell out of me yeah sure yeah I'm a little bit naive and that like I it I don't care at all about money and
00:27:51 so I'm  you you might be one of the good guys yeah but so the thought is but I don't have money so my thought is if
00:27:58 you give me a billion dollars I would it would change nothing and I would spend it right away on on investing it right
00:28:05 back and creating a good world but your intuition is that billion there's something about that money that maybe
00:28:13 slowly corrupt the people around you there's somebody gets in that corrupts your souls of you the way you view the
00:28:18 world money does corrupt we know that but but there's a different sort of problem aside from just the
00:28:26 money corrupts you know thing that we're familiar with in throughout history and it's it's more
00:28:34 about the sense of reinforcement an individual gets which is so it effectively works like the reason I
00:28:43 earned all this money and so much more money than anyone else is because I'm very gifted I'm actually a bit smarter
00:28:48 than they are or I'm a lot smarter than they are and I can see the future in the way they can't and maybe some of those
00:28:55 people are not particularly smart they're very lucky or they're very talented entrepreneurs and there's a
00:29:02 difference between it so in other words the the the acquisition of the money and power can suddenly start to feel like
00:29:09 evidence of virtue yes and it's not evidence of virtue it might be evidence of completely different things as
00:29:14 brilliantly put yeah yeah yeah that's brilliant put like so I think one of the fundamental drivers of my current
00:29:23 morality let me just represent nerds in general the of all kinds is of constant self-doubt and the signals you know I'm
00:29:35 very sensitive to signals from people that tell me I'm doing the wrong thing but when there's a huge inflow of money
00:29:43 it's you're there you just put it brilliantly that that could become an overpowering signal that everything you
00:29:51 do is right and so your moral compass can just get thrown off yeah and it's that that is not contained to Silicon
00:29:58 Valley that's across the board in general yeah like I said I'm from Soviet Union the current president is convinced
00:30:07 I believe actually he is he wants to do really good by the country and by the world but his moral clock may be our
00:30:14 compass may be off because yeah I mean it's the interesting thing about evil which is the I think most people who do
00:30:23 spectacularly evil things think themselves they're doing really good things that they're not they're thinking
00:30:29 I am a sort of incarnation of Satan they're thinking yeah I've seen a way to fix the world and everyone else is wrong
00:30:38 here I go in fact I  I'm having a fascinating conversation with a historian of Stalin and he took power is
00:30:45 what he actually got more power than almost any person in history and he wanted he didn't want power
00:30:54 he just wanted he truly and this is what people don't realize he truly believed that communism will make for a better
00:31:03 world absolutely and he wanted power he wanted to destroy the competition to make sure that we actually made
00:31:08 communism work in the Soviet Union and that spread it across the world he was trying to do good I think it's it's
00:31:16 typically the case yeah that that's what people think they're doing and I think that but you don't need to go to Stalin
00:31:22 I mean Stalin sure I think Stalin but probably got pretty crazy but actually that's another part of it which is that
00:31:29 the other thing that comes from being convinced of your own virtues that then you stop listening to the modifiers
00:31:36 around you and that tends to drive people crazy it's it's other people that keep us sane and if you stop listening
00:31:43 to them I think you go be mad so that that also that's funny a disagreement keeps us saying to jump back for an
00:31:53 entire generation of AI researchers 2001 a Space Odyssey put an image the idea of human level superhuman level
00:32:02 intelligence into their mind do you ever sort of jumping back to ex machina and talk a little bit about that you ever
00:32:09 consider the audience of people who you who are build the system's the robot assisted scientists that build the
00:32:16 systems based on the stories you create which I would argue I mean there's literally most of the top researchers
00:32:27 about 40 50 years old and plus you know that's their favorite movie 2001 Space Odyssey and it really is in their work
00:32:33 their idea of what ethics is of what is the target the hope the dangers of AI is that movie yeah right do you ever
00:32:43 consider the the impact on those researchers when you create the the work you do certainly not with Xbox in
00:32:52 relation to 2001 because I'm not sure I mean I'd be pleased if there was but I'm not sure in a way there isn't a fundamental
00:33:02 discussion of issues to do with AI that isn't already and better dealt with by 2001 2001 does a very very good account
00:33:14 of of the way in which an AI might think and also potential issues with the way the AI might think and also then a
00:33:23 separate question about whether the AI is malevolent or benevolent and 2001 doesn't really is it's a slightly odd
00:33:32 thing to be making a film when you know there's a pre-existing film which is not a really super job but there's a
00:33:38 questions of consciousness embodiment and also the same kinds of questions could you because those are my two
00:33:44 favorite AI movies so can you compare how all 9000 and Ava how 9,000 from 2001 Space Odyssey na or from ex machina the
00:33:52 in your view from a philosophical perspective they've got different goals the to a eyes have completely different
00:33:58 guy I think that's really the difference so in some respects ex machina took as a premise how do you assess whether
00:34:06 something else has consciousness so it was a version of the Turing test except instead of having the machine hidden you
00:34:13 you put the machine in plain sight in the way that we are in plain sight of each other and say now assess the
00:34:18 consciousness and a way it was illustrating the the the way in which you'd assess the state of consciousness
00:34:26 of a machine is this exactly the same way we assess the state of consciousness of each other and in exactly the same
00:34:34 way that in a funny way your sense of my consciousness is is actually based primarily on your own consciousness that
00:34:42 is also then true with the machine and and so it was actually about how much of the sense of consciousness is a
00:34:50 projection rather than something that consciousness is actually containing and Plato's cave I mean this view really
00:34:56 explored you could argue that how sort of space odyssey explores idea of the Turing test for intelligence or not test
00:35:03 there's no test but it's more focused on intelligence and ex machina kind of goes around intelligence and says the
00:35:12 consciousness of the human do you humanure by interactions more interesting more important more at least
00:35:19 the focus of that particular particular movie yeah it's about the interior state and and what constitutes the interior
00:35:26 state and how do we know it's there and actually in that respect ex machina is as much about consciousness in general
00:35:36 as it is to do specifically with machine consciousness yes and it's also interesting you know thing you started
00:35:43 asking about the dream state and I was saying well I think we're all in a dream state because we're all in a subjective
00:35:50 state yeah one of the things that I became aware of with ex machina is that the way in which people reacted to the
00:35:56 film was very based on what they took into the film so many people thought xmax magnet was a stet was the tale of a
00:36:04 sort of evil robot who murders two men and escapes and she has no empathy for example because she's a machine
00:36:13 whereas I felt no she was a conscious being with a consciousness different from mine but so what
00:36:21 imprisoned and made a bunch of value judgments about how to get out of that box and there's a moment which is sort
00:36:30 of slightly bugs me but nobody ever has noticed in its years after so I might as well say it now which is that after Ava
00:36:38 has escaped she crosses a room and has she's crossing a room this is just before she leaves the building she looks
00:36:45 over her shoulder and she smiles and I thought after all the conversation about tests but in a way the best indication
00:36:53 you could have of the interior state of someone is if they are not being observed and they smile about something
00:37:00 with they're smiling for themselves and that to me was evidence of Ava's true sentience whatever that sentience
00:37:09 was but those really interesting she we don't get to observe a ver much or or something like a smile in any context
00:37:18 except through interaction trying to convince others that she's conscious that's beautiful yeah exactly yeah but
00:37:25 it was a small it in a funny way I think maybe people saw it as an evil smile like ha yeah I
00:37:33 fooled them but actually it was just a smile and I thought well in the end after all the conversations about the
00:37:38 test that was the answer to the test and then off she goes so if we align if we just deliver it a little a little bit
00:37:47 longer on hell and Ava do you think in terms of motivation what was how's motivation is how good or evil is Ava
00:37:56 good or evil Ava's good in my opinion and how is neutral because I don't think how is
00:38:10 presented as having a sophisticated emotional life he has a set of paradigms which is that the mission needs to be
00:38:17 completed I mean it's a version of the paperclip yeah you know the idea there is just it's a super intelligent machine
00:38:24 but it's just performing a particular task yeah and in doing that tasks may destroy everybody on earth or may may achieve
00:38:32 undesirable effects for us humans precisely but what if okay at very end you said something like I'm afraid Dave but that
00:38:43 that maybe he is on some level experiencing fear or it may be this is the terms in which it would be wise to
00:38:52 stop someone from doing the thing they're doing if you see what it means yes absolutely so it actually has funny
00:39:00 so that's such of this is such a small short exploration of consciousness that I'm afraid
00:39:05 and then you just with ex machina say okay we're going to magnify that part and then minimize the other part so
00:39:11 that's that's a good way to sort of compare the two but if you could just use your imagination and if Ava sort of
00:39:23 I don't know ran the Quran easy was President of the United States also has some power so what kind of world which
00:39:30 you want to create if we here's you kind of say good and there is a sense that she has a really like I think there's a
00:39:40 desire for better human to human interaction human robot interaction in her but what kind of
00:39:47 world do you think she would create with that desire she also really it's a very interesting question that I'm gonna
00:39:53 approach it slightly obliquely which is the if if a friend of yours got stabbed in a mugging and you then felt
00:40:05 very angry at the person who'd done the stabbing but then you learned that it was a fifteen year old and the 15 year
00:40:12 old both their parents redic today crystal meth and the kid had been addicted since he was 10 and he really
00:40:17 never had any hope in the world and he'd been driven crazy by his upbringing and did the stabbing that would hugely
00:40:26 modify and it would also make you worry about that kid then becoming president of America right and Ava has had a very
00:40:34 very distorted introduction into the world so although there's nothing as it as it were organically within Ava that
00:40:46 would lean her towards badness it's not the robots or sentient robots are bad she did not her arrival into the world
00:40:55 was being imprisoned by humans so I'm not sure she'd be a great present the trajectory through which she arrived at
00:41:06 her moral views you have some dark elements then but I like ever personally I like over and I think vote for her I'm
00:41:15 having difficulty finding anyone to vote right now in my country or if I lived here in yours
00:41:22 I am so that's a yes I guess because the competition she could easily do a better job than any of the people I'd worked
00:41:33 her over Boris Johnson so what is a good test of consciousness just can we talk about consciousness a little bit more if
00:41:41 something appears conscious is it conscious he mentioned the smile which is seems to be something done I mean
00:41:51 that's a really good indication because it's a tree falling in the forest with nobody there to hear it but does the appearance
00:41:59 from a robotics perspective of consciousness mean consciousness - you know I I don't think you could say that
00:42:06 fully because I think you could then easily have a thought experiment which said we will create something which we
00:42:12 know is not conscious but is going to give a very very good account of seeming conscious and so and and also it would
00:42:20 be a particularly bad test where humans are involved because humans are so quick to project sentience into things that
00:42:29 don't have sentience so someone could have their computer playing up and feel as if their computer is being malevolent
00:42:35 to them when it clearly isn't and so so of all the things to judge consciousness us humans are better
00:42:43 we're empathy machines so that so the flipside of that the argument there is because we just attribute consciousness
00:42:50 to everything almost and anthropomorphize everything including Roombas the that maybe consciousness is
00:42:58 not real that would just attribute consciousness to each other so you have a sense that there is something really
00:43:05 special going on in our mind that makes us unique and gives us the subjective experience there's something very
00:43:14 interesting going on in our minds I'm slightly worried about the word special because it it gets a bit it nudges
00:43:22 towards metaphysics and maybe even magic in I mean in some ways something magic like which I don't think is there at all
00:43:30 I mean if you think about there's an idea of called pants like ism that says consciousness is in everything whatever
00:43:38 but as brother yeah so the idea that that there is a thing that it would be like to be the son yeah no I don't buy
00:43:45 that I think that consciousness is a thing did my sort of broad modification is that usually the more I find out
00:43:58 about things the more illusory our instinct is and is leading us into a different direction about what that
00:44:06 thing actually is that that happens it's in modern science that happens a hell of a lot whether it's to do with how even
00:44:14 how big or small things are so so my sense is that consciousness is a thing but it isn't quite the thing or maybe
00:44:20 very different from the thing that we instinctively think it is so it's there it's very interesting but we may be in
00:44:28 it's sort of quite fundamentally misunderstanding it for reasons that are based on intuition so I have to ask this
00:44:37 is this kind of an interesting question the ex machina for many people including myself is one of the greatest AI films
00:44:44 ever made well it's number two for me thanks yeah number one I'd really have to was anyway
00:44:51 yeah whenever you grow up with something right you may grow up for something it's it's an it's in the wood but there's 
00:45:01 one of the things that people bring up and can't please everyone including myself this is what I first reacted to
00:45:08 the film is the idea of the lone genius this is the the criticism that people say sort of me as an AI researcher I'm
00:45:17 trying to create what what what nathan is trying to do so there's a brilliant series called Chernobyl yes this one
00:45:25 tested how so you spec talk I think I mean as eyes are I mean they got so many things brilliant right but one of the
00:45:32 things again the criticism there yeah great nice place with lots of people who need your one character that represents
00:45:39 all nuclear scientists you wanna comb yet you know it's a composite character that presents all scientists is this
00:45:48 what you were is this the way you were thinking about that or is it just simplifies the storytelling how do you
00:45:54 think about the lone genius well I'd say this the series I'm doing at the moment is a critique in part of the lone genius concept
00:46:03 so yes I'm sort of oppositional and either agnostic or atheistic about that as a concept I mean they're not entirely
00:46:14 you know where the lone lone is the right word broadly isolated but Newton clearly exists in a sort of bubble of himself in
00:46:23 some respect such as Shakespearean do you think we would have an iPhone without Steve Jobs I mean how much Steve
00:46:30 Jobs clearly isn't alone genius because because there's too many other people in the sort of superstructure around him
00:46:37 who are absolutely fundamental to to that journey are you saying Newton but that's a scientific so there's an
00:46:44 engineering element to building Ava but just to say what ex machina is is really it's a thought experiment I mean so it's
00:46:54 a construction of putting four people in a house nothing about ex machina adds up in all sorts of ways in as much as that
00:47:03 who built the machine parts did the people building the machine parts know what they were creating and how did they
00:47:10 get there and it's a thought experiment yes so it doesn't it doesn't stand up to scrutiny of that sort I don't think it's
00:47:17 actually that interesting of a question but it's brought up so often that I had to ask it because that's exactly how I
00:47:27 felt after what you know there's something about there was almost a defense I got wash your movie the first
00:47:34 time in at least for the first little while in a defensive way like how dare this person try to step into the AI
00:47:43 space and try to beat Kubrick that's the way I was thinking like this because it comes off as a movie that really is
00:47:49 going after the deep fundamental questions about AI so there's a there's a kind of a you know nerds do psyche is
00:47:56 automatically searching for the for the flaws and I I decide exactly the same I think in annihilation and the other
00:48:05 movie the I was be able to free myself from that much quicker that it's a it is a thought experiment there's you know
00:48:11 who cares if there's batteries that don't run out right those kinds of questions that's the whole point
00:48:16 yeah but I bits nevertheless something I wanted to bring up it yeah it's a foot it's the first thing to bring up for me
00:48:23 the you you had all the lone genius thing for me it was actually people always said ex machina makes this big
00:48:32 leap in terms of where AI has got to and so what pay I would look like if it got to that point there's another one which
00:48:40 is just robotics I mean look at the way Ava walks around the rooms like forget it building that it's that that's that's
00:48:47 also got to be a very very long way often if you did get that would it look anything like that it's a thought experiment
00:48:54 actually it's figure we I think the way as a ballerina Alicia vikander brilliant actress actor that moves
00:49:02 around that we're very far away from creating that but the way she moves around is exactly the definition of
00:49:08 perfection for roboticist it's like smooth and efficient so it is where we want to get where I believe like I think
00:49:15 because so I hang out with a lot of like human robotics people they love elegant smooth motion like that that's
00:49:22 their dream so the way she moved is actually what I believe that would dream for a robot to move it might not be that
00:49:29 useful to move that sort of that way but that is important the definition of perfection in terms of movement drawing
00:49:36 inspiration from real life so for devs for ex machina look at characters like Elon Musk what do you think about the
00:49:45 various big technological efforts of Elon Musk and others like him and that he's involved with such as Tesla SpaceX
00:49:54 your link do you see any of any of that technology potentially defining the future worlds you create in your work
00:50:01 so Tesla's automation SpaceX is space exploration your link is brain machine interface somehow merger of biological
00:50:11 and electric systems I'm in a way I'm influenced by that almost by definition because that's the world I live in and
00:50:16 this is the thing that's happening in that world and I also feel supportive of it so I think I think amongst various
00:50:27 things Elon Musk has done I'm almost sure he's done a very very good thing with Tesla for all of us it's really
00:50:36 kicked all the other car manufacturers interfaces kicked the fossil fuel industry in the face and and they needed
00:50:42 kicking in the face and he's done it so and and so that's the world he's part of creating
00:50:50 and I live in that world just bought a Tesla in fact and so does that play into whatever I then make in some ways it
00:51:02 does partly because I try to be a writer who quite often filmmakers are in some ways fixated on the films they grew up
00:51:10 with and they sort of remake those films in some ways I've always tried to avoid that and so I looked at the real world
00:51:18 to get inspiration and as much as possible sort of by living I think and so so yeah I'm sure
00:51:27 which of the directions do you find most exciting space trouble space travel so you haven't really explored space travel
00:51:37 in your work you've said you've said something like if you had unlimited amount of money I think I now read at a
00:51:44 ma that you would make like a multi-year series space Wars or something like that so what what is it that excites you
00:51:52 about space exploration well because if we have any sort of long-term future it's that it just simply is that if
00:52:04 energy and matter are linked up in the way we think they're linked up will run out if we don't move so we got to move
00:52:16 and but but also how can we not it's it's built into us to to do it or die trying I was on Easter Island a few
00:52:29 months ago which is as I'm sure you know in the middle of the Pacific and and difficult for people to have got to but
00:52:35 they got there and I did think a lot about the way those boats it must have set out into something like space it was
00:52:46 the ocean and and how sort of fundamental that was to the way we are and it it's the one that most excites me
00:52:55 because it's the one I want most to happen it's the thing it's the place where we could get to is
00:53:01 like in a way I could live with us never really unlocking fully unlocking the nature of consciousness I like to know
00:53:10 I'm really curious but if we never leave the solar system and if we never get further out into this galaxy or maybe
00:53:17 even galaxies beyond our galaxy that that would that feel sad to me because because it's so limiting yeah there's
00:53:27 something hopeful and beautiful bar reaching out any kind of exploration reaching out across earth centuries ago
00:53:35 and reaching out into space so what do you think about colonization of Mars so go to Mars does that excite you the idea
00:53:40 of a human being stepping foot on Mars it does it absolutely does but in terms of what would really excite me it would
00:53:47 be leaving this solar system in as much as that I just think I think we already know quite a lot about Mars and but yes
00:53:56 listen if it happened that would be I hope I say in my lifetime I really hope I say in my lifetime I do it would be a
00:54:04 wonderful thing without giving anything away but the series begins with the use of quantum computers a new series does
00:54:14 begins with the use of quantum computers to simulate basic living organisms or actually I don't know if it's quantum
00:54:20 computers are used but basic living organisms simulated on a screen and yeah the cool kind of demo yeah that's right
00:54:27 they're using yes they are using a quantum computer to simulate a nematode pill so returning to our discussion of
00:54:37 simulation or thinking of the universe as a computer do you think the universe is deterministic is there a free will so
00:54:46 with the qualification of what do I know because I'm a layman right layperson but with big imagination thanks with that
00:54:55 qualification yeah I think the universe is deterministic and I see absolutely I I cannot see how freewill fits into that so
00:55:05 so yes deterministic no free will that would be my position and how does that make you feel it partly makes me feel
00:55:12 that it's exactly in keeping with the way these things tend to work out which is that we have an incredibly
00:55:19 strong sense that we do have free will and just as we have an incredibly strong sense that time is a constant and turns
00:55:30 out probably not to be the case or definitely in the case of time but but but it's the the problem I always have
00:55:38 with free will is that it gets I can never seem to find the place where it is supposed to reside and yet you explore
00:55:47 just but a very very but we have something we can call free will but it's not the thing that we think it is but
00:55:55 free was so what we call free will is just what they call it as the illusion of it and that's a subjective experience
00:56:00 of yeah the yeah yeah which is a useful thing to have and it partly it partly comes down to although we live in a
00:56:07 deterministic universe our brains are not very well equipped to fully determine the deterministic universe so
00:56:13 we're constantly surprised and feel like we're making snap decision decisions based on imperfect information so that
00:56:20 feels a lot like freewill it just isn't it would be might that's why I guess so in that sense your sort of sense is that
00:56:29 you can unroll the universe forward or backward and you will see the same thing and you would I mean that notion yeah
00:56:39 sort of sort of but yeah sorry go ahead I mean that notion is a bit uncomfortable to think about that it's
00:56:51 good you can roll it back and and forward and well if you were able to do it it would certainly have to be a
00:56:58 quantum computer yeah something that worked in a quantum mechanical way in order to understand a quantum mechanical
00:57:08 system I I guess but but and so that unrolling there may be a multiverse thing where there's a bunch of branching
00:57:12 what will exactly because it wouldn't follow that every time you roll it back or forward you'd get exactly the same
00:57:18 result which is another thing that's hard to rapamycin fact yeah but but but that yes it but essentially what you
00:57:26 just described that the the yes forwards and yes backwards but you might get a slightly
00:57:32 different result works very different though or very different along the same lines well you've
00:57:37 explored some really deep scientific ideas in this new series and I mean it's just in general you're unafraid to to
00:57:45 ground yourself and some of the most amazing scientific ideas of our time what what are the things you've learned
00:57:53 or ideas you find beautiful mysterious about quantum mechanics multiverse string theory quantum computing that
00:57:59 you've learned well I would have to say every single thing I've learned is beautiful and one of the motivators for
00:58:10 me is that I think that people tend not to see scientific thinking as being essentially poetic and lyrical but but I
00:58:20 think that is literally exactly what it is and I think the idea of entanglement or the idea of superpositions or the
00:58:27 fact that you could even demonstrate a superposition or have a machine that relies on the existence of super
00:58:34 positions in order to function to me is is almost indescribable beautiful I it it it fills me with all it fills me with
00:58:44 awe and also it's not it's not just a sort of grand massive or of but it's also delicate it's very very delicate
00:58:58 and subtle and it has these beautiful sort of nuances in it and also these completely paradigm changing thoughts
00:59:06 and truths so so it's it's as good as it gets as far as I can tell so so so broadly everything that doesn't mean I
00:59:13 believe everything I read quantum physics because because obviously a lot of the interpretations are completely in
00:59:20 conflict with each other and who knows whether string theory will turn out to be a good description or not but but the
00:59:30 beauty in it it seems undeniable and and I do wish people more readily understood how beautiful and poetic science
00:59:44 I would say Sciences poetry in terms of quantum computing being used to simulate things or just in general the idea of
00:59:56 simulating simulating small parts of our world which actually current physicists are really excited about simulating
01:00:02 small quantum mechanical systems on quantum computers but scaling that up to something bigger like simulating
01:00:10 life-forms how do you think what are the possible trajectories of that going wrong or going right if you if you
01:00:19 unroll it into the future well if a bit like Ava and her robotics you park the the sheer complexity of what you're
01:00:31 trying to do the the issues are I think I think it will have a profound it if you were able to have a machine that was
01:00:39 able to project forwards and backwards accurately it would in an empirical way show it would demonstrate that you don't
01:00:45 have free will so the first thing that would happen is people would have to to really take on a very very different
01:00:54 idea of what they were the thing that they truly truly believe they are they are not and so that that I suspect would
01:01:01 be very very disturbing to a lot of people do you think there has a positive or negative effect on society the the
01:01:09 realization that you are not you cannot control your actions essentially I guess is the way that could be interpreted
01:01:16 yeah although in some ways we instinctively understand that already because in the example I gave you of the
01:01:22 kid in the stabbing we would all understand that that kid was not really fully in control of their actions so
01:01:27 it's not an idea that's entirely alien to us but I don't know we understand that I think there's a bunch of people
01:01:36 who see the world that way but not everybody yes true i but what this machine would do is is
01:01:43 prove it any doubt because someone would say well I don't believe that's true and then you'd predict well in 10 seconds
01:01:49 you're going to do this and they'd say no no I'm not and then they'd do it and then determine is
01:01:54 would have played its part but I or something like that but actually the exact terms of that thought experiment
01:02:02 probably wouldn't play out but but still broadly speaking you could predict something happening in another room sort
01:02:08 of unseen I suppose the foreknowledge would not allow you to affect so what effect would that have I think people
01:02:15 would find it very disturbing but then after they'd got over their sense of being disturbed which by the way I don't
01:02:23 even think you need a machine to to take this idea on board but after they've got over that they'd still understand that
01:02:29 even though I have no free will and my actions are in effect already determined I still feel things I I still care about
01:02:40 stuff I remember my daughter saying to me wish it she'd got hold of the idea that my view of the universe made it
01:02:49 meaningless and she said well then it's meaningless and I said well it I can prove it's not meaningless because you
01:02:55 mean something to me and I mean something to you so it's not completely meaningless because there is a bit of
01:03:01 meaning contained within this space and so with a lack of free will space you could think well this robs me of
01:03:09 everything I am and then you'd say well no it doesn't because you still like eating cheeseburgers and you still like
01:03:15 going to see the movies and so so how big a difference does it really make but I think I think initially people would
01:03:22 find it very disturbing I think I think that what would come if you could really unlock with a determinism machine
01:03:29 everything there'd be this wonderful wisdom that would come from and I'd rather have that than not so that's a
01:03:36 really good example of a technology revealing to us human something fundamental about our world about our
01:03:43 society so it's it's almost this creation is helping us understand ourselves in the the thing to be said
01:03:52 about artificial intelligence so what do you think us creating something like Ava will help us understand about ourselves
01:04:01 how will that change society well I would hope it would teach us some humility humans are very big on exceptionalism
01:04:11 you know America is is constantly proclaiming itself to be the greatest nation on earth which it may feel like
01:04:18 that if you're an American but it may not feel like that if you're from Finland because there's all sorts of
01:04:24 things you dearly love about Finland and exceptionalism is usually probably not always if we both sat here
01:04:31 we could find a good example of something there isn't but as a rule of thumb and and and what it would do is it
01:04:39 would teach us some humility and about you know actually often that's what science does in a funny way it makes us
01:04:44 more and more interesting but it makes us a smaller and smaller part of the thing that's interesting and I don't
01:04:52 mind that humility at all I I don't think it's a bad thing our excesses don't tend to come from
01:04:58 humility you know our excesses come from the opposite megalomania we tend to think of consciousness as having some
01:05:05 form of exceptionalism attached to it I suspect if we ever unravel it it will turn out to be less
01:05:14 than we thought in a way and perhaps your very own Exceptionalist assertion earlier on in our conversation that
01:05:21 consciousness is something belongs to us humans or not humans belong organisms maybe you will one day find out that
01:05:30 consciousness is in everything and that will yeah will humble you exact if that was true it would certainly humble me
01:05:38 although maybe almost maybe I don't know aye-aye-aye sort of I mean my understanding of that principle is along
01:05:50 the lines of say that that an electron has a preferred state or it may or may not pass through a bed of glass it may
01:05:58 reflect off or it may go through or something like that and and so that but if if I'm going down the fully
01:06:11 deterministic routes I would say there's just an underlying determinism that has defined that that is defined the
01:06:17 preferred state or the reflection or non reflections but look yeah you're right if if if it turned out that there was a thing that
01:06:25 it was like to be the Sun then I would I'd be amazed and humbled I'd be happy to be both it sounds pretty cool and
01:06:31 they'll be you'll say the same thing as you said to your daughter but it's nevertheless feels something like to be
01:06:38 me and that that's pretty damn good yeah so Kubrick created many masterpieces including The Shining dr. Strangelove
01:06:47 Clockwork Orange but to me he will be remembered I think to many a hundred years from now for 2001 a Space Odyssey
01:06:54 I would say that's his greatest film I agree you are incredibly humble I've listened to a bunch of your interviews
01:07:04 and I really appreciate that you're humble in your creative efforts in your work but if I were to force you a
01:07:12 gunpoint keep it with God you don't know that the mystery is to imagine 100 years out into the future
01:07:23 what will Alex Carlin be remembered for from something you've created already or feel you may feel somewhere deep inside
01:07:31 you may still create well ok well I'll take I'll take the question in the spirit was asked but very generous
01:07:43 gunpoint yeah what what I what I try to do so therefore what I hope yeah if I remembered what I might be remembered
01:07:53 for is is as someone who who participates in a conversation and I think that often what happens is people
01:08:01 don't participate in conversations they make proclamations they make statements and people can either react against the
01:08:08 statement or can fall in line behind it and I don't like that so I want to be part of a conversation I take as a sort
01:08:16 of basic principle I think I take lots of my cues from science but one of the best ones it seems to me is that when a
01:08:21 scientist has something proved wrong that they previously believed in they then have to abandon that position so
01:08:28 I'd like to be someone who is allied to that sort of thinking so part of an exchange part of an exchange of ideas and the
01:08:37 exchange of ideas for me is something like people in your world show me things about how the world work and then I say
01:08:45 this is how I feel about what you've told me and then other people can react to that and it's it's not it's not to
01:08:52 say this is how the world is it's just to say it is interesting to think about the world in this way and the
01:08:59 conversation is one of the things I'm really hopeful about in your works that the conversation you're having is with
01:09:07 the viewer in the sense that you you're bringing back you and several others but you very much so sort of intellectual
01:09:22 depth to cinema to now series sort of allowing film to be something that yeah sparks a conversation is a conversation
01:09:32 lets people think allows them to think but also crew it's very important for me that if that conversation is going to be
01:09:39 a good conversation what that must involve is that someone like you who understands AI and I imagine understands
01:09:47 a lot about quantum mechanics if they then watch the narrative feels yes this is a fair account so it is a worthy
01:09:56 addition to the conversation that for me is hugely important I'm not interested in getting that stuff wrong I'm only
01:10:06 Alex it was truly an honor to talk to you I really appreciate I really enjoy thanks for listening to this
01:10:14 conversation with Alex Garland and thank you to representing sponsor cash app downloaded use code Lex podcast you'll
01:10:22 get ten dollars and $10 will go to first an organization that inspires and educates young minds to become science
01:10:29 and technology innovators of tomorrow if you enjoy this podcast subscribe on youtube give it five stars in a podcast
01:10:36 supported on patreon are simply connect with me on Twitter at Lex Friedman and now let me leave you with a question
01:10:44 from Ava the central artificial intelligence character in the movie ex machina that she asked during her Turing
