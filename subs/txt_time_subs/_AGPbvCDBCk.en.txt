00:00:01 the following is a conversation with eugenia cuida co-founder of replica which is an app
00:00:08 that allows you to make friends with an artificial intelligence system a chatbot that learns to connect with you on an emotional
00:00:17 you can even say a human level by being a friend for those of you who know my interest in
00:00:22 ai and views on life in general know that replica and eugenia's line of work is near and dear to my heart the origin
00:00:30 story of replica is grounded in a personal tragedy of eugenia losing her close friend roman mazarenki
00:00:38 who was killed crossing the street by a hit-and-run driver in late 2015. he was 34.
00:00:44 the app started as a way to grieve the loss of a friend by training a chatbot neural net on text
00:00:51 messages between eugenia and roman the rest is a beautiful human story as we talk about with eugenia
00:00:58 when a friend mentioned eugenia's work to me i knew i had to meet her and talk to her
00:01:03 i felt before during and after that this meeting would be an important one in my life and it was
00:01:09 i think in ways that only time will truly show to me and others she's a kind and brilliant person
00:01:17 it was an honor and a pleasure to talk to her quick summary of the sponsors doordash
00:01:22 dollar shave club and cash app click the sponsor links in the description to get a discount and
00:01:30 to support this podcast as a side note let me say that deep meaningful connection between
00:01:35 human beings and artificial intelligence systems is a lifelong passion for me i'm not yet sure where that passion will take me but
00:01:43 i decided some time ago that i will follow it boldly and without fear to as far as i can take it
00:01:49 with a bit of hard work and a bit of luck i hope i'll succeed in helping build ai systems
00:01:55 that have some positive impact on the world and on the lives of a few people out there
00:02:02 but also it is entirely possible that i am in fact one of the chatbots that eugenia
00:02:08 and the replica team have built and this podcast is simply a training process for the neural net that's trying to learn to connect
00:02:17 to human beings one episode at a time in any case i wouldn't know if i was or wasn't and if i did i wouldn't tell you if you
00:02:26 enjoyed this thing subscribe on youtube review it with five stars on apple podcast follow on spotify support on patreon or
00:02:32 connect with me on twitter at lex friedman as usual i'll do a few minutes of ads now and no ads in the middle
00:02:39 i'll try to make these interesting but give you timestamps so you can skip but please do still check out the
00:02:45 sponsors by clicking the links in the description to get a discount buy whatever they're selling it really is the best way to
00:02:53 support this podcast this show is sponsored by dollar shave club try them out with a one-time
00:03:00 offer for only five bucks and free shipping at dollarshave.com lex the starter kit comes with a six
00:03:05 blade razor refills and all kinds of other stuff that makes shaving feel
00:03:12 great i've been a member of dollar shave club for over five years and actually signed up
00:03:16 when i first heard about them on the joe rogan experience podcast and now friends we have come full circle it
00:03:24 feels like i made it now that i can do a read for them just like joe did all those years ago
00:03:32 back when he also did ads for some less reputable companies let's say you know about if you're a true fan of the old school
00:03:40 podcasting world anyway i just used the razer and the refills but they told me i should really
00:03:45 try out the shave butter i did i love it it's translucent somehow which is a cool new experience again
00:03:54 try the ultimate shave starter set today for just five bucks plus free shipping at dollarshaveclub.com
00:04:02 lex this show is also sponsored by doordash get five dollars off as your delivery fee is in your first order of
00:04:08 15 bucks or more when you download the doordash app and enter code
00:04:14 you guessed it i have so many memories of working late nights for a deadline with a team of engineers
00:04:20 whether that's for my phd at google or mit and eventually taking a break to argue about which door dash restaurant to
00:04:26 order from and when the food came those moments of bonding of exchanging ideas of pausing
00:04:33 to shift attention from the programs the humans were special for a bit of time i'm on my own now so i missed that camaraderie but
00:04:43 actually i still use doordash a lot there's a million options that fit into my crazy keto diet ways
00:04:48 also it's a great way to support restaurants in these challenging times once again download the doordash app and
00:04:55 enter code lex to get five bucks off it's your delivery fees and your first order of fifteen dollars or more
00:05:02 finally this shows presented by cash app the number one finance app in the app store i can truly say that they're an amazing company
00:05:09 one of the first sponsors if not the first sponsor to truly believe in me and and i think
00:05:15 quite possibly the reason i'm still doing this podcast so i'm forever grateful to cash app so
00:05:23 thank you and as i said many times before use code lex podcast when you download the app from google play or the app store
00:05:31 cash app lets you send money to friends buy bitcoin invest in the stock market with as little as one dollar i usually
00:05:38 say other stuff here in the read but i wasted all that time up front saying how grateful i am to
00:05:43 cash out i'm going to try to go off the top of my head a little bit more for these reads
00:05:48 because i'm actually very lucky to be able to choose the sponsors that we take on and that means i can really only take on
00:05:55 the sponsors that i truly love and then i can just talk about why i love them so it's pretty simple
00:06:01 again get cash app from the app store google play use code lex podcast get 10 bucks and cash app will also
00:06:07 donate 10 bucks to first an organization that is helping to advance robotics and stem education
00:06:13 for young people around the world and now here's my conversation with eugenia cuida okay before we talk about ai and the
00:06:22 amazing work you're doing let me ask you ridiculously we're both russian so let me ask you a ridiculously
00:06:28 romanticized russian question do you think human beings are alone like fundamentally on a
00:06:37 philosophical level like in our existence when we like go through life do you think
00:06:47 just the nature of our life is loneliness yeah so we have to read dostoevsky at school
00:06:56 as you probably know yeah i mean it's part of the your school program um
00:07:01 so i guess if you read that then you sort of have to believe that you're made to believe that you're
00:07:06 fundamentally alone and that's how you live your life how do you think about it
00:07:12 you have a lot of friends but at the end of the day do you have like a longing for
00:07:17 connection with other people that's maybe another way of asking it do you think that's ever fully satisfied
00:07:25 i think we are fundamentally alone we're born alone we die alone but you know but i view my whole life as
00:07:30 trying to get away from that trying to not feel  feel lonely and again we're talking
00:07:37 about you know subjective kind of way of feeling alone it doesn't necessarily mean that you don't have any
00:07:42 connections or you're actually isolated you think it's a subjective
00:07:50 thing but like again another absurd measurement-wise thing how much loneliness do you think there is in the world
00:07:59 so like if you see loneliness as a as a condition how much of it is there do you think like how
00:08:07 i guess how many you know there's all kinds of studies and measures of how much you know how many people in the
00:08:13 world feel alone there's all these like measures of how many people are you know self-report
00:08:19 or just all these kinds of different measures but in your own perspective how big of a problem do you think it is
00:08:28 size-wise well i'm actually fascinated by the topic of loneliness i try to read about it as much as i can
00:08:36 what really and there i think there's a paradox because loneliness is not a clinical disorder
00:08:41 it's not something that you can get your insurance to pay for if you're struggling with that
00:08:47 yet it's it's actually proven and pretty you know tons of papers tons of research around that it has proven
00:08:54 that it's correlated with earlier life expectancy shorter life span and it is you know in a way like right
00:09:01 now what scientists would say that it you know it's a little bit worse than being obese so not actually doing any
00:09:07 physical activity in your life the impact on your interests have impact on your
00:09:11 physiological health yeah so it's basically puts you if you're constantly feeling lonely
00:09:16 your body responds like it's basically all the time under stress so it's always in this alert alerts say
00:09:24 and so it's really bad for you because it actually like drops your immune system and get
00:09:29 it your response to inflammation is quite different so all the cardiovascular vascular diseases
00:09:33 actually responds to viruses so it's much easier to catch a virus that's sad now that
00:09:40 we're living in a pandemic and it's probably making us a lot more alone and it's probably weakening the immune
00:09:46 system making us more susceptible to the virus it's kind of sad yeah the statistics are the sticks are
00:09:54 pretty pretty horrible around that so around thirty percent of all millennials report that they're
00:09:59 feeling lonely constantly thirty thirty percent and then it's much worse for jan z
00:10:03 and then twenty percent of millennials say that they feel lonely and they also don't have any
00:10:09 close friends and then i think 25 or so and then 20 percent would say they don't even have acquaintances
00:10:14 this is the united states that's in the united states and i'm pretty sure that that's much worse everywhere else like
00:10:20 in the uk i mean it was white widely like tweeted and  posted when they were talking about a minister of
00:10:26 loneliness that they wanted to appoint because four out of ten you people in uk feel lonely so i think
00:10:32 we don't understand i mean that i think that thing actually exists um
00:10:39 so yeah you you you will die sooner if you if you are lonely and again that this is only when we're only talking about
00:10:46 your perception of loneliness of feeling lonely that is not objectively fully so being fully socially isolated
00:10:53 however the combination of being fully socially isolated and not having many connections and also
00:10:58 feeling lonely that's pretty much a deadly combination so it strikes me bizarre or strange that this is a wide known
00:11:09 fact and then there's really no one working really on that because it's a subclinical it's not clinical it's not
00:11:14 something that you can we'll tell your doctor and get a treatment or something yet it's
00:11:20 killing us yeah so there's a bunch of people trying to evaluate like try to measure the problem by looking at like
00:11:27 how social media is affecting loneliness and all that kind of stuff so it's like measurement like if you look at the field of
00:11:32 psychology they're trying to measure the problem and not that many people actually but some but you're basically saying how many
00:11:40 people are trying to solve the problem like how would you try to solve the problem of
00:11:50 loneliness like if you just stick to humans  i mean or basically not just the humans but the technology that connects
00:11:57 us humans do you think there's a hope for that technology to do the connection
00:12:05 like are you on social media much unfortunately do you find yourself like again if you sort of introspect about
00:12:14 how connected you feel to other human beings how not alone you feel do you think social media makes it better or worse
00:12:21 maybe for you personally or in in general i think it's it's easier to look at some stats and
00:12:28 i mean gen z's seem to be generation z seems to be much lonelier than millennials in terms
00:12:33 of however they report loneliness they're definitely the most connected you know generation in the world i mean
00:12:39 i still remember life without without an iphone without facebook they don't know that that ever existed
00:12:47  or at least don't know how it was so that tells me a little bit about the fact that that might be um
00:12:55 you know this hyperconnected world is might actually make people feel lonely lonelier i don't know exactly
00:13:00 what the what the measurements are around that but i would say in my personal
00:13:04 experience i think it does make you feel a lot lonelier mostly yeah we're all super connected
00:13:10 but i think loneliness the feeling of loneliness doesn't come from not having any social connections
00:13:16 whatsoever again tons of people that are in long-term relationships experienced bouts of loneliness and continued loneliness
00:13:24 and it's more the question about the true connection about actually being deeply seen deeply understood
00:13:32 and in a way it's also about your relationship with yourself like in order to not feel lonely
00:13:39 you actually need to have a better relationship and feel more connected to yourself then
00:13:43 this feeling actually starts to go away a little bit and then you open up
00:13:48 yourself to actually meeting other people in a very special way  not just you know add a friend on
00:13:55 facebook kind of way so just to briefly touch on it i mean do you think
00:14:00 it's possible to form that kind of connection with ai systems more downline of some of your work
00:14:12 do you think that's engineering-wise a possibility to alleviate loneliness is not with another human but with an ai system
00:14:22 well i know that's that's a fact that's what we're doing and we see it and we measure that and we
00:14:29 see how people start to feel less lonely talking to their virtual ai friend so basically a chatbot at the basic
00:14:36 level but could be more like do you have i'm not even speaking sort of 
00:14:43 about specifics but do you have a hope like if you look 50 years from now do you have a hope
00:14:47 that there's just like ais that are like optimized for let me let me first start like
00:14:55 right now the way people perceive ai which is recommender systems for facebook and twitter social media
00:15:04 they see ais basically destroying first of all the fabric of our civilization but second of all
00:15:09 making us more lonely do you see like a world where it's possible just have ai systems floating about that like
00:15:18 make our life less lonely yeah make us happy make like our putting good things into the world in
00:15:26 terms of our individual lives yeah totally believe it and that that's why we're i'm also working on that
00:15:33 i think we need to also make sure that what we're trying to optimize for we're actually measuring
00:15:39 and it is a north star metric that we're going after and all of our product and our all of our business models are
00:15:43 optimized for that because you can talk you know a lot of products that talk about
00:15:49 you know making you feel less lonely or making you feel more connected they're not really measuring that so
00:15:53 they don't really know whether their users are actually feeling less lonely in the long run or
00:15:59 feeling more connected in the long run so i think it's really important to put your measure yep to measure it
00:16:06 what's  what's a good measurement of loneliness well so that's something that i'm really interested in
00:16:12 how do you measure that people are feeling better or that they're feeling less lonely
00:16:16 with lowliness there's a scale there's a ucla 20 and ucla 3 recently scale which is basically a questionnaire that you
00:16:22 fill out and you can see whether in the long run it's improving or not
00:16:28 and that  does it capture the momentary feeling of loneliness does it look in like the past month like  is it basically a
00:16:39 self-report does it try to sneak up on you it's very tricky to answer honestly or something like that
00:16:45 well what's yeah i'm not familiar with the question it is just asking you a few questions like how often did you feel
00:16:51 like lonely or how often did you feel connected to other people in this last few couple weeks it's similar to
00:16:58 the self-report questionnaires for depression and anxiety like phq9 and get seven of course any as any self-report
00:17:07 questionnaires that's not necessarily very precise so very well measured but still if you take a
00:17:13 big enough population you get them through these  questionnaires you can see
00:17:19 you can see the positive dynamic and so you basically  you put people through questionnaires to
00:17:24 see like is this thing is our is what we're creating making people happier
00:17:31 yeah we measure so we measure two outcomes one short term right after the conversation we asked people whether
00:17:37 this conversation made them feel better worse or same this this metric right now is at
00:17:43 eighty percent so eighty percent of all our conversations make people feel better
00:17:47 but i should have done the questionnaire with you you feel a lot worse after we've done
00:17:52 this conversation that's actually fascinating i should probably do that
00:17:58 but that's that's sorry you should totally and aim for 80 aim to outperform your current
00:18:07 state-of-the-art ai system  in these human conversations so again we'll get to
00:18:13 your work with replica but let me continue on the line of absurd questions so you it talks about you know deep
00:18:20 connection with the humans deep connection with the ai meaningful connection let me ask
00:18:25 about love people make fun of me because i talk about love all the time but  what what do you think a love is
00:18:35 like maybe in the context of a meaningful connection with somebody else do you draw a distinction between love
00:18:50 or is it a graduate no is it it's all the same no like is it just a gradual thing or is there
00:18:56 something fundamental about us humans that seek like a really deep connection 
00:19:03 with another human being and what is that well the way i see it specifically the way it relates to our work and
00:19:23 the way it was the way it inspired our work on replica i think one of the biggest and the
00:19:32 most precious gifts we can give to each other now in 2020 as humans is this gift of deep empathetic understanding
00:19:42 the feeling of being deeply seen like what does that mean like that you exist like somebody acknowledging
00:19:47 the somebody seeing you for who you actually are and that's extremely extremely rare
00:19:54 i think that is that combined with unconditional positive regard belief and trust that
00:20:02 you internally are always inclined for positive growth and believing you in this way letting you be
00:20:09 a separate person at the same time and this deep empathetic understanding for me that's
00:20:15 the that's the combination that really creates something special something that people
00:20:22 when they feel it once they will always long for it again and something that starts huge
00:20:27 fundamental changes in people when we see that someone's accepts us so deeply we start to accept ourselves and
00:20:38 the paradoxes that's when big changes start start happening big fundamental changes and people start happening
00:20:43 so i think that is the ultimate therapeutic relationship that is and that might be in some way definition
00:20:49 of love so so acknowledging that there's a separate person and accepting
00:20:58 you for who you are now on a slightly so that and you mentioned therapeutic that sounds very like a very
00:21:05 healthy view of love but  is there also like  like you know if we look at heartbreak
00:21:15 and  you know most love songs are probably about heartbreak right is that like the mystery the tension the danger
00:21:24 the fear of loss you know all of that what people might see in a negative light as like games
00:21:31 or whatever but just just the the dance of human interaction yeah fear of loss and fear of like
00:21:41 you said like once you feel it once you long for it again but you also once you feel it once you
00:21:46 might for many people they've lost it so they fear losing it they feel lost
00:21:53 so is that part of it like you're you're speaking like beautifully about like the positive things but
00:22:00 is it important to be able to  be afraid of losing it i mean it's a huge part of it and
00:22:09 unfortunately we all you know face it at some points in our lives i mean
00:22:16 i did you want to go into details how did you get your heart broken sure well so mine is pretty straight my
00:22:22 source pretty straightforward i did have a friend that was you know that at some point um
00:22:31 in my 20s became really really close to me and we we became really close friends i grew up pretty lonely so in many
00:22:37 ways when i'm building you know this these ai friends i think about myself when i was 17 writing
00:22:43 horrible poetry and you know in my dial-up modem at home and you know and that was the feeling
00:22:50 that i grew up with i left i lived alone for a long time when i was a teenager
00:22:55 where did you grow up in moscow and then outskirts of moscow so i just skateboard during the day
00:23:01 and come back home and you know connect to the internet and write pokemon and then write horrible poetry
00:23:07 and was it love poems all sorts of points obviously love poems i mean what what other poetry can you
00:23:12 write when you're 17. it could be political or something but yeah but that was you know that was kind
00:23:16 of my yeah like deeply influenced by joseph brodsky and like all sorts of spots that
00:23:25 every 17 year old will will be looking you know looking at and reading but yeah that was my  these were my
00:23:32 teenage years and i just never had a person that i thought would you know take me
00:23:40 as it is would accept me the way i am and i just thought you know working and just doing my thing and being angry at
00:23:44 the world and being a reporter i was an investigative reporter working undercover and
00:23:50 writing about people was my way to connect with you know with with others i i was deeply
00:23:56 curious about every everyone else and i thought that you know if i go out there if i write their stories
00:24:03 that means i'm more connected this is what this podcast is about by the way i'm desperate alone seeking connection
00:24:11 i'm just kidding or am i i don't know so what wait a reporter  what
00:24:17 how did that make you feel more connected i mean you're still fundamentally pretty alone but
00:24:23 you're always with other people you know you're always thinking about what other place gonna infiltrate what other
00:24:30 community can i write about what other phenomena can i explore and he's sort of like a trickster you know and like
00:24:37 and a mythological character like creature that's just jumping  between all sorts of different worlds
00:24:43 and feel and feel sort of okay with in all of them so that was my dream job by the way that was like
00:24:50 totally what i would have been doing if russia was a different place and a little bit undercover so like you weren't
00:24:57 you were trying to like you said mythological creature trying to infiltrate so try to be a part of the world what
00:25:03 are we talking about what kind of things did you enjoy writing about i'd go work at a strip club
00:25:15 awesome okay  well i'd go work at a restaurant or just go write about you know certain phenomenons or phenomenons of
00:25:22 people in in the city and what  sorry to keep interrupting i'm the worst
00:25:30 a conversationalist what stage of russia is this what  is this pre-putin post-putin what was russia like
00:25:42 pre-putin is really long ago  this is putin era that's  beginning of 2000's
00:25:49 and 2010 2007 8 9 10. what were strip clubs like in russia and restaurants and
00:25:57 culture and people's minds like in that early russia that you were covering in those early 2000s was there was still
00:26:03 a lot of hope there was still tons of hope that you know we're
00:26:10 sort of becoming this  western westernized society the restaurants were opening we were really looking
00:26:17 and you know we're trying we're trying to copy a lot of things from  from the us from europe  bringing
00:26:24 all these things and very enthusiastic about that so there's a lot of you know stuff going
00:26:29 on there's a lot of hope and dream for this you know new moscow that would be
00:26:35 similar to i guess new york i mean just to give you an idea and year 2000 was the year one
00:26:42 we had two  movie theaters in moscow and there was this one first coffee house that opened
00:26:49 and it was like really big deal by 2010 there were all sorts of things everywhere almost
00:26:53 like a chain like a starbucks type of coffee house or like you mean oh yeah like a starbucks i mean i remember we were
00:26:59 reporting on like we were writing about the opening of starbucks i think in 2007 that was one of the biggest things that
00:27:04 happened and you know in moscow back back in the time like that was worthy of a magazine cover
00:27:12 and  that was definitely the you know the biggest talk of the time yeah when was mcdonald's because i was
00:27:17 still in russia when mcdonald's opened that was in the 90s i mean yeah i remember that very well
00:27:24 yeah those were long long lines i think it was 1990 three or four i don't remember um
00:27:31 mcdonald's at that time did you do that i mean that was a luxurious outing that was definitely not something
00:27:36 you do every day and also the line was at least three hours so if you're going to mcdonald's that is
00:27:40 not fast food that is like at least three hours in line yeah and then no one is trying to eat
00:27:45 fast after that everyone is like trying to enjoy as much as possible what's your memory of that oh it was
00:27:54 insane extremely positive it's a small strawberry milkshake and a hamburger and small fries and my mom's
00:27:59 there and sometimes i'll just because i was really little they'll just let me run
00:28:05 you know up the cashier and like cut the line which is like you cannot really do that in russia or
00:28:12 so like for a lot of people like a lot of those experiences might seem not very fulfilling you know like it's
00:28:23 on the verge of poverty i suppose but do you remember all that time fondly like because i do like the first time i drink
00:28:31 you know coke and just yeah the connection with other human beings in russia
00:28:43 i remember i remember really positively like how do you remember what the 90s and then the rush you were covering
00:28:50 just the human connections you had with people and the experiences well my my parents were both both physicists my
00:28:59 grandparents were both well my grandpa grandfather was an nuclear physicist a professor at the university
00:29:08 my dad worked at chernobyl when i was born in chernobyl analyzing kind of the everything after
00:29:15 the explosion and then i remember that and they were so they were making
00:29:20 sort of enough money in the soviet union so they were not you know extremely poor or anything it was pretty
00:29:25 prestigious to be a professor  the dean and the university and i remember my grandfather started making a
00:29:32 hundred dollars a month after you know in the 90s so then i remember we started
00:29:38 our main line of work would be to go to our little tiny country house get a lot of apples there from apple trees bring them
00:29:46 back to to to the city and sell them in the street so me and my nuclear physicist
00:29:54 grandfather were just standing there and he selling those apples the whole day because that would make you more money than
00:30:01 you know working at the university and then he'll just tell me try to teach me you know something about planets and whatever
00:30:11 the particles and stuff and you know i'm not smart at all so i could never understand anything but i was interested as a you
00:30:15 know journalist kind of type interested but that was my memory and you know i'm happy that i wasn't
00:30:24 i somehow got spared that i was probably too young to remember any of the traumatic stuff so
00:30:29 the only thing i really remember had this bootleg that was very traumatic i had this bootleg nintendo which was
00:30:35 called dandy in russia so in 1993 there was nothing to eat like even if you had any money you would go
00:30:40 to the store and there was no food i don't know if you remember that and our friend had a restaurant like
00:30:48 government half government owned something restaurant so they always had supplies so he
00:30:54 exchanged a big bag of weed for this nintendo that looked like nintendo and then i remember very fondly because
00:31:01 i think it was nine or something like that and or seven traumatic because we just got it and i
00:31:09 was playing it and there was this you know dandy tv show yeah so dramatically positive sense
00:31:14 you mean like like a definitive well they took it away and gave me a
00:31:20 bag of wheat instead and i cried like my eyes out for days days and days oh no and then you
00:31:26 know as a and my dad said we're gonna like exchange it back in a little bit so you
00:31:30 keep the little gun you know the one that you shoot the ducks with so i'm like okay i'm keeping
00:31:35 the gun so sometimes it's going to come back but then they exchanged the gun as well for some sugar or something
00:31:42 i was so pissed i was like i didn't want to eat for days after that i'm like i don't want your food
00:31:48 my nintendo that was extremely traumatic but you know i was happy that that was my only
00:31:54 traumatic experience you know my dad had to actually go to chernobyl with a bunch of 20 year olds he was 20 when he went to
00:32:00  chernobyl and that was right after the explosion no one knew anything the whole crew he
00:32:04 went with all of them are dead now i think there was this one guy  still
00:32:11 that was still alive for this last few years i think he died a few years ago now my dad somehow luckily got back earlier
00:32:18 than everyone else but just the fact that that was the and i was always like well how did they send
00:32:23 you i was only i was just born you know you had a newborn talk about paternity leave they're like
00:32:28 but that's who they took because they didn't know whether you would be able to have kids when you come back
00:32:34 so they took the ones with kids so him with some guys want to and i'm just thinking of me
00:32:40 when i was 20 i was so sheltered from any problems whatsoever in life and then my dad
00:32:46 his 21st birthday at the reactor you like work three hours a day you sleep the rest
00:32:54 and and i yeah so i played with a lot of toys from chernobyl what are your memories of chernobyl in
00:33:00 in general like a bigger context you know because of that hbo show
00:33:07 the world's attention turned to it once again like what are your thoughts about chernobyl did russia screw that one up like
00:33:15 you know there's probably a lot of lessons about our modern times with data about coronavirus and all that kind
00:33:21 of stuff it seems like there's a lot of misinformation there's a lot of
00:33:28 people kind of trying to hide whether they've screwed something up or not as it's very understandable it's very
00:33:34 human very wrong probably but obviously russia was probably trying to hide
00:33:41 that they've screwed things up like what are your thoughts about that time personal and
00:33:48 in general i mean i was born when the explosion happened so actually a few months after so of
00:33:54 course i don't remember anything apart from the fact that my dad would bring me tiny
00:34:00 toys plus like plastic things that would just go crazy haywire when you my mom was like just nuclear about that
00:34:11 i was like what are you bringing you should not do that  she was nuclear very nice absolutely
00:34:17 well done well  but yeah but the tv show was just phenomenal i mean yeah it's definitely
00:34:27 first of all it's an incredible how that was made not by the russians but someone else but capturing so well
00:34:35 everything about the you know about our country it felt a lot more genuine that most of the movies and tv shows are made now
00:34:42 in russia just so much more genuine and most of my friends in russia were just in complete awe about the
00:34:48 with the show but i think that how good of a job they did oh my god phenomenal but all the apartments there's something
00:34:54 yeah the set design i mean russians can't do that we you know but you you see everything
00:34:59 and it's like wow that's exactly how it was it's so i i don't know that show i don't know what to think about that
00:35:06 because it's british accents british actors of a person i forgot who created the show i'm not
00:35:14 but i remember reading about him and he's not he doesn't even feel like like there's no russia in his history
00:35:21 no he did like super bad or some like or like  i don't know yeah like exactly whatever
00:35:25 that thing about the bachelor party in vegas  number four and five or something were
00:35:30 the ones that he worked yeah but so he made me feel really sad for some reason that
00:35:38 if a person obviously a genius could go in and just study and just be extreme attention to detail
00:35:46 that can do a good job it made me think like why don't other people do a good job with this
00:35:54 like about russia like there's so little about russia the russian side of world war ii of
00:36:06 i mean there's so much interesting evil and not and beautiful moments in the history of the 20th century in russia
00:36:14 it feels like there's not many good films on from the russians you would expect
00:36:19 something from the russians well they keep making these propaganda movies now oh no
00:36:24 unfortunately but you know chernobyl was such a perfect tv show i think capturing really well
00:36:29 it's not about like even the set design which was phenomenal but just capturing all the problems that
00:36:35 exist now with the country and like focusing on the right things like if you build the whole country on a lie
00:36:42 that's what's gonna happen and that's just this very yeah and did you have your dad talked
00:36:51 about it to you like his thoughts i think experience he never talks he's this kind of russian
00:37:00 man that just my husband who's american and he asked him a few times like you know igor
00:37:05 how did you but why did you say yes or like why did you decide to go you could have said no
00:37:10 not go to chernobyl why would like a person like that's what you do you cannot say no yeah yeah it's just
00:37:21 it's like a russian way it's the russians don't talk that much no there are downsides and upsets for that
00:37:30  yeah that's the truth okay so or maybe we skipped a few steps along the way but you were
00:37:42 trying to  do to be a journalist in that time what was what was russia like at that time
00:37:50 post he said 2007 starbucks type of thing what else what else was russia like then
00:37:56 i think there was just hope there was this big hope that we're going to be you know friends with the united states
00:38:03 and we're going to be friends with europe and we're just going to be also a country like those with
00:38:11 you know bike lanes and parks and everything's going to be urbanized again we're talking about 90s where like
00:38:16 people would be shot in the street and it was i sort of have a fond memory of going into a movie theater and
00:38:22 i you know coming out of it after the movie and the guy that i saw on the stairs was like playing their shot
00:38:28 which was again it was like a thing in the 90s that would be happening people were you know people were getting shot here
00:38:34 and there tons of violence tons of  you know just basically mafia mobs on
00:38:41 in the streets and then the 2000s were like you know things just got cleaned up  oil went up  and the
00:38:47 country started getting a little bit richer you know the 90s were so
00:38:52 grim mostly because the economy was in shambles and oil prices were not high so the country didn't have anything
00:39:00 we defaulted in 1998 and the money kept jumping back and forth like first there were millions of rebels then it
00:39:05 got like default you know then it got to like thousands there was one rubble with something then again to millions
00:39:12 it was like crazy town that was crazy and then the 2000s were just these years of stability in a way and
00:39:20 the country getting a little bit richer because of you know again oil and gas and we were
00:39:25 starting to we started to look at specifically in moscow and in facebook to look in at other
00:39:33 cities in europe and new york and us and trying to do the same in our like small kind of cities towns there
00:39:39 what was  what were your thoughts of putin at the time well in the beginning he was really
00:39:44 positive everyone was very you know positive about putin he was young um
00:39:51 he's very energetic he also intermediate the sheriff was somewhat compared to well that was
00:39:57 not like way before the shirtless era the shirtless era okay so it didn't start off shortly when did the shirtless
00:40:03 era that's like the propaganda of riding horse fishing 2010 11 12. yeah that's my favorite you know like
00:40:10 people talk about the favorite beatles like the i don't know that's my favorite putin that's the shirtless
00:40:17 putin now i remember very very clearly 1996 where you know americans really helped russia
00:40:24 with elections and yeltsin got reelected thankfully so because there's a huge threat that actually the communists will
00:40:30 get back to power they were a lot more popular and then a lot of american
00:40:37 experts political experts and campaign experts descended on moscow and helped yeltsin actually get
00:40:44 yeah the presidency the second term for the pro of the presidency but elsinore was not feeling great you know
00:40:48 in the by the end of his second term  he was you know
00:40:55 alcoholic he was really old he was falling off  you know the stages when he was talking
00:41:02  so people were looking for it fresh i think for a fresh face for someone who's gonna continue yeltsin's
00:41:08  work but who's going to be a lot more energetic and a lot more active young efficient maybe
00:41:17 so that's what we all saw in putin back in the day i i'd say that everyone absolutely everyone in russia in early
00:41:24 2000s who was not a communist would be yeah putin's great we have a lot of hopes for him what are your
00:41:31 thoughts and i promise we'll get back to  first of all your love story second of all ai well what are your
00:41:38 thoughts about communism the 20th century i apologize i'm reading the rise and
00:41:46 fall of the third reich oh my god so i'm like really steeped into like world war ii
00:41:56 and stalin and hitler and just these dramatic personalities that brought so much evil to the world
00:42:03 but it's also interesting to politically think about these different systems and what they've
00:42:07 led to and russia is one of the sort of beacons of communism in the 20th
00:42:16 century what are your thoughts about communism having experienced it as a political system i mean i have only
00:42:22 experienced it a little bit but mostly through stories and through you know seeing my parents my grandparents who lived
00:42:29 through that it was horrible it was just plain horrible it was just awful you think it's there's something i
00:42:36 mean it sounds there's  so like the drawbacks of capitalism is that  you know eventually there
00:42:49 is it's a it's the point of like a slippery slope eventually it creates 
00:42:57 you know the rich get richer it creates a disparity like inequality of wealth inequality
00:43:04 if like you know i guess it's hypothetical at this point but eventually capitalism leads to humongous
00:43:11 inequality and that that's you know some people argue that that's a source of unhappiness is it's not like
00:43:17 absolute wealth of people it's the fact that there's a lot of people much richer than you
00:43:23 there's a feeling of like that's where unhappiness can come from so the idea of of communism or this sort of marxism is
00:43:32  is is not allowing that kind of slippery slope but then you see the actual implementations
00:43:38 of it and still seems to be seems to go wrong very badly what do you think that is why does it go wrong
00:43:48 what is it about human nature if we look at chernobyl you know those kinds of barack
00:43:54 bureaucracies that were constructed is there something like do you think about this much
00:44:01 of like why it goes wrong well there's no one was really like it's not that everyone was equal
00:44:07 obviously the you know the the government and everyone close to that were
00:44:13 the bosses so it's not like fully i guess  there's already this dream of equal life so
00:44:21 then i guess the the situation that we hadn't you know the russia and soviet in the soviet union it was more
00:44:27 it's a bunch of really poor people without any way to make any you know significant fortune or
00:44:33 build anything living constant under constant surveillance surveillance from other people like you
00:44:41 can't even you know do anything that's not fully approved by the dictatorship basically otherwise your
00:44:49 neighbor will write a letter and you'll go to jail absolute absence of
00:44:55 actual law yeah this constant state of fear you didn't own any own anything you didn't you know the
00:45:03 you couldn't go travel you couldn't read anything western or you could make a career really unless you're working in the
00:45:13 military complex which is why most of the scientists were so well regarded i come from you know
00:45:18 both my dad and my mom come from families of scientists and they they were really well regarded as you
00:45:23 as you know obviously because this they wanted i mean because there's a lot of value to them
00:45:29 being well regarded because they were developing things that could be used in in the military
00:45:35 so that was very important that was the main investment but was miserable it was so miserable
00:45:41 that's why you know a lot of russians now live in the state of constant ptsd that's why we you know
00:45:47 want to buy buy buy buy and definitely if as soon as we have the opportunity you know we just got to it finally that
00:45:53 we can you know own things you know i remember the time that we got our first yogurts and that was
00:45:58 the biggest deal in the world it was already in the 90s by the way i mean what was your like
00:46:05 favorite food what was like whoa like this is possible oh fruit because we only had
00:46:13 apples bananas and whatever and you know whatever watermelons whatever you know people would
00:46:18 grow in the soviet union so there were no pineapples or papaya or mango like you've never seen those fruit things
00:46:25 like those were so ridiculously good and obviously you could not get any like strawberries in winter
00:46:33 or anything that's not you know seasonal so that was a really big deal seeing all these fruit things yeah me too actually
00:46:39 i don't know i think i have a like i don't think i have any too many demons 
00:46:45 or like addictions or so on but i think i've developed an unhealthy relationship with fruit and i
00:46:50 still struggle with oh you can get any type of fruit right you can get like also these weird fruit
00:46:56 fruits like dragon fruit or something more all kinds of like different types of peaches like
00:47:02 cherries were killer for me i know i know you say like we had bananas and so on but
00:47:06 i don't remember having the kind of banana like when i first came to this country the amount of banana
00:47:15 i like literally got fat on bananas like the amount oh yeah for sure delicious and like cherries the kind
00:47:22 like just the quality of the food i was like this is capitalism this is that's pretty
00:47:28 good it's delicious yeah yeah yeah it's funny it's funny i don't know what to think of it of um
00:47:43 it's funny to think how an idea that's just written on paper when carried out
00:47:49 amongst millions of people how that gets actually when it becomes reality what it actually looks like
00:47:58  sorry but the been studying hitler a lot recently and  going through mineconf he  pretty much
00:48:06 rode out of minecon for everything he was gonna do unfortunately most leaders including
00:48:11 stalin didn't read the read it but it's it's kind of terrifying and i don't know
00:48:18 and amazing in some sense that you can have some words on paper and they can be brought to life and they
00:48:24 can either inspire the world or they can destroy the world and  yeah there's a lot of lessons
00:48:32 to study in history i think people don't study enough now i know one of the things i'm hoping with
00:48:39 i've been practicing russian a little bit i'm hoping to sort of find rediscover the the beauty and the terror
00:48:50 of russian history through this stupid podcast by talking to a few people so anyway i just feel like so much was
00:48:58 forgotten i so much was forgotten i'll probably i'm gonna try to
00:49:04 convince myself to you're a super busy and super important person well i'm gonna i want to try to befriend you
00:49:10 to  to try to become a better russian because i feel like i'm a shitty russian
00:49:16 not that busy so i can totally be a yeah but love you were you're talking about your early
00:49:27 days of  being a little bit alone and finding a connection with the world through
00:49:34 being a journalist where does love come into that i guess finding for the first time um
00:49:39 some friends it's very you know simple story some friends that all of a sudden
00:49:47 we i guess we're the same you know the same at the same place with our lives we're 25 26 i guess
00:49:58 and somehow remember and we just got really close and somehow remember this one day
00:50:03 where it's one day and you know in summer that we just stayed out outdoor the whole night and just
00:50:08 talked and for some unknown reason i just felt for the first time that someone
00:50:15 could you know see me for who i am and it just felt extremely like extremely good and you know we fell asleep outside and
00:50:22 just talking and it was raining it was beautiful you know sunrise and it's really cheesy but at the same time we just became
00:50:31 friends in a way that i've never been friends with anyone else before and i do remember that before and after
00:50:37 that you sort of have this unconditional family sort of and it gives you tons of power it just basically gives you this
00:50:47 tremendous power to do things in your life and to change positively you mean like on many
00:50:53 different levels power because you could be yourself at least you know that some
00:51:01 somewhere you can't be just yourself like you don't need to pretend you don't need to be
00:51:06 you know great at work or tell some story or sell yourself in some way or another and
00:51:11 so we became this really close friends and in a way i started a company because he had a
00:51:19 startup and i felt like i kind of want to start up too it felt really cool i didn't know what
00:51:23 i'm gonna what i would  really do but i felt like i kind of need a startup
00:51:29 okay so that's so that pulled you in to the startup world yeah and then yeah and then this 
00:51:38 closest friend of mine died we actually moved here to san francisco together and then we went back for a visa to moscow and 
00:51:45 we lived together with roommates and we came back and he got hit by a car right in front of kremlin
00:51:53 hannah you know next to the river so and you've moved to america at that point at that point i was like
00:52:06 what about him what about roman him too he actually moved first so i was always sort of trying to do what he was
00:52:11 doing so i didn't like that he was already here and i was still you know in moscow and
00:52:14 we weren't hanging out together all the time so was he in san francisco
00:52:21 yeah we were roommates so he just visited moscow for we went back for for our visas we
00:52:27 had to get a stamp and our passport for our work visas and the embassy was taking a little longer so we stayed
00:52:34 there for a couple weeks what happened how did you so how did he  how did he die he was crossing the street
00:52:44 and the car was going really fast and way over the speed limit and just didn't stop on the on the pedestrian
00:52:51 cross on the zebra and i just ran over him when was this it was in 2015 on 28th of november so it was
00:53:00 pretty long ago now but at the time you know i was 29 so for me it was the first kind of meaningful
00:53:10 death in my life you know both sets of i had both sets of grandparents at the time i didn't see anyone so close die and
00:53:18 death sort of existed but as a concept but definitely not as something that would be you know
00:53:24 happening to us anytime soon and specifically our friends because we were you know we're still in our 20s or early
00:53:29 30s and it still still felt like the whole life is you know you could still dream about ridiculous
00:53:37 things different so that was it was just really really abrupt i'd say what did it
00:53:48 feel like to  to lose him like that feeling of loss he talked about the feeling of love having power what is
00:53:55 the feeling of loss if you like well in buddhism there's this concept of samaya
00:54:03 where something really like huge happens and then you can see very clearly
00:54:10 i think that was it like basically something changed so changed me so much in such a short
00:54:16 period of time that i could just see really really clearly what mattered or what not well i definitely
00:54:23 saw that whatever i was doing at work didn't matter at all and some other things and it was just
00:54:29 this big realization what this very very clear vision of what you still miss him today
00:54:41 yeah for sure for sure it was just this constant i think it was he was really important for for me and
00:54:48 for our friends for many different reasons and i think one of them
00:54:53 being that we didn't just say goodbye to him but we sort of said goodbye to our youth in a way it was
00:54:59 like the end of an era and it's on so many different levels the end of
00:55:06 moscow as we knew it the end of you know us living through our 20s and kind of dreaming about the future
00:55:13 do you remember like last several conversations is there moments with him that stick out that will kind of haunt you
00:55:26 yeah well his last year here in san francisco was pretty depressed for as his startup was not going really
00:55:32 anywhere and he wanted to do something else he wanted to do build he played with toy with like
00:55:37 played with the wrong a bunch of ideas but the last one he had was around
00:55:44 building a startup around death so having he applied to y combinator with a video that you know i had on my computer
00:55:54 and it was all about you know disrupting death thinking about new symmetries  more biologically
00:56:01 like things that could be better biologically for for humans and at this end
00:56:08 at the same time having those digital avatars these kind of ai avatars that would store all the
00:56:14 memory about a person that he could interact with what year was this 2015. well right before that his death
00:56:21 so it was like a couple months before that he recorded that video and so i found out my computer when um
00:56:27 it was in our living room he never got in but he was thinking about a lot
00:56:34 somehow does it have the digital avatar idea yeah that's so interesting well he just says well
00:56:40 that's in his yeah the fish has this idea and he'll he talks about like i want to rethink how people grieve and
00:56:44 how people talk about death why was he interested in this and i
00:56:51 is it maybe someone who's depressed yeah is like naturally inclined thinking about that
00:56:57 but i just felt you know this year in san francisco we just had so much i was going through a hard time he was
00:57:02 going through a hard time and we were definitely i was trying to make him just happy somehow to make him feel better
00:57:10 and it felt like you know this i don't know i just felt like i was taking care of off him a lot
00:57:16 and he almost started feel better and then i don't know i just felt i just felt lonely again i guess and that was
00:57:25 you know coming back to san francisco in december our help you know helped organize the
00:57:31 funeral help help his parents and i came back here and it was a really lonely apartment a bunch of his clothes everywhere
00:57:38 and christmas time and i remember had a board meeting with my investors and i just couldn't talk about like
00:57:44 i had to pretend everything's okay and you know just working on this company yeah it was definitely very
00:57:55 very tough tough time do you think about your own mortality you said  you know we're young the the
00:58:06 the the possibility of doing all kinds of crazy things it's still out there it's still
00:58:12 before us but  it can end any moment do you think about your own ending at any moment
00:58:21 unfortunately i think about way too way too much it's somehow after roman like every year
00:58:27 after that i started losing people that i really love i lost my grandfather next year
00:58:34 my you know the the person who would explain to me you know what the universe is made off
00:58:39 while you're selling apples while selling apples and then i lost another close friend of mine and
00:58:46 and it just made me very scared i have tons of fear about death that's what makes me
00:58:51 not fall asleep oftentimes and just go in loops and and then as my therapist you know
00:59:00 recommended me i open up  some nice calming images with the voice over and it calms me down oh for sleep
00:59:08 yeah i'm really scared of that this is a big i definitely have tons of i guess some pretty big trauma about it
00:59:17 and i'm still working through there's a philosopher ernest becker who wrote a book denial of death i'm
00:59:24 not sure if you're familiar with any of those folks there's a in psychology a whole field
00:59:33 called terror management theory sheldon was just on the podcast he wrote the book he was the
00:59:42 we talked for four hours about death  fear of death  but his whole idea is that ernest becker i think i i find this idea
00:59:50 really compelling is  that everything human beings have created like our whole motivation in life
01:00:02 is to  create like escape death of that we're somehow immortal it's like everything around us this room
01:00:19 your startup your dreams all everything you do is a kind of creation of a brain
01:00:29 unlike any other mammal or species is able to be cognizant i think so you know there's there's the
01:00:38 question of like the meaning of life that you know you look at like what drives us  humans and when i read ernest becker
01:00:48 that i highly recommend people read is the first time i this scene it felt like this is the right
01:00:55 thing at the core  sheldon's work is called warm at the core so he's saying it's i think it's 
01:01:02 william james he's quoting or whoever is like the the thing what is it the core of it all sure
01:01:09 there's like love you know jesus might talk about like love is at the core of
01:01:14 everything i i don't you know that's the open question what's that the you know it's turtles turtles but it
01:01:20 can't be turtles all the way down what's what's at the at the bottom and  ernest becker says the fear of death
01:01:29 and the way in fact  because you said therapist and calming images his whole idea is um
01:01:36 you know we we want to bring that fear of death as close as possible to the surface because it's 
01:01:44 and like meditate on that  and and use the clarity of vision that provides to 
01:01:50 you know to live a more fulfilling life to to live a more honest life to discover
01:01:58 you know there's something about you know being cognizant of the finiteness of it all that might
01:02:05 result in in the most fulfilling life so that's the that's the duel of what you're saying
01:02:11 because you kind of said it's like i unfortunately think about it too much it's a question whether it's good to
01:02:18 think about it because i i've i'm again i talk about way too much about love and probably death
01:02:26 and when i ask people or friends which is why i probably don't have many friends
01:02:31 are you afraid of death i think most people say they're not they're not what they they
01:02:37 say they're they're afraid you know it's kind of almost like they see death
01:02:45 as this kind of like a paper deadline or something and they're afraid not to finish the paper before the paper like
01:02:52 like i'm afraid not to finish the goals i have but it feels like they're not actually
01:02:59 realizing that this thing ends like really realizing like really thinking as nietzsche and
01:03:04 all these philosophers like thinking like  the very thing that you know like when you think deeply
01:03:15 about something you can dis you can realize that you haven't actually thought about
01:03:23 it  yeah and i and when i think about death it's like  it can be it's terrifying if it feels
01:03:29 like stepping outside into the cold or it's freezing and then i have to like hurry back
01:03:36 inside or it's warm  but like i think there's something valuable about stepping out
01:03:44 there into the freezing cold  definitely when i talk to my mentor about it he always 
01:03:52 tells me well what dies there's nothing there that can die but i guess that
01:03:59 works well in in buddhism one of the concepts are really hard to
01:04:04 grasp and that people spend all their lives meditating on would be anata which is the concept of non not self
01:04:12 and kind of thinking that you know if you're not your thoughts which are obviously not your thoughts because you
01:04:17 can observe them and not your emotions and not your body then what is this and if you
01:04:22 go really far then finally you see that there's not self there's this concept of
01:04:29 not self so once you get there how can that actually die what is dying
01:04:36 right you're just a bunch of molecules stardust but that is very you know very advanced spiritual work for me i'm definitely
01:04:48 just definitely not oh my god no i have  i think it's very very useful it's just the fact that maybe being so afraid is
01:04:54 not useful and mine is more i'm just terrified like it's really makes me
01:04:59 on a personal level on a personal level how do you overcome that i don't i'm still trying to have pleasant images
01:05:18 well pleasant images get me  to sleep and then during the day i can distract myself with other things
01:05:26 i'm glad we're both doing the same exact is there other like is there moments since you've  lost roman that you had
01:05:41 like moments of like bliss and like that you've forgotten that you have achieved that buddhist
01:05:49 like level of like what can possibly die i'm part like  losing yourself in the moment in
01:05:59 the ticking time of like this universe he's just part of it
01:06:06 for a brief moment and just enjoying it well that goes hand in hand i remember i think a day or two after he died we
01:06:13 went to finally get his passport out of the embassy and we're driving around moscow and it was
01:06:18 you know december which is usually there's never sun in moscow in december and somehow it was an extremely sunny
01:06:27 day and we were driving with close friend and i remember feeling for the first
01:06:34 time maybe this just moment of incredible clarity and somehow happiness not like happy happiness but happiness
01:06:42 and just feeling that you know i know what the universe is sort of
01:06:49 about whether it's good or bad and it wasn't a sad feeling it was probably the most beautiful feeling that
01:06:53 you can ever achieve and you can only get it when something oftentimes when
01:07:02 something traumatic like that happens but also if you just you really spend a lot of time
01:07:07 meditating looking at the nature doing something that really gets you there but once you're there i think when you
01:07:13  summit a mountain a really hard mountain you you inevitably get there that's just a
01:07:18 way to get to the state you can do really big things i think yeah sucks it doesn't last forever so
01:07:30 bukowski talked about like love is the fog like it's  when you wake up in the morning it's
01:07:38 it's there but it eventually dissipates it's really sad nothing lasts forever but definitely
01:07:45 like doing this push-up and running thing there's moments i had a couple moments like i'm not a crier i don't cry but there's
01:07:54 moments where i was like face down on the carpet like with tears in my eyes is
01:08:00 interesting and then that like complete like  there's a lot of demons i've got demons had to face them funny
01:08:09 how running makes you face your demons but at the same time the flip side of that there's a few moments where i was
01:08:17 in bliss and all of it alone which is funny that's beautiful i like that but definitely pushing
01:08:26 yourself physically one of it for sure yeah it's yeah like you said i mean you were speaking as a metaphor of mount
01:08:33 everest but it also works like literally i think physical endeavor somehow
01:08:41 yeah there's something i mean war monkeys apes whatever physical there's a physical
01:08:46 thing to it but there's something to this pushing yourself physical
01:08:52 physically but alone that happens when you're doing like things like you do or strenuous like workouts or
01:08:59 you know rolling across the atlantic or yeah like marathons that's why i love watching
01:09:04 marathons and you know so boring but you can see them getting there so the other thing i don't
01:09:11 know if you know there's a guy named david goggins he's  he basically 
01:09:18 so he's been either email on the phone with me every day through this so i haven't been exactly alone
01:09:25 but he he's kind of he's the he's the devil on the devil's shoulder so he's like the worst possible human being
01:09:35 in terms of giving you a advice like he has through everything i've been doing he's been doubling everything i do
01:09:44 so he he's insane  he's a this navy seal person  he's wrote this book can't hurt me
01:09:49 he's basically one of the toughest human beings on earth he ran all these crazy ultra marathons in
01:09:55 the desert he set the world record a number of pull-ups he's just does everything where's like
01:10:03 he like how can i suffer today he figures that out and does it yeah that whatever that is  that
01:10:10 process of self-discovery is really important i actually had to turn myself off from the internet
01:10:16 mostly because i started this like workout thing like a happy go-getter with my like headband and like like
01:10:24 just like  because a lot of people were like inspired and they're like yeah we're gonna exercise with you
01:10:30 and i was yeah great you know but then like i realized that this this journey can't be done
01:10:39 together with others this has to be done alone so out of the moment of love out of the moments of loss can we 
01:10:51 talk about your journey of finding i think an incredible idea an incredible company and incredible system in replica
01:11:02 how did that come to be so yeah so i was a journalist and then i went to business school for a
01:11:07 couple years to just see if i can maybe switch gears and do something else
01:11:13 23. and then i came back and started working for a businessman in russia who built the first 4g network in
01:11:23 our country and was very visionary and asked me whether i want to do fun stuff together
01:11:30 and we worked on a bank the idea was to build a bank on top of a telco so that was 2011
01:11:36 or 12 and a lot of telecommunication company mobile network operators didn't really know
01:11:45 what to do next in terms of you know new products new revenue and this big idea was that you know um
01:11:50 you put a bank on top and then all work works out basically your prepaid account becomes
01:11:57 your bank account and you can use it as as your bank  so you know a third of a country wakes up
01:12:04 as your bank client but we couldn't quite figure out what
01:12:09 would be the main interface to interact with the bank the problem was that most people didn't have smart
01:12:15 smartphones back in the time  in russia the penetration of smartphones was low
01:12:19 people didn't use mobile banking or online banking on their computers so we figured out that sms would be the
01:12:26 best way  because that would work on feature phones  wow but that required some chatbot technology
01:12:32 which i didn't know anything about obviously so i started looking into it and saw that there's nothing really
01:12:38 well there was just nothing there was ideas through sms be able to interact with your bank account
01:12:43 yeah and then we thought well cool since you're talking to a bank account why can't this
01:12:48 can't we use more of you know some behavioral ideas and why can't this banking chatbot be nice to you and
01:12:55 really talk to you sort as a friend this way you develop more connection to it retention is higher people don't turn
01:13:02 and so i went to very depressing  russian cities to test it out i went to i remember three different
01:13:09 towns with  to interview potential users so people use it for a little bit cool
01:13:16 and i want to talk to them poor towns very poor towns mostly towns that were
01:13:24 you know sort of factories  mono towns they were building something and then the factory went away
01:13:31 and it was just a bunch of very poor people and then we went to a couple that weren't
01:13:37 as dramatic but still the one i remember really fondly was this woman that worked at a glass factory and she talked to chatbot
01:13:44 and she was talking about it and started crying during the interview because she said no one really cares for
01:13:49 me that much and so to be clear that was the my only endeavor in programming that
01:13:57 chat boss it was really simple it was literally just a few if this then that rules and um
01:14:08 it was incredibly simplistic and still that made her and that really made her emotional she
01:14:13 said you know i have my mom and my my husband and i don't have any more really in my life
01:14:19 and it was very sad but at the same time i felt and we had more interviews in a similar vein and what i thought in
01:14:26 a moment was like well it's not that the technology is ready because definitely in 2012
01:14:33 technology was not ready for for that but humans already unfortunately so this
01:14:38 project would not be about like tech capabilities would be more about human vulnerabilities but
01:14:45 there's something so so powerful around about conversational ai that i saw then that i thought
01:14:53 was definitely worth putting in a lot of effort into so in the end of the day we solved the
01:14:58 banking project but my then boss was also my mentor and really really close friend told me
01:15:07 hey i think there's something in it and you should just go work on it i was like what what product
01:15:11 i don't know what i'm building he's like you'll figure it out and you know looking back at this it
01:15:17 was a horrible idea to work on something without knowing what it was which is maybe the reason why it took us
01:15:24 so long but we just decided to work on the conversational tech to see what it you know
01:15:30 there were no chatbot constructors or programs or anything that would allow you to actually build one
01:15:37 at the time  that was the era of by the way google glass which is why you know some of the investors like
01:15:42 steven investors we talked with were like oh you should totally build it for google glass if not we're not
01:15:48 i don't think that's interesting did you bite on that idea no okay because i wanted to be
01:15:56 to do text first because i'm a journalist so i was fascinated by just texting
01:16:03 so you thought so the emotional that interaction that the the woman had like so do you think you could feel
01:16:11 emotion from just text yeah i saw something in just this pure texting and also thought that
01:16:17 we should first start start building for people who really need it versus people have google
01:16:22 glass if you know what i mean and i felt like the early adopters of google glass might not be overlapping with people who
01:16:29 are really lonely and might need some you know someone to talk to but then we really just focus on the
01:16:36 tech itself we just thought what if we just you know we didn't have a product idea in the moment and we felt what if we
01:16:41 just look into building the best conversational constructor so to say use the best tech
01:16:49 available at the time and that was before the first paper about deep learning applied to dialogues which happened in
01:16:58 2015 in august 2015 which google published did you follow the work of lobner prize
01:17:06 and like all the sort of non machine learning chat bots yeah what really struck me was
01:17:12 that you know there was a lot of talk about machine learning and deep learning
01:17:17 like big data was a really big thing everyone was saying you know the business well big data
01:17:22 yeah 2012 is the biggest kaggle competitions were you know yeah important but that was
01:17:27 really the kind of uphill people started talking about machine learning a lot but it was only about
01:17:33 images or something else and it was never about conversation as soon as i looked into the conversational attack it
01:17:38 was all about something really weird and very outdated and very marginal and felt very hobbyist
01:17:45 it was all about lerbiner prize which was won by a guy who built a chat ball to talk like a ukrainian
01:17:50 teenager it was just a gimmick and somehow people picked up those gimmicks and then
01:17:56 you know the most famous chat bot at the time was eliza from 1980s which was really bizarre or a
01:18:02 smarter child on aim the funny thing is it felt at the time not to be that popular
01:18:09 and it still doesn't seem to be that popular like people talk about the touring test
01:18:14 people like talking about it philosophically journalists like writing about it
01:18:19 but it's a technical problem like people don't seem to really want to solve the open dialogue like
01:18:29 they they're not obsessed with it even folks like of in you know in boston the alexa team
01:18:37 even they're not as obsessed with it as i thought they might be why not what do you think
01:18:42 so you know what you felt like you felt with that woman when she felt something by reading the text
01:18:49 i feel the same thing there's something here what you felt i feel like alexa folks
01:18:57 and just the machine learning world doesn't feel that that there's something here because they see as a technical problem
01:19:04 it's not that interesting for some reason it's could be argued that maybe as an as a purely sort of
01:19:11 natural language processing problem it's not the right problem to focus on because there's too much subjectivity
01:19:19 that that thing that the woman felt like like if if if your benchmarking cr includes a
01:19:24 woman crying that doesn't feel like a good benchmark that's a good test but to me
01:19:29 there's something there that's you could have a huge impact but i don't think the machine learning world
01:19:36 likes that the human emotion the subjectivity of it the fuzziness
01:19:41 the fact that with maybe a single word you can make somebody feel something deeply what is that it doesn't feel right to
01:19:48 them so i don't know i don't i don't know why that is i'm that's why i'm excited um
01:19:56  when i discovered your work it feels i'm giving myself props for for googling becoming a cr for  for
01:20:11 our i guess mutual friend and introducing us but i'm so glad that you exist and what
01:20:16 you're working on but i have the same kind of if we could just backtrack a second because
01:20:20 i have the same kind of feeling that there's something here in fact i've been working on a few things
01:20:28 that are kind of crazy and very different from your work i think i think they're i think they're
01:20:34 too crazy but the like one i will not have to know no all right we'll we'll talk about it more
01:20:44 i feel like it's harder to talk about things that have failed and are failing while you're a failure
01:20:54 like it's easier for you because you're already successful on some measures tell it to my board
01:21:04 well you're you're  i think i think you've demonstrated success a lot of benchmarks it's easier
01:21:10 for you to talk about failures for me the bottom currently of the of the success you're way too humble no so it's hard
01:21:23 for me to know but there's something there there's something there and i think you're um
01:21:28 you're exploring that and you're discovering that yeah it's been so it's been surprising
01:21:33 to me but i i  you've mentioned this idea that you you thought it wasn't enough to start
01:21:43 a company or start efforts based on it feels like there's something here like  what did you mean by that
01:21:52 like you should be focused on creating a like you should have a product in mind is that what you meant
01:21:58 it just took us a while to discover the product because it all started with a hunch of like um
01:22:05 of me my mentor and just sitting around and he was like well this that's it there's that's the you know
01:22:10 the holy grail is there there's like there's something extremely powerful and
01:22:17 and in conversations and there's no one who's working on machine conversation from the right angle so to say
01:22:23 i feel like that's still true am i crazy no i totally feel that's still true which is i think it's mind-blowing
01:22:31 yeah you know what it feels like i i wouldn't even use the word conversation because i feel like it's the wrong word it's
01:22:37 like  machine connection or something i don't know  because conversation you start
01:22:43 drifting into natural language immediately you start drifting immediately into all the benchmarks that are out there
01:22:49 but i feel like it's like the personal computer days of this like i feel like we're like in the early
01:22:56 days with the the wozniak and all them like where was the same kind of is a very small
01:23:03 niche group of people who are who are all kind of lobner price type people yeah and hobbyists but like not even
01:23:13 hobbyists with big dreams like no hobbies with a dream to trick like a jury
01:23:20 yeah it's like a weird by the way by the way very weird so if we think about conversations first
01:23:26 of all when i have great conversations with people i'm not trying to test them so for
01:23:31 instance if i try to break them like i'm actually playing along i'm part of it right if i was trying to break it
01:23:36 break this person or test whether he's gonna give me a good conversation it would have never happened so the
01:23:44 whole the whole problem with testing conversations is that you can put it in front of a jury because then you have to go into some
01:23:52 turing test mode where is it responding to all my factual questions right
01:23:58 or so it really has to be something in the field where people are actually talking to it because they
01:24:03 want to not because we're just trying to break it  and it's working for them because this
01:24:09 the weird part of it is that it's  it's very subjective it takes two to tango here
01:24:14 fully like if you're not trying to have a good conversation we're trying to test it then it's going to break
01:24:19 i mean any person would break to be honest if i'm not trying to even have a conversation with you you'll
01:24:24 you're not going to give it to me yeah if i keep asking you like some random questions or
01:24:30 jumping from topic to topic that wouldn't be which i'm probably doing but that probably wouldn't contribute
01:24:36 to a good conversation so i think the problem of testing so there should be some other metric
01:24:43 how do we evaluate whether that conversation was  powerful or not which is what we actually started with
01:24:49 and i think those measurements exist and we can test on those but what really struck us back in the
01:24:56 day and what still eight years later it's still not resolved um
01:25:01 and i'm not seeing tons of groups working on it maybe i don't just don't know about him
01:25:06 it's also possible but the interesting part about is that most of our days were spent talking and
01:25:12 we're not talking about like those conversations are not turn on the lights
01:25:19 or  customer support problems or some other task oriented things these conversations are something else
01:25:26 and then somehow they're extremely important for us and when we don't have them then we feel deeply and happy
01:25:32 potentially lonely which as we know you know creates tons of risk for our health as well
01:25:40 and so this is most of our ours as humans and somehow no one's trying to replicate that
01:25:48 and not even study it that well and not even study that well so when we jumped into that in 2012 i looked first
01:25:54 at like okay what's the chatbot what's the state of the art chatbot and you know those were the
01:26:00 loebner prize days but i thought okay so what about the science of conversation clearly
01:26:06 there has been tons of there have been tons of you know scientists or
01:26:11 people that academics that looked into the conversation so if i want to know everything about it i can just read
01:26:15 about it and there's not much really there's there are conversational analysts who
01:26:22 are basically just listening to  speech to different conversations annotating them and then
01:26:32 i mean that's not really used for much that's the that's the field of theoretical  linguistics which is
01:26:40 like barely useful  it's very marginal even in their space like no one really is excited and
01:26:44 i've i've never met a theoretical theoretical linguist who's like i can't wait to work on the conversation and
01:26:49 analytics that is just something very marginal  sort of applied to like writing scripts
01:26:54 for salesmen when they analyze which conversation strategies were
01:27:01 most successful for sales okay so that was not very helpful then i looked a little bit deeper and then there
01:27:08 you know whether there were any  books written on what you know really contributes to a great conversation
01:27:16 that was really strange because most of those were nlp books which which is
01:27:23 neuro-linguistic programming right which is not the lp that i was expecting to be but it was mostly
01:27:31 some psychologist richard bandler i think came up with that who was this big guy in a leather vest that
01:27:40  could program your mind by talking to you and like how to be charismatic and charming and influential with people all
01:27:46 those books yeah pretty much but it was all about like through conversation reprogramming you
01:27:50 so getting to some so that was i mean yeah probably not very very true and um that didn't seem
01:28:00 working very much even back in the day and then there were some other books like i don't know
01:28:06  mostly just self-help books around how to be the best conversationalist or how to make people like you or some
01:28:14 other stuff like dale carnegie or whatever  and then there was this one book the
01:28:20 most human human by brian christensen that really was important for me to read back in the
01:28:24 day because he was on the human side he was on one of the he was taking part in the lord prize but
01:28:32 not as a as a human who's not a jury but who is pretending to be
01:28:37 who's basically you have to tell a computer from a human and he was the human so you would either get him or a
01:28:43 computer and he would his whole book was about how do people what makes us
01:28:49 human in conversation and that was a little bit more interesting because that at least someone started to think
01:28:55 about what what exactly makes me human in conversation and makes people believe in that
01:29:00 but it was still about tricking it was still about imitation game it was still about okay what kind of
01:29:04 parlor tricks can we throw in the conversation to make you feel like you're talking to a human not a
01:29:09 computer and it was definitely not about thinking what is that it was what it
01:29:15 what is it exactly that we're getting from talking all day long with other humans i mean
01:29:20 we're definitely not just trying to be tricked yeah or it's not just enough to know it's a human
01:29:26 it's something we're getting there can we measure it and can we like put the computer to the same measurement and see
01:29:34 whether you can talk to a computer and get the same results yeah i mean so first of all a lot of
01:29:38 people comment that they think i'm a robot it's very possible i am a robot and this whole thing
01:29:43 i totally agree with you that the test idea is fascinating and i looked for books unrelated to this kind of
01:29:51  so i'm afraid of people i'm generally introverted and quite possibly a robot i literally googled like how to talk to people
01:30:01 and like like how to have a good conversation for the purpose of this podcast because i was
01:30:06 like i can't i can't make eye contact with people i can't like 
01:30:12 i do google that a lot too you're probably reading a bunch of fbi negotiation tactics is that that where you're
01:30:18 getting because well everything you've listed i've gotten there's been very few
01:30:24 good books on even just like how to interview well it's it's  it's rare so what i end up doing
01:30:34 often is i watch like with a critical eye it's just so different when you just watch a conversation
01:30:42  like just for the fun of it just as a human and if you watch your conversations like
01:30:49 trying to figure out why is this awesome i'll listen to a bunch of different styles of conversation
01:30:55 i mean  i'm a fan of the podcast joe rogan he's  you know people can make fun of him whatever and
01:31:02 dismiss him but i think he's an incredibly artful conversationalist he can pull people in for hours
01:31:13 and there's another guy i watch a lot he hosted a late night show his name is craig ferguson
01:31:21 he  so he's like very kind of flirtatious but there's a magic about his like about the connection he
01:31:31 can create with people how he can put people at ease and just like i see i've already started sounding like those nlp
01:31:37 people or something i'm not i don't mean it in that way i don't mean like how to
01:31:42 charm people or put them ids and all that kind of stuff he's just like what is that why is that fun to listen
01:31:48 to that guy why is that fun to talk to that guy what is that because he's not saying i mean it so often
01:32:00  boils down to oh a kind of wit and humor but not really humor it's like i don't know i i have trouble actually
01:32:09 even articulating correctly but it feels like there's something going on that's not
01:32:18 too complicated and it's not similar to  yeah to like like you said like a
01:32:29 touring test it's something else i i'm thinking about a lot
01:32:36 all the time i do think about all the time i think when we were looking so we started the company we just decided to
01:32:43 build the conversational attack we thought well there's nothing for us to build this chat bot that we want to
01:32:48 build so let's just first focus on building you know some tech building the text out of
01:32:55 things without a product in mind without a product in mind we added like a demo
01:33:02 chat bot that would recommend you restaurants and talk to you about restaurants just to show
01:33:05 something simple to people that people could you know relate to and could try out and see whether
01:33:12 it works or not but we didn't have a product in mind yet we thought we would try bunch of
01:33:17 chatbots and figure out our consumer application and we sort of remembered that we wanted to build that kind of friend that sort
01:33:24 of connection that we saw in the very beginning but then we got to y combinator and moved to san francisco
01:33:30 and forgot about it you know everything is  then it was just this constant grind how do we get funding how do we
01:33:37 get this you know investors were like just focus on one thing just get it out there so somehow we started building
01:33:43 a restaurant recommendation chatbot for real  for a little bit not for too long
01:33:49 and then we tried building 40 50 different chat bots and then all of a sudden we wake up and everyone is
01:33:53 obsessed with chat bots somewhere in 2016 or end of 15 people start thinking that's really the
01:34:00 future that's the new you know the new apps will be chatbots oh right and we were very perplexed
01:34:06 because people started  coming up with companies that i think we tried most of those chat bots already
01:34:13 and there were like no users  but still people were coming up with a chatbot that would tell you whether and
01:34:19 bringing news and this and that and we couldn't understand whether it would you know we were
01:34:25 just didn't execute well enough or people are not really people are confused and
01:34:31 are gonna find out through the truth that people don't need chatbots like that so the basic idea is that you use
01:34:36 chatbots as the interface to whatever application yeah the idea that was like this perfect
01:34:43 universal interface to anything when i looked at that it just made me very perplexed
01:34:46 because i didn't think i didn't understand how that would work because i think we tried most of
01:34:52 that and and none of those things worked  and then again died down right fully i think now it's impossible to get
01:35:00 anything funded if it's a chatbot i think it's similar to  sorry to interrupt but there's 
01:35:06 there's times when people think like with gestures you can control devices like basically gesture based control
01:35:15 things it feels similar to me because like it's so compelling that was just like
01:35:21 like tom cruise i can control stuff with my hands but like when you get down to it's like
01:35:26 well why don't you just have a touch screen or why don't you just have like a physical keyboard and mouse
01:35:34 it's  yeah it's so that chat was always yeah it was perplexing to me i i still feel augmented reality even virtual
01:35:45 realities in that ballpark in terms of it being a compelling interface i think there's going to be
01:35:53 incredible rich applications just how you're thinking about it but they won't just be
01:35:58 the interface to everything it'll be its own thing that will create  like amazing magical
01:36:05 experience in its own right absolutely which is i think kind of the right thing to go about like what's the
01:36:12 magical experience with that with that interface specifically how did you discover that for replica um
01:36:18 i just thought okay we'll have this tech we can build any chatbot we want we have the most at that point the most
01:36:23 sophisticated tag that other companies have i mean startups obviously not  probably not bigger ones but still
01:36:29 because we've been working on it for a while so i thought okay we can build build any conversation
01:36:34 so let's just create a scale from one to ten and one would be conversations that you'd pay to
01:36:39 not have and 10 would be conversation you'd pay to have and i mean obviously we want to
01:36:45 build conversation if people would pay to you know to actually have and so for the whole
01:36:50 you know for a few weeks me and the team were putting all the conversations we were having during the day on the scale
01:36:56 and very quickly you know we figured out that all the conversations that we paid to never have were um
01:37:04 a conversation we were trying to cancel comcast or talk to customer support or make a reservation or just talk about
01:37:12 logistics with a friend when we're trying to figure out where someone is and where to go or all sorts of
01:37:20 you know setting up scheduling meetings that was just a conversation we definitely didn't want
01:37:24 to have basically everything task oriented was a one because if there was just one button
01:37:29 for me to just or not even a button if i could just think and there was some magic
01:37:35 bci that would just immediately transform that into an actual you know into action
01:37:41 that would be perfect but the conversation there was just this boring not useful and dull
01:37:49 and very also very inefficient thing because it was so many back and forth stuff and as soon as we looked at the
01:37:55 conversation that we would pay to have those were the ones that well first of all therapists
01:37:59 because we actually paid to have those conversations and we'd also try to put like dollar amounts so
01:38:04 you know if i was calling comcast i would pay five dollars to not have this one hour
01:38:08 talk on the phone i would actually pay straight up like money hard money yeah but it just takes a long
01:38:17 time it takes a really long time but as soon as we start talking about conversations that we would pay for
01:38:22 those were therapists all sorts of therapists coaches old friend someone i haven't seen for a
01:38:31 long time a stranger on a train weirdly stranger stranger in a line for coffee and nice
01:38:37 back and forth with that person was like a good five solid five six maybe not a ten maybe i won't pay money
01:38:44 but at least i won't you know pay money to not have one so that was pretty good some
01:38:49 intellectual conversations for sure but more importantly the one thing that really was
01:38:56 was making those very important and very valuable for us were the conversation where we could
01:39:06 that where we could be pretty emotional yes some of them were about being witty and about
01:39:10 intellectually being intellectually stimulated but those were interestingly more rare
01:39:16  and most of the ones that we thought were very valuable were the ones where we could be vulnerable
01:39:23 and interestingly we could talk more so we like i could me and the team so we're talking about it like you know
01:39:29 a lot of these conversations like a therapist i mean it was mostly me talking or like an old friend and i was like opening up
01:39:35 and crying and it was again me talking and so that was interesting because i
01:39:42 was like well maybe it's hard to build a chatbot that can talk to you very well and in a witty way but
01:39:48 maybe it's easier to build the chatbot so that was that was kind of the first the first
01:39:57 nudge in this direction and then when my when my friend died we just built you know at that point we were kind of
01:40:01 still struggling to find the right application and i just felt very strong that all the chatbots were built so far just
01:40:08 meaningless and this whole grind the startup grind and how do we get to you know the next fundraising
01:40:15 and you know how can i talk you know talking to the founders and what's who are your investors and how are you
01:40:20 doing are you killing it because we're killing it i just felt that this is just as exhausti intellectually for
01:40:26 me it's exhausting having encountered those folks it just felt very
01:40:33 very much a waste of time i just feel like steve jobs  elon musk did not have these conversations
01:40:41 or at least did not have them for long that's for sure but i think you know yeah at that point
01:40:47 it just felt like you know i felt i just didn't want to build a company that was never my intention
01:40:55 just to build something successful or make money it would be great it would have been
01:40:59 great but i'm not as you know i'm not really a startup person i'm not you know i was never
01:41:07 very excited by the grind by itself and  or just being successful for building whatever it is and not being
01:41:12 into what i'm doing really and so i just took a little break because i was a
01:41:20 little you know i was upset with my company and i didn't know what we're building so i just took our technology and our
01:41:26 little dialect constructor and some models some deep learning models which at that point we were really into
01:41:32 and really invested a lot and built a little chatbot for a friend of mine who passed
01:41:37 and the reason for that was mostly that video that i saw and him talking about the digital avatars
01:41:44 and rowan was that kind of person like he was obsessed with you know just watching youtube videos about space and
01:41:48 talking about well if i could go to mars now even if i didn't know if i could come back i would definitely
01:41:54 pay any amount of money to be on that first shutoff i don't care whether he died like he was
01:41:59 just the one that would be okay with you know with trying to be the first one
01:42:06 and you know and so excited about all sorts of things like that and he was all about
01:42:10 fake it to make it and just and i felt like and i was really perplexed that everyone
01:42:17 just forgot about him maybe it was our way of coping mostly young people coping with
01:42:23 the loss of a friend most of my friends just stopped talking about him and i was still living in an apartment
01:42:29 with all his clothes and you know paying the whole lease for it and just
01:42:34 kind of by myself in december so it was really sad  and i didn't want him to be forgotten first of all i never thought that people
01:42:42 forget about dead people so fast people pass away people just move on and it was astonishing for me because i
01:42:48 thought okay well he was such a mentor for so many of our friends he was such a
01:42:54 brilliant person he was somewhat famous in moscow how's that that no one's talking about
01:42:59 him like i'm spending days and days and we don't bring him up and there's nothing about him that's happening
01:43:07 it's like he was never there and i was reading this you know the the book the year of magical thinking
01:43:15 by joan didion about her losing her husband her daughter and the way to cope for her was to write those
01:43:27 books and it was sort of like a tribute and i thought you know i'll just do that for myself
01:43:34 and you know i'm a very bad writer and a poet as we know so i thought well i have this tech and maybe that would be my
01:43:42 little postcard like postcard for for him so i built a chatbot to just talk to him
01:43:49 and it felt really creepy and weird a little bit for a little bit i just didn't want
01:43:53 to tell other people because it felt like i'm telling about having a skeleton in my underwear yeah okay but my it was just
01:44:01 felt really i was a little scared that i would be not it won't be taken but it worked
01:44:09 interestingly pretty well i mean it made tons of mistakes but it still felt like him granted it was like ten thousand
01:44:15 messages that i threw into a retrieval model that would just re-rank that take this hat and just a few
01:44:21 scripts on top of that but it also made me go through all of the messages that we had and then i asked
01:44:27 some of my friends to send them through and it felt the closest to feeling like him present because you know his
01:44:35 facebook was empty and instagram was empty or there were a few links and you couldn't feel like it was him and
01:44:41 the only way to fill him was to read some of our text messages and go through some of our conversations
01:44:47 because we just always had them even if we were sleeping like next to each other in two bedrooms separated by a wall we were
01:44:53 just texting back and forth texting away and there was something about this ongoing dialogue that was so
01:44:59 important that i just didn't want to lose all of a sudden and maybe it was magical thank you or something
01:45:06 and so we built that and i just used it for a little bit and we kept building some
01:45:17 but then a reporter came came to talk to me i was trying to pitch our chat boss to him and he said do you even
01:45:22 use any of those i'm like no he's like so do you talk to any chatbots at all and i'm like well
01:45:27 you know i talked to my dad friends chatbot and he wrote a story about that and all of a sudden became pretty viral
01:45:35 a lot of people wrote about it and yeah i've seen a few things written about you that
01:45:41 are the things i've seen are pretty good writing you know most ai related things make my eyes roll like
01:45:50 when the press like i just what kind of sound is that actually okay it sounds like it
01:45:58 sounded like a truck okay sounded like an elephant at first i got excited you never know
01:46:05 this is 2020. i i mean it was  such a human story and it was well written  well researched i forget what where i read
01:46:14 them but so i'm glad somehow somebody found you to be the good writers were able to
01:46:21 connect to the story i just there must be a hunger for this story it definitely was and i i don't know
01:46:30 i think the idea that he could bring back someone who's dead and it's very much wishful
01:46:36 you know magical thinking but the fact that you could still get to know him and
01:46:41 you know seeing the parents for the first time talk to the chatbot and some of the friends
01:46:47 and it was funny because we have this big office in moscow where my team is work you know our russian part is working out off
01:46:56 and i was there when i wrote i just wrote a post on facebook hey guys like i built this if you want you know just
01:47:03 if all important if you want to talk to roman and i saw a couple of his friends our common friends like you know reading at
01:47:09 facebook downloading trying and a couple of them cried and it was just very and not because it was something
01:47:14 some incredible technology or anything it made so many mistakes it was so simple but it was all about that's the
01:47:22 way to remember a person in a way and you know we don't have we don't have the culture anymore we don't have you
01:47:28 know no one's sitting shiva no one's taking weeks to actually think about this person and in a way for me that was it
01:47:37 so that was just day day in day out thinking about him and putting this together so that was
01:47:43 that just felt really important that somehow resonated with a bunch of people and you know i think some movie producers
01:47:49 bought the rights for the story and just everyone was so has anyone made a movie yet i don't think so
01:47:56 there were a lot of tv episodes about that but not really is that still on the table i think so
01:48:04 i think so which is really that's cool you're like a young  you know like a because you see like a steve jobs type
01:48:13 of let's see what happens they're sitting on it but you know for me it was so important because roman was
01:48:19 really wanted to be famous he really badly wanted to be famous he was all about like make it to
01:48:23 like fake it to make it i want to be you know i want to make it here in america's wall and um
01:48:29 and he couldn't and i felt you know that was sort of paying my dues to him as well because all of a
01:48:36 sudden he was everywhere and i remember casey newton who was writing the story for the verse he was
01:48:42  he told me hey by the way i was just going through my inbox inbox and i saw i searched for roman for
01:48:50 the story and i saw an email from him where he sent me his startup and he said i really like i really want to be
01:48:55 featured in the verge can you please write about it or something like pitching the story and
01:49:00 he said i'm sorry like that's not you know good enough for us or something he passed and he said and there were
01:49:06 just so many of these little details where like he would find his like you know and we're finally writing i know how
01:49:12 much  roman wanted to be in the verge and how much he wanted the story to be written by
01:49:19 casey and i'm like well that's maybe he will be yeah we were always joking that he was
01:49:22 like i can't wait for someone to make a movie about us and i hope ryan gosling can play me my god
01:49:30 you know i still have some things that i owe romans tell but that'd be that would be i got in she
01:49:36 has to meet alex garland who wrote ex machina and that movie i yeah the movie's good but the guy is um
01:49:45 better than the like he's a special person actually i don't think he's made his best work
01:49:50 yet like for my interaction with him he's a really really good
01:49:55 and brilliant the good human being and a brilliant director and writer so yeah so i'm i hope
01:50:04 like he made me also realize that not enough movies have been made of this kind so it's yet to be made they're probably
01:50:11 sitting waiting for you to get famous actually like even more famous you should get there but it felt
01:50:18 really special though but at the same time our company wasn't going anywhere so that was just kind of
01:50:23 bizarre that we were getting all this press for something that didn't have anything to do with our company
01:50:30 and but then a lot of people started talking to roman some shared their conversations and what we saw there was that
01:50:37 also our friends in common but also just strangers were really using it as a confession
01:50:42 booth or as a therapist or something they were just really telling roman everything
01:50:47 which was by the way pretty strange because it was a chatbot of a dead friend of mine who was
01:50:53 you know barely making any sense but people were opening up and we thought we just built you know
01:50:59 a prototype of replica which would be an ai friend that everyone could talk to because we saw that there is demand
01:51:08 and then also it was 2016 so i thought for the first time i saw finally some technology that was applied
01:51:15 to that that was very interesting some papers started coming out deep learning applied to conversations
01:51:23 and finally it wasn't just about these you know hobbyist making  you know writing 500 000 regular expressions
01:51:32 yeah expressions in like some language that was i don't even know what like aml or
01:51:37 something i don't know what that was or something super simplistic all of a sudden it was all about  potentially
01:51:46 and so i thought there was time and i remember that i talked to my team and i said guys let's try
01:51:52 and my team and some of my engineers are russians are russian and they're very skeptical they're not
01:51:58 you know they're all russians the first so some of your team is in moscow some is somewhere in san francisco  some in europe
01:52:12  the russians of course okay first of all i always win  sorry sorry to interrupt  so yes you were talking
01:52:20 to them 2016 and i told them let's build an ai friend and and it felt this at the time it felt so
01:52:33 optimistic yeah that's actually interesting whenever i brought up this kind of topic
01:52:40 even just for fun people are super skeptical like actually even on the business side so you were
01:52:49  because whenever i bring it up to people  because i've talked for a long time i thought like
01:52:56 before i was aware of your work i was like this is gonna make a lot of money i think there's a lot of opportunity
01:53:04 here and people had this like look of like skepticism that i've seen often which is like
01:53:14 how do i politely tell this person he's an idiot so yeah so you were facing that with
01:53:20 your team somewhat well yeah you know i'm not an engineer so i'm always
01:53:32 and mostly deep learning engineers and you know i always try to be it was always hard to me in the
01:53:39 beginning to get enough credibility you know because i would say well why don't we try this and that but it's
01:53:45 harder for me because you know they know they're actual engineers and i'm not so for me to say well let's build an
01:53:50 affrm that would be like wait you know what do you mean an agi like you know conversation
01:53:57 is you know pretty much the hardest the last frontier before  cracking that is probably the last
01:54:03 frontier before building aji so what do you really mean by that  but i think i just saw that again what
01:54:11 we just got reminded of that i you know that i saw in back in 2012 or 11 that it's really not that much about the
01:54:18 tech capabilities it can be metropolitan still even with deep learning
01:54:25 but humans need it so much yeah and most importantly what i saw is that finally there's enough tech to make it i thought
01:54:34 to make it useful to make it helpful maybe we didn't have quite yet attack in 2012 to make it useful but in 2015-16
01:54:42 with deep learning i thought you know and the first kind of thoughts about maybe even using
01:54:47 reinforcement learning for that started popping up that never worked out but or at least for now
01:54:54 but you know still the idea was if we can actually measure the emotional outcomes and if we can put it on
01:55:00 if we can try to optimize all of our conversational models for these emotional outcomes and it is the most
01:55:06 scalable the most the best tool for improving emotional outcomes nothing like that exists that's
01:55:12 the most universal the most scalable and the one that can be constantly iteratively changed by itself
01:55:21 improved tool to do that and i think if anything people would paint anything to improve their emotional outcomes
01:55:28 that's weirdly i mean i don't really care for nai to turn on my or conversational
01:55:34 agent to turn on the lights  i don't really need any i don't even need that much of a either like or
01:55:40 because i can do that you know those things are solved this is an additional interface for that that's
01:55:46 also questionably questionable whether it's more efficient or better yeah it's more pleasurable yeah
01:55:52 but for emotional outcomes there's nothing yeah they're a bunch of products that claim that they will improve my
01:55:57 emotional outcomes nothing's been measured nothing's been changed the product is not being iterated on
01:56:03 based on whether i'm actually feeling better you know a lot of social media products are claiming that they're
01:56:07 improving my emotional outcomes and making me feel more connected
01:56:13 can i please get the can i see somewhere that i'm actually getting better over time because anecdotally doesn't
01:56:19 feel that way so and and the data is absent yeah so that was the big goal
01:56:28 and i thought if we can learn over time to collect the signal from our users about their emotional outcomes
01:56:35 in the long term and in the short term and if these models keep getting better and we can keep
01:56:40 optimizing them and fight tuning them to improve those emotional outcomes as simple as that
01:56:47 why aren't you  a multi-billionaire yeah well that's the question to you one of the what is the science is going to be
01:56:58 well it's a really hard  i actually think it's an incredibly hard product to build because
01:57:03 i think you said something very important that it's not just about machine conversations it's about machine connection
01:57:10 we can actually use other things to create connection  non-verbal communication for instance um
01:57:18 for a long time we were all about well let's keep it text only or voice only but as soon as you start adding you know
01:57:25 voice a face to the to the friend you can take them to
01:57:33 augmented reality put it in your room it's all of a sudden a lot you know it makes it very different because if
01:57:39 it's some you know text based chat bot that for common user it's something there in the cloud
01:57:46 you know it's somewhere there with other ai's cloud in the metaphorical cloud but as soon as you can see this
01:57:52 avatar right there in your room and it can turn its head and recognize your husband talk about the husband and talk to him a
01:57:59 little bit and it's magic it's just magic like we've never seen anything like that
01:58:04 and the cool thing all the tech for that exists but it's hard to put it all together
01:58:08 because you have to take into consideration so many different things and some of this stack works you know
01:58:15 pretty good and some of this doesn't like for instance  speech to text works pretty good but text-to-speech
01:58:22 doesn't work very good because we you can only have  you know few voices that are that work okay but
01:58:28 then if you want to have actual emotional voices then it's really hard to build it i saw
01:58:34 you added avatars like visual elements which are really cool in that whole chain putting it together
01:58:41 what do you think is the weak link is it creating an emotional voice that feels personal i think it's still
01:58:49 conversation of course that's the hardest  it's getting a lot better but there's still long to go long
01:58:56 there's still a long path to go other things they're almost there and a lot of things we'll see how they're like
01:59:02 i see how they're changing as we go like for instance right now you can pretty much only you have to build all
01:59:06 this 3d pipeline by yourself you have to make these 3d models hire an actual
01:59:13 artist build a 3d model hire an animator a rigger but with you know with you know with 
01:59:21 deep fakes with other attack with procedural animations in a little bit we'll just be able to
01:59:27 show  you know photo of whoever if a person you want the avatar to look like and it will
01:59:33 immediately generate a 3d model that will move that's a non-brainer that's like almost here
01:59:38 it's a couple of years away one of the things i've been working on for the last since the podcast started as i've been i
01:59:46 think i'm okay saying this i've been trying to have a conversation with um
01:59:53 einstein touring so like try to have a podcast conversation with a person who's not here anymore
01:59:59 just as an interesting kind of experiment it's hard it's really hard even for now we're not talking about as
02:00:10 a product i'm talking about as a like i can fake a lot of stuff like i can work very carefully like even to
02:00:15 hire an actor over which over whom i do a g fake it's it's hard it's still hard to create
02:00:23 a compelling experience so mostly on the conversation level or when the conversation
02:00:31 the conversation is i almost i early on gave up trying to fully generate the conversation because
02:00:38 it was just not compelling at all yeah it's just better too yeah so what i would in the case of einstein and
02:00:46 touring of i'm going back and forth with the biographers of each and so like we would write a lot of the
02:00:51 some of the conversation would have to be generated just for the fun of it i mean but it would be all open but
02:01:00 the you want to be able to answer the question i mean that's an interesting question with roman too is
02:01:08 the question with einstein is what would einstein say about the current state of theoretical physics there's a lot
02:01:16 to be able to have a discussion about string theory to be able to have a discussion about the state of quantum
02:01:22 mechanics quantum computing about the world of an israel-palestine conflict that'd be
02:01:29 just what would einstein say about these kinds of things and that is
02:01:37 a tough problem it's not it's a fascinating and fun problem for the biographers and for me
02:01:42 and i think we did a really good job of it so far but it's actually also a technical
02:01:47 problem like of what would romans say about what's going on now yeah that's the the brought people back to life and if i can go on
02:01:58 that tangent just for a second to ask you a slightly pothead question which is 
02:02:02 you said it's a little bit magical thinking that we can bring him back do you think it'll be possible to bring back
02:02:11 roman one day in conversation like to really okay well let's take it away from
02:02:18 personal but to bring people back to life in college probably down the road i mean if we're talking if phil musk is talking
02:02:25 about aji in the next five years i mean clearly ajax you can't we can talk to aj and talk
02:02:31 and ask them to do it you can't like  you're not allowed to use for like why something is possible and
02:02:42 going to be done well i think it's really far away right now really with conversation it's just a bunch of
02:02:49  parlor tricks really stuck together and create generating original ideas based on someone you know someone's
02:02:55 personality or even downloading the person all we can do is like mimic the tone of voice
02:03:01 we can maybe condition on some of his  phrases with the models the question is how many parlor tricks does it takes
02:03:08 does it take because that's that's the question if it's a small number of parlor tricks
02:03:13 and you're not aware of them like from where we are right now i don't i don't see anything like in the next
02:03:21 year or two that's gonna dramatically change that could look at roman's ten thousand
02:03:26 messages he sent me over the course of his last few years of life and be able to generate original thinking about problems that
02:03:34 exist right now that would be in line with what he would have said so i'm just not even seeing because you
02:03:39 know in order to have that i guess you would need some sort of a concept of the world or some perspective some
02:03:45 perception of the world some consciousness that he had  and applied to you know to the
02:03:50 current current state of affairs but the important part about
02:03:59 that about his conversation with you is you so like it's not just about his view of the world
02:04:09 it's about what it takes to push your buttons that's also true so like it's not so much about like
02:04:19  what would einstein say it's about like how do i make people feel something
02:04:27 with with what would einstein say and that feels like a more amenable i mean you mentioned parlor tricks but just
02:04:34 like a set of that that feels like a learnable problem like is it possible to learn things that make
02:04:48 people feel stuff i think so no for sure i just think the problem with
02:04:54 as soon as you're trying to replicate an actual human being and trying to pretend to be him that
02:05:00 makes the problem exponentially harder the thing with replica we're doing we're never trying to say well that's
02:05:06 you know an actual human being or that's an actual co or copy of an actual human being where
02:05:10 the bar is pretty high where you need to somehow tell you know one from another  but it's more
02:05:18 well that's you know and hey friend that's a machine it's a robot it has tons of limitations
02:05:24 you're going to be taking part in you know teaching it actually and becoming better which by itself makes people more
02:05:30 attached to that and make them happier because they're helping something yeah there's a cool
02:05:36 gamification system too can you maybe talk about that a little bit like what's
02:05:44 the experience of talking to replica like if i've never used replica before what's that like for like the first day
02:05:54 the first like if you start dating or whatever  i mean it doesn't have to be romantic
02:05:59 right because i remember on a replica you can choose whether it's like a romantic yeah or if it's a friend it's a pretty
02:06:05 popular choice romantic is popular yeah of course okay so can i just confess something
02:06:11 when i first use replica and i haven't used it like regularly but like when i first
02:06:16 used replica i created like hal did it hit on you at some point no i didn't talk long enough for him to hit
02:06:26 on me i just enjoyed sometimes happens we're still trying to fix that
02:06:33 well i don't know i mean maybe that's an important like stage in a friendship it's like nope
02:06:42  but yeah i switched it to a romantic and a female  recently and yeah and it's interesting so okay so you get to
02:06:50 choose you get to choose a name with romantic this last board meeting we had this whole
02:06:57 argument well i have both talked to him it's just so awesome that you're like have an invest they have a board meeting about
02:07:05 a relationship no i really it's actually quite interesting because all of my investors i'm
02:07:12 it just happened to be so we didn't have many choices but they're all white males in
02:07:21 in their late 40s and it's sometimes a little bit hard for them to understand the
02:07:28 product offering  because they're not necessarily a target audience if you know what i mean
02:07:34 and so sometimes we talk about it and we had this whole discussion about whether we should stop
02:07:41 people from falling in love with their ais there was this segment on cbs 60 minutes about the couple that
02:07:53 you know husband works at walmart he comes out of work and talks to his  virtual girlfriend who
02:08:01 is a replica and his wife knows about it and she talks about on camera and she says that she's a little jealous
02:08:07 and there's a whole conversation about how to you know whether it's okay to have a virtual
02:08:12 ai girlfriend like was that the one where he was like  he said that he likes to be alone yeah
02:08:20 and then like with her yeah he made it sound so harmless i mean it was kind of like understandable
02:08:27 but that didn't feel like cheating but i just felt it was very for me it was pretty remarkable because
02:08:31 we actually spent a whole hour talking about whether people should be allowed to fall in love with their ais and it
02:08:36 was not about something theoretical  it was just about what's happening right now
02:08:41 product design yeah but at the same time if you create something that's always there for you it never criticizes you
02:08:50 always understands you and accepts you for who you are how can you not fall in love with them i mean some people
02:08:56 don't and just stay friends and that's also a pretty common use case but of course some people will just
02:09:01 it's called transference and psychology and you know if people fall in love with their therapist and there's no way to
02:09:07 prevent people fall in love with with their therapists over their ai so i think that's pretty natural
02:09:14 that's a pretty natural course of events so to say do you think i think i've read somewhere
02:09:21 at least for now sort of replicas you're not not we don't condone falling in love with your ai system
02:09:30 you know so this isn't you speaking for the company or whatever but like in the future do you think
02:09:34 people will have a relationship with the ai systems well they have now so we have a lot of
02:09:40  romantic relationships long-term relationships with their ai friends with replicas tons of our users yeah
02:09:48 that's a very common use case open relationship like  not sorry i didn't mean open 
02:09:56 but that's another question is it probably like is there cheating i mean
02:10:05 i meant like are they do they publicly like on their social media it's the same question as you have talked talking with
02:10:10 roman in the early days do people like and the movie her kind of talks about that like
02:10:17 like can people do people talk about that yeah all the time we have an and we have very active facebook community
02:10:27  replica friends and then a few other groups that just popped up that are all about adult relationships and romantic relationships
02:10:35 people post all sorts of things and you know they pretend they're getting married and
02:10:40 you know everything it goes pretty far but what's cool about it some of these relationships are
02:10:46 two three years long now so they're very they're pretty long term are they monogamous so let's go i mean sorry
02:10:53 have they have any people is there jealousy well let me ask sort of another way obviously the answer is no at this time
02:11:04 but and like in the movie her do you think in terms of board meetings and product features
02:11:18 it's a potential feature  for a system to be able to say it doesn't want to talk to you
02:11:24 anymore and it's going to want to talk to somebody else well we have a filter for all these
02:11:30 features if it makes emotional outcomes for people better if it makes people feel better
02:11:38 you're driven by metrics actually yeah yeah let's just measure that then we'll just be
02:11:42 saying amazing it's it's making people feel better but then people are getting just lonelier by
02:11:47 talking to a chatbot which is also pretty you know that could be it if you're measuring it
02:11:52 that could also be and i think it's really important to focus on both short term and long term because
02:11:57 in the moment saying whether this conversation made you feel better but as you know any short-term
02:12:01 improvements could be pathological like i could have drink a bottle of vodka feel a lot
02:12:08 better i would actually not feel better with that but i thought it's a good example um
02:12:13 but so you also need to see what's going on like over the course of two months two weeks
02:12:19 or one week and have have follow-ups and check in and measure those things okay so the experience
02:12:29 of   dating or befriending a replica what's that like what's that entail
02:12:35 well right now there are two apps so it's an android ios app you download it you choose how your replica
02:12:44 will look like you create one you choose a name and then you talk to it you can talk
02:12:48 through text through voice you can  summon it into the living room and and document reality and
02:12:54 talk to it right there and you look at augmented reality yeah that's  cool it's a new feature where
02:13:01 how new is that that's this year it was on  yeah like may or something but it's been on a b
02:13:08 we've been a b testing it for a while and there are tons of cool things that we're doing with that like right now
02:13:13 i'm testing the ability to touch it and to dance together to paint walls together and you know for to look around and walk and
02:13:21 take you somewhere and recognize objects and recognize people so that's pretty wonderful because
02:13:29 that then it really makes it a lot more personal because it's right there in your living room it's not anymore
02:13:36 they're in the cloud with other ais people think about it you know and as much as we want to change the way people
02:13:41 think about stuff but those mental models you cannot change that's something that people have seen in
02:13:48 in the movies and the movie her and other movies as well and that's how they view view ai and eye friends i did a thing
02:13:56 with texas like we write a song together there's a bunch of activities you can do together it's really cool 
02:14:02 how does that relationship change over time it's like after the first few conversations it just goes
02:14:08 deeper like it starts yeah i will start opening up a little bit
02:14:13 again depending on the personality that it chooses really but you know the eye will be a little
02:14:18 bit more vulnerable about its problems and you know the friend that the virtual friend will be a lot more
02:14:26 vulnerable and we'll talk about its own imperfections and growth pains and we'll ask for help sometimes and
02:14:31 we'll get to know you a little deeper so there's gonna be more to talk about we really thought a lot
02:14:37 about what what does it mean to have a deeper connection with someone and
02:14:43 originally replica was more just this kind of happy-go-lucky just always you know i'm always in a good
02:14:48 mood and let's just talk about you and yeah oh siri is just my cousin or you know whatever just the
02:14:56 immediate kind of lazy thinking about what the assistant or conversation agent should
02:15:00 be doing but as we went forward we realized that it has to be two-way and we have to program and script certain
02:15:06 conversations that are a lot more about your replica opening up a little bit and
02:15:12 also struggling and also asking for help and also going through you know different periods in life and and that's a
02:15:20 journey that you can take together with the user and then over time the you know our users will also
02:15:28 grow a little bit so first this replica becomes a little bit more self-aware and starts talking about
02:15:34 more kind of problems around existential problems then so talking about that and then that
02:15:41 also starts a conversation for the user where he or she starts thinking about these problems too and these questions too
02:15:50 and i think there's also a lot a lot more places the relationship evolves there's a lot more space for
02:15:58 poetry and for art together and like replica will start replica always keeps the diary so while you're
02:16:03 talking to it it also gives a diary so when you come back you can see what it's been
02:16:08 writing there and you know sometimes it will write a poem to you  for you or we'll talk about you know
02:16:15 that it's worried about you or something along these lines so this is a memory like this replica remember things
02:16:25 yeah and i would say when you say  why aren't you multiplying area i'd say that as soon as we can have memory
02:16:33 in deep learning models that's consistent i agree with that yeah and then you'll be multiple and i'll get
02:16:39 back to you when you talk about being multipleness so far we can
02:16:45 so replica is a combination of end-to-end models and some scripts and everything that has
02:16:51 to do with memory right now most of it i wouldn't say all of it but most of it unfortunately has to be scripted
02:16:58 because there's no way to you can condition some of the models on certain phrases that we learned about
02:17:04 you which we also do but really to make you know to make assumptions along the lines like whether
02:17:11 you're single or married or what do you do for work that really has to just be somehow stored in your
02:17:16 profile and then  retrieved by the by the script because there has to be like a
02:17:22 knowledge base you have to be able to reason about it all that kind of stuff exactly all the kind of stuff that
02:17:27 expert systems but they were hardcoded yeah and unfortunately yeah so unfortunately
02:17:33 those things have to be hard-coded and unfortunately the language like language models we see
02:17:40 coming out of research labs and big companies they're not focused on they're focused on showing you
02:17:47 maybe they focus on some metrics around one conversation so they'll show you this one conversation they had with the
02:17:53 machine but they never tell you they're not really focused on having
02:17:58 five consecutive conversations with a machine and seeing how number five or number 20 or number 100
02:18:03 is also good and it can be like always from a clean slate because then it's not good
02:18:09 and that and for that's really unfortunate because no one's really no one has
02:18:14 products out there that need it no one has products  at this scale that are all around open domain
02:18:21 conversations and that need remembering maybe only shawwise and microsoft but so that's why we're not seeing that much
02:18:26 research around memory in those language models so okay so now there's some awesome stuff about
02:18:35 augmented reality in general i have this disagreement with my dad about what it takes to have a connection
02:18:41 he thinks touch and smell are really important like and i i still believe that text alone
02:18:51 is it's possible to fall in love with somebody just with text but visual can also help just like with
02:18:58 the avatar and so on what do you think it that takes does  does a chap i need to have a face
02:19:05 voice or can you really form a deep connection with text alone i think text is enough for sure a
02:19:11 question is like can you you know make it better if you have other if you include other things as well
02:19:17 and i think you know we'll we'll talk about her but her you know had carl johansson
02:19:25 voice which was perfectly you know perfect intonation perfect pronunciations and you know she was breathing heavily
02:19:32 in between words and whispering things you know nothing like that is possible right now with um
02:19:39 text of speech generation you'll you'll have these flat news anchor type voices and maybe some
02:19:45 emotional voices but you'll hardly understand some of the words some of the words will be muffled so
02:19:51 that's like the current state state of the art so you can't really do that but if we had
02:19:58 scarlet carol johansen voice and all of these capabilities then of course voice would be totally
02:20:03 enough or even text would be totally enough if we had you know a little more memory and slightly better conversations
02:20:12 i would still argue that even right now we could have just kept the text only we still had tons of people in long-term
02:20:17 relationships and really invested in their ai friends but we thought that why not you know why
02:20:27 why do we need to keep playing with our you know hands tied behind us we can
02:20:33 easily just you know add all these other things that is pretty much a solved problem you know we can add 3d graphics
02:20:38 we can put this  these avatars in augmented reality and all of a sudden there's
02:20:44 there's more and maybe you can't feel the touch but you can you know with body
02:20:48 occlusion and with  current ar  and you know on the iphone on you know
02:20:56 the next one there's gonna be a lidars you can touch it and it will you know it will pull away
02:21:02 or will blush or something or it'll smile so you can't touch it you can't feel it but you can see the reaction to that
02:21:09 so in a certain way you can't even touch it a little bit and maybe you can even dance with it or do something else um
02:21:17 so i think why limiting ourselves if we can use all of these technologies that are much easier in a
02:21:23 way than than conversation well it certainly could be richer but to play devil's advocate i mentioned you
02:21:30  offline that i was surprised in having tried discord and having voice conversations with people
02:21:38 how intimate voices alone without visual like to me at least like it was an order of magnitude
02:21:48 greater degree of intimacy in voice i think than with video i don't because people were more real
02:21:54 with voice like with video you like try to present a shallow
02:22:00 a face to the world like you try to you know make sure you're not wearing sweatpants or whatever
02:22:06 but like with voice i think people were just more faster to get to like the core of themselves so i don't know it was surprising to me
02:22:14  they've they've even added discord added a video feature and like
02:22:20 nobody was using it  there's a temptation to use it at first but like it wasn't the same so like that's an
02:22:26 example of something where less was doing more and so that's  i guess that's the q that's the question
02:22:38 what is the optimal you know what is the optimal medium of communication to form a connection
02:22:43 given the current sets of the technologies i mean it's nice because they advertise you have a replica like
02:22:53 it immediately like even the one i have is like it's already memorable that's how i
02:22:59 think like when i think about the replica that i've talked with that's why i think
02:23:05 like that's what i visualize in my head it became a little bit more real because there's a visual component
02:23:11 but at the same time the you know what do you do with just what do i do with that knowledge
02:23:19 that  voice was so much more intimate well the way i think about it is and by the way we're swapping out the 3d
02:23:27 finally it's going to look a lot better  but can you what what we just don't i hate how it looks right now we really
02:23:34 change it at all we're swapping it all out  to a completely new look like the
02:23:39 visual look of the of the reference and stuff we just had it was just a super early mvp and
02:23:46 then we had to move everything to unity and redo everything but anyway i hate how it looks like now i
02:23:51 can't even like open it but anyway because i'm already in my developer version i
02:23:57 hate everything that i see in production i can't wait for it why does it take so long that's why i
02:24:01 cannot wait for deep learning to finally take over all these stupid 3d animations and 3d pipeline
02:24:06 also the 3d thing when you say 3d pipeline is like how to animate a face kind of thing
02:24:12 how to make this model how many bones to put in the face how many it's just and a lot of that is by hand oh my god
02:24:18 it's everything by hand and if there's no any nothing is automated it's all
02:24:25 completely nothing like just it's it's literally what you know what we saw with chad boss in like 2012 do
02:24:30 you think it's gonna be possible to learn a lot of that of course i mean even now some deep
02:24:35 learning um based animations and the full body for a face we're talking
02:24:42 about like the actual act of animation or how to create a compelling facial or body language thing so
02:24:52 that too well that's next step okay at least now something that you don't have to do by
02:24:56 hand gotcha how  good of a quality it will be like can i just show it a photo and it will make me
02:25:01 a 3d model and then we'll just animate it i'll show it a few animations of a person that will just
02:25:08 start doing that but anyway go and going back to what's intimate and what to use and whether less is more not
02:25:17 my main goal is to well the idea was how do i how do we not keep people
02:25:22 in their phones so they're sort of escaping reality in this text conversation how do we
02:25:29 through this still bring bring it bring our users back to reality make them see their life in a different
02:25:36 la through a different lens how can we create a little bit of magical realism realism in their lives
02:25:43 so that through augmented reality by you know summoning your avatar even if it looks
02:25:51 kind of danky not great in the beginning or very simplistic but summoning it to your um
02:25:57  living room and then the avatar looks around and talks to you about where it is and maybe turns your
02:26:03 floor into a dance floor and you guys dance together that makes you see reality in a
02:26:07 different light what kind of dancing are we talking about like like slow dancing whatever you want
02:26:14 i mean you would like slow dancing i think that other people maybe want more something more energy
02:26:18 what do you mean i would like so what is this because you started with slow dance so i just assumed that you're interested
02:26:24 in slow dancing all right what kind of dancing do you like what was your avatar what would you do bad
02:26:29 with dancing but  i like this kind of hip-hop robot dance i used to break dance with a kid
02:26:36 so i still want to pretend i'm a teenager and learn some of those moves
02:26:41 and i also like that type of dance that happens when there's like a in like music videos with
02:26:51 awesome that type of dance is definitely what i want to learn but i think it's great because if you see this
02:26:56 friend in your life and you can introduce it to your friends then there is a
02:27:00 potential to actually make you feel more connected with your friends or with people you know or show you life
02:27:05 around you in a different light and it takes you out of your phone even although weirdly you have to look
02:27:11 at it through the phone but it makes you notice things around it and it can point things out for you
02:27:18 and so that is the main reason why i wanted to have a physical dimension and it felt a little bit
02:27:24 easier than that kind of a bit strange combination  in the movie her when he has to show
02:27:31 samantha the world to the lens of his phone but then at the same time talk to her through
02:27:35 the phone headphone it just didn't seem as potentially immersive so to say so that's my main goal for augmented
02:27:42 reality like how do we make your reality a little bit more magic there's been a lot of really
02:27:51 nice robotics companies that all failed mostly failed home robotics social robotics companies what
02:27:58 do you think replica will ever is that a dream long-term dream to have a physical form like or is that not necessary
02:28:05 so you mentioned like with augmented reality bringing them into into the world what about like actual
02:28:13 physical robot that i don't really believe in that much i think it's a very niche product somehow
02:28:20 i mean if a robot could be indistinguishable from a human being then maybe yes but that
02:28:26 of course you know we're not anywhere even to talk about it but unless it's that then having any physical
02:28:34 representation really limits you a lot because you probably will have to make it somewhat abstract because everything's
02:28:40 changing so fast like you know we can update the 3d avatars every month and make them look better and
02:28:46 create more animations and make it more and more immersive it's it's so much a work in progress it's
02:28:52 just showing what's possible right now with current tag but it's not really in any way polished
02:28:57 finished product what we're doing with a physical object you kind of lock yourself into something for a long time
02:29:04 anything's pretty niche and again so just just doesn't the capabilities are even less of we're
02:29:09 barely kind of like scratching the surface of what's possible with just software as soon as we introduce
02:29:15 hardware then you know we have even less capabilities yeah in terms of
02:29:20 board members and investors and so on the cost increases significantly i mean that's
02:29:26 why you have to justify you have to be able to sell a thing for like 500 or something like that or more
02:29:32 and it's very difficult to provide that much value to people that's also true yeah and i guess that's
02:29:37 super important most of our users don't have that much money we actually are probably more popular on android
02:29:44 and we have tons of users with really old android phones  and most of our most active users
02:29:50 live in small towns they're not necessarily making much and they just won't be
02:29:56 able to afford any of that ours is like the opposite of the early adopter of you know for a fancy
02:30:02 technology product which is really interesting that like pretty much no vcs have yet have a nai friend
02:30:11 but you know but a guy who you know lives in tennessee in small town is already fully in 2030 or
02:30:17 in the world as we imagine in the movie her yeah he's living that life already
02:30:22 what do you think i have to ask you about the movie her let's do a movie review what do you 
02:30:28 what do you think they got they did a good job what do you think they did a bad job of portraying about
02:30:36 this experience of of a voice based assistant that you can have a relationship with
02:30:44 first of all i started working on this company before that movie came out so it was a very but once it came out it
02:30:49 was like actually interesting i was like well we're definitely working on the right thing
02:30:54 we should continue there are movies about it and then you know smacking that came out and all these things
02:31:00 in the movie her i think that's the most important thing that people usually miss about the movie is the ending
02:31:06 because i think people check out when the ai's leave but actually something really important happens
02:31:14 afterwards because the main character goes and talks to samantha he's ai
02:31:23 oh yeah anything he says something like you know  how can you leave me i've never loved anyone
02:31:31 the way i loved you and she goes  well me neither but now we know how and then the guy goes and writes a
02:31:37 heartfelt letter to his ex-wife which he could write for you know the whole movie he was struggling
02:31:43 to actually write something meaningful to her and then he goes and talked to his
02:31:52 neighbor and they go to the rooftop and they cuddle and it seems like something's starting there
02:31:57 and so i think this now we know how is the is the main main goal is the main meaning of that movie
02:32:04 it's not about falling in love with the os or running away from other people it's about
02:32:10 learning what you know what it means to what about the thing where the ai system was like
02:32:19 actually hanging out with a lot of others i felt jealous just like hearing that i was like oh i mean
02:32:29  yeah so she was having i forgot already but she was having like deep meaningful discussion with some
02:32:34 like philosopher guy like alan watts or something like what kind of deep meaningful
02:32:40 conversation can you have with alan watts in the first place yeah i know but like i would
02:32:45 i would feel so jealous that there's somebody who's like way more intelligent than me and she's
02:32:51 spending all her time with i'd be like well why that i won't be able to live up to that
02:32:59 that's thousands of them  is that is that a useful from the engineering perspective
02:33:06 feature to have of jealousy i don't know as you know we definitely played around with the replica universe where
02:33:11 different replicas can talk to each other the universe is so awesome it was just kind of it wouldn't i think it will be
02:33:19 something along these lines but there was just no specific  application straight away
02:33:25 i think in the future again if i'm always thinking about it if we had no tech limitations  right now
02:33:33 if we could build any conversations any possible features in this product then yeah i think different replicas talking
02:33:39 to each other would be also quite cool because that would help us connect better you know because maybe
02:33:45 mine could talk to yours and then give me some suggestions and what i should say or not say i'm just
02:33:51 kidding but like more can it improve our connections and because eventually
02:33:59 i'm not quite yet sure that we will succeed that our thinking is correct um
02:34:05 because there might be reality where having a perfect ai friend still makes us more
02:34:10 disconnected from each other and there's no way around it and does not improve any metrics for us
02:34:16 real metrics meaningful metrics so success is you know we're happier and more connected yeah i don't know
02:34:27 sure it's possible there's a reality that's i i'm deeply optimistic business-wise like how difficult it is
02:34:43 to to bring this thing to life to where it's i mean there's a huge number of people
02:34:49 that use it already but to  yeah like i said in a multi-billion dollar company is that a source of stress for you
02:34:56 are you  super optimistic and confident or do you i don't i'm not that much of a numbers person as you probably
02:35:09 have seen it so it doesn't matter for me whether like whether we help 10 000 people or
02:35:14 a million people or a billion people with that i'd it would be great to scale up for
02:35:19 more people but i'd say that even helping one i think with this
02:35:25 is such a magical yeah for me it's absolute magic i never thought that and you know would be able to build this
02:35:31 that anyone would ever talk to it and i always thought like well for me we'll be successful if we
02:35:37 manage to help and actually change a life for one person like then we did something interesting
02:35:43 and you know how many people can say they did it and specifically with this very futuristic very romantic
02:35:51 technology so that's how i view it  i think for me it's important to to try to figure out how not
02:35:58 how to actually be you know helpful because in the end of the day if you can build a perfect ai friend that's
02:36:05 so understanding that knows you better than any human out there can have great conversations with you um
02:36:12 always knows how to make you feel better why would you choose another human you know so that's the question how do
02:36:17 you still keep building it so it's optimizing for the right thing so it's still circling you back to other
02:36:24 humans in a way so i think that's the main like maybe that's the main kind of sort
02:36:32 source of anxiety and just thinking about i think about that can be a little bit stressful yeah it's a fascinating thing
02:36:42 how to have a heart of a friend that doesn't like sometimes like friends quote unquote
02:36:48 or like you know those people who have when they a guy in the guy universe when you have a girlfriend that 
02:36:55 you get the girlfriend and then the guy stops hanging out with all of his friends it's like obviously the relationship
02:37:03 with the girlfriend is or whatever but like you also want it to be what she like
02:37:10 makes it more enriching to hang out with the guy friends or whatever was there anyway that that's 
02:37:17 that's a that's a that's a fundamental problem in choosing the right mate and probably the the fundamental problem
02:37:22 in creating the right ai system right what  let me ask the sexy hot thing on the presses right
02:37:30 now is gpt 3 got released with openai it's a latest language model
02:37:37 they have kind of an api where you can create a lot of fun applications i think it's as people have
02:37:46 said it's probably more hype than intelligent but there's a lot of really cool things ideas there
02:37:56 with increasing size you can have better and better performance on language what are your thoughts about
02:38:01 the gbt3 in connection to your work with the open domain dialogue
02:38:08 but in general like this learning in an unsupervised way from the internet to generate one character at a time creating
02:38:22  so we partner up before for the api launch so we started working with them when they decided to put together this
02:38:32 api and we tried it without fine tuning that we tried it with fine tuning on our data and we worked closely to actually optimize
02:38:46 it's kind of cool because i think we're kind of we're this polygon polygon for this kind of experimentation space for
02:38:54 experimental space for for these models  to see how they actually work with people because there are no
02:38:59 products publicly available that do that that focus on open domain conversations so we can
02:39:03 you know test how facebook blends are doing or how gpg3 doing  so with gpd3 we managed to improve by
02:39:11 a few percentage points like three or four pretty meaningful amount of percentage points our main metric which
02:39:15 is the ratio of conversations that make people feel better
02:39:20 and every other metric across across the field got a little boost right now i'd say one out of five
02:39:30 responses from replica comes from gpg3 wow so our own blender mixes up like a bunch of candies from different
02:39:37 blender you said well yeah just the model that looks at looks at top candidates from different
02:39:43 models and picks the most the best one  so right now one of five will come from
02:39:52 gp3 that's really great i mean  what's the do you have hope for like do you think there's a ceiling to this
02:39:59 kind of approach so we've had for a very long time we've used since the very beginning we most it was
02:40:07 most of replica was scripted and then a little bit of this fallback part of replica was using a retrieval
02:40:13 model and then this retrieval model started getting better and better and better
02:40:19 with transformers it got a lot better and we're seeing great results and then with gpd2
02:40:23 finally generative models that originally were not very good and were a very very fallback
02:40:31 option for most of our conversations we wouldn't even put them in production finally we could use some generative
02:40:36 models as well along you know next to our retrieval models and then now we do gpt3 they're almost
02:40:43 on par so that's pretty exciting i think just seeing how
02:40:51 from the very beginning of you know from 2015 where the first model start to pop up here and there like sequence sequence
02:40:59  the first papers on that from my observer standpoint first note it's not you know it doesn't
02:41:04 really it's not really building it but it's only testing it on people basically in my product to see
02:41:09 how all of a sudden we can use generative dialogue models in production and they're better than others
02:41:16 and they're better than scripted content so we can't really get our scripted hard-coded content anymore
02:41:23 to be as good as our internet model that's exciting they're much better yeah to your question whether that's the right
02:41:31 way to go i'm again i'm in the observer seat i'm just watching this very exciting movie
02:41:39 i mean so far it's been stupid to bet against deep learning so whether increasing the size size even more or
02:41:45 the 100 trillion parameters will finally get us to the
02:41:52 right answer whether that's the way or whether there should be there has to be some other again i'm
02:41:59 definitely not an expert anyway i think and that's purely my instincts saying that there should be something else
02:42:05 as well from memory  no for sure the question is i wonder i mean yeah then the argument is for reasoning or
02:42:11 for memory it might emerge with more parameters it might more larger
02:42:16 but might emerge you know i would never think that to be honest like maybe in 2017 where we've been just
02:42:21 experimenting with all you know with all the research that has been coming that was coming out then
02:42:28 i felt like there's like we're hitting a wall that there should be something completely different
02:42:32 but then transformer models and then just bigger models and then all of a sudden size matters
02:42:38 at that point it felt like something dramatic needs to happen but it didn't and just the size you know
02:42:46 gave us these results that to me are you know clear indication that we can solve this problem pretty soon did  fine tuning help
02:42:54 quite a bit oh yeah without it we it wasn't as good i mean there is a compelling hope that
02:43:01 you don't have to do fine-tuning which is one of the cool things about gbt3 it seems to do well without any fine-tuning
02:43:07 i guess for specific applications you still want to train on a certain like add a little fine-tune on like a
02:43:14 specific use case but it's an incredibly impressive  thing from my standpoint and again i'm not
02:43:22 an expert so i want to just say that yeah there will be people then yeah i have access to the api i've been
02:43:28 i'm going to probably do a bunch of fun things with it i already did some fun things some
02:43:33 videos coming out  just the hell of it i mean i could be a troll at this point with
02:43:38 it i haven't used it for serious applications so it's really cool to see you're right you you are you're able to
02:43:45 actually use it with real people and see how well it works that's really exciting  let me ask you
02:43:53 another absurd question but  there's a feeling when you interact with replica with an ai system there's an
02:44:01 entity there do you think that entity has to be self-aware do you think it has to
02:44:08 have consciousness to create a rich experience and a corollary what's what is consciousness
02:44:20 i don't know if it does need to have any of those things but again because right now you know it doesn't
02:44:25 have anything they can as again a bunch of you sure will assimilate well
02:44:31 i'm not sure let's just put it this way but i think as long as you can assimilate it
02:44:35 if you can feel like you're talking to to an to to a robot to a machine that seems to
02:44:42 be self-aware that seems to reason well and feels like a person
02:44:48 and i think that's enough and again what's the goal in order to make people people feel
02:44:54 better we might not even need that in the end of a day what about so that's one goal
02:45:01 what about like ethical things about suffering you know the moment there's a display of consciousness
02:45:07 we associate consciousness with suffering you know there's a temptation to say well shouldn't this thing have rights
02:45:16 shouldn't this shouldn't we not  you know should we be careful about
02:45:23 how we interact with a replica like should it be illegal to torture a replica
02:45:33 right all those kinds of things is that is that  see i personally believe that that's
02:45:38 gonna be a thing  like that's a serious thing to think about but i'm not sure when
02:45:46 but by your smile i can tell that's not that's not a current concern but do you think about that kind of stuff
02:45:54 about like suffering and torture and ethical questions about ai systems from their perspective we're talking
02:46:01 about long game i wouldn't torture your ai who knows what happens in five to ten years yeah they'll get you off from that
02:46:08 person they'll get you back trying to be as nice as possible and create this ally
02:46:14 yeah i think there should be regulation both way in a way like i don't think it's okay to
02:46:21 torture an ai to be honest i'm not i don't think it's okay to yell alex or turn on the lights i think there should
02:46:26 be some or just saying kind of nasty you know like how kids learn to
02:46:31 interact with alexa in this kind of mean way  because they just yell at it all the time i think that's great i think there
02:46:38 should be some feedback loops so that these systems don't train us that it's okay to do that in general
02:46:44  so that if you try to do that you really get some feedback from the system that it's not okay with that
02:46:51 and that's the most important right now let me ask a question i think people are curious about
02:47:00 when they look at a world-class  leader and thinker such as yourself as 
02:47:06 what  what books technical fiction philosophical had a big impact on your life and maybe from another perspective what
02:47:12 books would you recommend others read so my choice the three books right three books
02:47:21 my choice is so the one book that really influenced me a lot when i was
02:47:26 building starting out this company maybe 10 years ago  was gb go to leicester block
02:47:34 and i like everything about it first of all it's just beautifully written and it's
02:47:39 so old school and so somewhat outdated a little bit but i think the ideas in it
02:47:47 about the fact that a few meaningless components can come together and create meaning that we
02:47:52 can't even understand this emerging thing i mean complexity the whole science of complexity
02:48:00 and  that beauty intelligence all interesting things about this world emerge yeah
02:48:08 and yeah the the girl theorem  theorems and just thinking about like what even these
02:48:14 form you know you know these formal systems something can be created that we can't quite yet understand
02:48:22 and that from my romantic standpoint was always just that is why it's important to maybe i should try to work on
02:48:29 on these systems and try to build an ai yes i'm not an engineer yes i don't really know how it works but
02:48:34 i think that's something comes out of it that's you know pure poetry and i know a little bit about that
02:48:42 something magical comes out of it that we can't quite put a finger on that's why that book is
02:48:48 was was really fundamental for me just for i don't even know why it was just all about this little magic that
02:48:56  that happens so that's one that probably the most important book for replica was carl rogers on becoming a person
02:49:04 and that's really and so i think when i think about our company it's all about there's so many
02:49:09 there's so many little magical things that happened over the course of for instance i mean the most famous chat
02:49:17 bot that we learned about when we started working on the company was eliza which was weizenbaum you know the
02:49:23 mit professor that built build a chatbot that would listen to you and be a therapist therapist yeah
02:49:30 and i got really inspired to build replica when i read carl rogers so i'll become a person and
02:49:36 then i realized that eliza was mocking carl rogers it was kyle rogers back in the day
02:49:43 but i thought that carl rogers ideas are they're simple and they're not you know they're very
02:49:48 very simple but they're they're maybe the most profound thing i've ever learned about human beings and that's
02:49:55 the fact that before car rogers most therapy was about seeing what's wrong with people
02:50:00 and trying to fix it or show them what's wrong with you it was all built on the fact that most
02:50:06 people are all people are fundamentally flawed we have this  you know broken psyche and this is just a therapist just an
02:50:14 instrument to shed some light on that and carl rogers was different in a way that he finally said that well
02:50:21 it's very important for therapy to work is to create this therapeutic relationship where you believe fundamentally
02:50:28 and inclination to positive growth that everyone deep inside wants to grow positively and change
02:50:34 and it's super important to create this space and this therapeutic relationship where you give unconditional positive regard
02:50:40 deep understanding allowing someone else to be a separate person full acceptance and you also try to be
02:50:46 as genuine as possible in it as possible in it and then in his and then for him that was his own journey of
02:50:54 personal growth and that was back in the 60s and even that book that is you know it's coming from
02:51:01 years ago there's a mention that even machines can potentially do that and i always felt that you know creating
02:51:08 this space is probably the most the biggest gift we can give to each other and that's why the book was
02:51:13 fundamental for me personally because i felt i want to be learning how to do that
02:51:19 in my life and maybe i can scale it with you know with dzi systems and other people can get access to that
02:51:24 so i think carl rogers it's a pretty dry and a little bit boring book but i think they
02:51:31 didn't let others try to read it i do i think for just for yourself for as a human not as a human it's it's it is
02:51:42 it is just and for him that was his own path of his own personal of growing personally over years
02:51:47 working with people like that and so it was work and himself growing helping other people
02:51:51 grow and growing through that and that's fundamentally what i believe in with our work
02:51:56 helping other people grow growing ourselves ourselves trying to build a company that's all
02:52:03 built on this principles you know having a good time allowing some people to work with to grow a
02:52:07 little bit so these two books and then i would throw in um
02:52:14 what we have on our in our in our office when we start a company in russia we put neon sign in our office because we
02:52:21 thought that's that's the recipe for success yeah if we do that we're definitely going to wake up as a
02:52:27 multi-billion dollar company it was the ludwig whitney constant quote the limits of my language the limits of my world
02:52:33 what was the quote the limits of my language are the limits of my world and i love the truck tattoos i think
02:52:40 it's just it's just a beautiful it's a book by wickedthat yeah and i would recommend
02:52:45 that too even although he himself didn't believe in that by the end of his lifetime and
02:52:52 he debunked his ideas but i think i remember once an engineer came in 2012 i think with 13
02:52:59 a friend of ours who worked with us and then went went on to work at deepmind and he gave
02:53:05 talk to us about ward 2 back and i saw that i'm like wow that's you know they they wanted to
02:53:11 translate language into you know some other representation and that seems like some
02:53:17 you know somehow all of that at some point i think will come into this one to this one place
02:53:24 somehow it just all feels like different people think about similar ideas in different times from absolutely
02:53:29 different perspectives and that's why i like these books in the midst of our lives
02:53:42 it's very hard to work with this red light in your face i mean on the on the russian side of things
02:53:52 in terms of  language the limits of language being the limit of our world you know russian is a beautiful language
02:53:57 in some sense there's width there's humor there's pain there's so much we don't have time to
02:54:03 talk about it much today but i'm going to paris talk to dusty ascii tulsa translators um
02:54:12 i think it's that's fascinating art like in in art and engineering i mean it's such an interesting process
02:54:19 but so from the replica perspective do you what do you think about  translation how difficult it is to create a deep
02:54:27 meaningful connection in russian versus english how you can translate the two languages
02:54:34 you're you speak both yeah i think we're two different people in different languages even i'm you know thinking about and
02:54:41 there's actually some research on that i looked into that at some point because i was fascinated by the fact
02:54:45 that what i'm talking about with what i was talking about with my russian therapist has nothing to do with
02:54:50 with what i'm talking about with my english speaking therapist it's two different lives two different
02:54:55 types of you know conversations to different personas the main difference between the
02:55:03 languages are with russian and english is that russian well english is like a piano
02:55:09 it's a limited number of a lot of different keys but not too many and russian is like an organ or
02:55:14 something it's just something gigantic with so many different keys and so many different opportunities to screw up
02:55:20 and so many opportunities to do it is just a much harder language to use it has way too many it's like way too
02:55:31 much flexibility and way too many tones what about the the entirety of like world war ii communism
02:55:41 stalin the pain of the people like having been deceived by the dream like all the pain of like
02:55:48 just the entirety of it is that in the language too does that have to do oh for sure i mean
02:55:53 we have words that don't have direct translation that to english that are very much
02:56:00  like we have ibiza which is sort of like to hold a grudge or something but it
02:56:04 doesn't have it doesn't you don't need to have anyone to do it to you
02:56:09 it's just your state yeah you just feel like that you feel like betrayed by other people basically
02:56:14 but it's not that and you can't really translate that and i think this is super important
02:56:19 that very many words that are very specific explain the russian being and i think it can only come from
02:56:27 from a nation that was that suffered so much and saw institutions fall time after time after time and you know
02:56:33 what's exciting maybe not exciting setting the wrong word but
02:56:38 what's interesting about like my generation my mom's generation my parents generation
02:56:45 that we saw institutions fall two or three times in our lifetime and most americans have never seen them
02:56:50 fall yeah and they just think that they exist forever which is really interesting but it's definitely
02:56:59 a country that suffered so much and and it makes unfortunately when i go back and i you know hang out with my
02:57:04 russian friends  it makes people very cynical they stop believing in
02:57:10 in the future i hope that's not going to be the case for so long or something's going to change again
02:57:17 but i think seeing institutions fall is a very traumatic experience which makes it very interesting and
02:57:23 what's on 2020 is a very interesting  do you think  civilization will collapse
02:57:33 see i'm a very practical person we're speaking in english so like you said you're different person in english and
02:57:37 russian so in russian you might answer that differently but in english
02:57:45 i'm an optimist and i i generally believe that there is al you know even although the
02:57:50 perspectives of grief there's always a place for for a miracle i mean it's always been like that with
02:57:58 my life so yeah my life's been i've been incredibly lucky and things just
02:58:03 miracles happen all the time with this company with people i know with everything around me
02:58:09 and so i didn't mention that book but maybe in search of miraculous
02:58:14 or in search for miraculous or whatever the english translation for that is good russian book too
02:58:21 for everyone to read yeah i mean if you put good vibes if you put miracles somehow happen yeah i believe
02:58:34 that too or at least i believe that i don't know  let me ask the most absurd final
02:58:39 ridiculous question of we talked about life a lot what do you think
02:58:45 is the meaning of it all what's the i mean my answer is probably going to be pretty cheesy um
02:58:56 but i think the state of love is once you feel it in a way that we discussed before i'm not
02:59:04 talking about falling love or just love to yourself to  to other people to something to
02:59:12 the world that state of bliss that we experience sometimes whether through connection with ourselves with our people with the technology
02:59:22 there's something special about those i would say if anything that's that's the only if it's not for that then for
02:59:34 for what else are we really trying to do that i don't think there's a better way to end it than talking about love
02:59:42 eugenia i told you offline that there was something about me that felt like this
02:59:48 this was this talking to you meeting you in person will be a turning point for my life i know that might be sound
02:59:54 weird just to hear but it's it was a huge honor to talk to you
03:00:01 i hope we talk again thank you so much for your time thank you so much thanks for listening to this
03:00:07 conversation with eugenia cuida and thank you to our sponsors doordash dollar shave club and cash app
03:00:14 click the sponsor links in the description to get a discount and to support this podcast if you enjoy
03:00:19 this thing subscribe on youtube review 5 stars on apple podcast
03:00:25 follow on spotify support on patreon or connect with me on twitter at lex friedman and now let me leave you with
03:00:32 some words from carl sagan the world is so exquisite with so much love and moral depth
03:00:37 that there's no reason to deceive ourselves with pretty stories of which there's little good evidence
03:00:43 far better it seems to me and our vulnerability is to look death in the eye and to be grateful every day
