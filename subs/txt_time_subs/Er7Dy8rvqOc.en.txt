00:00:02 the following is a conversation with Leslie Kayla bling she's a roboticist and professor at MIT
00:00:08 she's recognized for her work and reinforcement learning planning robot navigation and several other topics in
00:00:16 AI she won the edge KY computers and thought award and was the editor-in-chief of the prestigious
00:00:22 journal machine learning research this conversation is part of the artificial intelligence podcast at MIT and beyond
00:00:30 if you enjoy it subscribe on youtube itunes or simply connect with me on twitter at Lex Friedman spelled Fri D
00:00:39 and now here's my conversation with Leslie Kael Blaine what made me get excited about AI I can say that as I
00:00:47 read girdle Ashur back when I was in high school that was pretty formative for me because it exposed the
00:00:58 interestingness of primitives and combination and how you can make complex things out of simple parts and ideas of
00:01:05 AI and what kinds of programs might generate intelligent behavior so so you first fell in love with AI reasoning
00:01:12 logic versus robots yeah the robots came because my first job so I finished an undergraduate
00:01:19 degree in philosophy at Stanford and was about to finish master's in computer science and I got hired at SR I in their
00:01:28 AI lab and they were building a robot it was a kind of a follow-on to shaky but all the shaky people were not there anymore
00:01:35 and so my job was to try to get this robot to do stuff and that's really kind of what got me interested in robots so
00:01:42 maybe taking a small step back your bachelor's in Stanford and philosophy did masters and PhD in computer science
00:01:49 but the bachelors in philosophy so what was that journey like what elements of philosophy do you think you bring to
00:01:57 your work in computer science so the part of the reason that I didn't do a computer science undergraduate degree
00:02:02 was that there wasn't one at Stanford at the time but that there's part of philosophy and in fact Stanford has a
00:02:07 special sub major in something called now symbolic systems which is logic model theory formal semantics of natural
00:02:15 language and so that's actually a perfect preparation for work in AI and computer science that that's kind of
00:02:22 interesting so if you were interested in artificial intelligence what what kind of majors were people even thinking
00:02:30 about taking what is it in your science was so besides philosophies what were you supposed to do if you were
00:02:37 fascinated by the idea of creating intelligence there weren't enough people who did that for that even to be at
00:02:42 conversation okay I mean I think probably probably philosophy I mean it's interesting in my class my graduating
00:02:51 class of undergraduate philosophers probably maybe slightly less than half went on in computer science
00:02:59 slightly less than half went on in law and like one or two went on in philosophy so it was a common kind of
00:03:07 connection do you think AI researchers have a role be part time philosophers or should they stick to the solid science
00:03:14 and engineering without sort of taking the philosophizing tangents I mean you work with robots you think about what it
00:03:20 takes to create intelligent beings aren't you the perfect person to think about the big picture philosophy of it
00:03:26 all the parts of philosophy that are closest to AI I think or at least the closest to AI that I think about are
00:03:33 stuff like belief and knowledge and denotation and that kind of stuff and that's you know it's quite formal and
00:03:40 it's like just one step away from the kinds of computer science work that we do kind of routinely I think that there
00:03:51 are important questions still about what you can do with a machine and what you can't and so on although at least my
00:03:57 personal view is that I'm completely a materialist and I don't think that there's any reason why we can't make a
00:04:03 robot be behaviorally indistinguishable from a human and the question of whether it's in the distinguishable internally
00:04:11 whether it's a zombie or not in philosophy terms I actually don't I don't know and I
00:04:16 don't know if I care too much about that right there there's a philosophical notions they're mathematical and
00:04:23 philosophical because we don't know so much of how difficult it is how difficult is a perception problem how
00:04:29 difficult is the planning problem how difficult is it to operate in this world successfully because our robots are not
00:04:37 currently as successful human beings and many tasks the the question about the gap between current robots and human
00:04:44 beings borders a little bit on philosophy you know the expanse of knowledge that's required to operate in
00:04:53 this world and the ability to form common-sense knowledge the ability to reason about uncertainty much of the
00:05:00 work you've been doing there's those open questions there that I don't know require to activate a certain
00:05:08 big-picture view to me that doesn't seem like a philosophical gap to me it's a there is a big technical
00:05:16 gap yes technical gap but I don't see any reason why it's more than a technical gap perfect so when you
00:05:24 mention AI you know sorry and maybe can you describe to me when you first fell in love with robotics
00:05:34 with robots or inspired which so you should mention flaky or shaky shaky flaky and what was the robot that first
00:05:42 captured your imagination what's possible right well this so the first robot I worked was like shakey was a
00:05:48 robot that the SR I people had built but by the time I think when I arrived it was sitting in a corner of somebody's
00:05:54 office dripping hydraulic fluid into a pan but its iconic and really everybody should read the shaky tech report
00:06:02 because it has so many good ideas in it I mean they invented a star search and symbolic planning and learning macro
00:06:14 operators they had the level kind of configuration space planning for the robot they had vision they had all this
00:06:20 the basic ideas of a ton of things okay take a step by the shaky have arms that was a job could push objects and so it
00:06:30 would move things around with which actuator itself with its base okay so it could but it and they had painted the
00:06:43 baseboards black so it used it used vision to localize itself in a map it detected objects it could detect objects
00:06:51 that were surprising to it it would plan and re plan based on what it saw it reasoned about whether to look and take
00:06:59 pictures I mean it really had the basics of of so many of the things that we think about now how do you represent the
00:07:07 space around it so it had representations that are bunch of different levels of abstraction so it
00:07:12 had I think a kind of an occupancy grid of some sort at the lowest level at the high level it was abstract symbolic kind
00:07:20 of rooms and connectivity it's a word as flaky coming yeah okay so at us RI and we were building a
00:07:28 brand-new robot as I said none of the people from the previous project were kind of there or involved anymore so we
00:07:34 were kind of starting from scratch and my advisor was Stan resin shine he ended up being my thesis advisor and he was
00:07:44 motivated by this idea of situated computation or situated automata and the idea was that the tools of logical
00:07:54 reasoning were important but possibly only for the engineers or designers to use in the analysis of a system but not
00:08:04 necessarily to be manipulated in the head of the system itself right so I might use logic to prove a theorem about
00:08:11 the behavior of my robot even if the robots not using logic and it's headed to prove theorems right so that was kind
00:08:17 of the distinction and so the idea was to kind of use those principles to make a robot do stuff but a lot of the basic
00:08:27 things we had to kind of learn for ourselves because I had zero background in robotics I didn't know anything about
00:08:32 control I don't know anything about sensors so we reinvented a lot of wheels on the way to getting that robot to do
00:08:37 stuff do you think that was an advantage or hindrance oh no it's I mean I I'm big in favor of
00:08:44 wheel reinvention actually I mean I think you learn a lot by doing it it's important though to eventually have the
00:08:51 pointers to so that you can see what's really going on but I think you can appreciate much better the good solutions
00:08:59 once you've messed around a little bit on your own and found a bad one yeah I think you mentioned reinventing
00:09:03 reinforcement learning yeah and referring to rewards as pleasures by a pleasure yeah I think yeah I think it's
00:09:13 a nice name for it it's more it's more fun almost do you think you could tell the history of AI and machine learning
00:09:20 reinforcement learning and how you think about it from the 50s to now one thing is that its oscillates right so things
00:09:29 become fashionable and then they go out and then something else becomes cool and that it goes out and so on and I think
00:09:34 there's so there's some interesting sociological process that actually drives a lot of what's going on early days was
00:09:42 kind of cybernetics and control right and the idea that of homeostasis people have made these robots that could I
00:09:51 don't know try to plug into the wall when they needed power and then come loose and roll around and do stuff and
00:09:59 then I think over time the thought well that was inspiring but people said no no we want to get maybe closer to what
00:10:04 feels like real intelligence or human intelligence and then maybe the expert systems people tried to do that but
00:10:16 maybe a little too superficially right so oh we get the surface understanding of what intelligence is like because I
00:10:24 understand how a steel mill works and I can try to explain it to you and you can write it down in logic and then we can
00:10:30 make a computer infer that and then that didn't work out but what's interesting I think is when a thing starts to not be
00:10:40 working very well it's not only do we change methods we change problems right so it's not like we have better ways of
00:10:46 doing the problem of the experts those people are trying to do we have no ways of trying to do that problem oh yeah I
00:10:54 know I think maybe a few but we kind of give up on that problem and we switch to a different problem and we we work that
00:11:01 for a while and we I guess there's a broad community as a community and there's a lot of people who would argue
00:11:06 you don't give up on the problem it's just you decrease the number of people working on it you almost kind of like
00:11:11 put it on the shelf so we'll come back to this 20 years later yeah I think that's right or you
00:11:18 might decide that it's malformed like you might say it's wrong to just try to make something that does superficial
00:11:27 symbolic reasoning behave like a doctor you can't do that until you've had the sensorimotor experience of being a
00:11:34 doctor or something right so there's arguments that say that that's problem was not well formed or it could be that
00:11:40 it is well for it but but we just weren't approaching it well you mention that your favorite part of logic and
00:11:47 symbolic systems is that they give short names for large sets so there is some use to this they use
00:11:55 just as a symbolic reasoning though the looking at expert systems and symbolic computing what do you think are the
00:12:01 roadblocks that were hit in the eighties and nineties ah okay so right so the fact that I'm not a fan of expert
00:12:08 systems doesn't mean that I'm not a fan of some kinds of symbolic reasoning right so let's see road blocks but the
00:12:18 main road block I think was that the idea that humans could articulate their knowledge effectively into into you know
00:12:26 some kind of logical statements so it's not just the cost the effort but really just the capability of doing it right
00:12:33 because we're all experts in vision right but not totally don't have introspective access into how we do that
00:12:44 right and it's true that I mean I think the idea was well of course even people then would know of course I wouldn't ask
00:12:48 you to please write down the rules that you use for recognizing water bottle that's crazy and everyone understood
00:12:54 that but we might ask you to please write down the rules you use for deciding I don't know what tie to put on
00:13:03 or how to set up a microphone or something like that but even those things I think people maybe I think what
00:13:11 they found I'm not sure about this but I think what they found was that that so-called experts could give
00:13:18 explanations that sort of post hoc explanations for how and why they did things but they weren't necessarily very
00:13:24 good and then they different they depended on maybe some kinds of perceptual things which again they
00:13:33 couldn't really define very well so I think I think fundamentally I think that the underlying problem with that was the
00:13:39 assumption that people could articulate how and why they make their decisions all right so it's almost in call
00:13:47 encoding the knowledge from converting from expert to something that a machine could understand and reason with no no
00:13:54 not even just encoding but getting it out of you just not not writing it I mean yes hard also to write it down for
00:14:03 the computer yeah but I don't think that but can produce it you can tell me a story about why you do stuff but I'm not
00:14:12 so sure that's the way great so there are still on the hierarchical planning side places where symbolic reasoning is
00:14:27 very useful so as you've talked about so where so don't where's the gap yeah okay good so saying that humans can't provide
00:14:35 a description of their reasoning processes that's ok fine but that doesn't mean that it's not good to do
00:14:42 reasoning of various styles inside a computer those are just two orthogonal points so then the question is what kind
00:14:50 of reasoning should you do inside a computer right and the answer is I think you need to do all different kinds of
00:14:57 reasoning inside a computer depending on what kinds of problems you face I guess the question is what kind of things can
00:15:07 you encode symbolically so you can reason about I think the idea about an even symbolic I don't even like that
00:15:17 terminology because I don't know what it means technically informally I do believe in abstractions so abstractions are
00:15:24 critical right you cannot reason a completely fine grain about everything in your life right you can't make a plan
00:15:32 at the level of images and torques for getting a PhD right so you have to reduce the size of the state space and
00:15:40 you have to reduce the horizon if you're gonna reason about getting a PhD or even buying the ingredients to make dinner
00:15:48 and so so how can you reduce the spaces and the horizon of the reasoning you have to do and the answer is abstraction
00:15:53 spatial abstraction temporal abstraction I think abstraction along the lines of goals is also interesting like you might
00:16:00 or well abstraction and decomposition goals this may be more of a decomposition thing so I think that's
00:16:07 where these kinds of if you want to call it symbolic or discrete models come in you you talk about a room of your house
00:16:16 instead of your pose you talk about you know doing something during the afternoon instead of at 2:54 and you do
00:16:23 that because it makes your reasoning problem easier and also because you have you don't have enough information to
00:16:34 reason in high fidelity about your pose of your elbow at 2:35 this afternoon anyway right when you're trying to get a
00:16:43 PhD okay except for at that moment at that moment you do have to use it about the pose of your elbow maybe but then
00:16:48 you maybe you do that in some continuous joint space kind of modeling so I again I my biggest point about all of this is
00:16:57 that there should be the dogma is not the thing right we shouldn't it shouldn't be that I'm in favor against
00:17:03 symbolic reasoning and you're in favor against neural networks it should be that just just computer science tells us
00:17:10 what the right answer to all these questions is smart enough to figure it out oh yeah when you try to actually solve
00:17:16 the problem with computers the right answer comes out you mentioned abstractions mm-hmm I mean you all
00:17:23 networks form abstractions or rather there's there's automated ways to form strategies and there's expert driven
00:17:31 ways to form abstractions and export human driven ways and humans just seems to be way better at forming abstractions
00:17:38 currently and certain problems so when you're referring to 2:45 and PM versus afternoon how do we construct that
00:17:48 taxonomy is there any room for automated construction of such abstractions oh I think eventually yeah I mean I think
00:17:57 when we get to be better and machine learning engineers will build algorithms that build awesome abstractions that are
00:18:03 useful in this kind of way that you describe yeah yeah so let's then step from the the abstraction discussion and
00:18:16 let's talk about BOM mdps partially observable Markov decision processes so uncertainty so first water Markov
00:18:25 decision processes and maybe how much of our world could be models and mdps how much when you wake up in them
00:18:31 morning me making breakfast how do you think of yourself as an MDP so how do you think about MVPs and how they relate
00:18:40 to our world well so there's a stance question right so a stance is a position that I take with respect to a problem so
00:18:49 I as a researcher or person who design systems can decide to make a model of the world around me
00:18:56 in some terms right so I take this messy world and I say I'm gonna treat it as if it were a problem of this formal kind
00:19:04 and then I can apply solution concepts around rhythms or whatever to solve that formal thang right so of course the
00:19:10 world is not anything it's not an MDP or a pom DP I don't know what it is but I can model aspects of it in some way or
00:19:17 some other way and when I model some aspect of it in a certain way that gives me some set of algorithms I can use you
00:19:23 can model the world in all kinds of ways some have some are more accepting of uncertainty more easily modeling
00:19:32 uncertainty of the world some really force the world to be deterministic and so the certainly NDP's model the
00:19:42 uncertainty of the world yes model some uncertainty the model not present state uncertainty but they model uncertainty
00:19:49 in the way the future will unfold right so what are Markov decision process so marketers process is a model it's a kind
00:19:57 of model that you could make that says I I know completely the current state of my system and what it means to be a
00:20:05 state is that I that all they have all the information right now that will let me make predictions about the future as
00:20:12 well as I can so that remembering anything about my history wouldn't make my predictions any better and but it but
00:20:21 then it also says that that then I can take some actions that might change the state of the world and that I don't have
00:20:26 a deterministic model of those changes I have a probabilistic model of how the world might change it's a it's a useful
00:20:34 model for some kinds of systems I think it's a I mean it's certainly not a good model for most problems I think because
00:20:43 for most problems you don't actually know State for most problems you it's partially observed so that's now a
00:20:52 different problem class so okay that's where the poverty P is the partially observable Markov decision process step
00:21:00 n so how do they address the fact that you can't observe most your incomplete information about most of the world
00:21:07 around you right so now the idea is we still kind of postulate that there exists a state we think that there is
00:21:13 some information about the world out there such that if we knew that we could make good predictions but we don't know
00:21:20 the state and so then we have to think about how but we do get observations maybe I get images right here things are
00:21:28 I feel things and those might be local or noisy and so therefore they don't tell me everything about what's going on
00:21:34 and then I have to reason about given the history of actions I've taken in observations I've gotten what do I think
00:21:40 is going on in the world and then given my own kind of uncertainty about what's going on in the world I can decide what
00:21:46 actions to take and so difficult is this problem of planning under uncertainty in your view and you know long experience
00:21:56 of modeling the world trying to deal with this uncertainty in special and real of all systems optimal planning for
00:22:04 even discrete hamdi peas can be undecidable depending on how you set it up and free so lots of people say I
00:22:12 don't use pom D peas because they are intractable and I think that that's are kind of a very funny thing to say
00:22:20 because the problem you have to solve is the problem you have to solve so if the problem you have to solve is intractable
00:22:26 that's what makes us AI people right so we saw we understand that the problem we're solving is is compute wildly
00:22:32 intractable that we can't we will never be able to solve it optimally at least I don't yeah right so later we can come
00:22:41 back to an idea about bounded optimality and something but anyway I don't we can't come up with optimal solutions to
00:22:46 these problems so we have to make approximations approximations in modeling approximations in the solution
00:22:53 algorithms and so on and so I don't have a problem with saying yeah my problem actually it is pom DP
00:22:59 in continuous space with continuous observations and it's so computationally complex I can't even think about it's
00:23:08 you know Big O whatever but that doesn't prevent me from it helps me gives me some clarity to think about it that way
00:23:16 and to then take steps to make approximation after approximation to get down to something that's like computable
00:23:22 in some reasonable time when you think about optimality you know the community broadly is shifted on that I think a
00:23:30 little bit in how much they value the idea of optimality of chasing an optimal solution positive views of chasing an
00:23:40 optimal solution changed over the years and when you work with robots that's interesting I think we have a little bit
00:23:50 of a methodological crisis actually from the theoretical side I mean I do think that theory is important in that right
00:23:57 now we're not doing much of it so there's lots of empirical hacking around and training this and doing that and
00:24:03 reporting numbers but is it good is it bad we don't know we very hard to say things and if you look at like computer science theory
00:24:16 so people talked for a while everyone was about solving problems optimally or completely and and then there were
00:24:23 interesting relaxation so people look at oh can I are their regret bounds or can I do some kind of you know approximation
00:24:31 can I prove something that I can approximately solve this problem or that I get closer to the solution as I spend
00:24:37 more time and so on what's interesting I think is that we don't have good approximate solution concepts for very
00:24:48 difficult problems right I like to you know I like to say that I I'm interested in doing a very bad job of very big
00:25:02 problems but I would I wish I could say something I wish I had a I don't know some kind of a formal solution concept
00:25:13 that I could use to say oh this this algorithm actually it gives me something like I know what I'm gonna get I can do
00:25:19 something other than just run it and get out so that having that notion is still somewhere deeply compelling to you the
00:25:28 notion that you can say you can drop thing on the table says this you can expect this this out gonna give me some
00:25:33 good results I hope science will I mean there's engineering in there science I think
00:25:42 that they're not exactly the same and I think right now we're making huge engineering like leaps and bounds so
00:25:48 that engineering is running away ahead of the science which is cool and often how it goes right so we're making things
00:25:54 and nobody knows how and why they work roughly but we need to turn that into science there's some form it's yeah
00:26:05 there's some room for formalizing we need to know what the principles are why does this work why does that not work I
00:26:10 mean for awhile people built bridges by trying but now we can often predict whether it's going to work or not
00:26:16 without building it can we do that for learning systems or for robots so your hope is
00:26:22 from a materialistic perspective that intelligence artificial intelligence systems robots okay I were just more
00:26:30 fancier bridges believe space what's the difference between belief space and state space I mentioned MDPs fond
00:26:38 appease you reasoning about you sense the world there's a state what's this belief space idea I believe
00:26:49 space that is instead of thinking about what's the state of the world and trying to control that as a robot I think about
00:26:58 what is the space of beliefs that I could have about the world what's if I think of a belief as a probability
00:27:04 distribution over ways the world could be a belief state is a distribution and then my control problem if I'm reasoning
00:27:12 about how to move through a world I'm uncertain about my control problem is actually the problem of controlling my
00:27:19 beliefs so I think about taking actions not just what effect they'll have on the world outside but what effect I'll have
00:27:24 on my own understanding of the world outside and so that might compel me to ask a question or look somewhere to
00:27:33 gather information which may not really change the world state but it changes my own belief about the world that's a
00:27:42 powerful way to to empower the agent to reason about the world to explore the world what kind of problems does it
00:27:49 allow you to solve to to consider belief space versus just state space well any problem that requires deliberate
00:27:58 information gathering right so if in some problems like chess there's no uncertainty or maybe there's uncertainty
00:28:05 about the opponent there's no uncertainty about the state and some problems there's uncertainty but you
00:28:13 gather information as you go right you might say oh I'm driving my autonomous car down the road and it doesn't know
00:28:18 perfectly where it is but the Llyod ours are all going all the time so I don't have to think about whether to gather
00:28:25 information but if you're a human driving down the road you sometimes look over your shoulder to see what's going
00:28:32 on behind you in the lane and you have to side whether you should do that now and you have to trade off the fact that
00:28:39 you're not seeing in front of you and you're looking behind you and how valuable is that information and so on
00:28:45 and so to make choices about information also also I mean also to just take into account your own uncertainty before
00:28:59 trying to do things so you might say if I understand where I'm standing relative to the door jamb pretty accurately then
00:29:07 it's okay for me to go through the door but if I'm really not sure where the door is then it might be better to not
00:29:13 do that right now the degree of your uncertainty ball about the world is actually part of the
00:29:18 thing you're trying to optimize in forming the plan right so this idea of a long horizon of planning for a PhD or
00:29:27 just even how to get out of the house or how to make breakfast you show this presentation of the the WTF was the fork
00:29:38 of robot looking at a sink and can you describe how we plan in this world of this idea of hierarchical planning we've
00:29:46 mentioned this is a yeah how can a robot hope to plan about something this was such a long hallway people since
00:29:57 probably reasoning began have thought about hierarchical reasoning the temporal hierarchy and particular
00:30:03 spatial hierarchy but let's talk about temporal hierarchy so you might say oh I have this long execution I have to do
00:30:12 but I can divide it into some segments abstractly right so maybe you have to get out of house I have to get in the
00:30:21 car I have to drive so on and so you can plan if you can build abstractions so this we started out by talking about
00:30:26 abstractions and we're back to that now if you can build abstractions in your state space and abstractions sort of
00:30:35 temporal abstractions then you can make plans at a high level and you can say I'm gonna go to town and then I'll have
00:30:42 to get gas and then I can go here and I can do this other thing and you can reason about the dependencies and
00:30:47 constraints among these actions again without thinking about the complete details what we do in our
00:30:56 hierarchical planning work is then say alright I make a plan at a high level of abstraction I have to have some reason
00:31:03 to think that it's feasible without working it out in complete detail and that's actually the interesting step I
00:31:09 always like to talk about walking through an airport like you can plan to go to New York and arrive at the airport
00:31:16 and then find yourself in an office building later you can't even tell me in advance what your plan is for walking
00:31:21 through the airport partly because you're too lazy to think about it maybe but partly also because
00:31:27 you just don't have the information you don't know what gate you're landing in or what people are gonna be in front of
00:31:34 you or anything so there's no point in planning in detail but you have to have you have to make a leap of faith that
00:31:42 you can figure it out once you get there and it's really interesting to me how you arrive at that how do you they say
00:31:52 you have learned over your lifetime to be able to make some kinds of predictions about how hard it is to
00:31:57 achieve some kinds of sub goals and that's critical like you would never plan to fly somewhere if you couldn't
00:32:03 didn't have a model of how hard it was to do some of the intermediate steps so one of the things we're thinking about
00:32:08 now is how do you do this kind of very aggressive generalization to situations that you haven't been in and so on to
00:32:17 predict how long will it take to walk through the Kuala Lumpur Airport like you give me an estimate and it wouldn't
00:32:23 be crazy and you have to have an estimate of that in order to make plans that involve walking through the Kuala
00:32:29 Lumpur Airport even if you don't need to know it in detail so I'm really interested in these kinds of abstract
00:32:35 models and how do we acquire them but once we have them we can use them to do hierarchical reasoning which is I think
00:32:40 it's very important yeah there's this notion of gold' regression and preimage back chaining this idea of starting at
00:32:49 the goal and it's just for these big clouds of states you get I mean it's almost like saying to the airport you
00:32:59 know you you know once you show up to the airport that that's you you're like a few steps away from the goal so
00:33:08 like thinking of it this way it's kind of interesting I don't know if you have sort of further comments on them of
00:33:15 starting at the goal why that yeah I mean it's interesting that Simon herb Simon back in the early days of AI did
00:33:23 talked a lot about means-ends reasoning and reasoning back from the goal there's a kind of an intuition that people have
00:33:32 that the number of that state space is big the number of actions you could take is really big so if you say here I sit
00:33:38 and I want to search forward from where I am what are all the things I could do that's just overwhelming if you say if
00:33:44 you can reason at this other level and say here's what I'm hoping to achieve what can I do to make that true that
00:33:51 somehow the branching is smaller now what's interesting is that like in the AI planning community that hasn't worked
00:33:57 out in the class of problems that they look at and the methods that they tend to use it hasn't turned out that it's
00:34:03 better to go backward it's still kind of my intuition that it is but I can't prove that to you right now all right
00:34:10 I'd share your intuition at least for us mere humans speaking of which when you maybe never take it and take a look take
00:34:20 a little step into that philosophy circle how hard would it when you think about human life you should give those
00:34:28 examples often how hard do you think it is to formulate human life is a planning problem or aspects of human life so when
00:34:35 you look at robots you're often trying to think about object manipulation tasks about moving a thing when you when you
00:34:45 take a slight step outside the room let the robot leave and go get lunch or maybe try to pursue more fuzzy goals how
00:34:55 hard do you think is that problem if you were to try to maybe put another way try to formulate human life as a planning
00:35:03 problem well that would be a mistake I mean it's not all the planning problem right every think it's really really
00:35:09 important that we understand that you have to put together pieces and parts that have different styles of reasoning
00:35:16 representation and learning I think I think it's it's seems probably clear to anybody that that you you can't all be
00:35:25 this or all be that brains aren't all like this are all like that right they have different pieces and parts and
00:35:30 substructure and so on so I don't think that there's any good reason to think that there's going to be like one true
00:35:36 algorithmic thing that's gonna do the whole job just a bunch of pieces together designed to solve a bunch of
00:35:46 specific problem one the specific styles of problems I mean there's probably some reasoning that needs to go on in image
00:35:56 space I think again there's this model based vs. model free idea it's I only enforce spent learning people talk about
00:36:03 it oh should I learn I could learn a policy just straight up a way of behaving I could learn it's popularly a
00:36:10 value function that's some kind of weird intermediate ground or I could learn a transition model or it tells me
00:36:17 something about the dynamics of the world if I take a trip if imagine that I learned in a transition model and I
00:36:22 couple it with a planner and I draw a box around that I have a policy again it's just stored a different way right
00:36:32 right it's in but it's just as much of a policy as the other policy it's just I've made I think the way I see it is
00:36:38 it's a time-space trade-off in computation right a more overt policy representation maybe it takes more space
00:36:47 but maybe I can compute quickly what action I should take on the other hand maybe a very compact model of the world
00:36:53 dynamics plus a planner let's make compute what action to take to just more slowly
00:36:58 there's no I mean I don't think there's no argument to be had it's just like a question of what form of computation is
00:37:07 best for us for the various subproblems right so and and so like learning to do algebra manipulations for some reason is
00:37:15 good I mean that's probably gonna want naturally is sort of a different representation than riding a unicycle at
00:37:22 the time constraints on the unicycle or serious this thing space is maybe smaller I don't know
00:37:27 but so I could be the more human-sized of falling in love having a relationship that might be
00:37:35 another yeah another style of no idea how to model that yeah that's let's first solve the algebra an object may
00:37:45 patient what do you think is harder perception or planning perception that's understanding that's so what do you
00:37:54 think is so hard about perception by understanding the world around you well representational a hugely the question
00:38:07 is representation so perception has made great strides lately right and we can classify images and we can play certain
00:38:16 kinds of games of predict I to steer in the car and all this sort of stuff I don't think we have a very good idea of
00:38:27 what perception should deliver right so if you if you believe in modularity ok there's there's a very strong view which
00:38:36 says we shouldn't build in any modularity we should make a giant gigantic neural network trained it
00:38:42 end-to-end to do the thing and that's the best way forward and it's hard to argue with that except on a sample
00:38:51 complexity basis right so you might say oh well if I want to do end-to-end Rio first of all anything on this giant
00:38:56 giant neural network it's going to take a lot of data and a lot of like broken robot system so then the only answer is
00:39:09 to say ok we have to build something in build in some structure or some bias we know from theory of machine learning the
00:39:14 only way to cut down the sample complexity is to kind of cut down somehow cut down the hypothesis space
00:39:21 you can do that by building in bias there's all kinds of reason to think that nature built bias into humans
00:39:31 convolution is a bias right it's a very strong bias and it's a very critical bias so my own view is that we should
00:39:39 look for more things that are like convolution but that other aspects of reasoning right so
00:39:44 convolution helps us a lot with a certain kind of spatial reasoning that's quite close to the imaging I think
00:39:54 there's other ideas like that maybe some amount of forward search maybe some notions of abstraction maybe the notion
00:40:01 that objects exist actually I think that's pretty important and a lot of people won't give you that to start with
00:40:07 right so almost like a convolution in the in the object semantic object space of some kind sometimes some kind of
00:40:15 ideas in there that's right people who started like the graph graph convolutions are an idea that are
00:40:19 related to racial relational representations and so so I think there are so you I've come far afield from
00:40:30 perception but I think I think the thing that's going to make perception that kind of the next step is actually
00:40:35 understanding better what it should produce right so what are we going to do with the output of it right it's fine
00:40:41 when what we're gonna do with the output is Sudhir it's less clear when we're just trying to make a one integrated
00:40:49 intelligent agent what should the output of perception be we have no idea and how should that hook up to the other stuff
00:40:57 we don't know so I think the pressing question is what kinds of structure can we build in that are like the moral
00:41:04 equivalent of convolution that will make a really awesome super structure that then learning can kind of progress on
00:41:11 efficiently I agree very compelling description of actually where we stand with the perceptual mom you're teaching
00:41:18 a course on embodying intelligence what do you think it takes to build a robot with human level intelligence I don't
00:41:28 know if we knew we would do it if you were to I mean okay so do you think a robot needs to have a self-awareness
00:41:40 consciousness fear of mortality or is it is it simpler than that or is consciousness a simple thing like do you
00:41:47 think about these notions I don't think much about consciousness even most philosophers who care about it will give
00:41:54 you that you could have that are zombies right that behave like humans but are not conscious and I at
00:42:00 this moment we'd be happy enough for that so I'm not really worried one way or the other to the technical side
00:42:06 you're not thinking of the use of self-awareness no but okay but then what is self-awareness mean I mean that you
00:42:14 need to have some part of the system that can observe other parts of the system and tell whether they're working
00:42:22 well or not that seems critical so does that count this I mean does that kind of self-awareness or not well it depends on
00:42:29 whether you think that there's somebody at home who can articulate whether they're self-aware but clearly if I have
00:42:35 like you know some piece of code that's counting how many times this procedure gets executed that's a kind of
00:42:42 self-awareness right so there's a big spectrum it's clear you have to have some of it right
00:42:46 you know quite far away at many dimensions but there's a direction of research that's most compelling to you
00:42:53 for you know try to achieve human-level intelligence in our robots well to me I guess the thing that seems most
00:43:00 compelling to me at the moment is this question of what to build in and what to learn I think we're we don't we're
00:43:13 missing a bunch of ideas and and we you know people you know don't you dare ask me how many years it's gonna be until
00:43:19 that happens because I won't even participate in the conversation because I think we're missing ideas and I don't
00:43:24 know how long it's gonna take to find them so I won't ask you how many years but maybe I'll ask you what it when
00:43:33 you'll be sufficiently impressed that we've achieved it so what's what's a good test of intelligence do you like
00:43:41 the Turing test the natural language in the robotic space is there something wait you would sit back and think us
00:43:50 that's pretty impressive as a test as a benchmark do you think about these kinds of problems no I resist I mean I think
00:43:57 all the time that we spend arguing about those kinds of things could be better spent just making the robots work better
00:44:03 so you competition so I mean there's a nature of benchmark benchmarks and data sets or
00:44:11 touring test challenges or everybody kind of gets together and tries to build a better robot because they want to
00:44:16 compete each other like the DARPA challenge with the autonomous vehicles do you see the value of that I can get
00:44:26 in the way I think in the way I mean some people many people find it motivating and so that's good
00:44:33 I find it anti motivating but I think I mean I think you get an interesting cycle where for a contest a bunch of
00:44:40 smart people get super motivated and they hack the brains out and much of what gets done is just hacks but
00:44:46 sometimes really cool ideas emerge and then that gives us something to chew on after that so I'm it's not a thing for
00:44:55 me but I don't I don't regret that other people do it yeah it's like he says with everything else that makes is good so
00:45:01 jumping topics a little bit he started the journal of machine learning research and served as its
00:45:09 editor-in-chief how did the publication come about and what do you think about the current publishing model space and
00:45:18 machine learning artificial intelligence ok good so it came about because there was a journal called machine learning
00:45:24 which still exists which was owned by Kluwer and there was I was on the editorial board and we used to have
00:45:32 these meetings and really where we would complain to Kluwer that it was too expensive for the libraries and that
00:45:37 people couldn't publish and we would really like to have some kind of relief on those friends and they would always
00:45:45 sympathize but not do anything so we just decided to make a new journal and there was the Journal of AI research
00:45:51 which has was on the same model which had been and exists us for maybe five years or so and it was going on pretty
00:46:01 well so  we just made a new journal it wasn't I mean they don't know I guess it was work but it wasn't that hard so
00:46:07 basically the editorial board probably 75% of the editorial board of machine learning resigned and we founded the
00:46:17 Neuse new journal but it was sort of it was more open yeah right so it's completely open its open
00:46:28 access actually I I had a postdoc George Kennedy artists who wanted to call these journals free for all because there were
00:46:36 I mean it both has no page charges and has no access restrictions and the reason and so lots of people I mean
00:46:47 there were there were people who are mad about the existence of this journal who thought it was a fraud or something it
00:46:53 would be impossible they said to run a journal like this with basically I mean for a long time I didn't even have a
00:47:00 bank account I paid for the lawyer to incorporate and the IP address and it cost a couple hundred dollars a year to
00:47:09 run it's a little bit more now but not that much more but that's because I think computer scientists are competent
00:47:18 and autonomous in a way that many scientists and other fields aren't I mean at doing these kinds of things we
00:47:24 already typeset around papers we all have students and people who can hack a website together in an afternoon so the
00:47:30 infrastructure for us was like not a problem but for other people in other fields it's a harder thing to do yeah
00:47:38 and this kind of open access journal and there's nevertheless one of the most prestigious journals so it's not like a
00:47:46 prestige and it can be achieved without any other paper it's not required yeah for prestige it turns out yeah so on the
00:47:53 review process side of actually a long time ago I don't remember when I reviewed a paper where you were also a
00:47:59 reviewer and I remember reading your if you were being influenced by it and it was really well-written
00:48:04 it influenced how I write future reviews you disagreed with me actually and you made it my review but much better so I
00:48:16 but nevertheless the review process you know has its flaws and how do you think what do you think works well how can it
00:48:25 be improved so actually when I started Djamel our I wanted to do something completely different
00:48:32 and I didn't because it felt like we needed a traditional Journal of record and so we just made jam art be almost
00:48:38 like a normal Journal except for the increasingly of course publication is not even a sensible word you can publish
00:48:48 something about putting it in archives that I can publish everything tomorrow so making stuff public is there's no
00:49:01 barrier we still need curation and evaluation I don't have time to read all of our kyv and you could argue that kind
00:49:18 of social thumbs up being of articles suffice is right you might say oh heck with this we don't need journals at all
00:49:25 we'll put everything on archive and people will upload and down about the articles and then your CV will say oh
00:49:32 man they he got a lot of buzz so that's good but I think there's still value in careful reading and commentary of things
00:49:46 and it's hard to tell when people are voting and down voting or arguing about your paper on Twitter and reddit whether
00:49:54 they know what they're talking about right so then I have the second order problem of trying to decide whose
00:50:01 opinions I should value and such so I don't know I what I if I had infinite time which I don't and I'm not gonna do
00:50:06 this because I really want to make robots work but if I felt inclined to do something more in a publication
00:50:14 direction I would do this other thing which I thought about doing the first time which is to get together some set
00:50:20 of people whose opinions I value and who were pretty articulate and I guess we would be public although we could be
00:50:26 private I'm not sure and we would review papers we wouldn't publish them and you wouldn't submit them we were just fine
00:50:33 papers and we would write reviews and we would make those reviews public and maybe if you you know so we're Leslie's
00:50:40 friends who review papers and maybe eventually if if we are opinion was officially valued like the
00:50:47 opinion of Jay mor is valued then you'd say in your CV that Leslie's friends gave my paper a five-star reading and
00:50:52 that would be just as good as saying I got it so you know accepted into this journal so I think I think we should
00:51:02 have good public commentary and organize it in some way but I don't really know how to do it it's interesting at times
00:51:08 the way the way you describe text is really interesting and you would do it for movies IMDB done know there's
00:51:14 experts critics come in they write reviews but there's also regular yeah non critics humans write reviews and
00:51:22 they're separated I like open review the the eye I cleared process I think is interesting it's a
00:51:31 step in the right direction but it's still not as compelling as reviewing movies or video games I mean it
00:51:40 sometimes almost it might be silly it's my perspective to say but it boils down to the user interface how fun and easy
00:51:46 it is to actually perform the reviews how efficient how much you as a reviewer get street cred for being a good
00:51:55 reviewer those element those human elements come into play now it's a big investment to do a good review of a
00:52:03 paper and the flood of papers is that control right so you know there aren't 3,000 new I don't know how many new
00:52:08 movies are there any year I don't know but that's probably gonna be less than how many machine learning papers are in
00:52:16 a year now and I'm worried I you know I I and right so I'm like an old person so of course I'm gonna say rawrrr things
00:52:26 are moving too fast I'm a stick in the mud so I can say that but my particular flavor of that is I think the horizon
00:52:35 for researchers has gotten very short that students want to publish a lot of papers and there's a huge there's value
00:52:45 it's exciting and there's value in that and you get patted on the head for it and so on but and some of that is fine
00:52:56 but I'm worried that we're driving out people who would spend two years thinking about something back in my day
00:53:05 when we worked on our theses we did not publish papers you did your thesis for years you picked a hard problem and then you
00:53:12 worked and chewed on it and did stuff and wasted time and a long time and when it was roughly when it was done you
00:53:21 would write papers and so I I don't know how to inside and I don't think that everybody has to work in that mode but I
00:53:26 think there's some problems that are hard enough that it's important to have a longer her research horizon and I'm
00:53:33 worried though we don't incentivize that at all at this point in this current structure right so what do you see as
00:53:43 what are your hopes and fears about the future of AI and continuing this theme so AI has gone through a few winters ups
00:53:52 and downs do you see another winter of AI coming are you more hopeful about making robots
00:54:01 work as he said I think the cycles are inevitable but I think each time we we get higher right I mean so you know it's
00:54:10 like climbing some kind of landscape with a noisy optimizer yeah so it's clear that the the you know the deep
00:54:21 learning stuff has made deep and important improvements and so the high-water mark is now higher I there's
00:54:29 no question but of course I think people are over sawing and eventually investors I guess and other people look around and
00:54:39 say well you're not quite delivering on this grand claim and that wild hypothesis it's so probably it's going
00:54:48 to crash them out and then it's okay I mean but I don't I can't imagine that there's like some awesome monotonic
00:54:56 improvement from here to human level III so in you know I have to ask this question I probably anticipate answers
00:55:05 the answers but do you have a worry short term and long term about the existential threats of AI and maybe short-term less
00:55:18 existential but more robots taking away jobs actually let me talk a little bit about utility actually I had an
00:55:28 interesting conversation with some military ethicists who wanted to talk to me about autonomous weapons and there
00:55:36 they were interesting smart well-educated guys who didn't know too much about AI are machine learning and
00:55:43 the first question they asked me was has your robot ever done something you didn't expect and I like burst out
00:55:49 laughing because anybody who's ever done something other robot right knows that they don't do it and what I realized was
00:55:56 that their model of how we program a robot was completely wrong their model of how we can put program robot was like
00:56:03 Lego Mindstorms like oh go for it a meter turn left take a picture do this do that and so if you have that model of
00:56:10 programming then it's true it's kind of weird that your robot would do something that you didn't anticipate but the fact
00:56:17 is and and actually so now this is my new educational mission if I have to talk to non experts I try to teach them
00:56:24 the idea that we don't operate we operate at least one or maybe many levels of abstraction about that and we
00:56:31 say oh here's a hypothesis class maybe it's a space of plans or maybe it's a space of classifiers or whatever but
00:56:37 there's some set of answers and an objective function and then we work on some optimization method that tries to
00:56:44 optimize a solution a solution in that class and we don't know what solution that's going to come out right so I
00:56:51 think it's important to communicate that so I read of course probably people who listen to this they they know that
00:56:56 lesson but I think it's really critical to communicate that lesson and then lots of people are now talking about you know
00:57:03 the value alignment problem so you want to be sure as robots or software systems get more competent that their objectives
00:57:11 are aligned with your objectives or that our objectives are compatible in some way or we have a good way of mediating
00:57:18 when they have different objectives and so I think it is important to start thinking in terms like
00:57:24 you don't have to be freaked out by the robot apocalypse - except that it's important to think about objective
00:57:31 functions of value alignment yes and that you have to really everyone who's done optimization knows that you have to
00:57:37 be careful what you wish for that ah you know sometimes you get the optimal solution and you realize man that was
00:57:44 that objective was wrong so pragmatically in the shortest term it seems to me that that those are really
00:57:51 interesting and critical questions and the idea that we're gonna go from being people who engineer algorithms to being
00:57:57 people who engineer objective functions I think that's that's definitely going to happen and that's gonna change our
00:58:03 thinking and methodology and we're gonna you started at Stanford philosophy because as we also know as machine
00:58:17 learning people right when you're design in fact this is the lecture I gave in class today when you design an objective
00:58:23 function you have to worry about with hats there's the Hat that says what do I want and there's the hat that says but I know
00:58:30 what my optimizer can do to some degree and I have to take that into account okay so it's it's always a trade-off and
00:58:36 we have to kind of be mindful of that the part about taking people's jobs I understand that that's important I don't
00:58:47 understand sociology or economics or people very well so I don't know how to think about that so that's yeah so there
00:58:53 might be a sociological aspect there the economical aspect that's very difficult to say well okay I mean I think other
00:58:58 people should be thinking about it but I'm just that's not my strength so what do you think is the most exciting area
00:59:04 of research in the short term for the community and for your for yourself well so I mean there's the story I've been
00:59:11 telling about how to engineer intelligent robots so that's what we want to do we all kind of want to do
00:59:18 well I mean some set of us want to do this and the question is what's the most effective strategy and we've tried and
00:59:24 there's a bunch of different things you could do at the extremes right one super extreme is we do introspection then we
00:59:31 write a program okay that has not worked out very well another extreme is we take a giant bunch
00:59:36 of neural and we trying to train it up to do something I don't think that's gonna
00:59:42 work either so the question is what's the middle ground and and again this isn't a theological question or anything
00:59:50 like that it's just like going how do just how do we what's the best way to make this work out and I think it's
00:59:58 clear it's a combination of learning to me it's clear it's a combination of learning and not learning and what
01:00:04 should that combination be and what's the stuff we built in so to me that's the most compelling question and when
01:00:10 you say engineer robots you mean engineering systems that work in the real world is that that's the emphasis
01:00:20 last question which robots or robot is your favorite from science fiction so you can go with Star Wars
01:00:29 Arthur r2d2 or you can go with more modern maybe Hal this is this is back to you like to make robots work in the real
01:00:46 world here not Madden I mean I love the process and I care more about the process engineering process yeah I mean
01:00:54 I do research because it's fun not because I care about what we produce well that's a that's a beautiful note
