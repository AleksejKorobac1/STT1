00:00:00 - The following is a conversation with Elon Musk. He's the CEO of Tesla, SpaceX, Neuralink, and a co-founder of several other companies.
00:00:09 This conversation is part of the Artificial Intelligence Podcast. This series includes leading researchers
00:00:15 in academia and industry, including CEOs and CTOs of automotive, robotics, AI and technology companies.
00:00:24 This conversation happened after the release of the paper from our group at MIT on driver functional vigilance
00:00:30 during use of Tesla's Autopilot. The Tesla team reached out to me offering a podcast conversation with Mr. Musk.
00:00:37 I accepted with full control of questions I could ask and the choice of what is released publicly.
00:00:43 I ended up editing out nothing of substance. I've never spoken with Elon before this conversation,
00:00:49 publicly or privately. Neither he nor his companies have any influence on my opinion, nor on
00:00:54 the rigor and integrity of the scientific method that I practice in my position at MIT.
00:01:01 Tesla has never financially supported my research and I've never owned a Tesla vehicle, and I've never owned Tesla stock.
00:01:10 This podcast is not a scientific paper, it is a conversation. I respect Elon as I do all other leaders
00:01:16 and engineers I've spoken with. We agree on some things and disagree on others. My goal, as always with
00:01:21 these conversations, is to understand the way the guest sees the world. One particular point of
00:01:26 disagreement in this conversation was the extent to which camera-based driver monitoring will improve outcomes and for how long
00:01:36 it will remain relevant for AI-assisted driving. As someone who works on and is fascinated by
00:01:42 human-centered artificial intelligence, I believe that, if implemented and integrated effectively, camera-based driver monitoring
00:01:48 is likely to be of benefit in both the short term and the long term. In contrast, Elon and Tesla's focus
00:01:59 is on the improvement of Autopilot such that its statistical safety benefits override any concern for human behavior and psychology.
00:02:09 Elon and I may not agree on everything, but I deeply respect the engineering and innovation behind the efforts that he leads.
00:02:16 My goal here is to catalyze a rigorous, nuanced and objective discussion in industry and academia on AI-assisted driving,
00:02:26 one that ultimately makes for a safer and better world. And now, here's my conversation with Elon Musk.
00:02:35 What was the vision, the dream, of Autopilot in the beginning? The big picture system level when it was first conceived
00:02:43 and started being installed in 2014, the hardware in the cars? What was the vision, the dream?
00:02:49 - I wouldn't characterize it as a vision or dream, it's simply that there are obviously two massive revolutions
00:02:56 in the automobile industry. One is the transition to electrification, and then the other is autonomy.
00:03:07 And it became obvious to me that, in the future, any car that does not have autonomy would be about as useful as a horse.
00:03:19 Which is not to say that there's no use, it's just rare, and somewhat idiosyncratic, if somebody has a horse at this point.
00:03:25 It's just obvious that cars will drive themselves completely, it's just a question of time.
00:03:29 And if we did not participate in the autonomy revolution, then our cars would not be useful to people,
00:03:40 relative to cars that are autonomous. I mean, an autonomous car is arguably worth five to 10 times more than a
00:03:48 car which is not autonomous. - In the long term. - Depends what you mean by long term but,
00:03:57 let's say at least for the next five years, perhaps 10 years. - So there are a lot of very interesting design choices
00:04:04 with Autopilot early on. First is showing on the instrument cluster, or in the Model 3 and
00:04:10 the center stack display, what the combined sensor suite sees. What was the thinking behind that choice?
00:04:17 Was there a debate, what was the process? - The whole point of the display is to provide a health check on
00:04:26 the vehicle's perception of reality. So the vehicle's taking in information from a bunch of sensors, primarily cameras,
00:04:32 but also radar and ultrasonics, GPS and so forth. And then, that information is then rendered into
00:04:42 vector space with a bunch of objects, with properties like lane lines and traffic lights and other cars.
00:04:51 And then, in vector space, that is re-rendered onto a display so you can confirm whether the car knows what's going on or not,
00:05:00 by looking out the window. - Right, I think that's an extremely powerful thing for people to get an understanding,
00:05:07 sort of become one with the system and understanding what the system is capable of. Now, have you considered showing more?
00:05:14 So if we look at the computer vision, like road segmentation, lane detection, vehicle detection, object detection, underlying the system,
00:05:23 there is at the edges, some uncertainty. Have you considered revealing the parts that the uncertainty in the system, the sort of--
00:05:33 - Probabilities associated with say, image recognition or something like that? - Yeah, so right now, it shows the vehicles in the vicinity,
00:05:40 a very clean crisp image, and people do confirm that there's a car in front of me
00:05:44 and the system sees there's a car in front of me, but to help people build an intuition of what computer vision is,
00:05:50 by showing some of the uncertainty. - Well, in my car I always look at this with the debug view. And there's two debug views.
00:06:00 One is augmented vision, which I'm sure you've seen, where it's basically we draw boxes and labels
00:06:08 around objects that are recognized. And then there's we what call the visualizer, which is basically vector
00:06:15 space representation, summing up the input from all sensors. That does not show any pictures,
00:06:28 which basically shows the car's view of the world in vector space. But I think this is very difficult
00:06:35 for normal people to understand, they're would not know what thing they're looking at. - So it's almost an HMI challenge through
00:06:41 the current things that are being displayed is optimized for the general public understanding of what the system's capable of.
00:06:48 - If you have no idea how computer vision works or anything, you can still look at the screen and see if the car knows what's going on.
00:06:55 And then if you're a development engineer, or if you have the development build like I do, then you can see all
00:07:02 the debug information. But this would just be like total gibberish to most people. - What's your view on how
00:07:11 to best distribute effort? So there's three, I would say, technical aspects of Autopilot that are really important.
00:07:19 So it's the underlying algorithms, like the neural network architecture, there's the data that it's trained on,
00:07:24 and then there's the hardware development and maybe others. So, look, algorithm, data, hardware. You only have so much money, only have so much time.
00:07:35 What do you think is the most important thing to allocate resources to?
00:07:40 Or do you see it as pretty evenly distributed between those three? - We automatically get vast amounts of data
00:07:46 because all of our cars have eight external facing cameras, and radar, and usually 12 ultrasonic sensors,
00:07:59 GPS obviously, and IMU. And we've got about 400,000 cars on the road that have that level of data.
00:08:13 Actually, I think you keep quite close track of it actually. - Yes. - Yeah, so we're approaching half a million cars on the road
00:08:20 that have the full sensor suite. I'm not sure how many other cars on the road have this sensor suite,
00:08:29 but I'd be surprised if it's more than 5,000, which means that we have 99% of all the data.
00:08:36 - So there's this huge inflow of data. - Absolutely, a massive inflow of data. And then it's taken us about three years,
00:08:44 but now we've finally developed our full self-driving computer, which can process an order of magnitude as much
00:08:53 as the NVIDIA system that we currently have in the cars, and to use it, you unplug the NVIDIA computer
00:09:00 and plug the Tesla computer in and that's it. In fact, we still are exploring
00:09:07 the boundaries of its capabilities. We're able to run the cameras at full frame-rate, full resolution, not even crop the images,
00:09:15 and it's still got headroom even on one of the systems. The full self-driving computer is really two computers,
00:09:23 two systems on a chip, that are fully redundant. So you could put a boat through basically any part of that system and it still works.
00:09:30 - The redundancy, are they perfect copies of each other or-- - Yeah.
00:09:34 - Oh, so it's purely for redundancy as opposed to an arguing machine kind of architecture where they're both making decisions,
00:09:40 this is purely for redundancy. - Think of it more like it's a twin-engine commercial aircraft.
00:09:47 The system will operate best if both systems are operating, but it's capable of operating safely on one.
00:09:56 So, as it is right now, we can just run, we haven't even hit the edge of performance so there's no need to actually distribute
00:10:09 functionality across both SOCs. We can actually just run a full duplicate on each one. - So you haven't really explored
00:10:19 or hit the limit of the system. - [Elon] No not yet, the limit, no. - So the magic of deep learning
00:10:24 is that it gets better with data. You said there's a huge inflow of data, but the thing about driving, - Yeah.
00:10:32 - the really valuable data to learn from is the edge cases. I've heard you talk somewhere about Autopilot disengagements
00:10:44 being an important moment of time to use. Is there other edge cases or perhaps can you speak to those edge cases,
00:10:52 what aspects of them might be valuable, or if you have other ideas, how to discover more and more
00:10:57 and more edge cases in driving? - Well there's a lot of things that are learnt. There are certainly edge cases where,
00:11:04 say somebody's on Autopilot and they take over, and then that's a trigger that goes out to our system
00:11:12 and says, okay, did they take over for convenience, or did they take over because the Autopilot
00:11:18 wasn't working properly? There's also, let's say we're trying to figure out, what is the optimal spline for
00:11:21 traversing an intersection. Then the ones where there are no interventions are the right ones.
00:11:33 So you then you say, okay, when it looks like this, do the following. And then you get the optimal spline for
00:11:42 navigating a complex intersection. - So there's kind of the common case, So you're trying to capture a huge amount of samples
00:11:52 of a particular intersection when things went right, and then there's the edge case
00:11:57 where, as you said, not for convenience, but something didn't go exactly right. - So if somebody started manual control from Autopilot.
00:12:06 And really, the way to look at this is view all input as error. If the user had to do input, there's something,
00:12:12 all input is error. - That's a powerful line to think of it that way 'cause it may very well be error,
00:12:17 but if you wanna exit the highway, or if it's a navigation decision that Autopilot's not currently designed to do,
00:12:25 then the driver takes over, how do you know the difference? - Yeah, that's gonna change
00:12:29 with Navigate on Autopilot, which we've just released, and without stalk confirm.
00:12:37 Assuming control in order to do a lane change, or exit a freeway, or doing a highway interchange,
00:12:44 the vast majority of that will go away with the release that just went out. - Yeah, so that, I don't think people quite understand
00:12:52 how big of a step that is. - Yeah, they don't. If you drive the car then you do.
00:12:58 - So you still have to keep your hands on the steering wheel currently when it does the automatic lane change.
00:13:05 There's these big leaps through he development of Autopilot, through its history and, what stands out to you as the big leaps?
00:13:13 I would say this one, Navigate on Autopilot without having to confirm is a huge leap. - It is a huge leap. - What are the--
00:13:22 It also automatically overtakes slow cars. So it's both navigation and seeking the fastest lane. So it'll overtake slow
00:13:31 cars and exit the freeway and take highway interchanges, and then we have traffic light recognition,
00:13:47 which introduced initially as a warning. I mean, on the development version that I'm driving, the car fully stops and
00:13:52 goes at traffic lights. - So those are the steps, right? You've just mentioned some things
00:14:00 that are an inkling of a step towards full autonomy. What would you say are the biggest technological
00:14:07 roadblocks to full self-driving? - Actually, the full self-driving computer that we just, the Tesla, what we call, FSD computer
00:14:17 that's now in production, so if you order any Model S or X, or any Model 3 that has the full self-driving package,
00:14:29 you'll get the FSD computer. That's important to have enough base computation. Then refining the neural net
00:14:37 and the control software. All of that can just be provided as an over-the-air update. The thing that's really profound,
00:14:47 and what I'll be emphasizing at the investor day that we're having focused on autonomy, is that the car is currently being produced,
00:14:56 with the hard word currently being produced, is capable of full self-driving.
00:15:01 - But capable is an interesting word because-- - [Elon] The hardware is. - Yeah, the hardware.
00:15:06 - And as we refine the software, the capabilities will increase dramatically, and then the reliability
00:15:11 will increase dramatically, and then it will receive regulatory approval. So essentially, buying a car today
00:15:17 is an investment in the future. I think the most profound thing is that if you buy a Tesla today,
00:15:27 I believe you're buying an appreciating asset, not a depreciating asset. - So that's a really important statement there
00:15:35 because if hardware is capable enough, that's the hard thing to upgrade usually. - Yes, exactly.
00:15:41 - Then the rest is a software problem-- - Yes, software has no marginal cost really. - But, what's your intuition
00:15:47 on the software side? How hard are the remaining steps to get it to where the experience,
00:16:02 not just the safety, but the full experience is something that people would enjoy? - I think people it enjoy it very much so on highways.
00:16:12 It's a total game changer for quality of life, for using Tesla Autopilot on the highways.
00:16:21 So it's really just extending that functionality to city streets, adding in the traffic light recognition,
00:16:29 navigating complex intersections, and then being able to navigate complicated parking lots so the car can exit a parking
00:16:37 space and come and find you, even if it's in a complete maze of a parking lot. And, then it can just drop you off
00:16:49 and find a parking spot, by itself. - Yeah, in terms of enjoyabilty, and something that people would actually find a lotta use from,
00:16:58 the parking lot, it's rich of annoyance when you have to do it manually, so there's a lot of benefit to be gained
00:17:06 from automation there. So, let me start injecting the human into this discussion a little bit.
00:17:12 So let's talk about full autonomy, if you look at the current level four vehicles being tested on row like Waymo and so on,
00:17:20 they're only technically autonomous, they're really level two systems with just a different design philosophy,
00:17:28 because there's always a safety driver in almost all cases, and they're monitoring the system. - Right.
00:17:33 - Do you see Tesla's full self-driving as still, for a time to come, requiring supervision
00:17:43 of the human being. So its capabilities are powerful enough to drive but nevertheless requires a human
00:17:49 to still be supervising, just like a safety driver is in other fully autonomous vehicles? - I think it will require
00:17:57 detecting hands on wheel for at least six months or something like that from here. Really it's a question of,
00:18:09 from a regulatory standpoint, how much safer than a person does Autopilot need to be, for it to be okay to not monitor the car.
00:18:24 And this is a debate that one can have, and then, but you need a large amount of data, so that you can prove,
00:18:32 with high confidence, statistically speaking, that the car is dramatically safer than a person.
00:18:40 And that adding in the person monitoring does not materially affect the safety. So it might need to be 200 or 300% safer than a person.
00:18:50 - And how do you prove that? - Incidents per mile. - Yeah. - So crashes and fatalities--
00:18:56 - Yeah, fatalities would be a factor, but there are just not enough fatalities to be statistically significant, at scale.
00:19:04 But there are enough crashes, there are far more crashes then there are fatalities. So you can assess what is
00:19:11 the probability of a crash. Then there's another step which is probability of injury. And probability of permanent injury,
00:19:21 the probability of death. And all of those need to be much better than a person, by at least, perhaps, 200%.
00:19:33 - And you think there's the ability to have a healthy discourse with the regulatory bodies
00:19:38 on this topic? - I mean, there's no question that regulators paid a disproportionate amount of attention
00:19:46 to that which generates press, this is just an objective fact. And it also generates a lot of press.
00:19:53 So, in the United States there's, I think, almost 40,000 automotive deaths per year. But if there are four in Tesla,
00:20:04 they will probably receive a thousand times more press than anyone else. - So the psychology of that is actually fascinating,
00:20:11 I don't think we'll have enough time to talk about that, but I have to talk to you about the human side of things.
00:20:17 So, myself and our team at MIT recently released a paper on functional vigilance of drivers while using Autopilot.
00:20:24 This is work we've been doing since Autopilot was first released publicly, over three years ago,
00:20:31 collecting video of driver faces and driver body. So I saw that you tweeted a quote from the abstract,
00:20:38 so I can at least guess that you've glanced at it. - Yeah, I read it. - Can I talk you through what we found?
00:20:46 - Sure. - Okay, it appears that in the data that we've collected, that drivers are maintaining
00:20:52 functional vigilance such that, we're looking at 18,000 disengagements from Autopilot, 18,900, and annotating were they able
00:21:03 to take over control in a timely manner. So they were there, present, looking at the road to take over control, okay.
00:21:11 So this goes against what many would predict from the body of literature on vigilance with automation.
00:21:19 Now the question is, do you think these results hold across the broader population. So, ours is just a small subset.
00:21:28 One of the criticism is that, there's a small minority of drivers that may be highly responsible, where their vigilance decrement would increase
00:21:38 with Autopilot use. - I think this is all really gonna be swept, I mean, the system's improving so much,
00:21:46 so fast, that this is gonna be a moot point very soon. Where vigilance is, if something's many times safer
00:21:57 than a person, then adding a person does, the effect on safety is limited. And, in fact, it could be negative.
00:22:10 - That's really interesting, so the fact that a human may, some percent of the population may exhibit a vigilance decrement, will not affect
00:22:20 overall statistics, numbers on safety? - No, in fact, I think it will become, very, very quickly, maybe even towards the end of this year,
00:22:29 but I would say, I'd be shocked if it's not next year at the latest, that having a human intervene
00:22:36 will decrease safety. Decrease, like imagine if you're in an elevator. Now it used to be that there
00:22:42 were elevator operators. And you couldn't go on an elevator by yourself and work the lever to move between floors.
00:22:52 And now nobody wants an elevator operator, because the automated elevator that stops at the floors is much safer than the elevator operator.
00:23:04 And in fact it would be quite dangerous to have someone with a lever that can move the elevator between floors.
00:23:09 - So, that's a really powerful statement, and a really interesting one, but I also have to ask from a user experience
00:23:16 and from a safety perspective, one of the passions for me algorithmically is camera-based detection of just sensing the human,
00:23:26 but detecting what the driver's looking at, cognitive load, body pose, on the computer vision side
00:23:30 that's a fascinating problem. And there's many in industry who believe you have to have camera-based driver monitoring.
00:23:37 Do you think there could be benefit gained from driver monitoring? - If you have a system that's at or below a human level
00:23:46 of reliability, then driver monitoring makes sense. But if your system is dramatically better,
00:23:52 more reliable than a human, then driver monitoring does not help much. And, like I said,
00:24:05 if you're in an elevator, do you really want someone with a big lever, some random person
00:24:09 operating the elevator between floors? I wouldn't trust that. I would rather have the buttons.
00:24:17 - Okay, you're optimistic about the pace of improvement of the system, from what you've seen with the full self-driving car computer.
00:24:25 - The rate of improvement is exponential. - So, one of the other very interesting design choices early on that connects to this,
00:24:33 is the operational design domain of Autopilot. So, where Autopilot is able to be turned on.
00:24:43 So contrast another vehicle system that we were studying is the Cadillac Super Cruise system that's,
00:24:49 in terms of ODD, very constrained to particular kinds of highways, well mapped, tested, but it's much narrower
00:24:56 than the ODD of Tesla vehicles. - It's like ADD (both laugh). - Yeah, that's good, that's a good line.
00:25:08 What was the design decision in that different philosophy of thinking, where there's pros and cons.
00:25:15 What we see with a wide ODD is Tesla drivers are able to explore more the limitations of the system,
00:25:23 at least early on, and they understand, together with the instrument cluster display, they start to understand
00:25:28 what are the capabilities, so that's a benefit. The con is you're letting drivers
00:25:34 use it basically anywhere-- - Anywhere that it can detect lanes with confidence. - Lanes, was there a philosophy,
00:25:44 design decisions that were challenging, that were being made there? Or from the very beginning was that done on purpose,
00:25:53 with intent? - Frankly it's pretty crazy letting people drive a two-ton death machine manually.
00:26:02 That's crazy, like, in the future will people be like, I can't believe anyone was just allowed to drive
00:26:09 one of these two-ton death machines, and they just drive wherever they wanted. Just like elevators, you could just move
00:26:16 that elevator with that lever wherever you wanted, can stop it halfway between floors if you want.
00:26:22 It's pretty crazy, so, it's gonna seem like a mad thing in the future that people were driving cars.
00:26:32 - So I have a bunch of questions about the human psychology, about behavior and so on-- - That's moot, it's totally moot.
00:26:41 - Because you have faith in the AI system, not faith but, both on the hardware side and the deep learning approach of learning from data,
00:26:52 will make it just far safer than humans. - Yeah, exactly. - Recently there were a few hackers,
00:26:59 who tricked Autopilot to act in unexpected ways for the adversarial examples. So we all know that neural network systems
00:27:06 are very sensitive to minor disturbances, these adversarial examples, on input. Do you think it's possible
00:27:12 to defend against something like this, for the industry? - Sure (both laugh), yeah. - Can you elaborate on the
00:27:19 confidence behind that answer? - A neural net is just basically a bunch of matrix math.
00:27:28 But you have to be a very sophisticated, somebody who really understands neural nets and basically reverse-engineer
00:27:33 how the matrix is being built, and then create a little thing that's just exactly causes the matrix math
00:27:44 to be slightly off. But it's very easy to block that by having, what would basically negative recognition,
00:27:51 it's like if the system sees something that looks like a matrix hack, exclude it. It's such a easy thing to do.
00:28:02 - So learn both on the valid data and the invalid data, so basically learn on the adversarial examples
00:28:08 to be able to exclude them. - Yeah, you like basically wanna both know what is a car and what is definitely not a car.
00:28:16 And you train for, this is a car, and this is definitely not a car. Those are two different things.
00:28:21 People have no idea of neural nets really, They probably think neural nets involves, a fishing net or something (Lex laughs).
00:28:29 - So, as you know, taking a step beyond just Tesla and Autopilot, current deep learning approaches
00:28:37 still seem, in some ways, to be far from general intelligence systems. Do you think the current approaches
00:28:46 will take us to general intelligence, or do totally new ideas need to be invented? - I think we're missing a few key ideas
00:28:57 for artificial general intelligence. But it's gonna be upon us very quickly, and then we'll need to figure out what shall we do,
00:29:12 if we even have that choice. It's amazing how people can't differentiate between, say, the narrow
00:29:18 AI that allows a car to figure out what a lane line is, and navigate streets, versus general intelligence.
00:29:30 Like these are just very different things. Like your toaster and your computer are both machines, but one's much more
00:29:35 sophisticated than another. - You're confident with Tesla you can create the world's best toaster--
00:29:43 - The world's best toaster, yes. The world's best self-driving... yes, to me right now this seems game, set and match.
00:29:55 I mean, I don't want us to be complacent or over-confident, but that's what it, that is just literally how it appears right now,
00:30:02 I could be wrong, but it appears to be the case that Tesla is vastly ahead of everyone.
00:30:10 - Do you think we will ever create an AI system that we can love, and loves us back in a deep meaningful way,
00:30:16 like in the movie Her? - I think AI will capable of convincing you to fall in love with it very well.
00:30:25 - And that's different than us humans? - You know, we start getting into a metaphysical question of, do emotions
00:30:33 and thoughts exist in a different realm than the physical? And maybe they do, maybe they don't, I don't know.
00:30:38 But from a physics standpoint, I tend to think of things, you know, like physics was my main sort of training,
00:30:47 and from a physics standpoint, essentially, if it loves you in a way that you can't tell
00:30:54 whether it's real or not, it is real. - That's a physics view of love. - Yeah (laughs), if you cannot prove that it does not,
00:31:06 if there's no test that you can apply that would make it, allow you to tell the difference,
00:31:15 then there is no difference. - Right, and it's similar to seeing our world a simulation, they may not be a test to
00:31:20 tell the difference between what the real world - Yes. - and the simulation, and therefore,
00:31:26 from a physics perspective, it might as well be the same thing. - Yes, and there may be ways to test whether
00:31:32 it's a simulation, there might be, I'm not saying there aren't. But you could certainly imagine that
00:31:37 a simulation could correct, that once an entity in the simulation found a way to detect the simulation,
00:31:43 it could either pause the simulation, start a new simulation, or do one of many other things that then corrects for that error.
00:31:53 - So when, maybe you, or somebody else creates an AGI system, and you get to ask her one question,
00:32:03 what would that question be? - What's outside the simulation? - Elon, thank you so much for talking today,
