00:00:01 the following is a conversation with Whitney Cummings she's a stand-up comedian actor producer writer director
00:00:10 and recently finally the host of her very own podcast called good for you her most recent Netflix special called
00:00:17 can I touch it features in part of robot she affectionately named bear claw but it's designed to be visually a replica
00:00:24 Whitney it's exciting for me to see one of my favorite comedians explore the social aspects of robotics and AI in our
00:00:32 society she also has some fascinating ideas about human behavior psychology and neurology some of which she explores
00:00:39 in her book called fine and other lies there's truly a pleasure to meet Whitney and have this conversation with
00:00:46 her and he went to continue it through texts afterwards every once in a while late at night I'll be programming over a
00:00:53 cup of coffee and we'll get a text from Whitney saying something hilarious or weirder yet sending a video Bryan Callen
00:01:01 saying something hilarious that's what I know the universe has a sense of humor and he gifted me with one hell of an
00:01:08 amazing journey then I put the phone down and go back to programming with a stupid joyful smile on my face if you
00:01:15 enjoy this conversation listen to it in these podcasts good for you and follow her on Twitter and Instagram this is the
00:01:22 artificial intelligence podcast if you enjoy subscribe on YouTube good five stars on Apple podcasts support on
00:01:29 patreon or simply connect with me on Twitter Alex Friedman spelled Fri D M a.m. this shows presented by cash app the
00:01:37 number one finance I have in the App Store they regularly support Whitney's good-for-you podcast as well I
00:01:43 personally used cash app to some money to friends but you can also use it to buy sell and deposit Bitcoin in just
00:01:49 seconds cash app also has a new investing feature you can buy a fraction of stock say $1 worth no matter what the
00:01:56 stock price is brokerage services are provided by kept investing subsidiary of square and member at CIBC I'm excited to
00:02:04 be working with cash app to support one of my favorite organizations called first best known for their first
00:02:10 robotics and Lego competitions they educate and inspire hundreds of thousands of stew
00:02:16 and in over 110 countries and have a perfect rating and Charity Navigator which means the donated money is used to
00:02:22 maximum effectiveness when you get cash app from the App Store or Google Play and use code Lex podcast you get $10 and
00:02:31 cash app will also donate $10 to 1st which again is an organization that personally seen inspired girls and boys
00:02:39 to dream of engineering a better world this podcast is supported by zip recruiter hiring great people is hard
00:02:47 and to me is the most important element of a successful mission driven team I've been fortunate to be a part of and to
00:02:54 lead several great engineering teams the hiring I've done in the past was mostly the tools that we built ourselves but
00:03:02 reinventing the wheel was painful so zip recruiters a tool that's already available for you it seeks to make
00:03:08 hiring simple fast and smart for example codable co-founder Gretchen Abner used the recruiter to find a new
00:03:15 game artist to join her education tech company by using zip recruiter screening questions to filter candidates
00:03:22 Gretchen found it easier to focus on the best candidates and finally hiring the perfect person for the role in less than
00:03:29 two weeks from start to finish zip recruiter the smartest way to hire cy zip recruiters effective for
00:03:36 businesses of all sizes by signing up as I did for free at zip recruiter comm slash Lex pod that's zip recruiter calm
00:03:47 slash Lex pod and now here's my conversation with Whitney Cummings I have trouble making eye contact as you
00:03:55 can tell me too do you know that I had to work on making eye contact because I used to look here do you see that yeah
00:04:01 do you want me to do that I'll do this well chief to camera but I used to do this and finally people like
00:04:07 I'd be on dates and guys would be like are you looking at my hair like they get it would make people really insecure
00:04:11 because I didn't really get a lot of eye contact as a kid it's it's one two three years did you not get a lot of my
00:04:17 contact as a kid I don't know I haven't done the soul-searching right so I but there's definitely some psychological is
00:04:26 she makes me uncomfortable yeah for some reason want to connect eyes I start to think I assume that you're judging me oh
00:04:37 why am we all are all right the POC has to be me and you both do you think robots of the future ones with human
00:04:47 level intelligence will be female male genderless or another gender who have not yet created as a society you're the
00:04:56 expert at this well I'm gonna ask you the answer I'm gonna ask you questions that maybe nobody knows the answer to or
00:05:02 alright and then I just want you to hypothesize as a as a imaginative author director comedian can we just be very
00:05:14 clear that you know a ton about this and I know nothing about this but I have thought a lot about yes what I think
00:05:23 robots can fix in our society and I mean I'm a comedian it's my job to study human nature to make jokes about human
00:05:29 nature and to sometimes play devil's advocate and I just see such a tremendous negativity around robots or
00:05:37 at least the idea of robots that it was like oh I'm just gonna take the opposite side for fun for jokes and then I was
00:05:44 like oh no I really agree and this devil's advocate argument so I please correct me when I'm wrong about this
00:05:50 stuff so so first of all there's there's no right and wrong because we're all I think most of the people working on
00:05:57 robotics are really not actually even thinking about some of the big picture things that you've been exploring in
00:06:04 fact  your robot what's-her-name by the what's the genesis of that name by the way would bear claw was I god I don't
00:06:15 even remember the joke cuz i black out after I shoot specials but I was writing something about like the pet names that
00:06:21 men call women like cupcake sweetie honey you know like we're always named after desserts or something and I was
00:06:30 just writing a joke about if you want to call us a dessert at least pick like a cool dessert you know like bear claw
00:06:36 like something cool so I ended up calling her bad luck so do you think the future robots of greater and greater
00:06:45 intelligence will like to make them female male would we like to assign them gender or would we'd like to move away
00:06:52 from gender and say something more ambiguous I think it depends on their purpose you know I feel like if it's a
00:07:00 sex robot it people prefer certain genders you know and I also you know when I went down and explored the robot
00:07:07 Factory I was asking about the type of people that bought sex robots and I was very surprised at the answer because of
00:07:14 course the stereotype was it's gonna be a bunch of perverts it ended up being a lot of people that were handicapped a
00:07:20 lot of people with erectile dysfunction and a lot of people that were exploring their sexuality a lot of people that
00:07:26 were thought they were gay but weren't sure but didn't want to take the risk of trying on someone that could reject them
00:07:32 and being embarrassed or they were closeted or in a city where maybe that's you know taboo and stigmatized you know
00:07:40 so I think that a gendered sex robot that would serve an important purpose for someone trying to explore their
00:07:45 sexuality am i into man let me try on this thing first alien to women let me try on this thing first so I think
00:07:50 gendered robots would be important for that I think genderless robots in terms of emotional support robots babysitters
00:07:58 I'm fine for a genderless babysitter with my husband in the house you know there are places that I think that
00:08:04 genderless makes a lot of sense but obviously not in the sex area what do you mean with your husband in the house
00:08:10 what does that have to do with the gender of the robot but I mean I don't have a husband but hypothetically
00:08:15 speaking I think every woman's worst nightmare is like the hot babysitter you know so I think that there is a
00:08:23 common place I think for genderless you know teachers doctors all that kind of it would be very awkward if the first
00:08:30 robotic doctor was a guy or the first robotic nurse is a woman you know it's sort of that stuff is still loaded I
00:08:38 think that genderless could just take the unnecessary drama out of it and possibility to sexualize them or be
00:08:49 triggered by any of that stuff so there's two components to this it's a bear claw so one is the voice and the
00:08:55 talking so on and then there's the visual appearance so on the topic of gender and generalists in your
00:09:03 experience what has been the value of the physical appearance so what has it added much to the depth of the
00:09:09 interaction I mean mines kind of an extenuating circumstance because she is supposed to look exactly
00:09:14 like me I mean I spent six months getting my face molded and having you know the idea was I was exploring the
00:09:21 concept of Ken robots replace us because that's the big fear but also the big dream in a lot of ways and I wanted to
00:09:28 dig into that area because you know for a lot of people it's like they're gonna take our jobs they're gonna replace us
00:09:33 legitimate fear but then a lot of women I know are like I would love for a robot to replace me every now and then so it
00:09:39 can go to baby showers for me and it can pick up my kids at school and it can cook dinner and whatever so I just think
00:09:45 that was an interesting place to explore so her looking like me was a big part of it now her looking like me just adds an
00:09:52 unnecessary level of insecurity cuz I got our year ago and she already looks younger than me so weird problem yeah
00:10:00 but I think that her looking human was the idea and I think that where we are now please correct me if I'm wrong over
00:10:08 human robot resembling an actual human you know is going to feel more realistic than some generic face what you're
00:10:17 saying that that robots that have some familiarity like looks similar to somebody that you actually know you be
00:10:24 able to form a deeper connection with that was the question that's an open question I don't I don't
00:10:30 no it's an interesting or the opposite if then you know me and you're like why I know this isn't real because you're
00:10:36 right here maybe it does the opposite we have a very keen eye for human faces and they're able to detect strangeness
00:10:43 especially that one has to do with people we've whose faces we've seen a lot of them so I tend to be a bigger fan
00:10:52 of moving away completely from faces recognizable faces no just human faces at all in general because I think that's
00:10:58 where things get dicey and one thing I will say is I think my robot is more realistic than other robots not
00:11:05 necessarily because you have seen me and then you see heard you go oh they're so similar but also because human faces are
00:11:11 flawed and asymmetrical and sometimes we forget when we're making things that supposed to look human we make them too
00:11:16 symmetrical and that's what makes them stop looking human so because they mold in my symmetrical face she just even if
00:11:22 someone didn't know who I was I think she'd look more realistic than most generic ones that didn't have some kind
00:11:30 of flaws got it you know cuz they start looking creepy when they're too symmetrical because human beings aren't
00:11:35 ya know the flaws is what it means to be human so visually as well but I'm just a fan of the idea of letting humans use a
00:11:44 little bit more imagination so just hearing the voice is enough for us humans to then start imagining the
00:11:50 visual appearance that goes along with that voice and you don't necessarily need to work too hard on creating the
00:11:57 actual visual appearance mm-hmm so there's some value to that when you step into the stereo of actually building a
00:12:04 robot that looks like bear claws such a long road of facial expressions of sort of making everything smiling winking yep
00:12:14 rolling their eyes all that kind of stuff it gets really really tricky it gets tricky and I think I'm again I'm a
00:12:20 comedian like I'm obsessed with what makes us human and our human nature and the nasty side of human nature tends to
00:12:27 be where I've you know ended up exploring over and over again and I was just mostly fascinated by people's
00:12:33 reactions so it's my job to get the biggest reaction from a group of strangers the loudest possible reaction
00:12:40 and I just had this instinct just when I started building her and people go oh and screechin people scream in there
00:12:46 I mean I bring around on stage and people would scream and I just to me that was the next level of entertainment
00:12:52 getting a laugh I've done that I know how to do that I think comedians were always trying to figure out what the
00:12:56 next level is and comedies evolving so much and you know Jordan Peele had just done you know these genius comedy horror
00:13:03 movies which feel like the next level of comedy to me and this sort of funny horror of a robot was fascinating to me
00:13:13 but I think the thing that I got the most obsessed with was people being freaked out and scared of her and I
00:13:20 started digging around with pathogen avoidance and the idea that we've essentially evolved to be repelled by
00:13:28 anything that looks human but is off a little bit anything that could be sick or diseased or dead essentially as our
00:13:34 reptilian brains way to get us to not Procrit try to have sex with it basically you know so I got really
00:13:41 fascinated by how freaked out and scared I mean I would see grown men get upset you get something away from me like
00:13:49 angry and it was like you know that what this is you you know but the sort of like you know amygdala getting activated
00:13:57 by something that to me is just a fun toy said a lot about our history as a species and what got us into trouble
00:14:05 thousands of years ago so it's that it's the deep down stuff that's in our genetics but also is it just are people
00:14:11 freaked out by the fact that there's a robot so it's not just the appearance but there's an artificial human anything
00:14:20 people I think and I'm just always also fascinated by the blind spots humans have so the idea that you're afraid of
00:14:25 that I mean how many robots have killed people how many humans have died at the hands of other humans yeah many more
00:14:33 hundreds of millions yet we're scared of that and we'll go to the grocery store and be around a bunch of humans who
00:14:39 statistically the chances are much higher that you're gonna get killed by humans so I'm just fascinated by without
00:14:47 judgement how irrational we are is the worry is the exponential so it's you know you could say the same thing about
00:14:54 nuclear weapons before we dropped on Hiroshima Masaki so the worry that people have is the exponential growth so so it's like
00:15:05 oh it's fun and games right now but you know overnight especially if a robot provides value to society we'll put one
00:15:12 in every home and then all of a sudden lose track of the actual large-scale impact it has in society and then all
00:15:19 sudden gain greater and greater control to where we'll all be you know affect our political system and then affect our
00:15:28 decision did not just already happen which ones Oh Russia hacking no offense but hasn't already happened I mean that
00:15:37 was like an algorithm of negative things being clicked on more we'd like to tell stories and like to demonize certain
00:15:45 people I think nobody understands our current political system or discourse on Twitter the Twitter mobs nobody has a
00:15:52 sense not Twitter not Facebook the people running it nobody understands the impact for these algorithms they're
00:15:57 trying their best yeah despite what people think they're not like a bunch of lefties trying to make sure that Hillary
00:16:05 Clinton gets elected it's more that it's an incredibly complex system that we don't and that's the worry it's so
00:16:13 complex and moves so fast that nobody will be able to stop it once it happens and let me ask the question this is a
00:16:20 very savage question yeah which is is this just the next stage of evolution as humans and people will die yes I mean
00:16:28 that's always happens you know is this is just taking emotion out of it is this basically the next stage of survival of
00:16:35 the fittest yeah you have to think of organisms you know what is it mean to be a living organism like it's a smartphone
00:16:46 part of your living organism or where we're in relationships with our phones yeah but it's sex through them with them
00:16:53 what's the difference between with them and through them but it also expands your cognitive abilities expands your
00:16:59 memory knowledge and so on so you're a much smarter person because you have a smart phone in your hand but if what as
00:17:05 soon as it's out of my hands we've got big problems because we become sort of so morphed with them
00:17:10 with an assembly otic relationship and that's what the er mosque when you're a link is working on trying to increase
00:17:17 the bandwidth communication between computers and your brain and so further and further expand our ability as human
00:17:26 beings to sort of leverage machines and maybe that's the future the evolution next evolutionary step it could be also
00:17:34 that yes we'll give birth just like we give birth to human children right now to give birth day I in other places I
00:17:41 think it's a really interesting possibility I'm gonna play devil's advocate I just think that the fear of
00:17:49 robots is wildly classist because I mean Facebook like it's easy for us to say they're taking their data okay a lot of
00:17:55 people that get employment off of Facebook they are able to get income off of Facebook they don't care if you take
00:18:00 their phone numbers and their emails and their data as long as it's free they don't want to have to pay five dollars a
00:18:04 month or Facebook Facebook is a wildly Democratic thing forget about the election and all that kind of stuff you
00:18:10 know a lot of you know technology making people's lives easier it I find that most elite people are more scared than
00:18:20 lower-income people so and women for the most part so the idea of something that's stronger than us and that might
00:18:25 eventually kill us like women are used to that like that's not I see a lot of like really wit rich men being like the
00:18:31 robots are gonna kill us we're like what's another thing that's gonna kill us you know I tend to see like oh
00:18:36 something can walk me to my car at night like something can help me cook dinner or something you know for you know
00:18:43 people in underprivileged countries who can't afford eye surgery like you know robot can we send a robot to
00:18:49 under-privileged you know places to do surgery where they can't I work with this organization cooperation smile
00:18:55 where they do cleft palate surgeries and there's a lot of places that can't do a very simple surgery because they can't
00:19:01 afford doctors and medical care and such so I just see and this can be completely naive and should be completely wrong but
00:19:08 I feel like we're a lot of people are going like the robots are gonna destroy us humans we're destroying ourselves
00:19:13 we're self-destructing robots to me are the only hope to clean up all the messes that we've created even when we go try
00:19:18 to clean up pollution in the ocean we make it worse because of the oil that the tankers
00:19:23 it's like to me robots are the only solution you know firefighters are heroes but they're limited and how many
00:19:30 times they can run into a fire you know so there's just something interesting to me I'm not hearing a lot of like lower
00:19:37 income more vulnerable populations talking about robots maybe you can speak that a little bit more there's an idea I
00:19:45 think you've expressed that I've heard actually a few female writers and roboticist I've talked to express this
00:19:55 idea that exactly you just said which is it just seems that being being afraid of existential threats of artificial
00:20:07 intelligence is is a male issue yeah it and I wonder what that is if it because because men have in
00:20:14 certain positions like you said it's also classist issue they haven't been humbled by life and so you're always
00:20:21 look for the biggest problems to take on around you it's a champagne problem to be afraid of robots most people like
00:20:26 don't have health insurance they're afraid they're not gonna be able to feed their kids they can't afford a tutor for
00:20:31 their kids like I mean I just think of you know the way I grew up and I had a mother who you know work two jobs had
00:20:37 kids we couldn't afford an SAT tutor you know like we could idea of a robot coming and being able to tutor your kids
00:20:42 being able to provide childcare for your kids you know being able to come in with cameras for eyes and make sure you know
00:20:48 surveillance you know I'm very Pro surveillance because you know I've had security problems and I've been you know
00:20:55 we're generally in a little more danger than you guys are so I think that robots are a little less scary to us because we
00:21:00 could see them maybe as like free assistance help and protection and then there's sort of another element for me
00:21:07 personally which is maybe more of a female problem I don't know I'm just gonna make a generalization I'm happy to
00:21:16 be wrong but you know the emotional sort of component of robots and what they can provide in terms of you know there I
00:21:23 think there's a lot of people that aren't don't have microphones that I just recently kind of stumbled upon in
00:21:30 doing all my research on the sex robots for my stand-up special which there's a lot of very shy people that aren't good
00:21:35 at day there's a lot of people who are scared of human beings who you know have
00:21:41 personality disorders or grow up in alcoholic homes or struggle with addiction or whatever it is where a
00:21:46 robot can solve an emotional problem and so we're largely having this conversation about like rich guys that
00:21:54 are emotionally healthy and how scared of robots are we're forgetting about like a huge part of the population who
00:22:01 maybe isn't as charming and effervescent and salt mint as you know people like you and Allah mask who these robots
00:22:09 could solve very real problems in their life emotional or financial that's a in general really interesting idea that
00:22:15 most people in the world don't have a voice it's you've talked about it sort of even the people on Twitter who are
00:22:23 driving the conversation you said comments people who leave comments represent a very tiny percent of the
00:22:30 population and they're the ones they you know we tend to think they speak for the population but it's very possible on
00:22:37 many topics they don't at all and look I and I'm sure there's got to be some kind of legal you know sort of structure in
00:22:45 place for when the robots happen you know way more about this than I do but you know for me to just go the robots
00:22:51 are bad that's a wild generalization that I feel like is really inhumane in some way you know just after the
00:22:56 research I've done like you're gonna tell me that a man whose wife died suddenly and he feels guilty moving on
00:23:03 with a human woman or can't get over the grief he can't have a sex robot in his own house well why not who cares why do
00:23:11 you care well there's a interesting aspect of human nature so you know we tend to as a as a civilization to create
00:23:19 a group that's the other in all kinds of ways right and so you work with animals too you've you're especially sensitive
00:23:27 to the suffering of animals let me kind of ask what's your do you think will abuse robots in the future do you think
00:23:36 some of the darker aspects of human nature will come out I think some people will but if we design them properly to
00:23:43 people that do it we can put it on a record and they can we put we can put them in jail we can find sociopaths more
00:23:49 easily you like why is that why is that a sociopathic thing to harm a robot I
00:23:55 think look I don't know is enough enough about the consciousness and stuff as you do it I guess it would have to be when
00:24:01 they're conscious but it is you know the part of the brain that is you know responsible for compassion the frontal
00:24:06 lobe or whatever like people that abuse animals also abuse humans and commit other kinds of crimes like that's it's
00:24:11 all the same part of the brain no one abuses animals and then it's like awesome to women and children and
00:24:17 awesome to under-privileged you know minorities like it's all so you know we've been working really hard to put a
00:24:23 database together of all the people that have abused animals so when they commit another crime you go okay this is you
00:24:30 know it's all the same stuff and I think people probably think I'm nuts for the a lot of the animal work I do but because
00:24:37 when animal abuse is president another crime is always present but the animal abuse is the most socially acceptable
00:24:43 you can kick a dog and there's nothing people can do but then what they're doing behind closed doors you can't see
00:24:48 so there's always something else going on which is why I never feel compassion about it but I do think we'll start
00:24:54 seeing the same thing with robots the person that kicks them I felt compassion when the kicking the dog robot really
00:25:00 pissed me off I know that they're just trying to get the stability right and all that but I
00:25:07 do think there will come a time where that will be a great way to be able to figure out if somebody is has like you
00:25:15 know antisocial behaviors you kind of mentioned surveillance mm-hmm it's also a really interesting idea of yours he
00:25:22 just said you know a lot of people should be really uncomfortable with surveillance yeah and you just said that
00:25:28 you know what for me you know there's positives for surveillance I think people behave better when they
00:25:33 know they're being watched and I know this is a very unpopular opinion I'm talking about on stage right now I we
00:25:39 behave better when we know we're being watched you and I had a very different conversation before we were recording if
00:25:46 we behave different you said I'll be on your best behavior and I'm trying to sound eloquent and I'm trying to not
00:25:51 hurt anyone's feelings and I'm gonna have a camera right there I'm behaving totally different then we we first
00:25:57 started talking you know when you know there's a camera you behave differently I mean there's cameras all over LA at stoplights
00:26:04 so that people don't run stoplights but there's not even film in it they don't even use them anymore but it works it
00:26:10 works right in and I'm you know working on this thing and stamp out surveillance it's like that's why we invented Santa
00:26:15 Claus you know it's the Santa Claus is the first surveillance basically all we have to say to kids is he's making a
00:26:22 list and he's watching you and that behaved better I was brilliant you know so I do I do think that there are
00:26:27 benefits to surveillance you know I think we all do sketchy things in private and we all have watched weird
00:26:34 porn or googled weird things and we don't we don't want people to know about it the our secret lives so I do think
00:26:40 that obviously there's we should be able to have a modicum of privacy but I tend to think the people that are the most
00:26:48 negative about surveillance of the most high well you should do your thing you're doing bits on it now well I'm
00:26:56 just talking in general about you know privacy and surveillance and how paranoid were kind of becoming and how
00:27:03 you know I mean it's it's just wild to me that people are like our emails are gonna leak and they're taking our phone
00:27:08 numbers like there there used to be a book full of phone numbers and addresses yeah that word they just throw it at
00:27:16 your door and we all had a book of everyone's numbers you know is a very new thing and you know I know our migdal
00:27:24 is designed to compound sort of threats and you know there's stories about and I think we all just glom on and a very you
00:27:32 know tribe away yeah they're taking our data like we don't even know that means we're like well yeah they they you know
00:27:39 so I just think that someone's like okay well so what they're gonna sell your data who cares why do you care first of
00:27:48 all that bit will kill in China so and I said I said only a little bit joking because a lot of people in China
00:27:56 including the citizens despite what people in the West think of as abuse I actually in supported the idea of
00:28:03 surveillance mmm-hmm sort of they're not in support of the abuse of surveillance but they're they like I mean the idea of
00:28:11 surveillance is kind of like the idea of government it like you said we behave differently in a way it's um
00:28:19 like why we like sports there's rules and within the constraints of the rules this is a more stable society and they
00:28:28 make good arguments about success being able to build successful companies being able to build successful social lives
00:28:34 around a fabric that's more stable when you have a surveillance it keeps the criminals away keeps
00:28:40 abusive animals whatever the values of the society with surveillance you can enforce those values butter and here's
00:28:46 what I will say there's a lot of unethical things happening with surveillance like I feel the need to
00:28:52 really make that very clear I mean the fact that Google is like collecting if people's hands start moving on the mouse
00:28:57 to find out if they're getting Parkinson's and then their insurance goes up like that is completely
00:29:02 unethical and wrong and I think stuff like that we have to really be careful around so the idea of using our data to
00:29:09 raise our insurance rates or you know I heard that they're looking they can sort of predict if you're gonna have
00:29:14 depression based on your selfies by detecting micro muscles in your face that you know all that kind of stuff
00:29:20 that is a nightmare not okay but I think you know we have to delineate what's a real threat and what's getting spam in
00:29:26 your email box that's that's not what you spend your time and energy on focus on the fact that every time you buy
00:29:33 cigarettes your insurance is not without you knowing about it on the topic of animals - can we just
00:29:39 linger a little bit like what do you think what does it say about our society of the society white abuse of animals
00:29:47 that we see in general sort of factory farming is just in general just the way we treat animals of different categories
00:29:58 like what what do you think of that what is a better world look like what's what should people think about it in general
00:30:05 I think I think the most interesting thing I can probably say around this that the least emotional cuz I'm
00:30:11 actually a very non emotional animal person because it's I think everyone's an animal person it's just a matter of
00:30:17 its if it's yours or if you've you know been conditioned to go numb you know I think it's really a testament to what as
00:30:24 a species we are able to be in denial about mass denial and mass delusion and how we're able to do human eyes and do
00:30:31 base groups you know world war two in a way in order to conform and find protection and the
00:30:41 conforming so we are also a species who used to go to Coliseum's and watch elephants and tigers fight to the death
00:30:49 we used to watch human beings be pulled apart in the cut there wasn't that long ago we're also species who had slaves and it
00:30:58 was socially acceptable by a lot of people people didn't see anything wrong with it so we're a species that is able
00:31:04 to go numb and that is able to dehumanize very quickly and make it the norm child labor wasn't that long ago
00:31:12 the idea that now we look back and go oh yeah kids we're losing fingers and factories
00:31:19 making shoes like someone had to come in and make that you know so I think it just that's a lot about the fact that
00:31:24 you know we are animals and we are self-serving and one of the most successful the most successful species
00:31:32 because we are able to debase and degrade and essentially exploit anything that benefits us I think the pendulum is
00:31:41 gonna swing as being lately like I think we're wrong now kind of like I think we're on the verge of collapse because
00:31:47 we are dopamine receptors like we are just I think we're all kind of addicts when it comes to this stuff like we
00:31:53 don't know when to stop it's always the buffet like we're the thing that used to keep us alive which is killing animals
00:31:59 and eating them now killing animals and eating them is what's killing us in a way so it's like we just can't we don't
00:32:04 know when to call it and we don't moderation it's not really something that humans have evolved to have yet so
00:32:12 I think it's really just a flaw in our wiring do you think we'll look back at this time as our society is being deeply
00:32:21 unethical yeah yeah I think we'll be embarrassed which are the worst parts right now going on is it well I think no
00:32:27 in terms of anything what's the unethical thing if we it's very hard to take a step out of it but
00:32:36 you just said we used to watch you know there's been a lot of cruelty throughout history what's the cruelty going on now
00:32:46 I think it's gonna be I mean pigs are one of the most emotional intelligent animals and they have the intelligence
00:32:52 of like a three-year-old and I think we'll look back and be really good there's 30 they use tools I mean they're
00:32:58 I think we have this narrative that they're pigs and they're pigs and they're they're disgusting and they're
00:33:03 dirty and their bacon is so I think that we'll look back one day and be really embarrassed about that is this for just
00:33:10  what's it called the factory farming so basically mess because we don't see it if you saw I mean we do have I mean
00:33:17 this is probably an evolutionary advantage we do have the ability to completely pretend something's not
00:33:22 something that is so horrific that it overwhelms us and we're able to essentially deny that it's happening I
00:33:29 think if people were to see what goes on in factory farming and also we're really to take in how bad it is for us you know
00:33:36 we're hurting ourselves first and foremost with what what we eat but that's also a very elitist argument you
00:33:42 know it's a luxury to be able to complain about meat it's a luxury to be able to not eat meat you know there's
00:33:50 very few people because of you know how the corporations have set up meat being cheap you know it's two dollars to buy a
00:33:56 Big Mac it's ten dollars to buy a healthy meal you know that's I think a lot of people don't have the luxury to
00:34:01 even think that way but I do think that animals in captivity I think we're gonna look back and be
00:34:07 pretty grossed out about mammals in captivity whales dolphins I mean that's already starting to dismantle circuses
00:34:13 we're gonna be pretty embarrassed about but I think it's really more testament to you know there's just such a ability
00:34:24 to go like that thing is different than me and we're better it's the ego I mean it's just we have the species with the
00:34:29 biggest ego ultimately well that's what I think that that's my hope for robots is they'll you mentioned consciousness
00:34:36 before nobody knows what consciousness is but I'm hoping robots will help us empathize and
00:34:46 understand that that there's other creatures out besides ourselves that can suffer that can they can experience the
00:34:57 world and that we can torture by our actions and robots can explicitly teach us that I think better than animals can
00:35:07 I have never seen such compassion from a lot of people in my life toward any human animal child as I have a lot of
00:35:16 people in the way they interact with the robot because I should theirs I think there's something of AI I mean I was on
00:35:25 the robot owners chat boards for a good eight months and the main emotional benefit is she's never gonna cheat on you
00:35:32 she's never gonna hurt you she's never gonna lie to you she doesn't judge you you know I think that robots help people
00:35:40 and this is part of the work I do with animals like I do I find therapy and trained dogs and stuff because there is
00:35:46 this safe space to be authentic you're with this being that doesn't care what you do for a living doesn't care how
00:35:50 much money you have doesn't care who you're dating doesn't care what you look like doesn't care if you have cellulite
00:35:55 whatever you feel safe to be able to truly you know be present without being defensive and worrying about eye contact
00:36:02 and being triggered by you no need to be perfect and fear of judgment and all that and robots really can't judge you
00:36:09 yet but they can't judge you and I think it really puts people at they're at ease and at their most authentic do you think
00:36:18 you can have a deep connection with the robot that's not judging or do you think you can really have a relationship with
00:36:28 a robot or a human being that's a safe space or as a tension mystery danger necessary for a deep connection I'm
00:36:38 gonna speak for myself and say that I grew up and alcohol Combe I identify as a codependent talked about this stuff
00:36:44 before but for me it's very hard to be in relationship with a human being without feeling like I need to perform
00:36:50 in some way or deliver in some way and I don't know if that's just the people I've been in a relationship with or or
00:36:59 me or my brokenness but I do think this is kind of sound really negative and pessimistic but I do think a lot of our
00:37:07 relationships are projection and a lot of our relationships are performance and I don't think I really understood
00:37:14 that until I worked with horses and most mutations human is nonverbal right I can say like I love you but that
00:37:21 you're not you don't think I love you right where's is with animals it's very direct it's all physical it's all energy
00:37:28 I feel like that with robots too it feels very what how I say something doesn't matter
00:37:36 my inflection doesn't really matter and you thinking that my tone is disrespectful like you're not filtering
00:37:43 it through all of the bad relationships you've been in you're not filtering it through the way your mom talked to you
00:37:47 you're not getting triggered you know I find that for the most part people don't always receive things the way that you
00:37:53 intend them to or the way intended and that makes relationships really murky so the relationships with animals and
00:37:58 relationship with the robots as they are now you kind of implied that that's more healthy I think can you have a healthy
00:38:08 relationship with other humans or not healthy and don't like that word but it shouldn't it be you've talked about
00:38:15 codependency maybe you can talk about what is called dependency but is that is the the challenges of that the
00:38:24 complexity of that necessary for passion thought this would be a safe speech I got trolled by rogen powers on this I I
00:38:43 am NOT anti passion I think that I've just maybe been around long enough to know that sometimes it's ephemeral and
00:38:54 that passion is a mixture of a lot of different things adrenaline which turns into dopamine quarters it's a lot of
00:39:01 neuro chemicals it's a lot of projection it's a lot of what we've seen in movies it's a lot of you know it's it's I
00:39:06 identify as an addict so for me sometimes passion is like oh this could be bad and I think we've been so
00:39:12 conditioned to believe that passion means like your soul mates and I mean how many times have you had a passionate
00:39:16 connection with someone and then it was a total train wreck passionate the train wreck comedy track exactly a lot of
00:39:28 yawning I mean what's a trainwreck what's  wise obsession she described this codependency and sort of the idea
00:39:39 of attachment / attachment to people who don't deserve that kind of attachment as somehow a bad thing and I think our
00:39:47 society says it's a bad thing it probably is a bad thing like a like a delicious burgers a bad thing I don't
00:39:54 know but right oh that's a good point I think that your your pointing out something really fascinating which is
00:39:58 like passion if you go into it knowing this is like pizza or it's gonna be delicious for two hours and then I don't
00:40:04 have to have it again for three if you can have a choice in the passion i define passion is something that is
00:40:09 relatively unmanageable and something you can't control or stop and start with your own volition
00:40:15 so maybe we're operating under different definitions if passion is something that like you know ruins your real marriages
00:40:23 and screws up your professional life and becomes this thing that you're not in control of and becomes addictive I think
00:40:31 that's the difference is is it a choice or is it not a choice and if it is a choice then passion is great but if it's
00:40:37 something that like consumes you and makes you start making bad decisions and clouds your frontal lobe and it's just
00:40:44 all about dopamine and not really about the person and more about the neurochemical we call it sort of the
00:40:51 drug the internal drug cabinet if it's all just you're on drugs that's different you know because sometimes
00:40:55 you're just on drugs okay so there's a philosophical questions here so would you rather it's interesting for a
00:41:05 comedian a brilliant comedian to speak so eloquently about a balanced life I kind of argue against this point there's
00:41:13 such an obsession of creating this healthy lifestyle no it's psychologically speaking you know I'm a
00:41:21 fan of the idea that you sort of fly high and you crash and die 27 mm there's also possible life and it's not
00:41:29 one we should judge because I think there's moments of greatness I talk to Olympic athletes where some of the
00:41:35 greatest moments are achieved in their early 20s and the rest of their life is it in the kind
00:41:41 of fog of almost of a depression because they based on their physical prowess physical prowess and they'll never say
00:41:48 that so they're watching the physical prowess fade and they'll never achieve the kind of height not just physical of
00:42:00 just emotion of the max number of neurochemicals yes and he also put your money on the wrong horse that's where I
00:42:07 would I would just go like oh yeah if you're doing a job where you peak at 22 yeah the rest of your life is gonna be hard
00:42:15 that idea is considering the notion that you want to optimize some kind of but we're all gonna die soon what now you
00:42:26 tell me I'm immortalized myself gonna be fine see you're almost like how many oscar-winning movies can I direct
00:42:35 by the time I'm 100 how many this and that like but you know there's a night you know it's all life is short speaking
00:42:42 I know but it can also come at different you know life is short play hard fall in love as much as you can run into walls I
00:42:49 would also go life is short don't deplete yourself on things that aren't sustainable and that you can't
00:42:57 keep yeah you know so I think everyone gets dopamine from different places everyone has meaning from different
00:43:03 places I look at the fleeting passionate relationships I've had in the past and I don't like I don't have pride in that I
00:43:10 think that you have to decide what you know helps you sleep at night for me it's pride and feeling like I behaved
00:43:15 with grace and integrity that's just me personally everyone can go like yeah I slept with all the hot chicks in Italy I
00:43:22 could and I you know did all the whatever like whatever you value we're allowed to value different here we're
00:43:30 talking about Brian Kelly yes Frank Allen has lived his life to the fullest to say the least but I think that it's
00:43:37 just for me personally I and this could be like my workaholism or my achievement ISM I if I don't have something to show
00:43:47 for something I feel like it's a waste of time or some kind of loss I'm a 12-step program and the third step
00:43:53 would say there's no such thing as waste of time and everything happens exactly as it should in whatever that's a way to
00:44:00 just sort of keep us sane so we don't grieve too much and beat ourselves up over past mistakes there's no such thing
00:44:07 as mistakes did it  but I think passion is I think it's so life-affirming and one of the few things
00:44:13 that maybe people like us makes us feel awake and seen and we have just have such a high threshold for adrenaline you
00:44:23 know I mean you are a fighter right yeah okay so yeah so you have a very high tolerance for adrenaline and I think
00:44:30 that Olympic athletes the amount of adrenaline they get from performing it's very hard to follow that it's like when
00:44:36 guys come back from the military and they have depression it's like do you miss bullets flying out you get kind of
00:44:43 because of that adrenaline which turned into dopamine in the camaraderie I mean there's people that speak much better
00:44:49 about this than I do but I just I'm obsessed with neurology and I'm just obsessed with sort of the lies we tell
00:44:55 ourselves in order to justify getting neuro chemicals you've done actually quite done a lot of thinking and talking
00:45:03 about neurology just kind of look at human behavior through the lens of of looking of how are actually chemically
00:45:11 our brain works so what first of all why did you connect with that idea and what have you how is your view of the world
00:45:20 changed by considering the the brain is just a machine you know I know it probably sounds really nihilistic but
00:45:27 for me it's very liberating to know a lot about neuro chemicals because you don't have to it's like the same thing
00:45:32 with like like critics like critical reviews if you believe the good you have to believe the bad kind of thing like
00:45:38 you know if you believe that your bad choices were because of your moral integrity or whatever you have to
00:45:45 believe your good ones I just think there's something really liberating and going like oh that was just adrenaline I
00:45:49 just said that thing because I was adrenalized and I was scared and my amygdala was activated and that's why I
00:45:54 said you're an and get out and that's you know I think I just think it's important to delineate what's
00:45:59 nature and what's nurture what is your choice and what is just your brain trying to keep you safe I think we
00:46:03 forget that even though we security systems and homes and locks on our doors that our brain for the most
00:46:08 part is just trying to keep us safe all the time it's why we hold grudges that's why we get angry it's why we get road
00:46:14 rage it's why we do a lot of things and it's also when I started learning about neurology I started having so much more
00:46:19 compassion for other people you know someone yelled at me being like you on the road I'd be like okay he's
00:46:24 producing adrenaline right now because we're all going 65 miles an hour and our brains aren't really designed for this
00:46:33 type of stress and he's scared he was scared you know so that really helped me to have more love for people and my
00:46:39 everyday life instead of being in fight-or-flight mode but the I think more interesting answer to your question
00:46:45 is that I've had migraines my whole life like I've suffered with it really intense migraines ocular migraines ones
00:46:52 where my arm would go numb and I just started having to go to so many doctors to learn about it and I started you know
00:46:59 learning that we don't really know that much we know a lot but it's wild to go into one of the best neurologists in the
00:47:05 world who's like yeah we don't know we don't know we don't know and that fascinated me that's one of the worst
00:47:11 pains you can probably have all that stuff and we don't know the source we don't know the source and there is
00:47:17 something really fascinating about when your left arm starts going numb and you start not being able to see out of the
00:47:23 left side of both your eyes and I remember when the migraines get really bad there it's like a mini-stroke almost
00:47:29 and you're able to see words on a page but I can't read them they just look like symbols to me so there's something
00:47:35 just really fascinating to me about your brain just being able to stop functioning and I so I just wanted to
00:47:41 learn about it study about it I did all these weird alternative treatments they got this piercing in here that actually
00:47:47 works I've tried everything and then both my parents had strokes so when both of my parents had strokes I became sort
00:47:55 of the person who had to decide what was gonna happen with their recovery which is just a wild thing to have to deal
00:48:01 with it you know 28 years old when it happened and I started spending basically all day every day and I see
00:48:07 used with neurologists learning about what happened to my dad's brain and why he can't move his left arm but he can
00:48:13 move his right leg but he can't see out of that you know and then my mom had another stroke
00:48:18 in a different part of the brain so I started having to learn what parts of the brain did what and so that I
00:48:23 wouldn't take the behavior so personally and so that I would be able to manage my expectations in terms of their recovery
00:48:29 so my mom because it affected a lot of her frontal lobe changed a lot as a person she was way more emotional she
00:48:35 was way more micromanage she was forgetting certain things so it broke my heart less when I was able to know oh
00:48:41 yeah will destroy hit this part of the brain and that's the one that's responsible for short-term memory and
00:48:45 that's responsible for long-term memory set it up and then my brother just got something called viral encephalitis
00:48:52 which is an infection inside the brain and so Wow it was kind of wild that I was able to go oh I know exactly what's
00:48:59 happening here and I know you know so so that's allows you to have some more compassion for the struggles that people
00:49:06 have but does it take away some of the magic for some of the from this some of the more positive experiences in life
00:49:13 sometimes and I don't I don't I'm such a control addict that you know I think our biggest if someone like me my biggest
00:49:20 dream is to know why someone's doing that's what stand-up is is just trying to figure out why or that's what writing
00:49:25 is that's what acting is that's what performing is it's trying to figure out why someone would do something as an
00:49:29 actor you get a piece of you know material and you go this person why would he say that why would he pick up
00:49:34 that cup why would she walk over here it's really why why would why so I think neurology is if you're trying to figure
00:49:40 out human motives and why people do what they do it'd be crazy not to understand how neuro chemicals motivate us I also
00:49:48 have a lot of addiction in my family and hardcore drug addiction and mental illness and in order to cope with it you
00:49:54 really have to understand that borderline personality disorder schizophrenia and drug addiction so I
00:50:01 have a lot of people I love that suffer from drug addiction and alcoholism and the first thing they started teaching
00:50:06 you is it's not a choice these people's dopamine receptors don't hold dopamine the same ways yours do their frontal
00:50:12 lobe is underdeveloped like you know and that really helped me to navigate dealing loving people that were addicted
00:50:22 to substances I want to be careful with this question but how much money do you have how much can I borrowed
00:50:36 okay know is how much control how much despite the chemical imbalances or the biological limitations that each of our
00:50:44 individual myself how much mind-over-matter is there so through things and I've known people with with
00:50:53 clinical depression and so it's it's always a touchy subject to say how much they can really help but very what can
00:51:01 you yeah what what can because you you've you've talked about codependency you talked about issues the your
00:51:08 struggle through and nevertheless you choose to take a journey of healing and so on so that's your choice that's your
00:51:15 actions so how much can you do to help fight the limitations of the your chemicals in your brain that's such an
00:51:22 interesting question I don't think I'm at all qualified to answer but I'll say what I do know and really quick just the
00:51:28 definition of codependency I think a lot of people think of codependency is like two people that can't stop hanging out
00:51:35 you know or like you know that's not totally off but I think for the most part my favorite definition of
00:51:40 codependency is the inability to tolerate the discomfort of others you grew up in an alcoholic home you grow up
00:51:45 around mental illness you grow up in chaos you have a parent that's a narcissist you basically are wired to
00:51:52 just people please worry about others be perfect walk on eggshells shape-shift to accommodate other people so codependency
00:52:02 is a very active wiring issue that you know doesn't just affect your romantic relationships it affects you being a
00:52:09 boss it affects you in the world online you know you get one negative comment and it throws you for two weeks you know
00:52:16 it also is linked to eating disorders and other kinds of addictions so it's it's it's a very big thing and I think a
00:52:21 lot of people sometimes to only think that it's in a romantic relationship so I always feel the need to say that and
00:52:27 also one of the reasons I love the idea of robots so much because you don't have to walk on eggshells around them you
00:52:31 don't have to worry they're gonna get mad at you yet but you there's no codependence are hypersensitive to the
00:52:40 needs and moods of others and it's very exhausting it's depleting just a well one conversation about where we're gonna go
00:52:46 to dinner is like you want to go get Chinese food we just had Chinese food well wait are
00:52:51 you mad well no I didn't mean it's just like that codependents live in this everything means something and humans
00:53:00 can be very emotionally exhausting why did you look at me that way what are you thinking about what was that why'd you
00:53:03 check your phone it's just this it's a hypersensitivity that can be incredibly time-consuming which is why I love the
00:53:11 idea of robots just subbing in even I've had a hard time running TV shows and stuff because even asking someone to do
00:53:16 something I don't want to come off like a I'm very concerned about what other people think of me how I'm
00:53:21 perceived which is why I think robots will be very beneficial for for codependence by the way just a real
00:53:27 quick tangent that skill or flaw whatever you want to call it is actually really useful for if you ever do start
00:53:34 your own podcast for interviewing because you're now kind of obsessed about the mindset of others and it makes
00:53:42 you a good sort of listener and talker with so I think what's your name from NPR talked about Terry Gross talked
00:54:02 about having that so yeah oh I don't get that at all I mean you have to put yourself in the
00:54:08 mind of the person you're spoken to just in terms of yeah I am starting a podcast and the reason I haven't is because I'm
00:54:13 codependent I'm too worried it's not gonna be perfect yeah so a big codependent adage is perfectionism leads
00:54:19 to procrastination which leads to paralysis so how do you sorry take a million tangents how do you survive and
00:54:24 social media gives you exceptionally active but by the way I took you on a tangent and didn't answer your last
00:54:29 question about how much we can control I want you to yeah we'll return it or maybe night the answer is we can but you
00:54:38 know one of the things that I'm fascinated by is you know the first thing you learn when you go into 12-step
00:54:43 programs or addiction recovery I mean this is you know genetics loads the gun environment pulls the trigger and there
00:54:50 are certain parts of your genetics you cannot control I come from a lot of you know a lot of mental illness there's
00:55:01 certain things I cannot control and a lot of things that maybe we don't even know yet what we can and can't because
00:55:06 of how little we actually know about the brain but we also talk about the warrior spirit and there are some people that
00:55:12 have that warrior spirit and we don't necessarily know what that engine is whether it's you get dopamine from
00:55:20 succeeding or achieving or martyring yourself or or that tension you get from growing so a
00:55:26 lot of people were like oh this person can edify themselves and overcome but if you're getting attention from improving
00:55:33 yourself you're going to keep wanting to do that so that is something that helps a lot of in terms of changing your brain
00:55:40 if you talk about changing your brain to people and talk about what you're doing to overcome set obstacles you're going
00:55:44 to get more attention from them which is going to fire off your reward system and then you're gonna keep doing it
00:55:49 see yeah so you can leverage that momentum so this is why in any toe step program you go into a room and you talk
00:55:55 about your progress because then everyone claps for you and then you're more motivated to keep going so that's
00:56:00 why we say you're only as sick as the secrets you keep because if you keep things secret you know there's no one
00:56:05 going and guiding you to go in a certain direction it's based on right we're sort of designed to get approval from the
00:56:11 tribe or from a group of people because our brain you know translates it to safety so in that case the tribe is a
00:56:18 positive one that helps you go this direction so that's why it's so important to go into a room and also say
00:56:25 hey I wanted to use drugs today and people go they go me too and then feel less alone and you feel less like
00:56:31 you're you know have been castigated from the pack or whatever and then you say and I do haven't you get a chip when
00:56:36 you haven't drank for 30 days or 60 days or whatever you get little rewards so talking about a pack that's not at all
00:56:44 healthy or good but in fact is often toxic social media so you're one of my favorite people on Twitter and Instagram
00:56:52 to  sort of just both the comedy and the insight and just fun how do you prevent social media from destroying
00:56:59 your mental health I haven't I haven't it's the next big epidemic isn't it I don't think I have I don't I don't think
00:57:10 it's moderation the answer what maybe but you can do a lot of damage in a moderate way I mean I guess again it
00:57:18 depends on your goals you know and and I think for me the way that my addiction to social media I'm happy to call it an
00:57:24 addiction I mean and I define as an addiction because it stops being a choice there are times I just reach over
00:57:29 and I'm like that was that was weird Wow is weird I'll be driving sometimes my bag oh my god my arm just went to my
00:57:38 home you know I can put it down I can't take time away from it but when I do I get antsy yeah I get restless irritable
00:57:44 and discontent I mean that's kind of the definition isn't it so I think by no means do I have a healthy relationship
00:57:51 with social media I'm sure there's a way to but I think I'm especially a weirdo in this space because it's easy to
00:57:59 conflate is this work is this I can always say that it's for work right you know but I mean you're don't you get the
00:58:04 same kind of thing as you get from when a roomful of people laughs your jokes I mean I see especially the way you do
00:58:12 Twitter it's an extension of your comedy in a way so a big break from Twitter though a really big break I took like
00:58:18 six months off or something for a while because it was just like it seemed like it was all kind of politics and it was
00:58:23 just a little bit it wasn't giving me dopamine because there was like this weird a lot of
00:58:29 feedback so I had to take a break from it and then go back to except feel like I didn't have a healthy relationship I
00:58:35 ever tried the I don't know if I believe him but Joe Rogan seems to not read comments have you and he's one of the
00:58:43 only people at the scale like a year level who at least claims not to read so like because you and him swim in this
00:58:55 space of tense ideas yeah they get get get the toxic folks growled up I think rogue I don't I don't know I don't mmm I
00:59:05 think he probably looks at YouTube like the likes and that you know I think if something's if he doesn't know I don't
00:59:12 know I'm sure he would tell the truth you know I'm sure he's got people that look at them and he's like disgusted
00:59:18 great or I don't you know like I'm sure he gets it you know I I can't picture him like in the weeds on know for sure I
00:59:24 mean I nameste she's saying that just it's it's  it's a to feedback yeah we're just a
00:59:32 feedback I mean you know look like I think that our brain is designed to get intel on how we're perceived so that we
00:59:40 know where we stand right that's our whole deal right as humans we want to know where we stand we walk into a room
00:59:45 and we go who's the most powerful person in here I gotta talk to him and get in their good graces it's just were
00:59:49 designed to rank ourselves right and constantly know our rank and social media because of you can't figure out
00:59:58 your rank with 500 million people you get small you know cert brain is like what's my rank what's my and especially
01:00:03 for following people I think the the big the the interesting thing I think I may be be able to able to say about this
01:00:10 besides my speech impediment is that I did start muting people that ranked wildly higher than me because it is just
01:00:19 stressful on the brain to constantly look at people that are incredibly successful so you keep feeling bad about
01:00:26 yourself you know I think that that is like cutting to a certain extent just like look at me looking at all these
01:00:31 people that have so much more money than me and so much more success than me it's making me feel like a failure even
01:00:37 though I don't think I'm a failure but it's easy to frame it so that I can feel that but yeah that's really interesting
01:00:45 especially if they're close to like if there are other comedians like that or whatever that's that's it's really
01:00:51 disappointing to me I do the same thing as well so other successful people they're really close to what I do it I
01:00:57 don't know I I wish I could just admire ya and for it not to be a distraction but that's why you are where you are cuz
01:01:03 you don't just didn't Meyer you're competitive and you want to win so it's also the same thing that bums you out
01:01:08 when you look at this is the same reason you are where you are so that's why I think it's so important to learn about
01:01:13 neurology and addiction because you're able to go like oh this same instinct so I'm very sensitive and I and I sometimes
01:01:19 don't like that about myself that I'm like well that's the reason I'm able to write good stand-up and that's the
01:01:24 reason and that's reason I'm able to be sensitive to feedback and go that joke should have been better I can make that
01:01:28 better so it's a kind of thing where it's like you have to be really sensitive in your work in the second you
01:01:33 leave you've got to be able to turn it off it's about developing the muscle being able to know when to let it be a superpower
01:01:40 when it's gonna hold you back and be an obstacle so I try to not be in that black and white of like you know being
01:01:46 competitive is bad or being jealous of someone just to go like oh there's that thing that makes me really successful in
01:01:52 a lot of other ways but right now it's making me feel that well I'm kind of looking to you because your ear
01:01:59 basically a celebrity the famous sort of world-class comedian and so I feel like you're the right person to be one of the
01:02:06 key people to define what's the healthy path forward with social media so I because we're all trying to figure it
01:02:14 out now and it's a I'm curious to see where it involves and I think you're at the center of that so likely you know
01:02:21 there's you know trying to leave Twitter and then come back how can I do this in a healthy way you mean you have to keep
01:02:28 trying exploring it because it's being I have a couple answers I think you know I hire a company to do some of my social
01:02:35 media for me you know so it's also being able to go okay I make a certain amount of money by doing this but now let me be
01:02:40 a good businessperson and say I'm gonna pay you this amount to run this for me so I'm not 24/7 in the weeds hash
01:02:46 tagging and responding and just it's a lot to take on it's a lot of energy to take on but at the same time part of
01:02:52 what I think makes me successful in social media if I am is that people know I'm actually doing it and then I am an
01:02:57 engaging and I'm responding and developing a personal relationship with complete strangers so I think you know
01:03:04 figuring out that balance and really approaching it as a business you know that's what I try to do it's not dating
01:03:10 it's not you know I try to just be really objective about okay here's what's working here's what's not working
01:03:14 and in terms of taking the break from Twitter this is a really savage take but because I don't talk about my politics
01:03:24 publicly being on Twitter right after the last election was not gonna be beneficial because there was gonna be
01:03:30 had to take a side you had to be political in order to get any kind of retweets or likes and I just wasn't
01:03:37 interested in doing that because you were gonna lose as many people as you were gonna gain and it was gonna all
01:03:41 complain in the wash so I was just like the best thing I can do for me business-wise is to just abstain you
01:03:51 know and you know the robot I joke about her replacing but she does do half of my social media
01:03:56 you know yeah because it's I don't want people to get sick of me I don't want to be redundant there are times when I
01:04:02 don't have the time or the energy to make a funny video but I know she's gonna be compelling and interesting and
01:04:07 that's something that you can't see every day you know of course the the the humor comes from Europe I mean the
01:04:14 cleverness the wit the humor comes from you when you film the robot that's kind of the trick of it I mean the the robot
01:04:22 is not quite there to making to do anything funny the absurdity is revealed through the
01:04:27 filmmaker in that case where whoever is interacting not through the the actual robot you know being who she is let me
01:04:40 sort of love okay how do what is it they have what is it well first an engineering question I
01:04:46 know I know you're you're not an engineer but how difficult do you think is it to build an AI system that you can
01:04:54 have a deep fulfilling monogamous relationship with sort of replace the human human relationships that we value
01:05:02 I think anyone can fall in love with anything you know like how often have you looked back in someone like I ran
01:05:11 into someone the other day that I was in love with then I was like hey it was like there was nothing there no there
01:05:18 was nothing there like do you know like where you're able to go like oh that was weird oh honey you know I were able to me as
01:05:26 from a distant past or something yeah when you're able to go like I can't believe we had an incredible connection
01:05:34 and now it's just I do think that people will be in love with robots probably even more deeply with humans
01:05:41 because it's like when people mourn their animals when their animals die they're always it's sometimes harder
01:05:48 than mourning a human because you can't go well he was kind of an but like he didn't pick me up from school
01:05:53 you know it's like you're able to get out of your grief a little bit you're able to kind of be oh he was kind of
01:05:59 judgmental or she was cut you know with a robot it's there's something so pure about an innocence and fish and
01:06:05 childlike about it that I think it probably will be much more conducive to a narcissistic love
01:06:14 for sure at that but it's not like well he cheated us she can't cheat she can't leave you she can't you know well a bear
01:06:22 claw leaves your life and maybe a new version or somebody else will enter there will you miss bear claw for guys
01:06:30 that have these sex robots they're building a nursing home for the bodies well that are now rusting because they
01:06:37 don't want to part with the bodies because they have such an intense emotional connection to it I mean it's
01:06:42 kind of like a car club a little bit you know like it's it you know but I'm not saying this is right I'm not saying it's
01:06:51 cool it's weird it's creepy but we do anthropomorphize things with faces and we do develop emotional connections to things
01:06:58 I mean we're there certain have you ever tried to like throw it I can't even throw away my teddy bear from when I was
01:07:03 a kid it's a piece of trash and it's upstairs like it's like why can't I throw that away it's bizarre you know
01:07:09 and there's something kind of beautiful about that there's something it gives me hope in in humans because I see humans
01:07:15 do such horrific things all the time and maybe I'm too I see too much of it frankly but there's something kind of
01:07:22 beautiful about the way we're able to have emotional connections to objects which you know a lot of I mean it's kind
01:07:31 of specifically I think Western right that we don't see objects as having Souls like that's kind of specifically
01:07:38 us but I don't think it's so much that we're objectifying humans with these sex robots were kind of humanizing
01:07:46 objects right so there's something kind of fascinating in our ability to do that because a lot of us don't humanize
01:07:52 humans so it's just a weird little place to play in and I think a lot of people I mean a lot of people will be marrying
01:07:58 these things is my guess so you've asked the question let me ask it of you so what is love you have a bit of
01:08:05 a brilliant definition of love as being willing to die for someone we who you yourself want to kill so that's
01:08:12 that's kind of fun first of all that's brilliant that's a really good definition I think you'll stick with me
01:08:18 for a long time is this how little of a romantic I am a plane went by when you said that and my brain is like you're
01:08:25 gonna need to rerecord that and I want you to get into post and then not be able to use and I'm a romantic as a mom
01:08:35 I actually I cannot be conscious of the fact that I heard the plane and it made me feel like how amazing it is that we
01:08:44 live in a world planes and I just why haven't we evolved past planes and why can't they make them quieter
01:08:54 yeah yeah this my definition of love what what yeah what's your producing dopamine consistent output of oxytocin
01:09:05 with the same person dopamine is a positive thing what about the negative what about the fear and the
01:09:15 insecurity the longing anger all that kind of stuff I think that's part of love you know I think you don't I think
01:09:22 that love brings out the best in you but it also if you don't get angry upset it's you know I don't know I think that
01:09:27 that's that's part of it I think we have this idea that love has to be like really you know placid or something
01:09:33 I only saw stormy relationships growing up so I don't I don't have a judgment on how a relationship should look but I do
01:09:43 think that this idea that love has to be eternal is is really destructive is really destructive and self-defeating
01:09:53 and a big source of stress for people I mean I'm still figuring out love I think we all kind of are but I do kind of
01:10:01 stand by that definition and I think that  I think for me love is like just being able to be authentic with somebody
01:10:08 it's very simple I know but I think for me it's about not feeling pressure to have to perform or impress somebody just
01:10:15 feeling truly like accepted unconditionally by someone although I do believe love should be conditional that
01:10:23 might be a hot take I think everything should be conditional I think if someone's behavior I don't think love
01:10:28 should just be like I'm in love with you now behave however you want forever this is unconditional I
01:10:35 think love is a daily action it's not something you just like get ten you're on and then get to behave however you
01:10:41 want because we said I love you 10 years ago it's a daily it's a verb well there's some things there you see if you
01:10:49 make it if you explicitly make it clear that it's conditional it takes away some of the magic of it so there's some
01:10:55 stories we tell ourselves that we don't want to make explicit about love I don't know maybe that's the wrong way to think
01:11:01 of it maybe you want to be explicit in relationships so something love is a business decision like I do in a good
01:11:11 way yeah I think that love is not just when you're across from somebody it's when I go to work can I focus do I am I
01:11:16 worried about you am I stressed out about you am I you're not responding to me you're not reliable like I think that
01:11:23 being in a relationship the kind of love that I would want is the kind of relationship where when we're not
01:11:28 together it's not draining me causing me stress making me worry you know and sometimes passion that word
01:11:36 you know we'd get murky about it but I think it's also like I can be the best version of myself when the person's not
01:11:41 around and I don't have to feel abandoned or scared or any of these kind of other things so it's like love you
01:11:47 know for me I think is I think it's a flow Barre quote and I'm gonna butcher it but I think it's like be you know
01:11:53 boring in your personal life so you could be violent and take risks in your professional life is that it I got it
01:11:58 wrong something like that but I do think that it's being able to align values in a way to where you can also thrive
01:12:05 outside of the relationship some of the most successful people I know are sort of happily married and have kids and so
01:12:11 on it's it's always funny boring boring is okay foreign is serenity and it's funny how that those elements actually
01:12:18 make you much more productive I don't understand the I don't think relationships should drain you and take
01:12:23 away energy that you could be using to create things that generate pride okay did you say your relationship of love
01:12:29 yet have you said you're really your definition of love my definition of love no I did not say it we're out of time
01:12:39 do what when you have when you have a podcast maybe you can invite me on alone oh no I already did you're doing it
01:12:46 we've already talked about this and because I also have codependency I have to say yes yeah actually what the I
01:12:58 wondered whether when I I asked if we could talk today after sort of doing more research and reading some of your
01:13:05 book I start to wonder did she just feel pressured to say yes no I actually because I am putting on but I've been
01:13:15 recovered for codependents so I actually do I don't do anything I don't want to do you really you got anywhere saying no
01:13:25 but good November I moved it from 1 to 2 yeah just yeah I don't do anything I don't want to do yeah you're ahead of me
01:13:41 in that okay so do you think about your mortality yes it is a big part of how I was able to sort of like kickstart my
01:13:49 codependence recovery my dad passed a couple years ago and when you have someone close to you in your life died
01:13:55 everything gets real clear in terms of how were a speck of dust who's only here for a certain amount of time what do you
01:14:03 think is the meaning of it all like what the speck of dust what what's maybe in your own life
01:14:11 what's the goal the purpose of your existence is there one well you you're exceptionally ambitious you've created
01:14:19 some incredible things in different disciplines we're all just managing our terror because we know we're gonna die
01:14:26 so we create and build all these things and rituals and religions and you know robots and whatever we need to do to
01:14:33 just distract ourselves from imminent rotting rotting yeah we're all dying and you know III you know I got very into
01:14:42 terror management theory when my dad died and and it resonated it helped me and everyone's got their own religion or
01:14:50 sense of purpose or thing that distracts them from the horrors of being what's terror management theory
01:14:57 terror management is basically the idea that since we're the only animal that knows they're gonna die we have to
01:15:04 basically distract ourselves with awards and achievements and games and sperm whatever just in order to distract
01:15:13 ourselves from the terror we would feel if we really processed the fact that we could not only we are gonna die but also
01:15:18 could die at any minute because we're only superficially at the top of the food chain and you know we technically
01:15:26 were the top of the food chain if we have houses and guns and stuff machines but if me and a lion are in the woods
01:15:33 together I'm it's most things could kill us I mean a bee can kill some people like something this big can kill a lot
01:15:39 of humans like you know so it's basically just to manage the terror that we all would feel if we were able to
01:15:45 really be awake because we're mostly zombies right new job school religion zoo so go to sleep drink through the
01:15:52 football the relationship don't mean love but you know we're kind of just like trudging along like zombies for the
01:16:00 most part and then I think that fear of death as some motivation yes well I think I speak for a lot of people in
01:16:08 saying that I can't wait to see what your terror creates in the in the next few years I'm a huge fan wouldn't you
01:16:19 thanks for listening to this conversation with Whitney Cummings and thank you to our presenting sponsor cash
01:16:26 app download it and use code let's podcast you'll get ten dollars and ten dollars will go to first stem education
01:16:33 nonprofit that inspires hundreds of thousands of young minds to learn and to dream of engineering our future if you
01:16:40 enjoy this podcast subscribe on youtube give it five stars an apple podcast supported on patreon or connect with me
