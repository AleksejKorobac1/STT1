00:00:00 - The following is a conversation with Noam Chomsky. He's truly one of the great minds of our time
00:00:06 and is one of the most cited scholars in the history of our civilization. He has spent over 60 years at MIT
00:00:13 and recently also joined the University of Arizona where we met for this conversation, but it was at MIT about four and 1/2 years ago
00:00:21 when I first met Noam. My first few days there I remember getting into an elevator at Stata Center,
00:00:27 pressing the button for whatever floor, looking up and realizing it was just me and Noam Chomsky
00:00:33 riding the elevator, just me and one of the seminal figures of linguistics, cognitive science, philosophy,
00:00:40 and political thought in the past century if not ever. I tell that silly story because I think life
00:00:46 is made up of funny little defining moments that you never forget for reasons that may be too poetic
00:00:52 to try and explain, that was one of mine. Noam has been an inspiration to me and millions of others. It was truly an honor for me
00:01:02 to sit down with him in Arizona. I traveled there just for this conversation, and in a rare, heartbreaking moment
00:01:10 after everything was set up and tested the camera was moved and accidentally the recording button was pressed stopping the recording.
00:01:18 So I have good audio of both of us but no video of Noam, just a video of me and my sleep deprived but excited face
00:01:26 that I get to keep as a reminder of my failures. Most people just listen to this audio version
00:01:32 for the podcast as opposed to watching it on YouTube, but still it's heartbreaking for me.
00:01:39 I hope you understand and still enjoy this conversation as much as I did. The depth of intellect that Noam showed
00:01:45 and his willingness to truly listen to me, a silly looking Russian in a suit was humbling and something I'm deeply grateful for.
00:01:55 As some of you know, this podcast is a side project for me where my main journey and dream is to build AI systems that do some good for the world.
00:02:05 This latter effort takes up most of my time but for the moment has been mostly private,
00:02:10 but the former, the podcast is something I put my heart and soul into and I hope you feel that
00:02:16 even when I screw things up. I recently started doing ads at the end of the introduction.
00:02:22 I'll do one or two minutes after introducing the episode and never any ads in the middle that break the flow of the conversation.
00:02:29 I hope that works for you and doesn't hurt the listening experience. This is the Artificial Intelligence podcast.
00:02:37 If you enjoy it, subscribe on YouTube, give it five stars on Apple Podcast, support it on Patreon, or simply contact with me on Twitter
00:02:45 @lexfridman spelled F-R-I-D-M-A-N. This show is presented by Cash App, the number one finance app on the App Store.
00:02:54 I personally use cash app to send money to friends, but you can also use it to buy, sell,
00:02:58 and deposit Bitcoin in just seconds. Cash App also has a new investing feature. You can buy fractions of a stock,
00:03:05 say $1 worth, no matter what the stock price is. Broker services are provided by Cash App Investing,
00:03:11 a subsidiary of Square and member SIPC. I'm excited to be working with Cash App to support one of my favorite organizations called the FIRST
00:03:20 best known for their FIRST robotics and LEGO competitions. They educate and inspire hundreds of thousands of students
00:03:27 in over 110 countries and have a perfect rating on Charity Navigator which means the donated money
00:03:33 is used to maximum effectiveness. When you get Cash App in the App Store or Google Play and use code LexPodcast you'll get $10
00:03:43 and Cash App will also donate $10 to FIRST, which again is an organization that I've personally seen inspire girls and boys
00:03:51 to dream of engineering a better world. And now here's my conversation with Noam Chomsky. I apologize for the absurd
00:03:59 philosophical question, but if an alien species were to visit Earth, do you think we would be able
00:04:08 to find a common language or protocol of communication with them? - [Noam] There are arguments to the effect that we could.
00:04:18 In fact, one of them was Marv Minsky's. Back about 20 or 30 years ago he performed a brief experiment with a student of his, Daniel Bobrow
00:04:31 they essentially ran the simplest possible Turing machines just free to see what would happen.
00:04:39 And most of them crashed, either got into an infinite loop or were stopped, the few that persisted essentially gave something like arithmetic.
00:04:55 And his conclusion from that was that if some alien species developed higher intelligence they would at least have arithmetic.
00:05:07 They would at least have what the simplest computer would do and in fact he didn't know that at the time,
00:05:16 but the core principles of natural language are based on operations which yield something
00:05:25 like arithmetic in the limiting case, in the minimal case. So it's conceivable that a mode of communication
00:05:34 could be established based on the core properties of human language and the core properties of arithmetic
00:05:41 which maybe are universally shared so it's conceivable. - [Lex] What is the structure of that language,
00:05:50 of language as an internal system inside our mind versus an external system as it's expressed?
00:05:59 - [Noam] It's not an alternative. It's two different concepts of language. - [Lex] Different.
00:06:03 - [Noam] It's a simple fact that there's something about you, a trait of yours, part of the organism you that determines
00:06:13 that you're talking English and not Tagalog, let's say. So there is an inner system. It determines the sound and meaning
00:06:23 of the infinite number of expressions of your language. It's localized, it's not in your foot obviously it's in your brain.
00:06:31 If you look more closely it's in specific configurations of your brain and that's essentially like the internal structure of your laptop.
00:06:42 Whatever programs it has are in there. Now, one of the things you can do with language, it's a marginal thing in
00:06:47 fact is use it to externalize what's in your head. I think most of your use of language is thought,
00:06:57 internal thought, but can do what you and I are now doing. We can externalize it.
00:07:02 Well, the set of things that we're externalizing are an external system, they're noises in the atmosphere,
00:07:11 and you can call that language in some other sense of the word, but it's not a set of alternatives.
00:07:16 These are just different concepts. - [Lex] So how deep do the roots of language go in our brain?
00:07:23 - Well-- - Our mind, is it yet another feature like vision? Or is it something more fundamental
00:07:28 from which everything else springs in the human mind? - [Noam] Well in a way it's like vision. There's something about our genetic endowment
00:07:38 that determines that we have a mammalian rather than an insect visual system. And there's something in our genetic endowment
00:07:47 that determines that we have a human language faculty. No other organism has anything remotely similar.
00:07:55 So in that sense it's internal. Now, there is a long tradition which I think is valid going back centuries to the
00:08:01 early scientific revolution at least that holds that language is the sort of the core of human cognitive nature.
00:08:13 It's the source, it's the mode for constructing thoughts and expressing them and that is what forms thought
00:08:22 and it's got fundamental creative capacities. It's free, independent, unbounded and so on.
00:08:31 And undoubtedly I think the basis for our creative capacities and the other remarkable human capacities that lead
00:08:42 to the unique achievements and not so great achievements of the species. - [Lex] The capacity to think and reason.
00:08:53 Do you think that's deeply linked with language? Do you think the internal language system is essentially
00:09:01 the mechanism by which we also reason internally? - [Noam] It is undoubtedly the mechanism by which we reason.
00:09:06 There may also be other, there are undoubtedly other faculties involved in reasoning. We have a kind of scientific faculty.
00:09:17 Nobody knows what it is, but whatever it is that enables us to pursue certain lines of endeavor
00:09:24 and inquiry and to decide what makes sense and doesn't make sense and to achieve a certain degree of understanding in the
00:09:32 world that uses language but goes beyond it just as using our capacity for arithmetic is not the same as having the capacity.
00:09:45 - [Lex] The idea of capacity, our biology, evolution, you've talked about it defining essentially our capacity,
00:09:52 our limit and our scope. Can you try to define what limit and scope are, and the bigger question,
00:09:58 do you think it's possible to find the limit of human cognition? - [Noam] Well that's an interesting question.
00:10:09 It's commonly believed, most scientists believe that human intelligence
00:10:15 can answer any question in principle. I think that's a very strange belief. If we're biological organisms which are not angels
00:10:26 then our capacities ought to have scope and limits which are interrelated.
00:10:34 - [Lex] Can you define those two terms? - [Noam] Well, let's take a concrete example. Your genetic endowment, it determines
00:10:44 that you can have a mammalian visual system and arms and legs and so on and therefore become a rich, complex organism,
00:10:53 but if you look at that same genetic endowment it prevents you from developing in other directions.
00:11:00 There's no kind of experience which would yield the embryo to develop an insect visual system
00:11:08 or to develop wings instead of arms. So the very endowment that confers richness and complexity also sets bounds on what can be attained.
00:11:23 Now I assume that our cognitive capacities are part of the organic world therefore they should have the same properties.
00:11:32 If they had no built-in capacity to develop a rich and complex structure we would understand nothing
00:11:41 just as if your genetic endowment did not compel you to develop arms and legs you would just be some kind
00:11:50 of a random ameboid creature with no structure at all so I think it's plausible to assume that there are limits,
00:12:00 and I think we even have some evidence as to what they are. So for example there's a classic moment in the history of science at the time of Newton.
00:12:11 There was from Galileo to Newton modern science developed on a fundamental assumption which Newton also accepted,
00:12:20 namely that the world, the entire universe is a mechanical object and by mechanical they meant something like the kinds of artifacts
00:12:30 that were being developed by skilled artisans all over Europe, the gears, levers, and so on.
00:12:37 And their belief was, well the world is just a more complex variant of this. Newton to his astonishment and distress proved that there
00:12:49 are no machines, that there's interaction without contact. His contemporaries like Leibniz and Huygens
00:12:57 just dismissed this as returning to the mysticism of the Neo-Scholastics and Newton agreed.
00:13:05 He said, "It is totally absurd. "No person of any scientific intelligence "could ever accept this for a moment."
00:13:13 In fact, he spent the rest of his life trying to get around it somehow as did many other scientists.
00:13:20 That was the very criterion of intelligibility for say Galileo or Newton. Theory did not produce an intelligible world
00:13:31 unless you could duplicate it in a machine and he showed you can't, there are no machines, any. Finally after a long
00:13:37 struggle, took a long time scientists just accepted this as common sense, but that's a significant moment.
00:13:47 That means they abandoned the search for an intelligible world and the great philosophers of the time understood that very well.
00:13:57 So for example, David Hume in his encomium to Newton wrote that, who was the greatest thinker ever and so on.
00:14:05 He said that he unveiled many of the secrets of nature but by showing the imperfections of the mechanical philosophy, mechanical science
00:14:17 he left us with, he showed that there are mysteries which ever will remain, and science just changed its goals.
00:14:26 It abandoned the mysteries. It can't solve it, they'll put it aside. We only look for intelligible theories.
00:14:34 Newton's theories were intelligible it's just what they described wasn't. Well, Locke said the same thing.
00:14:42 I think they're basically right and if so that showed something about the limits of human cognition. We cannot attain the goal
00:14:49 of understanding the world, of finding an intelligible world. This mechanical philosophy, Galileo to Newton,
00:15:03 there's a good case that can be made that that's our instinctive conception of how things work. So if say infants are tested with things
00:15:15 that if this moves and then this moves they kind of invent something that must be invisible that's in between them that's
00:15:22 making them move and so on. - [Lex] Yeah, we like physical contact. Something about our brain seeks--
00:15:28 - [Noam] Makes us want a world like then just like it wants a world that has regular geometric figures so for example Descartes
00:15:38 pointed this out that if you have an infant who's never seen a triangle before and you draw a triangle
00:15:47 the infant will see a distorted triangle not whatever crazy figure it actually is, you know, three lines not coming quite together
00:15:58 or one of them a little bit curved and so on. We just impose a conception of the world in terms of perfect geometric objects.
00:16:09 It's now been shown that it goes way beyond that, that if you show on a tachistoscope, let's say,
00:16:16 a couple of lights shining, you do it three or four times in a row what people actually see
00:16:22 is a rigid object in motion not whatever's there. We all know that from a television set basically.
00:16:31 - [Lex] So that gives us hints of potential limits to our cognition? - I think it does,
00:16:36 but it's a very contested view. If you do a poll among scientists they'll say impossible. We can understand anything.
00:16:46 - [Lex] Let me ask and give me a chance with this. So I just spent a day at a company called Neuralink,
00:16:52 and what they do is try to design what's called a brain machine, a brain computer interface.
00:16:59 So they try to just do thousands of readings in the brain, be able to read what the neurons are firing
00:17:05 and then stimulate back, so two-way. Do you think their dream is to expand the capacity of the brain to attain information,
00:17:16 sort of increase the bandwidth at which we can search Google kind of thing? Do you think our cognitive
00:17:22 capacity might be expanded, our linguistic capacity, our ability to reason might be expanded by adding
00:17:29 a machine into the picture? - [Noam] It can be expanded in a certain sense, but a sense that was known
00:17:35 thousands of years ago. A book expands your cognitive capacity, okay, so this could expand it, too.
00:17:46 - [Lex] But it's not a fundamental expansion. It's not totally new things could be understood.
00:17:51 - [Noam] Well, nothing that goes beyond our native cognitive capacities just like you can't turn the visual system
00:17:58 into an insect system. - [Lex] Well, I mean the thought is perhaps you can't directly but you can map.
00:18:07 - [Noam] You could be we know that without this experiment you could map what a bee sees and present it
00:18:16 in a form so that we could follow it. In fact every bee scientist does that. - [Lex] Uh-huh, but you don't think there's something
00:18:23 greater than bees that we can map and then all of a sudden discover something, be able to understand a quantum
00:18:29 world, quantum mechanics, be able to start to be able to make sense. - [Noam] You can, students at MIT study
00:18:37 and understand quantum mechanics. - [Lex] (laughs) But they always reduce it to the infant, the physical, I mean they
00:18:44 don't really understand-- - [Noam] Not physical, that may be another area where there's just a
00:18:50 limit to understanding. We understand the theories, but the world that it describes doesn't make any sense.
00:18:58 So you know the experiment, the Schrodinger's cat for example, can understand the theory
00:19:03 but as Schrodinger pointed out it's not an intelligible world. One of the reasons why Einstein was always very skeptical
00:19:13 about quantum theory, he described himself as a classical realist and wants intelligibility. - [Lex] He has something in
00:19:23 common with infants in that way. So back to linguistics, if you could humor me, what are the most beautiful
00:19:32 or fascinating aspects of language or ideas in linguistics or cognitive science that you've seen
00:19:39 in a lifetime of studying language and studying the human mind? - [Noam] Well, I think the deepest property of language
00:19:50 and puzzling property that's been discovered is what is sometimes called structure dependence.
00:19:57 We now understand it pretty well, but it was puzzling for a long time. I'll give you a concrete example.
00:20:03 So suppose you say, the guy who fixed the car carefully packed his tools. That's ambiguous, he could fix the car carefully
00:20:15 or carefully pack his tools. Now suppose you put carefully in front. Carefully the guy who fixed the car packed his tools.
00:20:25 Then it's carefully packed, not carefully fixed. And in fact you do that even if it makes no sense.
00:20:32 So suppose you say, carefully the guy who fixed the car is tall. You have to interpret it as carefully he's tall
00:20:41 even though that doesn't make any sense. And notice that that's a very puzzling fact because you're relating carefully
00:20:50 not to the linearly closest verb but to the linearly more remote verb. Linear closeness is a easy computation,
00:21:02 but here you're doing a much more, what looks like a more complex computation. You're doing something that's taking you
00:21:09 essentially to the more remote thing, it's now if you look at the actual structure of the sentence where the phrases are and so on turns out
00:21:20 you're picking out the structurally closest thing, but the linearly more remote thing. But notice that what's linear is 100% of what you hear.
00:21:32 You never hear of structure. So what you're doing is and instantly this is universal. All constructions, all languages
00:21:42 and what we're compelled to do is carry out what looks like the more complex computation
00:21:48 on material that we never hear and we ignore 100% of what we hear on the simplest computation.
00:21:57 And by now there's even a neural basis for this that's somewhat understood, and there's good theories
00:22:04 but none that explain why it's true. That's a deep insight into the surprising nature of language with many consequences.
00:22:13 - [Lex] Let me ask you about a field of machine learning and deep learning, there's been a lot of progress
00:22:20 in neural network-based machine learning in the recent decade. Of course, neural network research goes back many decades.
00:22:30 - [Noam] Yeah. - [Lex] What do you think are the limits of deep learning, of neural network-based machine learning?
00:22:38 - [Noam] Well, to give a real answer to that you'd have to understand the exact processes
00:22:44 that are taking place, and those are pretty opaque so it's pretty hard to prove a theorem about what can be done and what can't be done.
00:22:54 But I think it's reasonably clear, I mean, putting technicalities aside what deep learning is doing is taking huge numbers
00:23:04 of examples and finding some patterns. Okay, that could be interesting and in some areas it is but we have to ask here
00:23:12 a certain question. Is it engineering or is it science? Engineering in the sense of just trying to build something
00:23:21 that's useful or science in the sense that it's trying to understand something about elements of the world so it takes a Google parser.
00:23:31 We can ask that question, is it useful? Yeah, it's pretty useful. I use Google Translator so on engineering grounds
00:23:41 it's kinda worth having like a bulldozer. Does it tell you anything about human language? Zero, nothing, and in
00:23:49 fact it's very striking. From the very beginning it's just totally remote from science
00:24:00 so what is a Google parser doing? It's taking an enormous text, let's say The Wall Street Journal corpus and asking,
00:24:08 how close can we come to getting the right description of every sentence in the corpus?
00:24:16 Well, ever sentence in the corpus is essentially an experiment. Each sentence that you produce is an experiment which is,
00:24:25 am I a grammatical sentence? Now the answer is usually yes so most of the stuff in the corpus is grammatical sentences,
00:24:33 but now ask yourself, is there any science which takes random experiments which are carried out for no reason whatsoever and tries
00:24:44 to find out something from them? Like if you're, say, a chemistry PhD student you want to get a thesis can you say,
00:24:51 well I'm just gonna do a lot of, mix a lot of things together, no purpose, and maybe I'll find something.
00:24:59 You'd be laughed out of the department. Science tries to find critical experiments, ones that answer some
00:25:06 theoretical question. Doesn't care about coverage of millions of experiments. So it just begins by being
00:25:13 very remote from science and it continues like that so the usual question that's asked about, say, a Google parser
00:25:23 is how well does it do, or some parser, how well does it do on a corpus? But there's another question that's never asked.
00:25:30 How well does it do on something that violates all the rules of language? So for example, take the structure dependence case
00:25:38 that I mentioned, suppose there was a language in which you used linear proximity as the mode
00:25:47 of interpretation, these deep learning would work very easily on that. In fact, much more easily than on an actual language.
00:25:54 Is that a success? No, that's a failure. From a scientific point of view that's a failure.
00:26:00 It shows that we're not discovering the nature of the system at all 'cause it does just as well or even better
00:26:07 on things that violate the structure of the system, and it goes on from there. It's not an argument against doing it.
00:26:14 It is useful to have devices like this. - [Lex] So yes, neural networks are kind of approximators that look, there's echoes of
00:26:20 the behavioral debates right, behavioralism. - More than echoes. Many of the people in deep learning
00:26:30 say they vindicated. - (laughs) Yeah. - [Noam] Terry Sejnowski for example in his recent book
00:26:35 says this vindicates Skinnerian behaviors and it doesn't have anything to do with it. - [Lex] Yes, but I think there's something
00:26:44 actually fundamentally different when the data set is huge, but your point is extremely well taken. But do you think we can learn, approximate
00:26:55 that interesting, complex structure of language with neural networks that will somehow help us understand the science?
00:27:03 - [Noam] It's possible, I mean, you find patterns that you hadn't noticed, let's say. Could be, in fact it's very much like a kind of linguistics
00:27:13 that's done, what's called corpus linguistics when you, suppose you have some language where all the speakers
00:27:22 have died out but you have records. So you just look at the records and see what you can figure out from that.
00:27:30 It's much better to have actual speakers where you can do critical experiments, but if they're all dead you can't do them
00:27:38 so you have to try to see what you can find out from just looking at the data that's around.
00:27:43 You can learn things. Anthropology is very much like that. You can't do a critical experiment
00:27:50 on what happened two million years ago so you're kinda forced to take what data's around and see what you can figure out from it.
00:27:59 Okay, it's a serious study. - [Lex] So let me venture into another whole body of work and philosophical question.
00:28:08 You've said that evil in society arises from institutions, not inherently from our nature. Do you think most human beings are good,
00:28:17 they have good intent or do most have the capacity for intentional evil that depends on their upbringing,
00:28:24 depends on their environment, on context? - [Noam] I wouldn't say that they don't arise from our nature.
00:28:31 Anything we do arises from our nature. And the fact that we have certain institutions and not others is one mode
00:28:40 in which human nature has expressed itself. But as far as we know, human nature could yield many different kinds of institutions.
00:28:50 The particular ones that have developed have to do with historical contingency, who conquered whom and that sort of thing,
00:29:00 then they're not rooted in our nature in the sense that they're essential to our nature so it's commonly argued that
00:29:06 these days that something like market systems is just part of our nature, but we know from a huge amount of evidence
00:29:18 that that's not true, there's all kinds of other structures. That's a particular fact of a moment of modern history.
00:29:26 Others have argued that the roots of classical liberalism actually argue that what's called sometimes
00:29:34 an instinct for freedom, an instinct to be free of domination by illegitimate authority is the core of our nature.
00:29:43 That would be the opposite of this. And we don't know, we just know that human nature can accommodate both kinds.
00:29:52 - [Lex] If you look back at your life, is there a moment in your intellectual life or life in general that jumps from memory
00:30:00 that brought you happiness that you would love to relive again? - [Noam] Sure, falling in love, having children.
00:30:10 - [Lex] What about, so you have put forward into the world a lot of incredible ideas in linguistics,
00:30:17 in cognitive science, in terms of ideas that just excites you when it first came to you that you love to relive those moments.
00:30:28 - [Noam] Well, I mean, when you make a discovery about something it's exciting like say even the observation of structure dependence
00:30:40 and on from that the explanation for it, but the major things just seem like common sense. So if you go back to, take your question
00:30:53 about external and internal language. You go back to, say, the 1950s almost entirely language is regarded as an external object,
00:31:03 something outside the mind. It just seemed obvious that that can't be true. Like I said, there's something
00:31:10 about you that determines you're talking English not Swahili or something. But that's not really a discovery.
00:31:20 That's just an observation of what's transparent. You might say it's kind of like the 17th century, the beginnings of modern science
00:31:32 17th century, they came from being willing to be puzzled about things that seemed obvious. So it seems obvious that a heavy
00:31:40 ball of lead'll fall faster than a light ball of lead, but Galileo was not impressed by the fact that it seemed obvious.
00:31:52 so he wanted to know if it's true He carried out experiments, actually thought experiments never actually carried
00:31:59 them out which showed that it can't be true, you know. And out of things like that, observations of that kind,
00:32:11 you know, why does a ball fall to the ground instead of rising, let's say?
00:32:16 It seems obvious till you start thinking about it 'cause why does steam rise, let's say. And I think the beginnings of modern linguistics
00:32:27 roughly in the 50s are kind of like that, just being willing to be puzzled about phenomena that looked from some
00:32:33 point of view obvious. And for example a kind of doctrine, almost official doctrine of structural linguistics
00:32:44 in the 50s was that languages can differ from one another in arbitrary ways and each one has to be studied
00:32:55 on its own without any presuppositions and in fact there were similar views among biologists about the nature of
00:33:02 organisms that each one's, they're so different when you look at them that you could be almost anything.
00:33:11 Well in both domains it's been learned that it's very far from true. There are very narrow constraints
00:33:17 on what could be an organism or what could be a language. But these are, you know, that's just the nature of inquiry.
00:33:27 - [Lex] Science in general, yeah, inquiry. So one of the peculiar things about us human beings is our mortality.
00:33:35 Ernest Becker explored it. In general do you ponder the value of mortality? Do you think about your own mortality?
00:33:43 - [Noam] I used to when I was about 12 years old. I wondered, I didn't care much about my own mortality,
00:33:51 but I was worried about the fact that if my consciousness disappeared would the entire universe disappear.
00:34:00 That was frightening. - [Lex] Did you ever find an answer to that question? - [Noam] No, nobody's
00:34:03 ever found an answer, but I stopped being bothered by it. It's kind of like Woody Allen in one of his films.
00:34:10 You may recall he goes to a shrink when he's a child and the shrink asks him, "What's your problem?"
00:34:17 He says, "I just learned that the universe is expanding. "I can't handle that."
00:34:23 - [Lex] (laughs) And another absurd question is, what do you think is the meaning of our existence here,
00:34:32 our life on Earth, our brief little moment in time? - [Noam] That's something we answer by our own activities.
00:34:40 There's no general answer. We determine what the meaning of it is. - [Lex] The action determine the meaning.
00:34:48 - [Noam] Meaning in the sense of significance not meaning in the sense that chair means this, you know,
00:34:55 but the significance of your life is something you create. - Noam, thank you so much for talking today.
00:35:02 It was a huge honor, thank you so much. Thanks for listening to this conversation with Noam Chomsky, and thank you to our
00:35:08 presenting sponsor Cash App. Download it, use code LexPodcast. You'll get $10 and $10 will go to FIRST,
00:35:18 a STEM education nonprofit that inspires hundreds of thousands of young minds to learn and to dream of engineering our future.
00:35:26 If you enjoy this podcast subscribe on YouTube. Give us five stars on Apple Podcast, support on Patreon, or connect with me on Twitter.
