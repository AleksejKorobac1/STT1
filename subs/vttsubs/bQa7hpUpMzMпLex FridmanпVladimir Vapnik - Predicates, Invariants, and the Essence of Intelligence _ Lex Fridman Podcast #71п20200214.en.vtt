WEBVTT
Kind: captions
Language: en

00:00:00.130 --> 00:00:03.290
- The following is a conversation
with Vladimir Vapnik,

00:00:03.290 --> 00:00:07.320
part two, the second time
we spoke on the podcast.

00:00:07.320 --> 00:00:09.870
He's the co inventor of
support vector machines,

00:00:09.870 --> 00:00:12.190
support vector clustering, VC theory

00:00:12.190 --> 00:00:15.010
and many foundational ideas
in statistical learning.

00:00:15.010 --> 00:00:17.400
He was born in the Soviet Union,

00:00:17.400 --> 00:00:20.330
worked at the Institute of
Control Sciences in Moscow,

00:00:20.330 --> 00:00:23.514
then in the U.S., worked at ATT&amp;T,

00:00:23.514 --> 00:00:26.200
NEC Labs, Facebook AI Research,

00:00:26.200 --> 00:00:29.480
and now is a professor
at Columbia University.

00:00:29.480 --> 00:00:33.100
His work has been cited
over 200,000 times.

00:00:33.100 --> 00:00:34.920
The first time we spoke on the podcast

00:00:34.920 --> 00:00:39.030
was just over a year ago,
one of the early episodes.

00:00:39.030 --> 00:00:41.797
This time we spoke after
a lecture he gave titled:

00:00:41.797 --> 00:00:44.480
"Complete Statistical Theory of Learning,"

00:00:44.480 --> 00:00:47.400
as part of the MIT series
of lectures on Deep Learning

00:00:47.400 --> 00:00:49.821
and AI that I organized.

00:00:49.821 --> 00:00:53.760
I'll release the video of the
lecture in the next few days.

00:00:53.760 --> 00:00:56.870
This podcast and the lecture
are independent from each other

00:00:56.870 --> 00:00:59.460
so you don't need one
to understand the other.

00:00:59.460 --> 00:01:03.150
The lecture is quite
technical and math heavy.

00:01:03.150 --> 00:01:05.180
So if you do watch both,
I recommend listening

00:01:05.180 --> 00:01:08.690
to this podcast first, since
the podcast is probably

00:01:08.690 --> 00:01:10.203
a bit more accessible.

00:01:11.250 --> 00:01:14.020
This is The Artificial
Intelligence Podcast.

00:01:14.020 --> 00:01:16.100
If you enjoy it, subscribe on YouTube,

00:01:16.100 --> 00:01:17.970
give it five starts on Apple PodCast,

00:01:17.970 --> 00:01:21.087
support it on Patreon, or simply
connect with me on Twitter

00:01:21.087 --> 00:01:24.820
@LexFridman, spelled: F-R-I-D-M-A-N.

00:01:24.820 --> 00:01:27.950
As usual, I'll do one or
two minutes of ads now,

00:01:27.950 --> 00:01:29.840
and never any ads in the
middle that can break

00:01:29.840 --> 00:01:31.510
the flow of the conversation.

00:01:31.510 --> 00:01:33.670
I hope that works for you and doesn't hurt

00:01:33.670 --> 00:01:35.023
the listening experience.

00:01:36.240 --> 00:01:38.220
This show is presented by Cash App,

00:01:38.220 --> 00:01:40.620
the number one finance
app on the App Store.

00:01:40.620 --> 00:01:42.523
When you get it, use code: LexPodcast.

00:01:43.880 --> 00:01:45.870
Cash App lets you send money to friends

00:01:45.870 --> 00:01:48.170
by BitCoin and invest in the stock market

00:01:48.170 --> 00:01:49.900
with as little as $1.

00:01:49.900 --> 00:01:52.660
Broker services are provided
by Cash App Investing,

00:01:52.660 --> 00:01:56.510
a subsidiary of Square,
and member S.I.P.C..

00:01:56.510 --> 00:01:58.770
Since Cash App allows you
to send and receive money

00:01:58.770 --> 00:02:02.030
digitally peer to peer,
and security in all digital

00:02:02.030 --> 00:02:04.340
transaction is very
important, let me mention

00:02:04.340 --> 00:02:06.447
that PCI data security standard.

00:02:06.447 --> 00:02:11.447
PCI DSS Level One, that
Cash App is complaint with.

00:02:12.220 --> 00:02:15.320
I'm a big fan of standards
for safety and security

00:02:15.320 --> 00:02:18.670
and PCI DSS is a good example of that.

00:02:18.670 --> 00:02:21.050
Where a bunch of competitors got together

00:02:21.050 --> 00:02:23.520
and agreed that there needs
to be a global standard

00:02:23.520 --> 00:02:25.830
around the security of transactions.

00:02:25.830 --> 00:02:28.930
Now we just need to do the
same for autonomous vehicles

00:02:28.930 --> 00:02:30.533
and A.I. systems in general.

00:02:31.420 --> 00:02:33.920
So again, if you get Cash
App from the App Store

00:02:33.920 --> 00:02:36.363
or Google Play, and use
the code: LexPodcast,

00:02:37.310 --> 00:02:41.260
you get $10, and Cash App
will also donate $10 to FIRST,

00:02:41.260 --> 00:02:43.700
one of my favorite
organizations that is helping

00:02:43.700 --> 00:02:46.460
to advance robotics and STEM education

00:02:46.460 --> 00:02:48.363
for young people around the world.

00:02:49.750 --> 00:02:53.303
And now, here's my conversation
with Vladimir Vapnik.

00:02:55.350 --> 00:02:58.150
You and I talked about
Alan Turing yesterday,

00:02:58.150 --> 00:02:59.820
a little bit.
- Yes.

00:02:59.820 --> 00:03:02.710
- And that he, as the father
of artificial intelligence

00:03:02.710 --> 00:03:05.770
may have instilled in our
field an ethic of engineering

00:03:05.770 --> 00:03:07.720
in that science.

00:03:07.720 --> 00:03:09.600
Seeking more to build intelligence

00:03:09.600 --> 00:03:11.970
rather than to understand it.

00:03:11.970 --> 00:03:15.540
What do you think is the
difference between these two paths

00:03:15.540 --> 00:03:20.493
of engineering intelligence and
the science of intelligence?

00:03:21.381 --> 00:03:23.680
- It's a completely different story.

00:03:23.680 --> 00:03:27.623
Engineering is imitation
of human activity.

00:03:28.500 --> 00:03:29.333
You have to make

00:03:30.970 --> 00:03:34.253
a device which behaves as a human behaves.

00:03:35.587 --> 00:03:39.190
You have all the functions of human.

00:03:39.190 --> 00:03:42.187
It does not matter how you do it.

00:03:42.187 --> 00:03:45.163
But to understand what
is intelligence about,

00:03:46.010 --> 00:03:47.683
is quite different problem.

00:03:48.980 --> 00:03:51.063
So I think, I believe,

00:03:52.209 --> 00:03:55.683
that it's somehow related to
predicated talk yesterday.

00:03:57.840 --> 00:03:58.773
Because,

00:04:00.390 --> 00:04:01.223
look at

00:04:02.430 --> 00:04:05.710
Vladimir Propp's idea.

00:04:05.710 --> 00:04:10.023
He just found such a one here, predicates.

00:04:12.610 --> 00:04:15.693
He called it units.

00:04:16.630 --> 00:04:19.180
Which can explain human behavior,

00:04:19.180 --> 00:04:20.993
at least in Russian tales.

00:04:22.182 --> 00:04:24.840
You look at the Russian
tales and derive from that.

00:04:24.840 --> 00:04:27.180
And then people realize that they're more

00:04:27.180 --> 00:04:29.600
violent in Russian tales.

00:04:29.600 --> 00:04:33.900
It is in TV, in movie
serials and so on and so on.

00:04:33.900 --> 00:04:35.940
- So you're talking about

00:04:35.940 --> 00:04:39.987
Vladimir Propp, who in
1928 published a book,

00:04:39.987 --> 00:04:42.600
"Morphology of the Folk Tale."
- Exactly.

00:04:42.600 --> 00:04:45.250
- Describing 31 predicates that

00:04:45.250 --> 00:04:49.860
have this kind of sequential structure

00:04:49.860 --> 00:04:52.900
that a lot of the
stories' narratives follow

00:04:52.900 --> 00:04:55.080
in Russian folklore and in other content.

00:04:55.080 --> 00:04:57.830
We'll talk about it; I'd
like to talk about predicates

00:04:57.830 --> 00:05:00.680
in a focused way, but let
me, if you'll allow me,

00:05:00.680 --> 00:05:03.783
to stay zoomed out on
our friend Allen Touring.

00:05:04.680 --> 00:05:07.560
And you know, he inspired a generation

00:05:07.560 --> 00:05:10.573
with the imitation game.
- Yes.

00:05:11.650 --> 00:05:15.230
- Do you think, if we can linger
on that a little bit longer

00:05:15.230 --> 00:05:18.570
do you think we can learn?

00:05:18.570 --> 00:05:21.170
Do you think learning
to imitate intelligence

00:05:21.170 --> 00:05:25.163
can get us closer to
understanding intelligence?

00:05:26.030 --> 00:05:31.030
Why do you think imitation
is so far from understanding?

00:05:32.920 --> 00:05:34.630
- I think that it is different

00:05:34.630 --> 00:05:36.633
between you have different goals.

00:05:39.510 --> 00:05:44.120
Your goal is to create
something, something useful.

00:05:44.120 --> 00:05:45.960
And that is great,

00:05:45.960 --> 00:05:49.970
and you can see how much things was done

00:05:49.970 --> 00:05:52.343
and I believe that it
will be done even more.

00:05:53.380 --> 00:05:56.890
Self-driving cars and all
sorts of this business.

00:05:56.890 --> 00:06:01.667
It is great, and it was
inspired by Turing's vision.

00:06:03.130 --> 00:06:05.520
But understanding is very difficult.

00:06:05.520 --> 00:06:08.360
It's more or less a
philosophical category.

00:06:08.360 --> 00:06:09.973
What means understandable?

00:06:11.300 --> 00:06:15.153
I believe in things
which start from Plato.

00:06:16.017 --> 00:06:19.230
That there exists world of ideas.

00:06:19.230 --> 00:06:22.960
I believe that intelligence,
it is world of ideas.

00:06:22.960 --> 00:06:25.183
But it is world of pure ideas.

00:06:26.890 --> 00:06:27.723
And when you

00:06:29.640 --> 00:06:33.410
combine that with reality things,

00:06:33.410 --> 00:06:36.570
it creates as in my case, in the variants,

00:06:36.570 --> 00:06:38.450
which is very specific.

00:06:38.450 --> 00:06:43.220
And that I believe, the combination

00:06:44.230 --> 00:06:47.720
of ideas and a way to
constructing the variant

00:06:48.610 --> 00:06:53.565
is intelligence, but
first of all a predicate.

00:06:53.565 --> 00:06:57.250
If you know predicate, and hope for this

00:06:57.250 --> 00:07:01.051
is not too much predicate exists.

00:07:01.051 --> 00:07:04.270
For example, sort of
unpredicted for human behavior

00:07:04.270 --> 00:07:07.940
is not a lot.
- Vladimir Propp used

00:07:07.940 --> 00:07:12.940
31 (sighs) you could even call
'em predicates, 31 predicates

00:07:14.100 --> 00:07:17.750
to describe stories, narratives.

00:07:17.750 --> 00:07:19.363
Do you think human behavior,

00:07:20.650 --> 00:07:23.090
how much of human behavior,
how much of our world,

00:07:23.090 --> 00:07:27.540
our universe, all the things
that matter in our existence

00:07:27.540 --> 00:07:30.040
can be summarized in predicates

00:07:30.040 --> 00:07:32.650
of the kind that Propp was working with?

00:07:32.650 --> 00:07:35.330
- I think that we have

00:07:35.330 --> 00:07:37.800
a lot of forms of behavior.

00:07:37.800 --> 00:07:41.020
But I think the predicate is much less.

00:07:41.020 --> 00:07:45.250
Because even in these examples
which I gave you yesterday,

00:07:45.250 --> 00:07:46.083
you saw

00:07:47.330 --> 00:07:50.233
that predicate can be,

00:07:51.926 --> 00:07:56.720
one, predicate can construct
many different invariants,

00:07:56.720 --> 00:07:59.620
depending on your data.

00:07:59.620 --> 00:08:01.630
They're applying to different data

00:08:01.630 --> 00:08:03.870
and they give different invariants.

00:08:04.760 --> 00:08:06.403
But pure ideas,

00:08:07.450 --> 00:08:09.420
maybe not so much.
- Not so many.

00:08:09.420 --> 00:08:11.430
- I don't know about that.

00:08:11.430 --> 00:08:13.570
But my guess, I hope,

00:08:13.570 --> 00:08:17.700
that's my challenge
about digit recognition,

00:08:17.700 --> 00:08:18.773
how much you need.

00:08:19.670 --> 00:08:21.880
- I think we'll talk about computer vision

00:08:21.880 --> 00:08:24.850
and 2-D images a little
bit in your challenge.

00:08:24.850 --> 00:08:27.100
- [Vladimir] That's
exact about intelligence.

00:08:28.860 --> 00:08:31.189
- That's exactly about, no,

00:08:31.189 --> 00:08:35.400
that hopes to be exactly about
the spirit of intelligence

00:08:35.400 --> 00:08:38.270
in the simplest possible way.
- Yeah, absolutely.

00:08:38.270 --> 00:08:40.420
You should start the simplest way,

00:08:40.420 --> 00:08:42.513
otherwise you will not be able to do it.

00:08:42.513 --> 00:08:44.760
- There's an open question whether

00:08:44.760 --> 00:08:48.580
starting at the MNIST digit recognition

00:08:48.580 --> 00:08:51.170
is a step towards intelligence
or it's an entirely

00:08:51.170 --> 00:08:54.620
different thing.
- I think that to build

00:08:54.620 --> 00:08:59.620
records using say, 100,
200 times less examples,

00:08:59.948 --> 00:09:01.580
you need intelligence.
- You need intelligence.

00:09:01.580 --> 00:09:03.820
So let's, because you use this term,

00:09:03.820 --> 00:09:07.320
and it would be nice,
I'd like to ask simple,

00:09:07.320 --> 00:09:10.040
maybe even dumb questions.

00:09:10.040 --> 00:09:11.490
Let's start with a predicate.

00:09:12.900 --> 00:09:14.990
In terms of terms and
how you think about it,

00:09:14.990 --> 00:09:16.153
what is a predicate?

00:09:17.520 --> 00:09:19.134
- I don't know.

00:09:19.134 --> 00:09:20.570
(laughs)
I have a feeling,

00:09:20.570 --> 00:09:22.093
formally they exist.

00:09:25.155 --> 00:09:27.880
I believe that predicate for 2-D images.

00:09:30.290 --> 00:09:32.310
One of them is symmetry.

00:09:32.310 --> 00:09:33.682
- Hold on a second.

00:09:33.682 --> 00:09:36.470
Sorry, sorry to interrupt
and pull you back.

00:09:36.470 --> 00:09:40.710
At the simplest level, we're
not being profound currently.

00:09:40.710 --> 00:09:44.023
A predicate is a statement
of something that is true.

00:09:44.900 --> 00:09:45.750
- [Vladimir] Yes.

00:09:46.610 --> 00:09:51.610
- Do you think of predicates
as somehow probabilistic

00:09:51.610 --> 00:09:54.690
in nature or is this binary?

00:09:54.690 --> 00:09:59.010
This is truly constraints
of logical statements

00:09:59.010 --> 00:10:01.320
about the world.
- In my definition,

00:10:01.320 --> 00:10:04.190
the simplest predicate is function.

00:10:04.190 --> 00:10:07.590
Function and you can use this function

00:10:07.590 --> 00:10:10.870
to make inner product, that is predicate.

00:10:10.870 --> 00:10:14.020
- What's the input and what's
the output of the function?

00:10:14.020 --> 00:10:17.773
- Input is X, something
which is input in reality.

00:10:18.640 --> 00:10:23.640
Say, if you considered digit
recognition, in pixel space.

00:10:25.010 --> 00:10:29.790
But it is function which in pixel space.

00:10:29.790 --> 00:10:34.790
But it can be any function, pixel space.

00:10:35.440 --> 00:10:38.150
And you choose, and I believe

00:10:38.150 --> 00:10:41.700
that there are several functions,

00:10:41.700 --> 00:10:45.823
which is important for
understanding of images.

00:10:46.693 --> 00:10:50.303
One of them is symmetry, it's
not so simple construction,

00:10:51.140 --> 00:10:55.010
as I described is the
derivative, it's all this stuff.

00:10:55.010 --> 00:10:58.860
But another I believe,
I don't know how many,

00:10:58.860 --> 00:11:02.493
is how well-structurized is picture.

00:11:03.571 --> 00:11:04.483
- Structurized?
- Yeah.

00:11:04.483 --> 00:11:06.970
- What do you mean by structurized?

00:11:06.970 --> 00:11:10.070
- It is formal definition, say,

00:11:10.070 --> 00:11:13.550
something heavy on the left corner,

00:11:13.550 --> 00:11:17.060
not so heavy in the middle and so on.

00:11:17.060 --> 00:11:21.870
You describe in general,
concept of what you assume.

00:11:21.870 --> 00:11:25.230
- Concepts, some kind
of universal concepts.

00:11:25.230 --> 00:11:26.710
- Yeah.

00:11:26.710 --> 00:11:29.173
But I don't know how to formalize this.

00:11:30.060 --> 00:11:32.430
- This is the thing,
there's a million ways

00:11:32.430 --> 00:11:34.880
we can talk about this,
I'll keep bringing it up.

00:11:35.900 --> 00:11:38.173
We humans have such concepts,

00:11:39.170 --> 00:11:41.550
when we look at digits.

00:11:41.550 --> 00:11:43.910
But it's hard to put them,
just like you're saying now,

00:11:43.910 --> 00:11:45.980
it's hard to put them into words.

00:11:45.980 --> 00:11:47.803
- You know, that is example.

00:11:48.640 --> 00:11:50.680
When critics

00:11:51.640 --> 00:11:55.700
in music, trying to describe music,

00:11:55.700 --> 00:11:57.123
they use predicate.

00:11:58.170 --> 00:12:02.900
And not too many predicate
but in different combination.

00:12:02.900 --> 00:12:07.900
But they have some special
words for describing music.

00:12:08.310 --> 00:12:12.710
And the same should be for images.

00:12:12.710 --> 00:12:15.680
But maybe there are critics who understand

00:12:16.770 --> 00:12:19.653
essence of what this image is about.

00:12:21.090 --> 00:12:24.490
- Do you think there
exists critics who can

00:12:25.700 --> 00:12:28.603
summarize the essence
of images, human beings?

00:12:30.190 --> 00:12:31.690
- [Vladimir] I hope that, yes.

00:12:32.710 --> 00:12:34.963
- Explicitly state them on paper?

00:12:37.540 --> 00:12:39.370
The fundamental question I'm asking

00:12:40.520 --> 00:12:44.280
is do you (chuckles) do
you think there exists

00:12:44.280 --> 00:12:48.110
a small set of predicates
that will summarize images?

00:12:48.110 --> 00:12:51.280
It feels to our mind like it does

00:12:51.280 --> 00:12:54.517
that the concept of what
makes a two and a three

00:12:54.517 --> 00:12:56.510
and a four--
- No, no, no.

00:12:56.510 --> 00:12:58.973
It's not only on this level.

00:13:01.606 --> 00:13:04.990
It should not describe two, three, four.

00:13:04.990 --> 00:13:08.810
It describes some
construction which allows you

00:13:08.810 --> 00:13:10.470
to create an invariants.

00:13:11.870 --> 00:13:14.190
- And invariants, sorry to stick on this,

00:13:14.190 --> 00:13:18.410
but terminology.
- Invariants, it is,

00:13:18.410 --> 00:13:19.243
it is projection

00:13:20.560 --> 00:13:22.963
of your image.

00:13:24.720 --> 00:13:25.553
Say,

00:13:26.690 --> 00:13:29.190
I can say, looking at my image,

00:13:29.190 --> 00:13:32.100
it is more or less symmetric

00:13:32.100 --> 00:13:34.200
and I can give you a variable of symmetry.

00:13:35.370 --> 00:13:39.380
Say, level of symmetry using this function

00:13:39.380 --> 00:13:41.293
which I gave yesterday.

00:13:43.664 --> 00:13:45.220
Then you can describe

00:13:48.034 --> 00:13:50.410
that your image

00:13:50.410 --> 00:13:53.240
has these characteristics
exactly in the way

00:13:53.240 --> 00:13:56.823
how musical critics describe music.

00:13:59.080 --> 00:14:04.080
But this is invariant
applied to specific data,

00:14:04.340 --> 00:14:05.973
to specific music, to something.

00:14:07.740 --> 00:14:09.590
I strongly believe in

00:14:11.456 --> 00:14:12.700
this Plato idea,

00:14:12.700 --> 00:14:16.893
that exists world of
predicate and world of reality

00:14:17.759 --> 00:14:20.590
and predicate and reality
are somehow connected

00:14:20.590 --> 00:14:22.490
and you have to figure out that.

00:14:22.490 --> 00:14:24.010
- Let's talk about Plato a little bit.

00:14:24.010 --> 00:14:27.240
So you draw a line from Plato to Hegel

00:14:27.240 --> 00:14:30.170
to Wigner to today.
- Yes.

00:14:30.170 --> 00:14:33.560
- So Plato has forms.

00:14:33.560 --> 00:14:37.367
The theory of forms;
there's a world of ideas

00:14:37.367 --> 00:14:39.407
and a world of things, as you talk about.

00:14:39.407 --> 00:14:42.250
And there's a connection,
and presumably the world

00:14:42.250 --> 00:14:45.830
of ideas is very small,
and the world of things

00:14:46.717 --> 00:14:48.770
is arbitrarily big, but they're all,

00:14:48.770 --> 00:14:50.223
what Plato calls them like,

00:14:51.320 --> 00:14:54.030
it's a shadow, the real world is a shadow

00:14:54.030 --> 00:14:56.880
from the world of form.
- Yeah and you have projection

00:14:56.880 --> 00:14:59.240
- Projection.
- Of a world of idea.

00:14:59.240 --> 00:15:02.880
- Yeah, very poetic.
- And in reality you can,

00:15:02.880 --> 00:15:07.050
realize this projection
using these invariants

00:15:07.050 --> 00:15:11.930
because it is a projection
for only specific examples

00:15:11.930 --> 00:15:15.113
which create specific
features of specific objects.

00:15:18.100 --> 00:15:20.383
- So the essence of intelligence is,

00:15:21.230 --> 00:15:24.720
while only being able to
observe the world of things,

00:15:24.720 --> 00:15:27.130
try to come up with a world of ideas.

00:15:27.130 --> 00:15:30.120
- Exactly, like in this music story.

00:15:30.120 --> 00:15:33.077
Intelligent musical
critics knows this world

00:15:33.077 --> 00:15:35.210
and have a feeling about them.
- I feel like

00:15:35.210 --> 00:15:39.850
that's a contradiction;
intelligent music critics.

00:15:39.850 --> 00:15:42.380
I think music is to be...

00:15:44.730 --> 00:15:47.710
enjoyed in all its forms.

00:15:47.710 --> 00:15:50.040
The notion of critic, like a food critic.

00:15:50.040 --> 00:15:52.370
- [Vladimir] No, I don't
want attach emotion.

00:15:52.370 --> 00:15:53.780
- That's an interesting question.

00:15:53.780 --> 00:15:56.730
Does emotion, there's certain elements

00:15:56.730 --> 00:15:59.540
of the human psychology,
of the human experience

00:16:01.045 --> 00:16:05.540
which seem to almost contradict
intelligence and reason.

00:16:05.540 --> 00:16:07.710
Like emotion, like fear.

00:16:07.710 --> 00:16:11.450
Like love, all of those things.

00:16:11.450 --> 00:16:16.343
Are those not connected in
any way to the space of ideas?

00:16:17.530 --> 00:16:18.877
- This I don't know.

00:16:20.606 --> 00:16:21.810
I just want

00:16:22.890 --> 00:16:26.460
to be concentrating on very simple story.

00:16:26.460 --> 00:16:27.980
On digit recognition.

00:16:27.980 --> 00:16:29.630
- So you don't think you have to love

00:16:29.630 --> 00:16:32.830
and fear death in order
to recognize digits?

00:16:32.830 --> 00:16:36.970
- I don't know because
it's so complicated.

00:16:36.970 --> 00:16:41.570
It involves a lot of stuff
which I never considered.

00:16:41.570 --> 00:16:45.365
But I know about digit recognition.

00:16:45.365 --> 00:16:48.448
And I know that for digit recognition

00:16:52.355 --> 00:16:57.330
to get the records from small
numbers of observations,

00:16:57.330 --> 00:17:01.610
you need predicate but
not special predicate

00:17:01.610 --> 00:17:03.600
for this problem.

00:17:03.600 --> 00:17:06.970
But universal predicate which understand

00:17:06.970 --> 00:17:08.600
world of images.

00:17:08.600 --> 00:17:11.410
- Of visual information.
- Visual, yeah.

00:17:11.410 --> 00:17:14.973
But on the first step, they understand

00:17:14.973 --> 00:17:18.570
say, a world of 100 digits

00:17:18.570 --> 00:17:21.660
or characters or something simple.

00:17:21.660 --> 00:17:23.737
- [Lex] So like you said,
symmetry is an interesting one.

00:17:23.737 --> 00:17:26.890
- No, that's what I think
one of the predicate

00:17:26.890 --> 00:17:31.177
is related to symmetry,
the level of symmetry.

00:17:31.177 --> 00:17:32.990
- Okay, degree of symmetry.
- Yeah.

00:17:32.990 --> 00:17:35.840
- So you think symmetry at the bottom

00:17:35.840 --> 00:17:38.820
is a universal notion and there's,

00:17:38.820 --> 00:17:41.530
there's degrees of a
single kind of symmetry?

00:17:41.530 --> 00:17:43.540
Or is there many kinds of symmetries?

00:17:43.540 --> 00:17:46.195
- Many kinds of symmetries.

00:17:46.195 --> 00:17:49.750
There is a symmetry/anti-symmetry
say, letter S.

00:17:52.370 --> 00:17:55.533
So it has vertical anti-symmetry.

00:17:58.565 --> 00:18:02.650
It could be diagonal
symmetry, vertical symmetry.

00:18:02.650 --> 00:18:06.959
- So when you cut
vertically the letter S--

00:18:06.959 --> 00:18:09.790
- Yeah, and then

00:18:09.790 --> 00:18:14.790
the upper part and lower part
are in different directions.

00:18:16.210 --> 00:18:18.609
- Inverted along the Y-axis.

00:18:18.609 --> 00:18:21.466
But that's just like, one
example of symmetry right?

00:18:21.466 --> 00:18:23.550
Isn't there like--
- Right, but there

00:18:23.550 --> 00:18:26.360
is a degree of symmetry.

00:18:26.360 --> 00:18:29.230
If you play all this lineated stuff

00:18:33.393 --> 00:18:34.900
to do tangent distance,

00:18:34.900 --> 00:18:36.939
whatever I described,

00:18:36.939 --> 00:18:40.490
you can have a degree of symmetry.

00:18:40.490 --> 00:18:45.490
And that is what is
describing reason of image.

00:18:45.950 --> 00:18:49.740
It is the same as you will describe

00:18:50.640 --> 00:18:52.550
this image

00:18:54.017 --> 00:18:55.360
saying about digit S

00:18:56.260 --> 00:18:57.950
has anti-symmetry,

00:18:57.950 --> 00:19:01.950
digit three is symmetric more/less.

00:19:01.950 --> 00:19:02.850
Look for symmetry.

00:19:04.630 --> 00:19:08.560
- Do you think such concepts
like symmetry predicates,

00:19:08.560 --> 00:19:13.560
like symmetry, is it a
hierarchical set of concepts?

00:19:14.380 --> 00:19:15.570
Or are these

00:19:16.960 --> 00:19:20.130
independent, distinct predicates

00:19:20.130 --> 00:19:22.913
that we want to discover a subset of?

00:19:23.819 --> 00:19:26.010
- There is a degree of symmetry.

00:19:26.010 --> 00:19:30.580
And this idea of symmetry made

00:19:32.381 --> 00:19:36.243
very general, like degree of symmetry,

00:19:37.320 --> 00:19:40.730
the degree of symmetry can
be zero, no symmetry at all.

00:19:40.730 --> 00:19:43.950
Or degree of symmetry of let's say,

00:19:43.950 --> 00:19:45.200
more or less symmetrical.

00:19:47.010 --> 00:19:50.067
But you have one of these descriptions,

00:19:50.067 --> 00:19:52.500
and symmetry can be different.

00:19:52.500 --> 00:19:55.743
As I told, horizontal, vertical, diagonal.

00:19:57.670 --> 00:20:01.430
Anti-symmetry also is
a concept of symmetry.

00:20:01.430 --> 00:20:03.350
- What about shape in general?

00:20:03.350 --> 00:20:05.340
I mean, symmetry is a fascinating notion,

00:20:05.340 --> 00:20:07.983
but it--
- No, no, I'm talking about

00:20:07.983 --> 00:20:10.520
digits, I would like to concentrate

00:20:10.520 --> 00:20:14.490
on all I would like to know
predicate for digit recognition.

00:20:14.490 --> 00:20:18.550
- Yes, but symmetry is not
enough for digit recognition,

00:20:18.550 --> 00:20:20.730
right?
- It is not necessarily

00:20:20.730 --> 00:20:24.480
for digit recognition; it helps

00:20:25.370 --> 00:20:26.927
to create invariant,

00:20:28.892 --> 00:20:32.410
which you can use when
you will have examples

00:20:33.470 --> 00:20:35.644
for digit recognition.

00:20:35.644 --> 00:20:38.200
You have regular problem
of digit recognition.

00:20:38.200 --> 00:20:41.630
You have examples of the
first class and second class.

00:20:41.630 --> 00:20:45.860
Plus you know that there exists
this concept of symmetry.

00:20:45.860 --> 00:20:50.410
And you apply when you're
looking for decision rule,

00:20:50.410 --> 00:20:51.640
you will apply

00:20:53.720 --> 00:20:55.450
concept of symmetry,

00:20:55.450 --> 00:20:59.493
of this level of symmetry
which you estimate from.

00:21:01.690 --> 00:21:03.053
Everything is,

00:21:04.170 --> 00:21:06.610
comes from weak convergence.

00:21:06.610 --> 00:21:07.860
- What is convergence?

00:21:07.860 --> 00:21:09.280
What is weak convergence?

00:21:09.280 --> 00:21:11.690
What is strong convergence?

00:21:11.690 --> 00:21:13.430
I'm sorry I'm gonna do this to you.

00:21:13.430 --> 00:21:15.333
What are we converging from and to?

00:21:16.200 --> 00:21:20.863
- You're converging, you
would like to have a function.

00:21:20.863 --> 00:21:24.820
The function which say, indicate
a function which indicate

00:21:26.300 --> 00:21:27.510
your digit

00:21:28.410 --> 00:21:31.490
five, for example.
- A classification/task--

00:21:31.490 --> 00:21:33.780
- Let's talk only about
classification task.

00:21:33.780 --> 00:21:36.890
- So classification means you will say

00:21:36.890 --> 00:21:38.640
whether this is a five or not,

00:21:38.640 --> 00:21:40.770
or say which of the 10 digits it is.

00:21:40.770 --> 00:21:42.996
- Right, right, I would like

00:21:42.996 --> 00:21:45.603
to have these functions.

00:21:46.840 --> 00:21:47.673
Then,

00:21:50.190 --> 00:21:52.513
I have some examples.

00:21:56.060 --> 00:22:00.283
I can consider property of these examples.

00:22:01.120 --> 00:22:04.870
Say, symmetry, and I can
measure level of symmetry

00:22:04.870 --> 00:22:06.543
for every digit.

00:22:08.070 --> 00:22:11.180
And then I can take average

00:22:14.160 --> 00:22:16.700
from my training data.

00:22:16.700 --> 00:22:19.680
And I will consider only functions

00:22:22.664 --> 00:22:24.810
of conditional probability,
which I'm looking

00:22:24.810 --> 00:22:26.423
for in my decision level.

00:22:27.450 --> 00:22:28.283
Which

00:22:30.180 --> 00:22:32.370
applying to

00:22:35.230 --> 00:22:38.350
the digits will give me the same average

00:22:38.350 --> 00:22:40.683
as I observed on training data.

00:22:41.960 --> 00:22:45.330
So actually this is different level

00:22:45.330 --> 00:22:48.500
of description of what you want.

00:22:48.500 --> 00:22:49.383
You want,

00:22:50.490 --> 00:22:54.090
not just, you show not one digit.

00:22:54.090 --> 00:22:58.370
You show this predicate,
show general property

00:22:59.830 --> 00:23:03.730
of all digits which you have in mind.

00:23:03.730 --> 00:23:06.050
If you have in mind digit three,

00:23:06.050 --> 00:23:09.540
it gives you property of digit three

00:23:10.380 --> 00:23:13.450
and you select as
admissible set of functions,

00:23:13.450 --> 00:23:15.803
only function which keeps this property.

00:23:16.990 --> 00:23:20.750
You will not consider the other functions.

00:23:20.750 --> 00:23:24.130
So you're immediately
looking for smaller subset

00:23:24.130 --> 00:23:25.490
of functions.
- That's what you mean

00:23:25.490 --> 00:23:28.120
by an admissible function.
- And admissible function.

00:23:28.120 --> 00:23:28.953
Exactly.
- Which is still

00:23:28.953 --> 00:23:32.546
a pretty large, for the number three,

00:23:32.546 --> 00:23:33.727
that's a large--
- It's large but,

00:23:33.727 --> 00:23:36.610
if you have one predicate.

00:23:36.610 --> 00:23:38.423
But according to,

00:23:39.284 --> 00:23:41.903
there is a strong and weak convergence.

00:23:42.760 --> 00:23:45.293
Strong convergence if
convergence in function.

00:23:46.410 --> 00:23:49.250
You're looking for the
function, on one function,

00:23:49.250 --> 00:23:51.313
and you're looking on another function.

00:23:52.724 --> 00:23:54.990
And square difference

00:23:56.290 --> 00:23:58.303
from them should be small.

00:23:59.530 --> 00:24:01.860
If you take difference at any points,

00:24:01.860 --> 00:24:05.640
make a square, make an integral,
and it should be small.

00:24:05.640 --> 00:24:08.010
That is convergence in function.

00:24:08.010 --> 00:24:11.260
Suppose you had some
function, any function.

00:24:11.260 --> 00:24:15.420
So I would say, I say that some function

00:24:15.420 --> 00:24:16.963
converged to this function.

00:24:17.890 --> 00:24:22.860
If integral from square
difference between them is small--

00:24:22.860 --> 00:24:24.720
- That's the definition
of strong convergence.

00:24:24.720 --> 00:24:26.388
- That's the definition of--
- Two functions,

00:24:26.388 --> 00:24:28.380
the integral of the difference

00:24:28.380 --> 00:24:29.469
is small.
- Yeah, it is convergence

00:24:29.469 --> 00:24:31.453
in functions.
- Yeah.

00:24:31.453 --> 00:24:35.803
- But you have different
convergence in functions.

00:24:35.803 --> 00:24:39.820
You take any function,
you take some function Fe

00:24:41.160 --> 00:24:45.123
and take inner product this
function, this F function.

00:24:46.070 --> 00:24:50.370
F zero function which you want to find,

00:24:50.370 --> 00:24:51.993
and that gives you some value.

00:24:52.970 --> 00:24:57.970
So you say that a set of functions

00:24:58.050 --> 00:25:03.050
converge in inner product to this function

00:25:03.070 --> 00:25:08.070
if this value of inner product
converge to value F zero.

00:25:09.963 --> 00:25:12.497
That is for one Fe.

00:25:12.497 --> 00:25:15.045
But three converges requires

00:25:15.045 --> 00:25:19.323
that it converges for any
function of field of space.

00:25:20.750 --> 00:25:23.850
If it converge for any
function of field of space,

00:25:23.850 --> 00:25:28.300
then you will say that
this is a weak convergence.

00:25:28.300 --> 00:25:32.260
You can think that when you take integral,

00:25:32.260 --> 00:25:35.980
that is property, integral
property of function.

00:25:35.980 --> 00:25:39.200
For example, if you will
take sine or cosine,

00:25:39.200 --> 00:25:44.003
it is coefficient of say, free expansion.

00:25:45.599 --> 00:25:47.530
If it converged

00:25:48.800 --> 00:25:52.030
for all coefficients or free expansion,

00:25:52.030 --> 00:25:55.360
so under some condition it converged

00:25:55.360 --> 00:25:57.393
to function you're looking for.

00:25:58.947 --> 00:26:01.243
But weak convergence means any property.

00:26:02.600 --> 00:26:05.870
Not convergence, not point-wise.

00:26:05.870 --> 00:26:08.653
But integral property of function.

00:26:09.530 --> 00:26:13.870
So weak convergence means
integral property of functions.

00:26:13.870 --> 00:26:17.460
When I'm talking about
predicate, I would like to

00:26:19.490 --> 00:26:22.100
formulate which integral properties

00:26:23.300 --> 00:26:26.693
I would like to have for convergence.

00:26:28.730 --> 00:26:32.290
And if I will take one predicate,

00:26:32.290 --> 00:26:35.563
predicate its function
which I measure property.

00:26:37.740 --> 00:26:40.620
If I will use one predicate and say,

00:26:40.620 --> 00:26:44.970
I will consider only
function which give me

00:26:44.970 --> 00:26:49.970
the same value as this
predicate, I select a set

00:26:49.970 --> 00:26:54.970
of functions from functions
which is admissible,

00:26:55.197 --> 00:26:58.390
in the sense that
function which I'm looking

00:26:58.390 --> 00:27:01.060
for in this set of functions.

00:27:01.060 --> 00:27:06.000
Because I'm checking in training data,

00:27:06.000 --> 00:27:07.623
it gives the same.

00:27:08.820 --> 00:27:10.330
- [Lex] Yeah, so it
always has to be connected

00:27:10.330 --> 00:27:12.670
to the training data in terms of--

00:27:12.670 --> 00:27:14.898
- Yeah, but property,

00:27:14.898 --> 00:27:18.830
you can know independent of training data.

00:27:18.830 --> 00:27:20.437
And this guy, Propp,

00:27:21.930 --> 00:27:24.020
says that there is formal property.

00:27:24.020 --> 00:27:25.972
31 property and if you--
- A fairy tale,

00:27:25.972 --> 00:27:27.665
the Russian fairy tale.
- Right.

00:27:27.665 --> 00:27:30.480
But the Russian fairy tale
is not so interesting.

00:27:30.480 --> 00:27:33.620
It's more interesting
that people applied this

00:27:33.620 --> 00:27:35.690
to movies, to theater,

00:27:35.690 --> 00:27:40.430
to different things and the same works.

00:27:40.430 --> 00:27:41.513
They're universal.

00:27:42.660 --> 00:27:44.850
- So I would argue that
there's a little bit

00:27:44.850 --> 00:27:46.147
of a difference between

00:27:47.720 --> 00:27:49.310
the kinds of things that would apply to,

00:27:49.310 --> 00:27:53.423
which are essentially stories
and digit recognition.

00:27:54.501 --> 00:27:55.970
- [Vladimir] It is the same story.

00:27:55.970 --> 00:27:59.690
- You're saying digits, there's
a story within the digit?

00:27:59.690 --> 00:28:01.410
- Yeah.
(laughing)

00:28:01.410 --> 00:28:03.790
So but my point is,

00:28:03.790 --> 00:28:08.600
well, I hope that it's
possible to beat a record.

00:28:08.600 --> 00:28:10.570
Using not 60,000

00:28:11.520 --> 00:28:13.860
but say, 100 times less.

00:28:13.860 --> 00:28:16.373
Because instead you will give predicates.

00:28:17.950 --> 00:28:21.420
And you will select your decision not

00:28:21.420 --> 00:28:24.330
from right set of functions.

00:28:24.330 --> 00:28:27.193
But from set of function
which gives this predicate.

00:28:28.100 --> 00:28:32.840
But predicate is not related
just to digit recognition.

00:28:32.840 --> 00:28:36.090
- Right, so--
- Like in Plato's case.

00:28:36.090 --> 00:28:38.940
- (laughs) Do you think it's possible

00:28:38.940 --> 00:28:42.150
to automatically discover the predicates?

00:28:42.150 --> 00:28:44.390
So, you basically said

00:28:44.390 --> 00:28:46.620
that the essence of intelligence

00:28:46.620 --> 00:28:49.650
is the discovery of good predicates.

00:28:49.650 --> 00:28:51.350
- [Vladimir] Yeah.

00:28:51.350 --> 00:28:53.623
- Now the natural question is,

00:28:55.210 --> 00:28:58.210
you know, that's what Einstein
was good at doing in physics.

00:28:59.110 --> 00:29:02.410
Can we make machines do these kinds

00:29:02.410 --> 00:29:04.560
of discovery of good predicates?

00:29:04.560 --> 00:29:06.853
Or is this ultimately a human endeavor?

00:29:07.780 --> 00:29:09.610
- That I don't know.

00:29:09.610 --> 00:29:11.430
I don't think that much it can do.

00:29:11.430 --> 00:29:12.273
Because,

00:29:14.970 --> 00:29:17.553
according to theory
about weak convergence,

00:29:18.970 --> 00:29:22.163
any function from Hilbert
Space can be predicate.

00:29:23.190 --> 00:29:27.290
So you have infinite number
of predicate in upper.

00:29:27.290 --> 00:29:32.290
And before you don't know which
predicate is good in which.

00:29:32.860 --> 00:29:35.090
But whatever

00:29:36.610 --> 00:29:39.910
Propp showed, and why
people call it breakthrough,

00:29:39.910 --> 00:29:44.770
that there is not too many predicate

00:29:44.770 --> 00:29:48.713
which cover most of situation
that happen in the world.

00:29:51.330 --> 00:29:53.353
- So there's a sea of predicates.

00:29:54.576 --> 00:29:58.830
Only a small amount are
useful for the kinds of things

00:29:58.830 --> 00:30:00.080
that happen in the world?

00:30:01.350 --> 00:30:02.760
- I think that,

00:30:02.760 --> 00:30:05.410
I would say only a small part

00:30:05.410 --> 00:30:08.740
of predicates very useful.

00:30:08.740 --> 00:30:11.928
Useful, all of them.
- Only a very few

00:30:11.928 --> 00:30:15.470
are what we should, let's
call them good predicates.

00:30:15.470 --> 00:30:17.873
- Very good predicates.
- Very good predicates.

00:30:19.860 --> 00:30:21.790
Can we linger on it,
what's your intuition?

00:30:21.790 --> 00:30:23.120
Why is it

00:30:24.320 --> 00:30:27.620
hard for a machine to
discover good predicates?

00:30:27.620 --> 00:30:30.740
- Even in my talk described
how to do a predicate.

00:30:30.740 --> 00:30:33.487
How to find new predicates, I'm not sure

00:30:33.487 --> 00:30:35.020
that it is very good predicate.

00:30:35.020 --> 00:30:37.290
- [Lex] What did you propose in your talk?

00:30:37.290 --> 00:30:42.020
- In my talk I gave example for diabetes.

00:30:42.020 --> 00:30:46.230
- Diabetes, yeah.
- When we achieve some percent

00:30:46.230 --> 00:30:48.523
so then we're looking from area,

00:30:50.951 --> 00:30:53.743
where some sort of predicate
which I formulated,

00:30:54.760 --> 00:30:55.760
does not...

00:30:58.712 --> 00:30:59.545
keep

00:31:01.042 --> 00:31:01.875
invariant.

00:31:03.190 --> 00:31:07.010
So if it doesn't keep, I retrain my data.

00:31:07.010 --> 00:31:10.777
I select only functions
which keep this invariant.

00:31:10.777 --> 00:31:14.510
In the way I did it, I
improved my performance.

00:31:14.510 --> 00:31:16.520
I came looking for this predicate.

00:31:16.520 --> 00:31:19.770
I know technically how to do that.

00:31:19.770 --> 00:31:21.880
You can of course

00:31:23.490 --> 00:31:27.330
do it using a machine, but I'm not sure

00:31:27.330 --> 00:31:30.613
that we will construct
the smartest predicate.

00:31:30.613 --> 00:31:34.210
- Well this is the,
allow me to linger on it.

00:31:34.210 --> 00:31:36.310
Because that's the essence,
that's the challenge.

00:31:36.310 --> 00:31:40.370
That is artificial, that's
the human-level intelligence

00:31:40.370 --> 00:31:43.840
that we seek, is the discovery
of these good predicates.

00:31:43.840 --> 00:31:47.490
You've talked about deep
learning as a way to,

00:31:47.490 --> 00:31:52.490
the predicates they use and
the functions are mediocre.

00:31:53.020 --> 00:31:55.070
Or you can find better ones.

00:31:55.070 --> 00:31:57.360
- Let's talk about deep learning.

00:31:57.360 --> 00:32:01.750
- Sure, let's do it.
- I know only Jans LaComb,

00:32:01.750 --> 00:32:05.524
convolutional network, and what else?

00:32:05.524 --> 00:32:07.940
And it's very simple convergence.

00:32:07.940 --> 00:32:09.701
- [Lex] There's not much else to know.

00:32:09.701 --> 00:32:10.534
- To fix it left and right.
- Yes.

00:32:10.534 --> 00:32:14.353
- I can do it like that
with one predicate.

00:32:14.353 --> 00:32:16.660
- [Lex] Convolution is a single predicate.

00:32:16.660 --> 00:32:17.493
- It's single,

00:32:19.319 --> 00:32:21.762
it's single predicate.
- Yes, but--

00:32:21.762 --> 00:32:25.490
- You know exactly,
you take the derivative

00:32:25.490 --> 00:32:29.943
for translational, and
predicate should be kept.

00:32:31.090 --> 00:32:33.770
- So that's a single predicate,
but humans discovered

00:32:33.770 --> 00:32:37.248
that one or at least--
- Not that that is the least

00:32:37.248 --> 00:32:39.040
not too many predicates.

00:32:39.040 --> 00:32:43.750
And that is big story because
Jan did it 25 years ago,

00:32:43.750 --> 00:32:48.750
and nothing so clear was
uttered to deep network.

00:32:50.270 --> 00:32:53.240
And then I don't understand

00:32:54.118 --> 00:32:57.420
why we should talk about deep network

00:32:57.420 --> 00:33:01.270
instead of talking about
piece-wise linear functions

00:33:01.270 --> 00:33:03.123
which keeps this predicate.

00:33:03.123 --> 00:33:06.133
- You know, a counter argument is,

00:33:07.320 --> 00:33:11.170
that maybe the amount
of predicates necessary

00:33:11.170 --> 00:33:16.170
to solve general intelligence,
say in the space of images,

00:33:16.380 --> 00:33:20.620
doing efficient recognition
of handwritten digits

00:33:20.620 --> 00:33:21.633
is very small.

00:33:23.550 --> 00:33:26.850
So we shouldn't be so
obsessed about finding,

00:33:26.850 --> 00:33:28.693
we'll find other good predicates

00:33:28.693 --> 00:33:30.920
like convolution, for example.

00:33:30.920 --> 00:33:34.412
There has been other advancements like,

00:33:34.412 --> 00:33:37.410
if you look at the work with attention,

00:33:37.410 --> 00:33:39.043
there's attentional mechanisms,

00:33:39.900 --> 00:33:42.150
especially used in natural language

00:33:42.150 --> 00:33:44.477
focusing the network's ability to,

00:33:44.477 --> 00:33:47.640
to learn at which part
of the input to look at.

00:33:47.640 --> 00:33:51.050
The thing is, there's other
things besides predicates

00:33:51.050 --> 00:33:55.270
that are important for the
actual engineering mechanism

00:33:55.270 --> 00:33:58.070
of showing how much you can really do,

00:33:58.070 --> 00:34:00.820
given such these predicates.

00:34:00.820 --> 00:34:04.360
I mean, that's essentially
the work of deep learning

00:34:04.360 --> 00:34:08.010
is constructing
architectures that are able

00:34:08.010 --> 00:34:13.010
to be given the training data
to be able to converge towards

00:34:16.260 --> 00:34:19.720
a function that can approximate,

00:34:19.720 --> 00:34:21.363
that can generalize well.

00:34:22.640 --> 00:34:26.130
It's an engineering problem.
- Yeah, I understand.

00:34:26.130 --> 00:34:27.360
But let's talk

00:34:28.250 --> 00:34:31.890
not on an emotional level,
but on a mathematical level.

00:34:31.890 --> 00:34:36.440
You have set of piece-wise
linear functions,

00:34:36.440 --> 00:34:40.143
it is all possible neural networks.

00:34:42.010 --> 00:34:44.003
It's just piece-wise linear functions.

00:34:44.003 --> 00:34:46.630
It's many, many pieces.
- Large, large number

00:34:46.630 --> 00:34:48.600
of piece-wise linear function.
- Exactly.

00:34:48.600 --> 00:34:50.170
- Very large.
- Very large.

00:34:50.170 --> 00:34:51.780
- [Lex] Almost, feels like too large.

00:34:51.780 --> 00:34:55.530
- It's still simpler
than say, convolution,

00:34:55.530 --> 00:34:58.213
which is reproducing Hilbert's Space

00:34:58.213 --> 00:35:00.900
and we have a Hilbert's set of functions.

00:35:00.900 --> 00:35:03.020
- What's Hilbert Space?

00:35:03.020 --> 00:35:06.783
- It's space with infinite
number of coordinates.

00:35:09.027 --> 00:35:11.800
A function for expansion,
something like that.

00:35:11.800 --> 00:35:13.463
So it's much richer.

00:35:15.039 --> 00:35:17.607
And when I'm talking about
closed-form solution,

00:35:17.607 --> 00:35:20.830
I'm talking about this set of functions.

00:35:20.830 --> 00:35:25.083
Not piece-wise linear set,
which is particular case

00:35:26.341 --> 00:35:30.840
of (chuckles) it is small part of it.

00:35:30.840 --> 00:35:32.990
- So neural networks is a small part

00:35:32.990 --> 00:35:36.384
of the space you're, of
functions you're talking about?

00:35:36.384 --> 00:35:39.180
- Small set of functions.
- Yeah.

00:35:39.180 --> 00:35:40.567
- Let me take it that.

00:35:40.567 --> 00:35:42.760
But it is fine, it is fine.

00:35:42.760 --> 00:35:47.760
I don't want to discuss the
small or big we take and what.

00:35:47.970 --> 00:35:50.113
So you have some set of functions.

00:35:51.000 --> 00:35:54.363
So now when you're trying
to create architecture,

00:35:55.370 --> 00:35:58.870
you would like to create
admissible set of functions,

00:35:58.870 --> 00:36:03.370
which all your tricks,
to use not all functions,

00:36:03.370 --> 00:36:06.003
but some subset of this set of functions.

00:36:07.280 --> 00:36:10.120
Say when you're introducing
convolutional network.

00:36:10.120 --> 00:36:13.003
It is a way to

00:36:13.003 --> 00:36:16.082
make this subset useful for you.

00:36:16.082 --> 00:36:19.820
But from my point of view, convolutional,

00:36:19.820 --> 00:36:24.820
it is something, you want
to keep some invariance.

00:36:24.850 --> 00:36:26.250
Say, translation invariance.

00:36:27.980 --> 00:36:31.840
But now if you understand this,

00:36:31.840 --> 00:36:35.530
and you cannot explain

00:36:35.530 --> 00:36:39.493
on the level of ideas
what neural network does,

00:36:41.270 --> 00:36:42.150
you should agree

00:36:43.457 --> 00:36:46.730
that it is much better to
have a set of functions.

00:36:46.730 --> 00:36:51.140
As I say, this set of
functions should be admissible,

00:36:51.140 --> 00:36:53.740
it must keep this
invariant, this invariant,

00:36:53.740 --> 00:36:55.250
and that invariant.

00:36:55.250 --> 00:36:58.867
You know that as soon as you
incorporate new invariants,

00:36:58.867 --> 00:37:02.140
set of functions becomes
smaller and smaller and smaller.

00:37:02.140 --> 00:37:03.400
- [Lex] But all the invariants

00:37:03.400 --> 00:37:05.533
are specified by you the human.

00:37:06.730 --> 00:37:09.690
- Yeah, but what I am hope,

00:37:09.690 --> 00:37:13.923
that there is a standard
predicate like, Propp showed.

00:37:15.727 --> 00:37:19.630
That's what I want to find
for digit recognition.

00:37:19.630 --> 00:37:22.680
If we start, it is completely new area

00:37:22.680 --> 00:37:25.830
of what is intelligence
about on the level,

00:37:25.830 --> 00:37:28.830
starting from Plato's idea.

00:37:28.830 --> 00:37:30.613
What is the world of ideas?

00:37:32.820 --> 00:37:34.803
And I believe there is not too many.

00:37:36.045 --> 00:37:39.250
But you know, it is
amusing that mathematicians

00:37:39.250 --> 00:37:44.030
are doing something with neural
network in general function.

00:37:44.030 --> 00:37:47.634
But people from literature, from art,

00:37:47.634 --> 00:37:49.622
they use this all the time.

00:37:49.622 --> 00:37:52.770
- That's right.
- Invariants.

00:37:52.770 --> 00:37:57.020
Say, it is great how
people describe music.

00:37:57.020 --> 00:37:59.060
We should learn from that.

00:37:59.060 --> 00:38:02.420
Something on this level.

00:38:02.420 --> 00:38:07.420
So why, Vladimir Propp
who was just theoretical.

00:38:09.150 --> 00:38:12.253
Who studied theoretical
literature, he found that.

00:38:13.380 --> 00:38:15.240
- You know what, let me
throw that right back at you.

00:38:15.240 --> 00:38:17.370
Because there's a little bit of a,

00:38:17.370 --> 00:38:20.090
that's less mathematical
and more emotional,

00:38:20.090 --> 00:38:21.743
philosophical Vladimir Propp.

00:38:22.780 --> 00:38:25.453
I mean, he wasn't doing math.
- No.

00:38:26.950 --> 00:38:30.140
- And you just said another
emotional statement,

00:38:30.140 --> 00:38:32.040
which is you believe that

00:38:32.040 --> 00:38:34.883
this Plato world of ideas is small.

00:38:35.900 --> 00:38:37.653
- I hope.
- I hope.

00:38:38.700 --> 00:38:40.860
Do (chuckles), do you,

00:38:40.860 --> 00:38:43.560
what's your intuition, though,
if we can linger on it?

00:38:44.920 --> 00:38:46.470
That bothers me.
- You know, because not

00:38:46.470 --> 00:38:48.650
just small or big.

00:38:48.650 --> 00:38:50.123
I know exactly.

00:38:51.387 --> 00:38:52.980
That when I'm introducing

00:38:54.960 --> 00:38:58.953
some predicate, I
decrease set of functions.

00:38:59.800 --> 00:39:02.983
But my goal to decrease
set of functions much.

00:39:04.090 --> 00:39:06.690
- By as much as possible.
- By as much as possible.

00:39:07.530 --> 00:39:11.130
Good predicate which does this,

00:39:11.130 --> 00:39:14.250
then I should choose next
predicate which does this,

00:39:14.250 --> 00:39:17.280
which decreases set as much as possible.

00:39:17.280 --> 00:39:20.520
So, set of good predicates,

00:39:20.520 --> 00:39:23.123
it is such that the decrease,

00:39:24.717 --> 00:39:27.830
amount of admissible functions--

00:39:27.830 --> 00:39:31.060
- So if each good predicate
significantly reduces

00:39:31.060 --> 00:39:32.660
the set of admissible functions

00:39:32.660 --> 00:39:35.600
that there naturally should
not be that many predicates.

00:39:35.600 --> 00:39:36.493
- No, but,

00:39:38.560 --> 00:39:43.560
if you reduce very well the
VC dimension of the function

00:39:44.020 --> 00:39:46.860
of admissible set of
functions, it's small.

00:39:46.860 --> 00:39:51.263
And you need not too much
training data to do well.

00:39:53.080 --> 00:39:55.360
- [Lex] And VC dimension, by the way,

00:39:55.360 --> 00:39:57.730
is some measure of capacity
of this set of functions.

00:39:57.730 --> 00:40:02.010
- Right, roughly speaking,
how many function in this set.

00:40:02.010 --> 00:40:03.980
So you're decreasing, decreasing,

00:40:03.980 --> 00:40:06.470
and it makes it easier for you

00:40:06.470 --> 00:40:09.143
to find the function you're looking for.

00:40:10.525 --> 00:40:12.750
But the most important part,

00:40:12.750 --> 00:40:15.630
to create a good admissible
set of functions.

00:40:15.630 --> 00:40:19.453
And it probably is that
there are many ways but,

00:40:21.519 --> 00:40:25.163
a good predicate is such
that it can do that.

00:40:26.391 --> 00:40:28.490
For this duck,

00:40:28.490 --> 00:40:30.713
you should know a little bit about duck.

00:40:31.552 --> 00:40:35.340
- What are the three
fundamental laws of ducks?

00:40:35.340 --> 00:40:37.470
- Looks like a duck, swims like a duck,

00:40:37.470 --> 00:40:38.410
and quacks like a duck.
- And quacks.

00:40:38.410 --> 00:40:40.750
You should know something about ducks

00:40:40.750 --> 00:40:42.170
to be able to--
- Not necessarily.

00:40:42.170 --> 00:40:45.090
Looks like say, horse.

00:40:45.090 --> 00:40:46.600
It's also good.

00:40:46.600 --> 00:40:47.890
- [Lex] So it's not (chuckles),

00:40:47.890 --> 00:40:50.841
it generalize from ducks.
- Yes, and talk like it,

00:40:50.841 --> 00:40:54.360
and make sound like horse or something.

00:40:54.360 --> 00:40:57.390
And run like horse and moves like horse.

00:40:57.390 --> 00:41:01.210
It is general, it is general predicate

00:41:02.110 --> 00:41:04.660
that this applies to duck.

00:41:04.660 --> 00:41:08.653
But for duck you can say,
play chess like duck.

00:41:09.890 --> 00:41:11.680
- [Lex] You cannot say,
play chess like a duck.

00:41:11.680 --> 00:41:14.070
- Why not?
- So you're saying you can

00:41:14.070 --> 00:41:15.800
but that that would not be a good--

00:41:15.800 --> 00:41:18.554
- [Vladimir] No, you will
not reduce that function.

00:41:18.554 --> 00:41:21.700
- Yeah, you would not
reduce the set of functions.

00:41:21.700 --> 00:41:25.239
- So you can, the story is formal story

00:41:25.239 --> 00:41:28.077
and it's a magical story
is that you can use

00:41:28.077 --> 00:41:30.343
any function you want as a predicate.

00:41:31.240 --> 00:41:33.210
But some of them are good,
some of them are not.

00:41:33.210 --> 00:41:36.223
Because some of them
reduce a lot of functions.

00:41:37.220 --> 00:41:40.300
The admissible set, some of them (mumbles)

00:41:40.300 --> 00:41:42.150
- So the question is, and
I'll probably keep asking

00:41:42.150 --> 00:41:45.740
this question, but how do
we find such predicates?

00:41:45.740 --> 00:41:47.420
What's your intuition?

00:41:47.420 --> 00:41:50.111
Handwritten recognition, how do we find

00:41:50.111 --> 00:41:52.990
the answer to your challenge?

00:41:52.990 --> 00:41:55.990
- Yeah, I understand it like that.

00:41:55.990 --> 00:41:57.920
I understand what.

00:41:57.920 --> 00:42:00.230
- What defined?
- What that means,

00:42:00.230 --> 00:42:02.810
a new predicate.
- Yeah.

00:42:02.810 --> 00:42:05.140
- Like, guy who understands music

00:42:05.140 --> 00:42:07.510
can say these words he describes

00:42:07.510 --> 00:42:09.003
when he listens to music.

00:42:09.913 --> 00:42:13.670
He understands music, he'll
use not too many different.

00:42:13.670 --> 00:42:15.570
Or you can do it like Propp.

00:42:15.570 --> 00:42:18.888
You can make collection, what
you're talking about music.

00:42:18.888 --> 00:42:20.703
About this, about that.

00:42:20.703 --> 00:42:25.020
It's not too many different
situations you describe.

00:42:25.020 --> 00:42:26.960
- Because we mentioned
Vladimir Propp a bunch,

00:42:26.960 --> 00:42:31.380
let me just mention, so
there's a sequence of 31

00:42:33.690 --> 00:42:36.930
structural notions that
are common in stories.

00:42:36.930 --> 00:42:38.600
And I think--
- They're called units.

00:42:38.600 --> 00:42:40.490
- Units, and I think they resonate.

00:42:40.490 --> 00:42:43.406
It starts, just to give an example,

00:42:43.406 --> 00:42:46.080
Absention: a member of
the hero's community

00:42:46.080 --> 00:42:48.960
or family leaves the security
of the home environment,

00:42:48.960 --> 00:42:51.100
then goes through the interdiction,

00:42:51.100 --> 00:42:54.560
a forbidding edict or command
that's passed upon the hero.

00:42:54.560 --> 00:42:56.680
Don't go there; don't do this.

00:42:56.680 --> 00:42:58.720
The hero's warned against some action.

00:42:58.720 --> 00:43:02.507
Then step three:
Violation of interdiction.

00:43:03.386 --> 00:43:07.630
You know, break the rules,
break out on your own.

00:43:07.630 --> 00:43:10.440
Then reconnaissance, the
villain makes an effort

00:43:10.440 --> 00:43:13.200
to attain knowledge needed
to fulfill their plot, so on.

00:43:13.200 --> 00:43:14.393
It goes on like this.

00:43:16.222 --> 00:43:20.943
Ends in a wedding, number
31, happily every after.

00:43:21.780 --> 00:43:25.980
- He just gave description
of all situations.

00:43:25.980 --> 00:43:28.948
He understands his world--
- Of folk tales.

00:43:28.948 --> 00:43:31.029
- Yeah, not folk--
- Stories.

00:43:31.029 --> 00:43:36.029
- Stories, and these stories
not just in folk tales.

00:43:36.620 --> 00:43:40.003
These stories in
detective serials as well.

00:43:40.930 --> 00:43:42.270
- [Lex] And probably in our lives.

00:43:42.270 --> 00:43:44.553
We probably live--
- Read this.

00:43:46.498 --> 00:43:47.498
They're all,

00:43:49.080 --> 00:43:53.493
this predicate is good
for different situations.

00:43:55.461 --> 00:43:58.330
For movie, for theater.
- By the way,

00:43:58.330 --> 00:44:00.680
there's also criticism, right?

00:44:00.680 --> 00:44:03.870
There's another way to
interpret narratives.

00:44:03.870 --> 00:44:04.840
From...

00:44:07.640 --> 00:44:12.530
Claude Levi Strauss.
- I am not in this business.

00:44:12.530 --> 00:44:14.390
- I know, that's theoretical literature,

00:44:14.390 --> 00:44:15.820
but it's looking at paradigms behind them.

00:44:15.820 --> 00:44:18.200
- [Vladimir] It's
always, this discussion--

00:44:18.200 --> 00:44:19.763
- Philosophers argue.
- Yeah.

00:44:20.609 --> 00:44:23.820
- Yeah.
- But at least there is units.

00:44:23.820 --> 00:44:27.200
It's not too many units that can describe.

00:44:27.200 --> 00:44:30.860
But describe probably
gives the other units.

00:44:30.860 --> 00:44:31.790
Or another way for description.

00:44:31.790 --> 00:44:33.900
- Exactly, another set of units.

00:44:33.900 --> 00:44:36.210
- [Vladimir] Another
set of predicates, yes.

00:44:36.210 --> 00:44:40.923
It doesn't matter how,
but they exist probably.

00:44:41.984 --> 00:44:46.250
- My question is, whether
given those units,

00:44:46.250 --> 00:44:49.513
whether without our human
brains to interpret these units,

00:44:50.370 --> 00:44:53.500
they would still hold as
much power as they have.

00:44:53.500 --> 00:44:57.080
Meaning, are those units
enough when we give them

00:44:57.080 --> 00:44:58.870
to the alien species?

00:44:58.870 --> 00:45:01.390
- Let me ask you, do you understand

00:45:03.438 --> 00:45:05.852
digit images?

00:45:05.852 --> 00:45:07.920
- No, I don't understand.
- No, no, no.

00:45:07.920 --> 00:45:11.010
When you can recognize these digit images,

00:45:11.010 --> 00:45:12.493
it means that you understand.

00:45:13.680 --> 00:45:15.390
- Yes, I understand.
- You understand

00:45:15.390 --> 00:45:18.973
characters, you understand.
- Nope, nope, nope, nope.

00:45:22.613 --> 00:45:25.500
It's the imitation versus
understanding question.

00:45:25.500 --> 00:45:28.390
Because I don't understand the mechanism

00:45:28.390 --> 00:45:29.500
by which I understand--
- No, no.

00:45:29.500 --> 00:45:32.780
I'm not talking about, I'm
talking about predicates.

00:45:32.780 --> 00:45:35.150
You understand that it involves symmetry,

00:45:35.150 --> 00:45:37.753
maybe structure, maybe something else.

00:45:37.753 --> 00:45:40.296
I cannot formulate, I just was able

00:45:40.296 --> 00:45:43.843
to find symmetries, or
degree of symmetries.

00:45:43.843 --> 00:45:46.129
- So this is a good line.

00:45:46.129 --> 00:45:50.156
I feel like I understand
the basic elements

00:45:50.156 --> 00:45:54.330
of what makes a good hand
recognition system my own.

00:45:54.330 --> 00:45:56.460
Like, symmetry connects with me.

00:45:56.460 --> 00:45:59.160
It seems like that's a
very powerful predicate.

00:45:59.160 --> 00:46:02.410
My question is, is there
a lot more going on

00:46:02.410 --> 00:46:04.523
that we're not able to introspect?

00:46:05.480 --> 00:46:09.640
Maybe I need to be able to understand

00:46:09.640 --> 00:46:13.083
a huge amount in the world of ideas.

00:46:14.580 --> 00:46:18.420
Thousands of predicates,
millions of predicates

00:46:18.420 --> 00:46:20.600
in order to do hand recognition.

00:46:20.600 --> 00:46:23.639
- [Vladimir] I don't think so.

00:46:23.639 --> 00:46:26.870
- Both your hope and your intuition

00:46:26.870 --> 00:46:28.990
are such that very few--
- No, no, let me explain.

00:46:28.990 --> 00:46:31.640
You're using digits.

00:46:31.640 --> 00:46:33.543
You're using examples as well.

00:46:34.500 --> 00:46:37.690
Theory says that if you will use

00:46:40.052 --> 00:46:44.680
all possible functions from Hilbert Space,

00:46:44.680 --> 00:46:47.903
all possible predicates, you
don't need training data.

00:46:49.000 --> 00:46:53.406
You just will have
admissible set of functions

00:46:53.406 --> 00:46:57.150
which contain one function.
- Yes.

00:46:57.150 --> 00:47:01.160
So the trade off is, when
you're not using all predicates,

00:47:01.160 --> 00:47:02.653
you're only using a few good predicates,

00:47:02.653 --> 00:47:05.040
that you need to have some training data.

00:47:05.040 --> 00:47:07.850
- Yes, exactly.
- The more good predicates

00:47:07.850 --> 00:47:09.616
you have, the less training data

00:47:09.616 --> 00:47:11.184
you need.
- Exactly.

00:47:11.184 --> 00:47:14.020
That is intelligent learning.

00:47:14.020 --> 00:47:17.440
- Okay, I'm gonna keep asking
the same dumb question,

00:47:17.440 --> 00:47:20.270
handwritten recognition,
to solve the challenge,

00:47:20.270 --> 00:47:21.960
you kind of propose a challenge that says

00:47:21.960 --> 00:47:26.960
we should be able to get state
of the art MNIST error rates

00:47:27.140 --> 00:47:31.343
by using very few, 60 maybe
few examples per digit.

00:47:32.880 --> 00:47:35.493
What kind of predicates
do you think you'll--

00:47:35.493 --> 00:47:37.352
- [Vladimir] That is the challenge.

00:47:37.352 --> 00:47:38.388
(laughs)

00:47:38.388 --> 00:47:39.830
So people who will solve this problem.

00:47:39.830 --> 00:47:41.527
- They will answer.
- They will answer it.

00:47:41.527 --> 00:47:44.780
- Do you think they'll
be able to answer it

00:47:44.780 --> 00:47:46.583
in a human explainable way?

00:47:48.045 --> 00:47:50.820
- They just need the
right function, that's it.

00:47:50.820 --> 00:47:54.040
- But so, can that
function be written I guess

00:47:55.524 --> 00:47:58.740
by an automated reasoning system?

00:47:58.740 --> 00:48:01.140
Whether we're talking
about a neural network

00:48:01.140 --> 00:48:05.090
learning a particular
function, or another mechanism.

00:48:05.090 --> 00:48:08.570
- No, I'm not against neural network.

00:48:08.570 --> 00:48:11.620
I am against admissible set of function

00:48:11.620 --> 00:48:13.070
which creates neural network.

00:48:14.114 --> 00:48:15.243
You did it by hand.

00:48:16.400 --> 00:48:20.799
You don't do it by invariants,

00:48:20.799 --> 00:48:23.383
by predicate, by reason.

00:48:24.630 --> 00:48:26.410
- But neural networks can then reverse,

00:48:26.410 --> 00:48:29.963
to the reverse step of
helping you find a function.

00:48:30.999 --> 00:48:34.604
The task of a neural network is to find

00:48:34.604 --> 00:48:39.120
disentangled representation,
for example is what they call,

00:48:39.120 --> 00:48:42.140
is to fine that one predicate function

00:48:42.140 --> 00:48:45.462
that's really captures
some kind of essence.

00:48:45.462 --> 00:48:48.640
Not the entire essence,
but one very useful essence

00:48:48.640 --> 00:48:52.690
of this particular visual space.

00:48:52.690 --> 00:48:54.140
Do you think that's possible?

00:48:55.470 --> 00:48:58.660
Listen, I'm grasping, hoping
there's an automated way

00:48:58.660 --> 00:49:00.330
to find good predicates, right?

00:49:00.330 --> 00:49:03.030
So the question is,
what are the mechanisms

00:49:03.030 --> 00:49:05.730
of finding good predicates, ideas,

00:49:05.730 --> 00:49:08.080
that you think we should pursue?

00:49:08.080 --> 00:49:10.130
A young grad student listening right now.

00:49:11.300 --> 00:49:13.400
- I gave example.

00:49:13.400 --> 00:49:17.300
So find situation where

00:49:18.980 --> 00:49:21.553
predicate, which you're suggesting,

00:49:23.510 --> 00:49:25.237
don't create invariant.

00:49:27.340 --> 00:49:30.910
It's like in physics, find situation

00:49:30.910 --> 00:49:34.393
where existing theory cannot explain it.

00:49:36.815 --> 00:49:39.394
- [Lex] Find a situation
where the existing theory

00:49:39.394 --> 00:49:40.970
can't explain it.
- Cannot explain this.

00:49:40.970 --> 00:49:42.770
- [Lex] So you're finding contradictions.

00:49:42.770 --> 00:49:46.140
- Find contradiction, and then
remove this contradiction.

00:49:46.140 --> 00:49:48.930
But in my case, what means contradiction,

00:49:48.930 --> 00:49:53.460
you find function which, if
you will use this function,

00:49:53.460 --> 00:49:54.960
you're not keeping invariants.

00:49:57.150 --> 00:49:58.430
- [Lex] So really the process

00:49:58.430 --> 00:50:01.300
of discovering contradictions.

00:50:01.300 --> 00:50:02.133
- Yeah.

00:50:04.070 --> 00:50:05.910
It is like in physics.

00:50:05.910 --> 00:50:09.810
Find situation where
you have contradiction

00:50:09.810 --> 00:50:11.963
for one of the property,

00:50:13.240 --> 00:50:15.500
for one of the predicate,

00:50:15.500 --> 00:50:18.990
then include this predicate
making invariants.

00:50:18.990 --> 00:50:20.470
And solve, again, this problem,

00:50:20.470 --> 00:50:22.120
now you don't have contradiction.

00:50:23.320 --> 00:50:24.513
But it is not

00:50:27.857 --> 00:50:30.360
the best way probably, I don't know,

00:50:30.360 --> 00:50:32.940
to looking for predicate.
- That's just one way.

00:50:32.940 --> 00:50:34.340
Okay.
- That, no, no.

00:50:34.340 --> 00:50:37.310
It is brute force way.
- The brute force way.

00:50:37.310 --> 00:50:38.150
What about

00:50:39.810 --> 00:50:44.693
the ideas of what, big
umbrella term of symbolic AI?

00:50:45.912 --> 00:50:48.510
In the '80s with Xper Systems,

00:50:48.510 --> 00:50:51.363
sort of logic, reasoning-based systems.

00:50:53.413 --> 00:50:55.713
Is there hope there to find some,

00:50:57.010 --> 00:51:00.490
through sort of, deductive reasoning,

00:51:00.490 --> 00:51:04.433
to find good predicates?

00:51:05.495 --> 00:51:06.995
- [Vladimir] I don't think so.

00:51:09.000 --> 00:51:11.223
I think that just logic is not enough.

00:51:12.080 --> 00:51:14.750
- Kind of a compelling notion, though.

00:51:14.750 --> 00:51:17.620
That when smart people sit in a room

00:51:17.620 --> 00:51:20.350
and reason through things,
it seems compelling.

00:51:20.350 --> 00:51:23.543
And making our machines do
the same is also compelling.

00:51:26.230 --> 00:51:27.760
- Everything is very simple

00:51:29.661 --> 00:51:32.773
when you have infinite
number of predicate.

00:51:34.080 --> 00:51:35.240
You can choose

00:51:36.860 --> 00:51:38.590
the function you want.

00:51:38.590 --> 00:51:41.683
You have invariants and you
choose the function you want.

00:51:43.740 --> 00:51:46.367
But you have to have

00:51:47.620 --> 00:51:48.660
not too many

00:51:50.459 --> 00:51:53.453
invariants to solve the problem.

00:51:56.743 --> 00:51:59.940
And how from infinite number function

00:51:59.940 --> 00:52:02.970
to select finite number

00:52:05.086 --> 00:52:08.483
and hopefully small finite
number of functions.

00:52:09.720 --> 00:52:11.080
Which is good enough

00:52:13.535 --> 00:52:16.693
to extract some small set
of admissible functions.

00:52:17.910 --> 00:52:19.850
So they will be admissible, it's for sure,

00:52:19.850 --> 00:52:23.880
because every function just
decrease set of function

00:52:23.880 --> 00:52:25.670
and leaving it admissible.

00:52:25.670 --> 00:52:27.720
But it will be small.

00:52:27.720 --> 00:52:32.720
- But why do you think
logic-based systems can't help?

00:52:34.380 --> 00:52:36.360
Intuition, not--
- Because you should

00:52:36.360 --> 00:52:39.460
know reality, you should know life.

00:52:39.460 --> 00:52:43.626
This guy like Propp, he knows something

00:52:43.626 --> 00:52:48.402
and he tried to put in
invariants his understanding.

00:52:48.402 --> 00:52:50.900
- So but that's the human, yeah, yeah.

00:52:50.900 --> 00:52:53.190
But see, you're putting too much value

00:52:53.190 --> 00:52:57.910
into Vladimir Propp's knowing something.

00:52:57.910 --> 00:53:01.120
- No, it is--
- Am I being misunderstanding?

00:53:01.120 --> 00:53:02.903
- What means you know life?

00:53:04.420 --> 00:53:07.010
What it mean?
- You know common sense.

00:53:07.010 --> 00:53:09.313
- No, no, you know something.

00:53:10.400 --> 00:53:13.430
Common sense, it is some rules.

00:53:13.430 --> 00:53:14.810
- You think so?

00:53:14.810 --> 00:53:17.190
Common sense is simply rules?

00:53:17.190 --> 00:53:21.943
Common sense is every, it's mortality,

00:53:23.237 --> 00:53:24.700
it's fear of death,

00:53:24.700 --> 00:53:27.900
it's love, it's spirituality,

00:53:27.900 --> 00:53:30.840
it's happiness and sadness.

00:53:30.840 --> 00:53:34.420
All of it is tied up into
understanding gravity

00:53:34.420 --> 00:53:37.102
which is what we think of as common sense.

00:53:37.102 --> 00:53:39.707
- I don't credit or discuss of that.

00:53:39.707 --> 00:53:44.707
I want to discuss understand
digit recognition.

00:53:45.190 --> 00:53:47.650
- Any time I bring up love and death

00:53:47.650 --> 00:53:50.650
you bring it back to digit recognition.

00:53:50.650 --> 00:53:52.300
I like it. (laughs)
- No, you know,

00:53:52.300 --> 00:53:55.190
it is doable because there is a challenge.

00:53:55.190 --> 00:53:57.720
- Yeah.
- Which I still have

00:53:57.720 --> 00:54:01.590
to solve it; if I will
have a student concentrate

00:54:01.590 --> 00:54:04.800
on this work, I will
suggest something or so.

00:54:04.800 --> 00:54:06.900
- You mean handwritten recognition?

00:54:06.900 --> 00:54:09.480
Yeah, it's a beautifully simple, elegant,

00:54:09.480 --> 00:54:11.383
and yet--
- I think that I know

00:54:11.383 --> 00:54:13.440
invariants which will solve this.

00:54:13.440 --> 00:54:15.440
- You do?
- I think that, I think that.

00:54:17.205 --> 00:54:20.163
But it is not universal.

00:54:21.600 --> 00:54:24.870
I want some universal
invariants which are good

00:54:24.870 --> 00:54:29.360
not only for digit recognition,
for image understanding.

00:54:30.680 --> 00:54:34.210
- So let me ask, how hard do you think

00:54:34.210 --> 00:54:37.133
is 2-D image understanding?

00:54:38.810 --> 00:54:42.663
If we can kind of intuit
handwritten recognition,

00:54:43.840 --> 00:54:48.645
how big of a step, leap,
journey is it from that?

00:54:48.645 --> 00:54:51.970
If I gave you good, if
I solved your challenge

00:54:51.970 --> 00:54:54.830
for handwritten recognition,
how long would my journey

00:54:54.830 --> 00:54:58.150
then be from that to
understanding more general,

00:54:58.150 --> 00:54:59.990
natural images?
- Immediately.

00:54:59.990 --> 00:55:04.990
You will understand it as soon
as you will make a record.

00:55:05.600 --> 00:55:07.750
- You think so?
- Because it is not for free.

00:55:07.750 --> 00:55:12.750
As soon as you will
create several invariants

00:55:13.210 --> 00:55:14.480
which will help you

00:55:15.510 --> 00:55:17.770
to get the same

00:55:18.700 --> 00:55:22.830
performance that the best neural net did

00:55:22.830 --> 00:55:27.790
using more than 100 times less examples.

00:55:27.790 --> 00:55:31.260
You have to have something
smart to do that.

00:55:31.260 --> 00:55:33.992
- And you're saying?
- That's not an invariant.

00:55:33.992 --> 00:55:37.457
It is predicate because
you should put some idea

00:55:37.457 --> 00:55:38.573
how to do that.

00:55:39.450 --> 00:55:40.363
- But okay.

00:55:41.580 --> 00:55:44.550
Let me just pause, maybe it's
a trivial point, maybe not,

00:55:44.550 --> 00:55:48.860
but handwritten recognition
feels like a 2-D,

00:55:48.860 --> 00:55:50.483
two-dimensional problem.

00:55:51.530 --> 00:55:54.420
And it seems, like how much complicated

00:55:54.420 --> 00:55:58.030
is the fact that most
images are a projection

00:55:58.030 --> 00:56:03.030
of a three-dimensional
world onto a 2-D plane?

00:56:03.140 --> 00:56:05.920
It feels like for a
three-dimensional world,

00:56:05.920 --> 00:56:08.710
we need to start
understanding common sense

00:56:08.710 --> 00:56:10.963
in order to understand an image.

00:56:12.010 --> 00:56:17.010
It's no longer visual shape and symmetry.

00:56:17.520 --> 00:56:20.750
It's having to start to
understand concepts of,

00:56:20.750 --> 00:56:22.723
understand life.
- Yeah.

00:56:24.250 --> 00:56:27.350
You're talking that there
are different invariant,

00:56:27.350 --> 00:56:28.950
different predicate, yeah.

00:56:28.950 --> 00:56:32.520
- [Lex] And potentially
much larger number.

00:56:32.520 --> 00:56:36.800
- You know, maybe, but
let's start from simple.

00:56:36.800 --> 00:56:38.574
- [Lex] But you said that
it would be immediate.

00:56:38.574 --> 00:56:41.440
- No, you know, I cannot
think about things

00:56:41.440 --> 00:56:43.163
which I don't understand yet.

00:56:43.163 --> 00:56:44.810
This I understand.

00:56:44.810 --> 00:56:48.460
But I'm sure that I don't
understand everything there.

00:56:48.460 --> 00:56:49.948
- [Lex] Yeah, that's the difference--

00:56:49.948 --> 00:56:50.980
- It's like they say,

00:56:50.980 --> 00:56:54.370
do as simple as possible, but not simpler,

00:56:54.370 --> 00:56:56.560
and that is exact case.

00:56:56.560 --> 00:56:58.980
- With handwritten rec--
- With handwritten.

00:56:58.980 --> 00:57:02.453
- Yeah, but that's the
difference between you and I.

00:57:02.453 --> 00:57:06.184
(laughs) I welcome and enjoy

00:57:06.184 --> 00:57:10.020
thinking about things that I
completely don't understand.

00:57:10.020 --> 00:57:12.410
Because to me it's a natural extension,

00:57:12.410 --> 00:57:15.170
without having solved
handwritten recognition

00:57:15.170 --> 00:57:17.733
to wonder how,

00:57:19.380 --> 00:57:24.340
how difficult is the next
step of understanding

00:57:24.340 --> 00:57:27.810
2-D and 3-D images, because ultimately,

00:57:27.810 --> 00:57:30.260
while the science of
intelligence is fascinating,

00:57:30.260 --> 00:57:31.940
it's also fascinating to see how

00:57:31.940 --> 00:57:34.730
that maps to the
engineering of intelligence.

00:57:34.730 --> 00:57:39.330
And recognizing handwritten digits is not,

00:57:39.330 --> 00:57:42.640
doesn't help you, it might, it may not,

00:57:42.640 --> 00:57:46.570
help you with the problem
of general intelligence.

00:57:46.570 --> 00:57:48.487
We don't know; it'll
help you a little bit.

00:57:48.487 --> 00:57:49.510
We don't know how much.
- It is unclear.

00:57:49.510 --> 00:57:50.690
- It's unclear.
- Yeah.

00:57:50.690 --> 00:57:52.130
- It might very much.
- But I would like

00:57:52.130 --> 00:57:55.140
to make a remark: I start not from very

00:57:56.980 --> 00:57:59.140
primitive problem like,

00:58:01.260 --> 00:58:06.260
challenge problem; I start
with very general problem,

00:58:06.330 --> 00:58:09.370
with Plato, so you understand.

00:58:09.370 --> 00:58:13.612
And it comes from Plato,
digit recognition.

00:58:13.612 --> 00:58:16.210
- So you basically took Plato

00:58:17.723 --> 00:58:20.340
and the world of forms and ideas,

00:58:20.340 --> 00:58:23.920
and mapped, and projected
it into the clearest,

00:58:23.920 --> 00:58:26.830
simplest formulation of that big world

00:58:26.830 --> 00:58:27.870
into handwritten recognition.

00:58:27.870 --> 00:58:30.880
- I will say that I did
not understand Plato until

00:58:33.273 --> 00:58:36.181
recently, and until

00:58:36.181 --> 00:58:40.800
I considered weak convergence
and then predicate

00:58:40.800 --> 00:58:43.630
and then, oh, this is what Plato thought.

00:58:45.840 --> 00:58:47.142
- Can you linger on that?

00:58:47.142 --> 00:58:50.210
How do you think about this world of ideas

00:58:50.210 --> 00:58:52.003
and world of things and Plato?

00:58:53.063 --> 00:58:55.879
- It is a metaphor.
- It's a metaphor for sure.

00:58:55.879 --> 00:58:58.295
It's a compelling, it's a
poetic and a beautiful metaphor.

00:58:58.295 --> 00:59:01.672
But what can you--
- But it is a way how

00:59:01.672 --> 00:59:04.960
you should try to understand

00:59:04.960 --> 00:59:07.890
how a duck ideas in the world.

00:59:07.890 --> 00:59:09.403
So from my point of view,

00:59:11.817 --> 00:59:15.560
it is very clear, but it
is a line all the time

00:59:15.560 --> 00:59:16.873
people looking for that.

00:59:18.461 --> 00:59:22.460
Say, Plato then Hegel,

00:59:22.460 --> 00:59:24.310
whatever reasonable it exists,

00:59:24.310 --> 00:59:26.217
whatever exists it is reasonable.

00:59:26.217 --> 00:59:29.173
I don't know what he
have in mind, reasonable.

00:59:30.230 --> 00:59:31.800
- [Lex] Right, these philosophers again.

00:59:31.800 --> 00:59:33.400
- No, no, no, no, no, no, it is,

00:59:34.336 --> 00:59:37.130
it is next stop of Wilner.

00:59:37.130 --> 00:59:40.163
That which we might understand
something of reality.

00:59:41.023 --> 00:59:43.090
He did the same Plato line.

00:59:43.090 --> 00:59:46.463
And then it comes suddenly
to Vladimir Propp.

00:59:48.628 --> 00:59:50.190
Look, 31 ideas, 31 units,
and describes everything.

00:59:54.330 --> 00:59:59.087
- There's abstractions, ideas
that represent our world,

01:00:00.480 --> 01:00:03.310
and we should always
try to reach into that.

01:00:03.310 --> 01:00:06.250
- Yeah, but what you
should make a projection

01:00:06.250 --> 01:00:09.120
on the reality, but understanding is,

01:00:09.120 --> 01:00:10.723
it is abstract ideas.

01:00:11.810 --> 01:00:15.950
You have in your mind
several abstract ideas

01:00:15.950 --> 01:00:17.627
which you can apply to reality.

01:00:17.627 --> 01:00:20.720
- And reality in this case so
if we look at machine learning

01:00:20.720 --> 01:00:22.700
is data.
- This example, data.

01:00:22.700 --> 01:00:24.060
- Data.

01:00:24.060 --> 01:00:26.270
Okay, let me put this on you,

01:00:26.270 --> 01:00:28.340
because I'm an emotional creature.

01:00:28.340 --> 01:00:30.800
I'm not a mathematical creature like you.

01:00:30.800 --> 01:00:35.221
I find compelling the
idea, forget the space,

01:00:35.221 --> 01:00:36.810
this sea of functions.

01:00:36.810 --> 01:00:39.560
There's also a sea of data in the world.

01:00:39.560 --> 01:00:42.320
And I find compelling that there might be,

01:00:42.320 --> 01:00:43.523
like you said, teacher,

01:00:44.640 --> 01:00:49.250
small examples of data
that are most useful

01:00:49.250 --> 01:00:54.020
for discovering good,
whether it's predicates

01:00:54.020 --> 01:00:57.640
or good functions, that
the selection of data

01:00:57.640 --> 01:01:02.170
may be a powerful journey,
a useful mechanism.

01:01:02.170 --> 01:01:04.440
You know, coming up with
a mechanism for selecting

01:01:04.440 --> 01:01:06.503
good data might be useful, too.

01:01:07.480 --> 01:01:12.440
Do you find this idea of
finding the right data set

01:01:12.440 --> 01:01:14.020
interesting at all?

01:01:14.020 --> 01:01:16.723
Or do you kinda take
the data set as a given?

01:01:17.740 --> 01:01:20.130
- I think that it is, you know,

01:01:20.130 --> 01:01:22.670
my thing is very simple.

01:01:22.670 --> 01:01:24.943
You have huge set of functions.

01:01:26.300 --> 01:01:30.703
If you will apply, and you
have not too many data.

01:01:32.290 --> 01:01:36.600
If you pick up function
which describes this data,

01:01:37.570 --> 01:01:39.963
you will do not very well.

01:01:41.220 --> 01:01:44.140
- Like randomly pick?
- Yeah (mumbles)

01:01:44.140 --> 01:01:45.443
It will be irritating.

01:01:46.380 --> 01:01:50.170
So you should decrease set of function

01:01:50.170 --> 01:01:53.640
from which you're picking out one.

01:01:53.640 --> 01:01:58.063
So you should go somehow to
admissible set of functions.

01:01:59.550 --> 01:02:02.770
And this, what about weak convergence?

01:02:04.874 --> 01:02:08.060
From another point of view,

01:02:08.060 --> 01:02:09.480
to make

01:02:11.160 --> 01:02:14.530
admissible set of function,
you need just the deal,

01:02:14.530 --> 01:02:18.983
just function which you
will take an inner product.

01:02:20.177 --> 01:02:21.290
Which you will measure

01:02:22.990 --> 01:02:24.563
property of your function.

01:02:28.640 --> 01:02:31.200
That is how it works.

01:02:31.200 --> 01:02:32.033
- [Lex] No, I get it, I get it.

01:02:32.033 --> 01:02:34.060
I understand it but do you,

01:02:34.060 --> 01:02:36.500
the reality is--
- But let's discuss,

01:02:36.500 --> 01:02:39.173
let's think about examples.

01:02:40.030 --> 01:02:44.133
You have huge set of function
and you have several examples.

01:02:45.508 --> 01:02:48.240
If you just trying to

01:02:48.240 --> 01:02:52.683
keep, take function which
satisfies these examples,

01:02:53.760 --> 01:02:55.273
you still will not have it.

01:02:56.640 --> 01:02:59.350
You need decrease, you need
admissible set of functions.

01:02:59.350 --> 01:03:03.270
- Absolutely, but what, say you have

01:03:03.270 --> 01:03:05.053
more data than functions.

01:03:07.327 --> 01:03:09.800
I mean, maybe not more
data than functions,

01:03:09.800 --> 01:03:11.500
'cause that's--
- That's impossible.

01:03:11.500 --> 01:03:15.180
- Impossible, I was trying
to be poetic for a second.

01:03:15.180 --> 01:03:17.300
I mean, you have a huge amount of data,

01:03:17.300 --> 01:03:19.033
a huge amount of examples.

01:03:19.870 --> 01:03:22.090
- But amount of function can be

01:03:22.090 --> 01:03:24.721
even bigger.
- Even bigger, I understand.

01:03:24.721 --> 01:03:25.554
- Everything is (chuckles)

01:03:25.554 --> 01:03:27.543
- [Lex] There's always a bigger boat.

01:03:27.543 --> 01:03:29.220
- Whole Hilbert Space of functions.

01:03:29.220 --> 01:03:31.830
- I got you, but okay.

01:03:31.830 --> 01:03:35.860
But you don't, you don't
find the world of data

01:03:35.860 --> 01:03:38.750
to be an interesting optimization space?

01:03:38.750 --> 01:03:42.113
Like, the optimization should
be in the space of functions.

01:03:45.262 --> 01:03:46.940
- In creating admissible set of functions.

01:03:46.940 --> 01:03:48.560
- [Lex] Admissible set of functions.

01:03:48.560 --> 01:03:52.233
- You know, even from the
classical, this is so.

01:03:54.500 --> 01:03:58.720
From structured reasoning,
you should organize

01:03:59.710 --> 01:04:03.063
function in the way

01:04:04.410 --> 01:04:07.540
they will be useful for you.
- Right.

01:04:07.540 --> 01:04:09.237
- And that is admissible step.

01:04:10.197 --> 01:04:12.610
- But the way you're thinking about useful

01:04:13.560 --> 01:04:17.293
is you're given a small set of examples.

01:04:17.293 --> 01:04:20.100
- Small set of functions which contain

01:04:20.100 --> 01:04:21.820
functions by looking for it.

01:04:21.820 --> 01:04:26.430
- Yeah, but as looking for
it based on the empirical set

01:04:26.430 --> 01:04:28.160
of small examples.
- Yeah.

01:04:28.160 --> 01:04:31.290
But that is another
story, I don't touch it.

01:04:31.290 --> 01:04:35.730
Because I believe that
these small examples,

01:04:35.730 --> 01:04:37.380
it's not too small.

01:04:37.380 --> 01:04:41.360
Say 65%, law of large numbers works.

01:04:41.360 --> 01:04:43.400
I don't need uniform law.

01:04:43.400 --> 01:04:46.740
The story is that in
statistics there are two laws.

01:04:46.740 --> 01:04:51.100
Law of large numbers and
uniform law of large numbers.

01:04:51.100 --> 01:04:56.100
So I want a situation where
I use law of large numbers

01:04:56.170 --> 01:04:58.280
but not uniform law of large numbers.

01:04:58.280 --> 01:05:00.380
- [Lex] Right, so 60 is law of large.

01:05:00.380 --> 01:05:02.034
It's large enough.
- I hope, I hope.

01:05:02.034 --> 01:05:05.206
It still needs some evaluation,

01:05:05.206 --> 01:05:07.270
some balance, et cetera.

01:05:08.122 --> 01:05:10.872
What I did is the following that,

01:05:11.800 --> 01:05:13.217
if you trust that

01:05:16.469 --> 01:05:20.110
say, this average gives
you something close

01:05:20.110 --> 01:05:24.031
to expectation so you can talk about that,

01:05:24.031 --> 01:05:26.880
about this predicate.
- Yeah.

01:05:26.880 --> 01:05:30.327
- [Vladimir] And that is
basis of human intelligence.

01:05:30.327 --> 01:05:33.770
- Good predicates, the
discovery of good predicates

01:05:33.770 --> 01:05:34.860
is the basis of human intelligence.

01:05:34.860 --> 01:05:36.200
- No, no, it is discovery

01:05:36.200 --> 01:05:39.218
of your understanding of world.

01:05:39.218 --> 01:05:44.218
Of your total logic of
understanding the world.

01:05:45.270 --> 01:05:47.765
Because you have several functions

01:05:47.765 --> 01:05:51.145
which you will apply to reality.

01:05:51.145 --> 01:05:52.794
- Can you say that again?

01:05:52.794 --> 01:05:56.127
So you're--
- You have several functions,

01:05:57.140 --> 01:05:59.890
predicates, but they're abstract.

01:06:01.112 --> 01:06:04.350
Then you will apply them
to reality, to your data,

01:06:04.350 --> 01:06:07.410
and you will create in
this weak predicate,

01:06:07.410 --> 01:06:09.673
which is useful for your task.

01:06:12.273 --> 01:06:16.170
But predicate are not related specifically

01:06:16.170 --> 01:06:17.830
to your task, to this here task.

01:06:17.830 --> 01:06:22.270
It is abstract functions,
which being applied,

01:06:22.270 --> 01:06:24.500
applied to--
- Many tasks that you might

01:06:24.500 --> 01:06:26.688
be interested in.
- It might be many tasks.

01:06:26.688 --> 01:06:27.917
I don't know.

01:06:27.917 --> 01:06:29.940
Different tasks.

01:06:29.940 --> 01:06:31.450
- [Lex] Well they should be many tasks.

01:06:31.450 --> 01:06:32.850
Right?
- Yeah, I believe.

01:06:34.066 --> 01:06:35.670
Like in Propp case.

01:06:35.670 --> 01:06:40.170
It was for fairy tales, but
it's happened everywhere.

01:06:40.170 --> 01:06:42.570
- Okay, we talked about
images a little bit but,

01:06:43.550 --> 01:06:45.773
can we talk about Noam
Chomsky for a second?

01:06:46.643 --> 01:06:48.893
(laughing)

01:06:52.128 --> 01:06:54.240
- I don't know him very well.

01:06:54.240 --> 01:06:57.030
- Personally?
- Not personally I don't know.

01:06:57.030 --> 01:06:58.230
- His ideas.
- His ideas.

01:06:58.230 --> 01:07:01.030
- Well let me just say,
do you think language,

01:07:01.030 --> 01:07:05.800
human language is essential
to expressing ideas,

01:07:05.800 --> 01:07:08.350
as Noam Chomsky believes?

01:07:08.350 --> 01:07:10.934
So like, language is at the core

01:07:10.934 --> 01:07:12.933
of our formation of predicates.

01:07:14.100 --> 01:07:15.033
Human language.

01:07:16.529 --> 01:07:20.750
- In all the story of
language is very complicated.

01:07:20.750 --> 01:07:24.775
I don't understand this
and I thought about--

01:07:24.775 --> 01:07:27.140
- Nobody does.
- I'm not ready

01:07:27.140 --> 01:07:30.770
to work on that because it's so huge.

01:07:30.770 --> 01:07:34.253
It is not for me, and I
believe not for our century.

01:07:35.910 --> 01:07:39.870
- The 21st century.
- Not for 21st century.

01:07:39.870 --> 01:07:42.180
We should learn something, a lot of stuff

01:07:42.180 --> 01:07:45.100
from simple tasks like digit recognition.

01:07:45.100 --> 01:07:49.250
- So you think digital recognition,

01:07:49.250 --> 01:07:53.660
2-D image, how would you more abstractly

01:07:53.660 --> 01:07:56.490
define it, digit recognition?

01:07:56.490 --> 01:07:58.263
It's 2-D image,

01:07:59.530 --> 01:08:03.113
symbol recognition essentially?

01:08:05.799 --> 01:08:09.730
I'm trying to get a sense,
sort of thinking about it now,

01:08:09.730 --> 01:08:12.243
having worked with MNIST forever,

01:08:13.174 --> 01:08:17.080
how small of a subset is
this of the general vision

01:08:17.080 --> 01:08:20.483
recognition problem and the
general intelligence problem?

01:08:21.620 --> 01:08:22.453
Is it?

01:08:24.075 --> 01:08:27.830
Is it a giant subset, is it not?

01:08:27.830 --> 01:08:30.200
And how far away is language?

01:08:30.200 --> 01:08:33.143
- You know, let me refer to Einstein.

01:08:34.580 --> 01:08:37.930
Take the simplest problem,
as simple as possible,

01:08:37.930 --> 01:08:42.930
but not simpler, and this is
challenge, is simple problem.

01:08:44.500 --> 01:08:49.147
But it's simple by idea,
but not simple to get it.

01:08:50.729 --> 01:08:52.562
When you will do this,

01:08:53.786 --> 01:08:57.410
you will find some
predicate which helps it.

01:08:57.410 --> 01:09:00.180
- Yeah, with Einstein you can,

01:09:00.180 --> 01:09:03.057
you look at General Relativity,

01:09:03.057 --> 01:09:06.783
but that doesn't help you
with quantum mechanics.

01:09:06.783 --> 01:09:08.750
- And that's another story.

01:09:08.750 --> 01:09:11.850
You don't have any universal instrument.

01:09:11.850 --> 01:09:14.550
- Yeah, so I'm trying to wonder

01:09:14.550 --> 01:09:16.663
if which space we're in.

01:09:17.911 --> 01:09:21.110
Whether handwritten recognition
is like General Relativity

01:09:21.110 --> 01:09:23.200
and then language is
like, quantum mechanics,

01:09:23.200 --> 01:09:26.970
are you still gonna
have to do a lot of mess

01:09:26.970 --> 01:09:29.223
to universalize it but,

01:09:31.940 --> 01:09:33.373
I'm trying to see.

01:09:35.623 --> 01:09:39.150
What's your intuition why
handwritten recognition

01:09:39.150 --> 01:09:40.913
is easier than language?

01:09:42.020 --> 01:09:45.330
Just, I think a lot of
people would agree with that,

01:09:45.330 --> 01:09:47.373
but if you could elucidate sort of,

01:09:48.398 --> 01:09:50.213
the intuition of why.

01:09:51.990 --> 01:09:53.900
- I don't know, no,

01:09:53.900 --> 01:09:56.443
I don't think in this direction.

01:09:56.443 --> 01:09:59.563
I just think in the direction
that this is problem,

01:10:00.870 --> 01:10:02.250
which if you will

01:10:03.950 --> 01:10:04.970
solve it well,

01:10:08.252 --> 01:10:09.419
we will create

01:10:12.550 --> 01:10:16.123
some abstract understanding of images.

01:10:18.030 --> 01:10:19.710
Maybe not all images.

01:10:19.710 --> 01:10:22.740
I would like talk to guys who doing

01:10:22.740 --> 01:10:26.280
in real images in Columbia University.

01:10:26.280 --> 01:10:27.210
- What kind of images?

01:10:27.210 --> 01:10:28.800
Unreal you said?

01:10:28.800 --> 01:10:29.820
- Real images.
- Real images.

01:10:29.820 --> 01:10:32.310
- Yeah, what their idea is,

01:10:32.310 --> 01:10:35.140
there are predicate what can be predicate.

01:10:35.140 --> 01:10:40.140
I say symmetry will play a
role in real-life images.

01:10:41.250 --> 01:10:43.900
In any real-life images, 2-D images,

01:10:43.900 --> 01:10:45.413
let's talk about 2-D images.

01:10:46.330 --> 01:10:47.250
Because...

01:10:50.250 --> 01:10:52.327
that's what we know.

01:10:52.327 --> 01:10:55.930
And neural network was
created for 2-D images.

01:10:55.930 --> 01:10:58.437
- So the people I know in
vision science, for example,

01:10:58.437 --> 01:11:01.000
for people who study human vision,

01:11:01.000 --> 01:11:04.500
that they usually go
to the world of symbols

01:11:04.500 --> 01:11:06.970
and like, handwritten
recognition but not really.

01:11:06.970 --> 01:11:08.470
It's other kinds of symbols

01:11:08.470 --> 01:11:11.560
to study our visual perception system.

01:11:11.560 --> 01:11:15.170
As far as I know, not much
predicate-type of thinking

01:11:15.170 --> 01:11:17.770
is understood about our vision system.

01:11:17.770 --> 01:11:19.390
- [Vladimir] They did not
think in this direction.

01:11:19.390 --> 01:11:21.730
- They don't, yeah, but
how do you even begin

01:11:21.730 --> 01:11:23.080
to think in that direction?

01:11:24.534 --> 01:11:26.603
- That is, I would like to discuss this.

01:11:27.710 --> 01:11:31.910
Because if you'll be
able to show that it is

01:11:32.810 --> 01:11:33.673
what's working,

01:11:36.764 --> 01:11:40.360
and theoretical thing, it's not so bad.

01:11:40.360 --> 01:11:43.360
- So if we compare it to language,

01:11:43.360 --> 01:11:46.530
language has like letters,
a finite set of letters

01:11:46.530 --> 01:11:49.480
and a finite set of ways
that you can put together

01:11:49.480 --> 01:11:53.720
those letters so it feels more
amenable to kind of analysis.

01:11:53.720 --> 01:11:58.690
With natural images,
there is so many pixels--

01:11:58.690 --> 01:12:00.840
- No, no, no, letter,

01:12:00.840 --> 01:12:03.660
language is much, much more complicated.

01:12:03.660 --> 01:12:08.030
It involves a lot of different stuff.

01:12:08.030 --> 01:12:09.530
It's not just understanding of

01:12:12.150 --> 01:12:13.893
simple class of tasks.

01:12:15.260 --> 01:12:18.190
I would like to see list of task

01:12:18.190 --> 01:12:20.240
where language is involved.
- Yes.

01:12:20.240 --> 01:12:23.210
So there's a lot of nice benchmarks now

01:12:23.210 --> 01:12:26.483
in natural language processing,
from the very trivial,

01:12:27.390 --> 01:12:30.190
like, understanding the
elements of a sentence,

01:12:30.190 --> 01:12:33.050
to question/answering,
so much more complicated

01:12:33.050 --> 01:12:36.120
where you talk about open domain dialogue.

01:12:36.120 --> 01:12:39.240
The natural question is,
will handwritten recognition,

01:12:39.240 --> 01:12:41.690
it's really the first step

01:12:41.690 --> 01:12:44.610
of understanding visual information.

01:12:44.610 --> 01:12:45.443
- Right.

01:12:48.099 --> 01:12:51.070
But even our records

01:12:51.070 --> 01:12:54.390
show that we're going wrong direction.

01:12:54.390 --> 01:12:56.580
Because we need 60,000 digits.

01:12:56.580 --> 01:12:59.330
- So even this first step, so forget about

01:12:59.330 --> 01:13:01.080
talking about the full journey.

01:13:01.080 --> 01:13:03.450
This first step should be
taking in the right direction.

01:13:03.450 --> 01:13:07.190
- No, no, in wrong direction
because 60,000 is unacceptable.

01:13:07.190 --> 01:13:11.207
- No, I'm saying it should be
taken in the right direction

01:13:11.207 --> 01:13:14.045
because 60,000 is not acceptable.

01:13:14.045 --> 01:13:18.470
- You can talk, it's great
we have 1/2 percent of error.

01:13:18.470 --> 01:13:21.620
- And hopefully the step from

01:13:21.620 --> 01:13:24.543
doing hand recognition
using very few examples,

01:13:24.543 --> 01:13:27.620
a step towards what
babies do when they crawl

01:13:27.620 --> 01:13:29.524
and they understand their
physical environment.

01:13:29.524 --> 01:13:30.940
- I don't know what baby do.
- I know you don't know

01:13:30.940 --> 01:13:33.920
about babies, but--
- If you will do from very

01:13:33.920 --> 01:13:37.620
small examples, you will find principals

01:13:38.755 --> 01:13:40.560
which are different.
- That will apply to babies.

01:13:40.560 --> 01:13:42.847
- From what we're using now.

01:13:45.430 --> 01:13:48.340
Theoretical it's more or less clear.

01:13:48.340 --> 01:13:52.300
That means you will use weak convergence,

01:13:52.300 --> 01:13:54.480
not just strong convergence.

01:13:54.480 --> 01:13:58.490
- Do you think these principals are,

01:13:58.490 --> 01:14:00.703
will naturally be human interpretable?

01:14:01.680 --> 01:14:02.550
- [Vladimir] Oh yeah.

01:14:02.550 --> 01:14:04.480
- So we'll be able to explain them

01:14:04.480 --> 01:14:06.230
and have a nice presentation to show

01:14:06.230 --> 01:14:07.530
what those principals are?

01:14:08.974 --> 01:14:10.780
Or are they very,

01:14:10.780 --> 01:14:14.420
going to be very kind of,
abstract kinds of functions?

01:14:14.420 --> 01:14:16.863
- For example, I talk
yesterday about symmetry.

01:14:18.710 --> 01:14:20.430
And I gave very simple examples.

01:14:20.430 --> 01:14:22.010
The same will be like that.

01:14:22.010 --> 01:14:24.680
- You gave like, a
predicate of a basic for--

01:14:24.680 --> 01:14:26.070
- For symmetries.
- Yes.

01:14:26.070 --> 01:14:28.220
For different symmetries
and you have for--

01:14:29.622 --> 01:14:30.455
- For degree of symmetries.

01:14:30.455 --> 01:14:33.670
That is important, not just symmetry

01:14:33.670 --> 01:14:36.143
exist and does not exist;
degree of symmetry.

01:14:38.048 --> 01:14:40.233
- [Lex] Yeah, for handwritten recognition.

01:14:41.590 --> 01:14:45.160
- It's not for handwritten,
it's for any images.

01:14:45.160 --> 01:14:47.700
But I would like to
apply it to handwritten.

01:14:47.700 --> 01:14:49.790
- Right, in theory it's more general.

01:14:49.790 --> 01:14:50.923
Okay, okay.

01:14:55.280 --> 01:14:58.170
So a lot of the things
we've been talking about

01:14:58.170 --> 01:15:01.840
falls, we've been talking
about philosophy a little bit,

01:15:01.840 --> 01:15:05.530
but also about mathematics and statistics.

01:15:05.530 --> 01:15:08.120
A lot of it falls into this idea,

01:15:08.120 --> 01:15:10.743
a universal idea of
statistical theory of learning.

01:15:11.800 --> 01:15:16.170
What is the most beautiful and sort of,

01:15:16.170 --> 01:15:19.110
powerful or essential idea
that you've come across,

01:15:19.110 --> 01:15:21.500
even for yourself just personally,

01:15:21.500 --> 01:15:25.490
in the world of statistics or
statistic theory of learning?

01:15:25.490 --> 01:15:29.323
- Probably uniform convergence
which we do with (mumbles).

01:15:32.990 --> 01:15:36.070
- [Lex] Can you describe
universal convergence?

01:15:36.070 --> 01:15:39.023
- You have law of large numbers.

01:15:40.070 --> 01:15:44.510
So for any function,
expectation of function,

01:15:44.510 --> 01:15:48.130
average of function converged expectation.

01:15:48.130 --> 01:15:50.510
But if you have a set of functions,

01:15:50.510 --> 01:15:52.363
for any function it is true.

01:15:53.280 --> 01:15:55.816
But it should converge similar to anywhere

01:15:55.816 --> 01:15:57.493
therefore all set of functions.

01:16:01.060 --> 01:16:03.370
For learning, you need

01:16:04.950 --> 01:16:08.563
uniform convergence; just
convergence is not enough.

01:16:11.210 --> 01:16:15.693
Because when you pick up
one which gives minimum,

01:16:17.875 --> 01:16:21.110
you can pick up one function

01:16:21.110 --> 01:16:25.730
which does not converge and it
will give you the best answer

01:16:26.730 --> 01:16:28.053
for this function.

01:16:31.470 --> 01:16:35.168
So you need the uniform
convergence to guarantee learning.

01:16:35.168 --> 01:16:37.390
Learning does not really enter
your law of large numbers,

01:16:40.760 --> 01:16:42.063
really universal.

01:16:46.307 --> 01:16:49.467
The idea of universal
convergence exists in statistics

01:16:49.467 --> 01:16:50.683
for a long time.

01:16:55.490 --> 01:16:57.107
It is interesting that

01:16:58.970 --> 01:17:02.130
as I think about myself,

01:17:02.130 --> 01:17:05.360
how stupid I was for 50 years,

01:17:05.360 --> 01:17:06.910
I did not see weak convergence.

01:17:08.455 --> 01:17:10.950
I work only on strong convergence.

01:17:10.950 --> 01:17:14.260
But now I think that most
powerful is weak convergence

01:17:15.260 --> 01:17:18.870
because it makes admissible
set of functions.

01:17:18.870 --> 01:17:21.703
And even in old proverbs,

01:17:22.720 --> 01:17:27.720
when people tried to understand
recognition about duck law,

01:17:28.280 --> 01:17:30.460
looks like a duck and so on,

01:17:30.460 --> 01:17:32.400
they used weak convergence.

01:17:32.400 --> 01:17:34.400
People in language they understand this.

01:17:36.110 --> 01:17:40.030
But when we're trying to
create artificial intelligence

01:17:42.260 --> 01:17:45.073
if we want invent in different way.

01:17:46.400 --> 01:17:50.550
Just consider strong convergence,
artificial intelligence.

01:17:50.550 --> 01:17:52.740
- So reducing the set
of admissible functions

01:17:52.740 --> 01:17:55.180
you think there should be

01:17:56.930 --> 01:17:59.920
effort put into
understanding the properties

01:17:59.920 --> 01:18:01.943
of weak convergence?
- You know,

01:18:02.890 --> 01:18:07.070
in classical mathematics,
in Hilbert Space,

01:18:07.070 --> 01:18:12.070
there are only two forms of
convergence, strong and weak.

01:18:14.170 --> 01:18:15.403
Now we can use both.

01:18:16.920 --> 01:18:19.263
That means that we did everything.

01:18:21.912 --> 01:18:24.473
And it so happened,

01:18:24.473 --> 01:18:29.473
that when we used Hilbert
Space, which is very rich space,

01:18:30.010 --> 01:18:31.950
space of continuous functions

01:18:34.870 --> 01:18:36.520
which has an integral and square.

01:18:38.020 --> 01:18:42.400
So we can apply weak and
strong convergence for learning

01:18:42.400 --> 01:18:44.193
and have closed-form solution.

01:18:45.130 --> 01:18:47.680
So for computation it is simple.

01:18:47.680 --> 01:18:51.093
For me it is sign that it is right way.

01:18:52.240 --> 01:18:56.047
Because you don't need any this theory.

01:18:56.047 --> 01:18:57.723
Yes, do whatever you want.

01:18:59.640 --> 01:19:02.297
But now the only way left

01:19:02.297 --> 01:19:04.820
is the concept of what is predicate?

01:19:04.820 --> 01:19:08.020
- Of predicate.
- But it is not statistics.

01:19:08.020 --> 01:19:09.760
- By the way, I like
the fact that you think

01:19:09.760 --> 01:19:13.270
that heuristics are a mess
that should be removed

01:19:13.270 --> 01:19:16.210
from the system, so closed-form solution

01:19:16.210 --> 01:19:19.513
is the ultimate goal.
- No it so happens

01:19:19.513 --> 01:19:20.810
that when you're using

01:19:22.430 --> 01:19:25.223
right instrument, you
have closed-form solution.

01:19:28.520 --> 01:19:32.770
- Do you think intelligence,
human-level intelligence,

01:19:32.770 --> 01:19:35.603
when we create it will,

01:19:37.660 --> 01:19:41.383
will have something like
a closed-form solution?

01:19:43.939 --> 01:19:46.390
- Now I'm looking on bounds,

01:19:46.390 --> 01:19:49.353
which I gave bounds for convergence.

01:19:50.907 --> 01:19:53.063
And when I'm looking for bounds,

01:19:54.350 --> 01:19:55.183
I'm thinking,

01:19:56.070 --> 01:20:00.973
what is the most appropriate
kernel of this bound would be.

01:20:02.480 --> 01:20:04.490
So we know that in say,

01:20:06.281 --> 01:20:09.720
all our businesses we use
radial basis function.

01:20:12.251 --> 01:20:14.290
But looking for the bound I think

01:20:14.290 --> 01:20:17.540
that I start to understand
that maybe we need

01:20:17.540 --> 01:20:21.140
to make corrections to
radial basis function,

01:20:21.140 --> 01:20:22.650
to be closer

01:20:24.960 --> 01:20:28.430
to what's better for these bounds.

01:20:28.430 --> 01:20:32.570
So I'm again trying to
understand what type of kernel

01:20:34.140 --> 01:20:35.140
have best

01:20:36.500 --> 01:20:38.753
approximation, not an approximation,

01:20:39.877 --> 01:20:43.470
best fit to these bounds.

01:20:43.470 --> 01:20:45.610
- Sure, so there's a
lot of interesting work

01:20:45.610 --> 01:20:47.870
that could be done in
discovering better function

01:20:47.870 --> 01:20:49.774
than the radial basis functions

01:20:49.774 --> 01:20:53.080
for the kinds of bounds you would find.

01:20:53.080 --> 01:20:55.890
- It still comes from,

01:20:55.890 --> 01:20:59.393
you're looking to match
and trying to understand.

01:21:00.270 --> 01:21:02.250
- From your own mind looking at the--

01:21:02.250 --> 01:21:03.929
- Yeah but--
- I don't know.

01:21:03.929 --> 01:21:05.479
- Then I'm trying to understand

01:21:08.660 --> 01:21:11.260
what will be good for that.

01:21:11.260 --> 01:21:14.010
- Yeah, but to me there's still a beauty,

01:21:14.010 --> 01:21:17.990
again, maybe I'm descending
value toward heuristics.

01:21:17.990 --> 01:21:22.343
To me, ultimately intelligence
will be a mess of heuristics.

01:21:23.610 --> 01:21:25.930
And that's the engineering answer,

01:21:25.930 --> 01:21:27.870
I guess.
- Absolutely.

01:21:27.870 --> 01:21:30.703
When you're doing say, self-driving cars,

01:21:32.560 --> 01:21:34.153
the great guy who will do this.

01:21:35.020 --> 01:21:38.633
It doesn't matter what theory behind that.

01:21:40.620 --> 01:21:43.923
Who has a better theory have to apply.

01:21:46.780 --> 01:21:50.400
It is the same story about predicate

01:21:50.400 --> 01:21:55.030
because you cannot create
rule for, situation is much

01:21:55.030 --> 01:21:57.787
more than you have rule for that.

01:22:01.220 --> 01:22:03.933
Maybe you can have more abstract rules,

01:22:05.017 --> 01:22:07.763
then it will be less literal.

01:22:08.780 --> 01:22:11.059
It is the same story about ideas

01:22:11.059 --> 01:22:15.133
and ideas applied to specific cases.

01:22:16.460 --> 01:22:18.920
- But still you should--
- You cannot avoid this.

01:22:18.920 --> 01:22:20.870
- [Lex] Yes of course,
but you should still reach

01:22:20.870 --> 01:22:22.310
for the ideas to understand

01:22:22.310 --> 01:22:23.980
the science.
- Yeah, yeah.

01:22:23.980 --> 01:22:25.303
- Let me kind of ask,

01:22:26.560 --> 01:22:29.390
do you think neural networks or functions

01:22:30.980 --> 01:22:32.653
can be made to reason?

01:22:34.258 --> 01:22:37.140
What do you think, we've been
talking about intelligence,

01:22:37.140 --> 01:22:39.660
but this idea of reasoning.

01:22:39.660 --> 01:22:43.923
There's an element of
sequentially disassembling,

01:22:45.498 --> 01:22:48.612
interpreting the images.

01:22:48.612 --> 01:22:51.853
When you think of handwritten recognition,

01:22:53.470 --> 01:22:55.270
we kind of think that
there will be a single,

01:22:55.270 --> 01:22:58.653
there's an input and an output;
there's not a recurrence.

01:23:00.060 --> 01:23:02.450
- Yeah.
- What do you think about,

01:23:02.450 --> 01:23:04.430
sort of, the idea of recurrence?

01:23:04.430 --> 01:23:06.670
Of going back to memory
and thinking through

01:23:06.670 --> 01:23:08.763
this sort of, sequentially,

01:23:10.570 --> 01:23:14.170
mangling the different
representations over and over

01:23:14.170 --> 01:23:17.403
until you arrive at a conclusion?

01:23:20.100 --> 01:23:22.010
Or is ultimately all of
that can be wrapped up

01:23:22.010 --> 01:23:24.160
in a function? (chuckles)

01:23:24.160 --> 01:23:26.850
- You're suggesting,

01:23:26.850 --> 01:23:29.840
that let us use this type of algorithm.

01:23:29.840 --> 01:23:33.090
When I started thinking, I first of all,

01:23:33.090 --> 01:23:35.203
starting to understand what I want.

01:23:36.570 --> 01:23:39.583
Can I write down what I want?

01:23:41.568 --> 01:23:43.223
And then I try to formalize.

01:23:44.687 --> 01:23:49.253
And when I do that, I'm thinking
how to solve this problem.

01:23:57.630 --> 01:24:02.446
Till now I did not see situation where--

01:24:02.446 --> 01:24:04.280
- Where you need recurrence.
- Recurrent.

01:24:04.280 --> 01:24:07.850
- But do you observe human beings?

01:24:07.850 --> 01:24:10.230
- Yeah.
- Do you try to,

01:24:10.230 --> 01:24:12.400
it's the imitation question, right?

01:24:12.400 --> 01:24:14.900
It seems that human beings reason,

01:24:14.900 --> 01:24:16.893
this kind of sequentially,

01:24:18.576 --> 01:24:22.760
sort of, does that
inspire in you a thought

01:24:22.760 --> 01:24:25.550
that we need to add that into our

01:24:27.690 --> 01:24:29.003
intelligence systems?

01:24:30.770 --> 01:24:32.393
You're saying, okay,

01:24:33.290 --> 01:24:34.430
you've kind of answered saying,

01:24:34.430 --> 01:24:37.050
until now I haven't seen a need for it.

01:24:37.050 --> 01:24:40.070
And so because of that,
you don't see a reason

01:24:40.070 --> 01:24:41.750
to think about it?

01:24:41.750 --> 01:24:44.983
- You know, most of
things I don't understand.

01:24:45.870 --> 01:24:47.503
In reasoning, in humans,

01:24:48.470 --> 01:24:50.543
it is for me too complicated.

01:24:52.730 --> 01:24:57.530
For me, the most difficult part is

01:24:59.110 --> 01:25:00.173
to ask questions,

01:25:01.210 --> 01:25:03.080
good questions.

01:25:03.080 --> 01:25:06.833
How it works, how people asking questions.

01:25:08.900 --> 01:25:09.800
I don't know this.

01:25:11.720 --> 01:25:13.650
- You said that machine
learning's not only

01:25:13.650 --> 01:25:16.490
about technical things,
speaking of questions,

01:25:16.490 --> 01:25:18.193
but it's also about philosophy.

01:25:20.800 --> 01:25:23.460
What role does philosophy
play in machine learning?

01:25:23.460 --> 01:25:26.860
We talked about Plato,
but generally thinking

01:25:28.230 --> 01:25:29.927
in this philosophical way,

01:25:32.015 --> 01:25:35.223
how does philosophy and math
fit together in your mind?

01:25:37.387 --> 01:25:39.373
- Just ideas, and then
their implementation.

01:25:39.373 --> 01:25:41.003
It's like predicate,

01:25:45.205 --> 01:25:47.955
say, admissible set of functions.

01:25:49.100 --> 01:25:51.500
It comes together, everything.

01:25:51.500 --> 01:25:52.333
Because,

01:25:54.530 --> 01:25:58.550
the first declaration of
theory was done 50 years ago,

01:25:58.550 --> 01:26:02.250
all that necessary, so everything there.

01:26:02.250 --> 01:26:04.707
If you have data you can, and you,

01:26:06.143 --> 01:26:07.280
in your set of functions

01:26:12.000 --> 01:26:13.610
has not big capacity.

01:26:13.610 --> 01:26:15.780
So law of inter-dimension,
you can do that.

01:26:15.780 --> 01:26:19.693
You can make structuralist
minimization, control capacity.

01:26:21.140 --> 01:26:21.973
But

01:26:24.042 --> 01:26:29.042
there was not table to make
admissible set of function with.

01:26:29.490 --> 01:26:31.930
Now when suddenly we realize that

01:26:33.153 --> 01:26:37.347
we did not use another idea
of convergence, which we can,

01:26:39.480 --> 01:26:41.500
everything comes together.

01:26:41.500 --> 01:26:43.340
- But those are mathematical notions.

01:26:43.340 --> 01:26:48.000
Philosophy plays a role of simply saying

01:26:48.000 --> 01:26:52.080
that we should be swimming
in the space of ideas.

01:26:52.080 --> 01:26:54.300
- Let's talk, what is philosophy?

01:26:54.300 --> 01:26:56.963
Philosophy means understanding of life.

01:26:59.070 --> 01:27:02.673
Understanding of life,
say people like Plato,

01:27:03.871 --> 01:27:06.793
they understand on very
high, abstract level of life.

01:27:09.245 --> 01:27:12.040
And whatever I'm doing,

01:27:12.040 --> 01:27:15.683
it's just implementation of
my understanding of life.

01:27:16.730 --> 01:27:18.480
But every new step,

01:27:20.447 --> 01:27:21.597
that is very difficult.

01:27:22.470 --> 01:27:23.573
For example,

01:27:26.170 --> 01:27:29.740
to find this idea that we need

01:27:31.903 --> 01:27:32.873
weak convergence,

01:27:35.670 --> 01:27:36.503
was not simple

01:27:37.920 --> 01:27:38.753
for me.

01:27:40.580 --> 01:27:43.180
- So that required thinking
about life a little bit.

01:27:44.530 --> 01:27:48.833
Hard to trace, but there
was some thought process.

01:27:49.790 --> 01:27:52.970
- You know, when I'm thinking
about the same problem

01:27:52.970 --> 01:27:55.617
for 50 years now,

01:27:57.160 --> 01:27:58.723
and again and again and again,

01:28:00.030 --> 01:28:02.670
I'm trying to understand
that, this is very important,

01:28:02.670 --> 01:28:04.333
not to be very enthusiastic.

01:28:06.227 --> 01:28:09.824
But concentrate on whatever
that was not able to achieve.

01:28:09.824 --> 01:28:11.241
- Patient.
- Yeah.

01:28:12.404 --> 01:28:14.170
And understand why.

01:28:14.170 --> 01:28:16.800
And now I understand that,

01:28:16.800 --> 01:28:21.680
because I believe in math, I believe that,

01:28:21.680 --> 01:28:23.740
in this idea.

01:28:23.740 --> 01:28:27.810
But now when I see that there are

01:28:27.810 --> 01:28:32.073
only two ways of convergence,
and we're using loss.

01:28:32.950 --> 01:28:37.950
That means that we must
as well as people do it.

01:28:40.310 --> 01:28:44.310
But now, exactly in
philosophy and what we know

01:28:44.310 --> 01:28:48.790
about predicate, how we
understand life can be described

01:28:48.790 --> 01:28:50.133
as a predicate.

01:28:51.420 --> 01:28:52.843
I thought about that.

01:28:54.760 --> 01:28:59.033
And that is more or less
obvious level of symmetry.

01:29:00.750 --> 01:29:02.903
But next,

01:29:04.000 --> 01:29:08.093
I have a feeling it's
something about structures.

01:29:09.550 --> 01:29:11.393
But I don't know how to formulate,

01:29:12.566 --> 01:29:14.493
how to measure and measure a
structure and all this stuff.

01:29:17.430 --> 01:29:18.263
The guy who will

01:29:19.283 --> 01:29:21.343
solve this challenge problem,

01:29:22.220 --> 01:29:25.373
then when they will look at how he did it,

01:29:27.270 --> 01:29:30.363
probably just only symmetry is not enough.

01:29:31.890 --> 01:29:33.760
- [Lex] But something like
symmetry will be there.

01:29:33.760 --> 01:29:36.084
Structures of that kind.
- Oh yeah, absolutely.

01:29:36.084 --> 01:29:37.540
Symmetry will be there.

01:29:37.540 --> 01:29:39.273
A level of symmetry will be there.

01:29:40.750 --> 01:29:42.870
And level of symmetry, anti-symmetry,

01:29:42.870 --> 01:29:46.904
diagonal, vertical, I even don't know

01:29:46.904 --> 01:29:49.700
how you can use in different direction

01:29:49.700 --> 01:29:52.290
the degree of symmetry;
that's very general.

01:29:52.290 --> 01:29:54.080
But it will be there.

01:29:55.277 --> 01:29:56.830
I think that people are very sensitive

01:29:56.830 --> 01:29:58.737
to the idea of symmetry.

01:29:58.737 --> 01:30:02.893
But there are several ideas like symmetry.

01:30:04.900 --> 01:30:07.010
As I would like to learn.

01:30:07.010 --> 01:30:11.820
But you cannot learn
just thinking about that.

01:30:11.820 --> 01:30:14.090
You should do challenging problems

01:30:14.090 --> 01:30:15.523
and then analyze them.

01:30:16.370 --> 01:30:19.493
Why it was able to solve them.

01:30:20.439 --> 01:30:21.539
And then you will see.

01:30:22.730 --> 01:30:25.423
Very simple things, it's not easy to find.

01:30:26.281 --> 01:30:29.460
(Lex laughs)
Even talking about this,

01:30:29.460 --> 01:30:32.890
every time.
- Yes.

01:30:32.890 --> 01:30:36.320
- I was surprised, I tried to understand,

01:30:36.320 --> 01:30:39.070
these people describe in language

01:30:40.120 --> 01:30:43.213
strong convergence mechanism for learning.

01:30:44.450 --> 01:30:47.219
I did not see it, I don't know.

01:30:47.219 --> 01:30:50.120
But weak convergence, the duck story

01:30:50.120 --> 01:30:53.023
and story like that when you will explain,

01:30:54.063 --> 01:30:57.620
you will use weak convergence argument.

01:30:57.620 --> 01:31:00.930
It looks like a (mumbles)

01:31:00.930 --> 01:31:04.410
but when you try to formalize,

01:31:04.410 --> 01:31:05.820
you're just ignoring this.

01:31:05.820 --> 01:31:07.683
Why? Why 50 years?

01:31:08.680 --> 01:31:10.140
From start of machine learning.

01:31:10.140 --> 01:31:11.910
- [Lex] And that's the role of philosophy,

01:31:11.910 --> 01:31:14.210
thinking about life.
- I think that might be.

01:31:15.175 --> 01:31:16.008
I don't know.

01:31:18.300 --> 01:31:20.363
Maybe this is theory also,

01:31:21.956 --> 01:31:25.810
we should blame for that because
empirical risk minimization

01:31:25.810 --> 01:31:30.700
and now just starting, if
you read now textbooks,

01:31:30.700 --> 01:31:34.410
they just about bound about
empirical risk minimization.

01:31:34.410 --> 01:31:39.410
They don't look for another
problem like admissible set.

01:31:41.420 --> 01:31:43.723
- But on the topic of life,

01:31:45.070 --> 01:31:50.020
perhaps we, you, could talk
in Russian for a little bit.

01:31:50.020 --> 01:31:53.160
What's your favorite
memory from childhood?

01:31:53.160 --> 01:31:57.690
Okay, I want you to be
my (speaks in Russian)

01:31:57.690 --> 01:31:58.523
- Music.

01:31:59.410 --> 01:32:02.886
- How about, can you try
and answer in Russian?

01:32:02.886 --> 01:32:06.053
(speaking in Russian)

01:32:07.896 --> 01:32:09.563
What kind of musica?

01:32:10.642 --> 01:32:13.809
(speaking in Russian)

01:33:06.105 --> 01:33:09.272
(speaking in Russian)

01:33:10.980 --> 01:33:12.983
Now that we're talking about Bach,

01:33:14.130 --> 01:33:15.730
let's switch back to English,

01:33:15.730 --> 01:33:17.733
'cause I like Beethoven and Chopin so.

01:33:18.610 --> 01:33:20.870
- [Vladimir] Chopin is
another amusing story.

01:33:20.870 --> 01:33:22.990
I was--
- But Bach, if we talk

01:33:22.990 --> 01:33:25.350
about predicates, Bach probably

01:33:26.760 --> 01:33:28.480
has the most

01:33:28.480 --> 01:33:31.097
sort of, well defined
predicates that underlie it.

01:33:31.097 --> 01:33:34.220
- You know, it is very interesting to read

01:33:35.240 --> 01:33:38.740
what critics writing about Bach,

01:33:38.740 --> 01:33:41.040
which words they're using, they're trying

01:33:41.040 --> 01:33:43.563
to describe predicates.
- Yeah.

01:33:45.561 --> 01:33:47.880
- And then Chopin.

01:33:47.880 --> 01:33:52.310
It is very different vocabulary.

01:33:52.310 --> 01:33:55.160
Very different predicate.

01:33:55.160 --> 01:33:56.433
And I think that,

01:33:58.190 --> 01:34:00.493
if you will make collection of that.

01:34:02.700 --> 01:34:05.570
So maybe from this you can describe

01:34:05.570 --> 01:34:07.543
predicate for digit recognition.

01:34:07.543 --> 01:34:10.450
- [Lex] From Bach and Chopin.

01:34:10.450 --> 01:34:12.550
- No, no, no, not from Bach and Chopin.

01:34:12.550 --> 01:34:14.140
- [Lex] From the the critic interpretation

01:34:14.140 --> 01:34:17.070
of the music, yeah.
- They're trying to explain

01:34:17.070 --> 01:34:18.720
you music, what they use this?

01:34:23.020 --> 01:34:26.380
They describe high-level
ideas of Plato's ideas

01:34:26.380 --> 01:34:29.703
behind this music.
- That's brilliant.

01:34:31.090 --> 01:34:34.940
Art is not self-explanatory in some sense.

01:34:34.940 --> 01:34:39.060
So you have to try to
convert it into ideas.

01:34:39.060 --> 01:34:40.950
- It is insulate problems.

01:34:40.950 --> 01:34:43.560
When you go from ideas to,

01:34:43.560 --> 01:34:46.080
to the representation.

01:34:46.080 --> 01:34:49.580
It is easy way, but when
you're trying to go back,

01:34:49.580 --> 01:34:51.630
it is you will pose problems but,

01:34:51.630 --> 01:34:56.630
nevertheless, I believe when
you're looking from that,

01:34:56.910 --> 01:34:59.710
even from art, you will be able

01:34:59.710 --> 01:35:02.543
to find predicate for digit recognition.

01:35:03.840 --> 01:35:08.500
- That's such a fascinating
and powerful notion.

01:35:08.500 --> 01:35:10.623
Do you ponder your own mortality?

01:35:11.670 --> 01:35:13.440
Do you think about it? Do you fear it?

01:35:13.440 --> 01:35:15.113
Do you draw insight from it?

01:35:17.250 --> 01:35:18.750
- About mortality?

01:35:19.860 --> 01:35:20.693
Oh yeah.

01:35:21.550 --> 01:35:23.150
- [Lex] Are you afraid of death?

01:35:25.860 --> 01:35:29.650
- Not too much, not too much.

01:35:29.650 --> 01:35:32.800
It is pity that I will not be able

01:35:32.800 --> 01:35:34.820
to do something which I think

01:35:36.853 --> 01:35:38.413
I was a feeling to do that.

01:35:39.905 --> 01:35:42.967
For example, I will be very happy

01:35:44.609 --> 01:35:48.412
to work with guys,

01:35:48.412 --> 01:35:49.712
take tradition from music.

01:35:50.700 --> 01:35:52.880
To write this collection of description,

01:35:52.880 --> 01:35:56.730
how they describe music,
how they use a predicate.

01:35:56.730 --> 01:35:59.553
And from art as well.

01:36:00.410 --> 01:36:02.393
Then take what's in common,

01:36:03.470 --> 01:36:05.350
and try to understand predicate

01:36:06.310 --> 01:36:08.994
which is absolute for everything.

01:36:08.994 --> 01:36:10.490
- [Lex] For visual recognition

01:36:10.490 --> 01:36:11.956
and see that there is a connection.

01:36:11.956 --> 01:36:13.970
- Yeah, yeah, exactly.

01:36:13.970 --> 01:36:16.326
- [Lex] There's still
time; we've got time.

01:36:16.326 --> 01:36:18.916
(laughing)

01:36:18.916 --> 01:36:20.166
We've got time.

01:36:21.660 --> 01:36:24.052
- It takes years and years

01:36:24.052 --> 01:36:24.885
and years.
- You think so?

01:36:24.885 --> 01:36:26.910
- It's a long way.

01:36:26.910 --> 01:36:30.930
- See, you've got the
patient mathematician's mind.

01:36:30.930 --> 01:36:33.050
I think it could be done very quickly

01:36:33.050 --> 01:36:34.100
and very beautifully.

01:36:34.100 --> 01:36:35.850
I think it's a really elegant idea.

01:36:36.990 --> 01:36:38.569
Some of many.
- Yeah, you know,

01:36:38.569 --> 01:36:42.973
the most time it is not
to make this collection,

01:36:43.840 --> 01:36:46.300
to understand what is in common,

01:36:46.300 --> 01:36:48.730
to think about that once again and again

01:36:48.730 --> 01:36:50.600
and again.
- Again and again and again.

01:36:50.600 --> 01:36:54.220
But I think sometimes,
especially when you just say

01:36:54.220 --> 01:36:58.800
this idea now, even just
putting together the collection

01:36:58.800 --> 01:37:03.340
and looking at the different sets of data.

01:37:03.340 --> 01:37:07.280
Language, trying to interpret
music, criticize music,

01:37:07.280 --> 01:37:10.010
and images, I think there will be sparks

01:37:10.010 --> 01:37:11.000
of ideas that will come.

01:37:11.000 --> 01:37:12.670
Of course, again and again you'll come up

01:37:12.670 --> 01:37:15.630
with better ideas but
even just that notion

01:37:15.630 --> 01:37:19.373
is a beautiful notion.
- I even have some example.

01:37:21.630 --> 01:37:23.033
So I have friend,

01:37:25.210 --> 01:37:26.340
who was

01:37:27.720 --> 01:37:29.873
specialized in Russian poetry.

01:37:30.950 --> 01:37:34.643
She is professor of Russian poetry.

01:37:35.582 --> 01:37:39.410
She did not write poems,

01:37:39.410 --> 01:37:40.570
but she

01:37:41.560 --> 01:37:43.493
know a lot of stuff.

01:37:44.515 --> 01:37:45.348
She make

01:37:47.184 --> 01:37:49.350
books, several books and one of them

01:37:49.350 --> 01:37:53.073
is a collection of Russian poetry.

01:37:54.690 --> 01:37:57.130
She has images of Russian poetry.

01:37:57.130 --> 01:37:59.283
She collected all images
of Russian poetry.

01:38:00.700 --> 01:38:03.253
And I asked her to do following.

01:38:05.420 --> 01:38:08.773
You have Nip's digit recognition.

01:38:09.720 --> 01:38:11.807
And we get 100 digits,

01:38:14.456 --> 01:38:18.827
less than 100, I don't
remember, maybe 50 digits.

01:38:18.827 --> 01:38:21.660
And try from practical point of view,

01:38:21.660 --> 01:38:25.450
describe every image you see,

01:38:25.450 --> 01:38:30.193
using only words of
images of Russian poetry.

01:38:31.330 --> 01:38:32.223
And she did it.

01:38:34.310 --> 01:38:37.603
And then we tried to,

01:38:41.140 --> 01:38:44.003
I call it learning using
privileged information.

01:38:44.003 --> 01:38:45.920
I call it privileged information.

01:38:45.920 --> 01:38:48.040
You have on two languages.

01:38:48.040 --> 01:38:53.040
One language is just image of digit.

01:38:53.130 --> 01:38:56.623
And another language by it
a description of this image.

01:38:57.750 --> 01:39:00.193
And this is privileged information.

01:39:02.587 --> 01:39:04.523
And there is an algorithm
when we are working

01:39:04.523 --> 01:39:06.880
with privileged information,
you're doing well.

01:39:06.880 --> 01:39:08.673
Better, much better.

01:39:08.673 --> 01:39:13.106
- So there's something there.
- Something there.

01:39:13.106 --> 01:39:14.106
And there is

01:39:15.443 --> 01:39:17.345
and the thing,

01:39:17.345 --> 01:39:18.820
she unfortunately died.

01:39:20.890 --> 01:39:24.830
The collection of digits

01:39:24.830 --> 01:39:27.223
and poetic descriptions of those digits.

01:39:29.378 --> 01:39:30.900
- [Lex] So there's something there

01:39:30.900 --> 01:39:33.240
in that poetic description.

01:39:33.240 --> 01:39:34.073
- I think that

01:39:35.590 --> 01:39:39.700
there is an abstract ideas on the Plato

01:39:39.700 --> 01:39:42.010
level of ideas.
- Yeah, that are there,

01:39:42.010 --> 01:39:44.030
that could be discovered, and music seems

01:39:44.030 --> 01:39:44.980
to be a good entry point.

01:39:44.980 --> 01:39:47.343
- But as soon as we start this,

01:39:48.420 --> 01:39:50.340
here's this challenge problem.

01:39:50.340 --> 01:39:53.310
- The challenge problem--
- It immediately connected

01:39:54.222 --> 01:39:55.410
to all this stuff.

01:39:55.410 --> 01:39:58.400
- Especially with your
talk and this podcast,

01:39:58.400 --> 01:40:00.090
I'll do whatever I can to advertise.

01:40:00.090 --> 01:40:03.260
Such a clean, beautiful,
Einstein-like formulation

01:40:03.260 --> 01:40:05.940
of the challenge before us.
- Right.

01:40:05.940 --> 01:40:09.503
- Let me ask another absurd question.

01:40:10.470 --> 01:40:14.020
We talked about mortality,
we talked about philosophy

01:40:14.020 --> 01:40:16.520
of life; what do you think
is the meaning of life?

01:40:17.560 --> 01:40:19.570
What's the predicate

01:40:20.880 --> 01:40:24.093
for mysterious existence here on Earth?

01:40:29.865 --> 01:40:31.115
- I don't know.

01:40:33.630 --> 01:40:35.733
It's very interesting how we have,

01:40:37.640 --> 01:40:39.560
in Russia, I don't know if you know

01:40:40.804 --> 01:40:41.930
the guy Strogatski?

01:40:44.270 --> 01:40:47.860
They're writing futures
they're thinking about,

01:40:47.860 --> 01:40:49.583
Hume, what's going on.

01:40:51.966 --> 01:40:55.611
And they have an idea

01:40:55.611 --> 01:40:59.130
that there are developing

01:41:00.570 --> 01:41:05.090
two type of people: Common
people and very smart people.

01:41:05.090 --> 01:41:05.990
They just started.

01:41:07.270 --> 01:41:10.400
And these two branches of people will go

01:41:10.400 --> 01:41:12.173
in different directions very soon.

01:41:13.550 --> 01:41:16.642
So that's what they're
thinking about next.

01:41:16.642 --> 01:41:19.790
- (laughs) So the purpose of life

01:41:19.790 --> 01:41:24.052
is to create two (chuckles) two paths.

01:41:24.052 --> 01:41:25.950
- Two paths.
- As human societies.

01:41:25.950 --> 01:41:28.050
Yeah.
- Yes, simple people

01:41:28.050 --> 01:41:29.980
and more complicated people.

01:41:29.980 --> 01:41:31.520
- Which do you like best?

01:41:31.520 --> 01:41:33.663
The simple people or the complicated ones?

01:41:34.500 --> 01:41:35.913
- I don't know, Strogatski,

01:41:37.135 --> 01:41:39.580
he's just, he's fantasy but you know,

01:41:39.580 --> 01:41:43.880
every week we have guy who is just

01:41:46.440 --> 01:41:50.823
writer, and also Soletskoff literature.

01:41:51.850 --> 01:41:56.610
And he explained how he
understands literature

01:41:56.610 --> 01:41:58.800
and human relationship.

01:41:58.800 --> 01:42:00.343
How he sees life.

01:42:02.477 --> 01:42:07.477
And I understood that I'm just
small kid comparing to him.

01:42:09.530 --> 01:42:12.550
He is very smart guy
in understanding life.

01:42:14.114 --> 01:42:18.137
He knows this predicate, he
knows big blocks of life.

01:42:20.255 --> 01:42:23.303
I'm amused every time I listen to him.

01:42:24.730 --> 01:42:27.160
And he's just talking about literature.

01:42:27.160 --> 01:42:31.383
And I think that I was surprised.

01:42:33.200 --> 01:42:36.870
So the

01:42:36.870 --> 01:42:39.943
managers in big companies,

01:42:41.470 --> 01:42:43.230
most of them are

01:42:44.630 --> 01:42:48.770
guys who study English language

01:42:48.770 --> 01:42:50.013
and English literature.

01:42:51.110 --> 01:42:52.510
So why?

01:42:52.510 --> 01:42:54.173
Because they understand life.

01:42:55.210 --> 01:42:57.030
They understand models.

01:42:57.030 --> 01:43:01.897
And among them, maybe
many talented creatures,

01:43:03.517 --> 01:43:06.010
which are just analyzing this.

01:43:06.957 --> 01:43:10.520
And this is big science like Propp did.

01:43:10.520 --> 01:43:12.393
This is his blocks.

01:43:13.360 --> 01:43:14.673
Yes, very smart.

01:43:17.490 --> 01:43:20.480
- It amazes me that you are and continue

01:43:20.480 --> 01:43:23.140
to be humbled by the brilliance of others.

01:43:23.140 --> 01:43:25.530
- I'm very modest about myself.

01:43:25.530 --> 01:43:28.960
I see so smart guys around.

01:43:28.960 --> 01:43:31.740
- Well let me immodest for you.

01:43:31.740 --> 01:43:34.540
You're one of the greatest
mathematicians/statisticians

01:43:34.540 --> 01:43:36.980
of our time, it's truly an honor.

01:43:36.980 --> 01:43:38.226
Thank you for talking.
- No, no, no, okay, okay.

01:43:38.226 --> 01:43:41.822
- And let's talk.
- (laughs) It is not.

01:43:41.822 --> 01:43:45.248
- Yeah, let's talk.
- I know my limits.

01:43:45.248 --> 01:43:49.130
- [Lex] Let's talk again when
your challenge is taken on

01:43:49.130 --> 01:43:51.951
and solved by a grad student.

01:43:51.951 --> 01:43:54.320
- Let's talk again.
- Especially when--

01:43:54.320 --> 01:43:56.220
- [Vladimir] I hope that this happens.

01:43:57.230 --> 01:43:58.920
- Maybe music will be involved.

01:43:58.920 --> 01:43:59.930
Vladimir, thank you so much.

01:43:59.930 --> 01:44:02.620
It's been an honor.
- Thank you very much.

01:44:02.620 --> 01:44:04.270
- Thanks for listening
to this conversation

01:44:04.270 --> 01:44:05.530
with Vladimir Vapnik.

01:44:05.530 --> 01:44:08.800
And thank you to our
presenting sponsor Cash App.

01:44:08.800 --> 01:44:10.902
Download it, use code: LexPodcast.

01:44:10.902 --> 01:44:14.028
You'll get $10 and $10 will go to FIRST,

01:44:14.028 --> 01:44:16.450
an organization that inspires and educates

01:44:16.450 --> 01:44:18.960
young mind to become
science and technology

01:44:18.960 --> 01:44:20.800
innovators of tomorrow.

01:44:20.800 --> 01:44:23.530
If you enjoyed this podcast,
subscribe on YouTube,

01:44:23.530 --> 01:44:26.391
give it five stars on Apple
PodCast, support it on Patreon,

01:44:26.391 --> 01:44:30.776
or simply connect with me
on Twitter @LexFridman.

01:44:30.776 --> 01:44:33.520
And now let me leave you with some words

01:44:33.520 --> 01:44:35.215
from Vladimir Vapnik.

01:44:35.215 --> 01:44:37.707
"When solving a problem of interest,

01:44:37.707 --> 01:44:40.027
"do not solve a more general problem

01:44:40.027 --> 01:44:42.527
"as an intermediate step."

01:44:42.527 --> 01:44:44.390
Thank you for listening.

01:44:44.390 --> 01:44:46.313
I hope to see you next time.

