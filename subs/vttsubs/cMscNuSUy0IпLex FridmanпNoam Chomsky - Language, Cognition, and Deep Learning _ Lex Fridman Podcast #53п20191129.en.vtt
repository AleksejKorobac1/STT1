WEBVTT
Kind: captions
Language: en

00:00:00.120 --> 00:00:03.820
- The following is a
conversation with Noam Chomsky.

00:00:03.820 --> 00:00:06.780
He's truly one of the
great minds of our time

00:00:06.780 --> 00:00:08.430
and is one of the most cited scholars

00:00:08.430 --> 00:00:10.770
in the history of our civilization.

00:00:10.770 --> 00:00:13.440
He has spent over 60 years at MIT

00:00:13.440 --> 00:00:16.350
and recently also joined
the University of Arizona

00:00:16.350 --> 00:00:18.660
where we met for this conversation,

00:00:18.660 --> 00:00:21.840
but it was at MIT about
four and 1/2 years ago

00:00:21.840 --> 00:00:23.480
when I first met Noam.

00:00:23.480 --> 00:00:25.180
My first few days there I remember

00:00:25.180 --> 00:00:27.420
getting into an elevator at Stata Center,

00:00:27.420 --> 00:00:30.600
pressing the button for
whatever floor, looking up

00:00:30.600 --> 00:00:33.610
and realizing it was
just me and Noam Chomsky

00:00:33.610 --> 00:00:37.490
riding the elevator, just me
and one of the seminal figures

00:00:37.490 --> 00:00:40.040
of linguistics, cognitive
science, philosophy,

00:00:40.040 --> 00:00:43.950
and political thought in the
past century if not ever.

00:00:43.950 --> 00:00:46.930
I tell that silly story
because I think life

00:00:46.930 --> 00:00:49.230
is made up of funny
little defining moments

00:00:49.230 --> 00:00:52.813
that you never forget for
reasons that may be too poetic

00:00:52.813 --> 00:00:56.193
to try and explain, that was one of mine.

00:00:57.350 --> 00:01:00.940
Noam has been an inspiration
to me and millions of others.

00:01:00.940 --> 00:01:02.610
It was truly an honor for me

00:01:02.610 --> 00:01:04.630
to sit down with him in Arizona.

00:01:04.630 --> 00:01:07.520
I traveled there just
for this conversation,

00:01:07.520 --> 00:01:10.150
and in a rare, heartbreaking moment

00:01:10.150 --> 00:01:12.720
after everything was set up and tested

00:01:12.720 --> 00:01:14.520
the camera was moved and accidentally

00:01:14.520 --> 00:01:17.320
the recording button was
pressed stopping the recording.

00:01:18.550 --> 00:01:22.180
So I have good audio of both
of us but no video of Noam,

00:01:22.180 --> 00:01:26.640
just a video of me and my
sleep deprived but excited face

00:01:26.640 --> 00:01:30.153
that I get to keep as a
reminder of my failures.

00:01:30.153 --> 00:01:32.500
Most people just listen
to this audio version

00:01:32.500 --> 00:01:35.800
for the podcast as opposed
to watching it on YouTube,

00:01:35.800 --> 00:01:39.040
but still it's heartbreaking for me.

00:01:39.040 --> 00:01:40.320
I hope you understand

00:01:40.320 --> 00:01:43.140
and still enjoy this
conversation as much as I did.

00:01:43.140 --> 00:01:45.042
The depth of intellect that Noam showed

00:01:45.042 --> 00:01:48.360
and his willingness to truly listen to me,

00:01:48.360 --> 00:01:52.550
a silly looking Russian
in a suit was humbling

00:01:52.550 --> 00:01:54.663
and something I'm deeply grateful for.

00:01:55.580 --> 00:01:59.334
As some of you know, this
podcast is a side project for me

00:01:59.334 --> 00:02:02.260
where my main journey and dream

00:02:02.260 --> 00:02:05.480
is to build AI systems that
do some good for the world.

00:02:05.480 --> 00:02:07.820
This latter effort
takes up most of my time

00:02:07.820 --> 00:02:10.560
but for the moment has
been mostly private,

00:02:10.560 --> 00:02:14.110
but the former, the podcast
is something I put my heart

00:02:14.110 --> 00:02:16.850
and soul into and I hope you feel that

00:02:16.850 --> 00:02:18.603
even when I screw things up.

00:02:19.550 --> 00:02:21.150
I recently started doing ads

00:02:21.150 --> 00:02:22.870
at the end of the introduction.

00:02:22.870 --> 00:02:25.660
I'll do one or two minutes
after introducing the episode

00:02:25.660 --> 00:02:27.440
and never any ads in the middle

00:02:27.440 --> 00:02:29.750
that break the flow of the conversation.

00:02:29.750 --> 00:02:31.210
I hope that works for you

00:02:31.210 --> 00:02:33.980
and doesn't hurt the listening experience.

00:02:33.980 --> 00:02:37.230
This is the Artificial
Intelligence podcast.

00:02:37.230 --> 00:02:39.850
If you enjoy it, subscribe on YouTube,

00:02:39.850 --> 00:02:41.880
give it five stars on Apple Podcast,

00:02:41.880 --> 00:02:45.377
support it on Patreon, or simply
contact with me on Twitter

00:02:45.377 --> 00:02:49.470
@lexfridman spelled F-R-I-D-M-A-N.

00:02:49.470 --> 00:02:51.760
This show is presented by Cash App,

00:02:51.760 --> 00:02:54.270
the number one finance
app on the App Store.

00:02:54.270 --> 00:02:56.850
I personally use cash app
to send money to friends,

00:02:56.850 --> 00:02:58.790
but you can also use it to buy, sell,

00:02:58.790 --> 00:03:01.370
and deposit Bitcoin in just seconds.

00:03:01.370 --> 00:03:04.220
Cash App also has a new investing feature.

00:03:04.220 --> 00:03:05.820
You can buy fractions of a stock,

00:03:05.820 --> 00:03:09.260
say $1 worth, no matter
what the stock price is.

00:03:09.260 --> 00:03:11.990
Broker services are provided
by Cash App Investing,

00:03:11.990 --> 00:03:15.570
a subsidiary of Square and member SIPC.

00:03:15.570 --> 00:03:17.700
I'm excited to be working with Cash App

00:03:17.700 --> 00:03:20.910
to support one of my favorite
organizations called the FIRST

00:03:20.910 --> 00:03:24.360
best known for their FIRST
robotics and LEGO competitions.

00:03:24.360 --> 00:03:27.710
They educate and inspire
hundreds of thousands of students

00:03:27.710 --> 00:03:30.740
in over 110 countries
and have a perfect rating

00:03:30.740 --> 00:03:33.840
on Charity Navigator which
means the donated money

00:03:33.840 --> 00:03:36.580
is used to maximum effectiveness.

00:03:36.580 --> 00:03:39.566
When you get Cash App in
the App Store or Google Play

00:03:39.566 --> 00:03:43.980
and use code LexPodcast you'll get $10

00:03:43.980 --> 00:03:47.140
and Cash App will also
donate $10 to FIRST,

00:03:47.140 --> 00:03:48.790
which again is an organization

00:03:48.790 --> 00:03:51.390
that I've personally seen
inspire girls and boys

00:03:51.390 --> 00:03:54.180
to dream of engineering a better world.

00:03:54.180 --> 00:03:58.923
And now here's my conversation
with Noam Chomsky.

00:03:59.860 --> 00:04:04.150
I apologize for the absurd
philosophical question,

00:04:04.150 --> 00:04:07.173
but if an alien species
were to visit Earth,

00:04:08.200 --> 00:04:10.960
do you think we would be able
to find a common language

00:04:10.960 --> 00:04:13.720
or protocol of communication with them?

00:04:13.720 --> 00:04:18.360
- [Noam] There are arguments
to the effect that we could.

00:04:18.360 --> 00:04:22.500
In fact, one of them was Marv Minsky's.

00:04:22.500 --> 00:04:26.860
Back about 20 or 30 years ago he performed

00:04:26.860 --> 00:04:31.020
a brief experiment with a
student of his, Daniel Bobrow

00:04:31.020 --> 00:04:36.020
they essentially ran the
simplest possible Turing machines

00:04:36.760 --> 00:04:39.610
just free to see what would happen.

00:04:39.610 --> 00:04:44.320
And most of them crashed,
either got into an infinite loop

00:04:44.320 --> 00:04:49.320
or were stopped, the few that persisted

00:04:51.050 --> 00:04:55.500
essentially gave
something like arithmetic.

00:04:55.500 --> 00:04:58.550
And his conclusion from that was

00:04:58.550 --> 00:05:03.550
that if some alien species
developed higher intelligence

00:05:05.850 --> 00:05:07.490
they would at least have arithmetic.

00:05:07.490 --> 00:05:12.490
They would at least have what
the simplest computer would do

00:05:12.970 --> 00:05:16.080
and in fact he didn't
know that at the time,

00:05:16.080 --> 00:05:20.800
but the core principles
of natural language

00:05:20.800 --> 00:05:25.260
are based on operations
which yield something

00:05:25.260 --> 00:05:29.400
like arithmetic in the limiting
case, in the minimal case.

00:05:29.400 --> 00:05:34.090
So it's conceivable that
a mode of communication

00:05:34.090 --> 00:05:38.600
could be established based
on the core properties

00:05:38.600 --> 00:05:41.510
of human language and the
core properties of arithmetic

00:05:41.510 --> 00:05:46.510
which maybe are universally
shared so it's conceivable.

00:05:46.720 --> 00:05:50.830
- [Lex] What is the
structure of that language,

00:05:50.830 --> 00:05:55.180
of language as an internal
system inside our mind

00:05:55.180 --> 00:05:58.163
versus an external
system as it's expressed?

00:05:59.060 --> 00:06:00.910
- [Noam] It's not an alternative.

00:06:00.910 --> 00:06:02.950
It's two different concepts of language.

00:06:02.950 --> 00:06:03.783
- [Lex] Different.

00:06:03.783 --> 00:06:05.000
- [Noam] It's a simple fact

00:06:05.000 --> 00:06:09.030
that there's something
about you, a trait of yours,

00:06:09.030 --> 00:06:13.220
part of the organism you that determines

00:06:13.220 --> 00:06:17.020
that you're talking English
and not Tagalog, let's say.

00:06:17.020 --> 00:06:18.683
So there is an inner system.

00:06:19.550 --> 00:06:23.010
It determines the sound and meaning

00:06:23.010 --> 00:06:27.150
of the infinite number of
expressions of your language.

00:06:27.150 --> 00:06:29.750
It's localized, it's not in your foot

00:06:29.750 --> 00:06:31.790
obviously it's in your brain.

00:06:31.790 --> 00:06:35.280
If you look more closely it's
in specific configurations

00:06:35.280 --> 00:06:37.820
of your brain and that's essentially

00:06:37.820 --> 00:06:42.000
like the internal
structure of your laptop.

00:06:42.000 --> 00:06:45.010
Whatever programs it has are in there.

00:06:45.010 --> 00:06:47.723
Now, one of the things
you can do with language,

00:06:47.723 --> 00:06:52.723
it's a marginal thing in
fact is use it to externalize

00:06:53.410 --> 00:06:54.990
what's in your head.

00:06:54.990 --> 00:06:57.400
I think most of your use
of language is thought,

00:06:57.400 --> 00:07:00.960
internal thought, but can do
what you and I are now doing.

00:07:00.960 --> 00:07:02.690
We can externalize it.

00:07:02.690 --> 00:07:05.680
Well, the set of things
that we're externalizing

00:07:05.680 --> 00:07:10.680
are an external system, they're
noises in the atmosphere,

00:07:11.200 --> 00:07:12.950
and you can call that language

00:07:12.950 --> 00:07:14.420
in some other sense of the word,

00:07:14.420 --> 00:07:16.870
but it's not a set of alternatives.

00:07:16.870 --> 00:07:19.010
These are just different concepts.

00:07:19.010 --> 00:07:20.610
- [Lex] So how deep do the roots

00:07:20.610 --> 00:07:22.253
of language go in our brain?

00:07:23.140 --> 00:07:24.111
- Well--
- Our mind,

00:07:24.111 --> 00:07:26.830
is it yet another feature like vision?

00:07:26.830 --> 00:07:28.510
Or is it something more fundamental

00:07:28.510 --> 00:07:31.560
from which everything else
springs in the human mind?

00:07:31.560 --> 00:07:33.903
- [Noam] Well in a way it's like vision.

00:07:35.960 --> 00:07:38.630
There's something about
our genetic endowment

00:07:38.630 --> 00:07:41.650
that determines that we have a mammalian

00:07:41.650 --> 00:07:44.750
rather than an insect visual system.

00:07:44.750 --> 00:07:47.470
And there's something
in our genetic endowment

00:07:47.470 --> 00:07:51.510
that determines that we have
a human language faculty.

00:07:51.510 --> 00:07:55.240
No other organism has
anything remotely similar.

00:07:55.240 --> 00:07:58.300
So in that sense it's internal.

00:07:58.300 --> 00:08:01.330
Now, there is a long tradition
which I think is valid

00:08:01.330 --> 00:08:05.550
going back centuries to the
early scientific revolution

00:08:05.550 --> 00:08:10.330
at least that holds that language is the

00:08:10.330 --> 00:08:13.660
sort of the core of
human cognitive nature.

00:08:13.660 --> 00:08:18.140
It's the source, it's the
mode for constructing thoughts

00:08:18.140 --> 00:08:22.780
and expressing them and
that is what forms thought

00:08:22.780 --> 00:08:27.220
and it's got fundamental
creative capacities.

00:08:27.220 --> 00:08:31.320
It's free, independent,
unbounded and so on.

00:08:31.320 --> 00:08:34.870
And undoubtedly I think the basis

00:08:34.870 --> 00:08:39.870
for our creative capacities
and the other remarkable

00:08:42.530 --> 00:08:47.490
human capacities that lead
to the unique achievements

00:08:47.490 --> 00:08:51.300
and not so great
achievements of the species.

00:08:51.300 --> 00:08:53.620
- [Lex] The capacity to think and reason.

00:08:53.620 --> 00:08:56.250
Do you think that's deeply
linked with language?

00:08:56.250 --> 00:09:01.010
Do you think the internal
language system is essentially

00:09:01.010 --> 00:09:04.160
the mechanism by which we
also reason internally?

00:09:04.160 --> 00:09:06.970
- [Noam] It is undoubtedly the
mechanism by which we reason.

00:09:06.970 --> 00:09:10.900
There may also be other,
there are undoubtedly

00:09:10.900 --> 00:09:13.263
other faculties involved in reasoning.

00:09:14.750 --> 00:09:17.560
We have a kind of scientific faculty.

00:09:17.560 --> 00:09:19.970
Nobody knows what it
is, but whatever it is

00:09:19.970 --> 00:09:24.740
that enables us to pursue
certain lines of endeavor

00:09:24.740 --> 00:09:28.480
and inquiry and to decide what makes sense

00:09:28.480 --> 00:09:32.240
and doesn't make sense and
to achieve a certain degree

00:09:32.240 --> 00:09:35.330
of understanding in the
world that uses language

00:09:35.330 --> 00:09:40.330
but goes beyond it just as using
our capacity for arithmetic

00:09:42.060 --> 00:09:44.010
is not the same as having the capacity.

00:09:45.154 --> 00:09:49.420
- [Lex] The idea of capacity,
our biology, evolution,

00:09:49.420 --> 00:09:52.550
you've talked about it defining
essentially our capacity,

00:09:52.550 --> 00:09:55.240
our limit and our scope.

00:09:55.240 --> 00:09:58.510
Can you try to define
what limit and scope are,

00:09:58.510 --> 00:10:02.450
and the bigger question,
do you think it's possible

00:10:02.450 --> 00:10:06.263
to find the limit of human cognition?

00:10:07.600 --> 00:10:09.930
- [Noam] Well that's an
interesting question.

00:10:09.930 --> 00:10:13.120
It's commonly believed,
most scientists believe

00:10:13.120 --> 00:10:15.750
that human intelligence

00:10:15.750 --> 00:10:19.380
can answer any question in principle.

00:10:19.380 --> 00:10:21.830
I think that's a very strange belief.

00:10:21.830 --> 00:10:26.190
If we're biological organisms
which are not angels

00:10:26.190 --> 00:10:31.190
then our capacities ought
to have scope and limits

00:10:33.220 --> 00:10:34.950
which are interrelated.

00:10:34.950 --> 00:10:36.650
- [Lex] Can you define those two terms?

00:10:36.650 --> 00:10:40.790
- [Noam] Well, let's
take a concrete example.

00:10:40.790 --> 00:10:44.080
Your genetic endowment, it determines

00:10:44.080 --> 00:10:46.870
that you can have a
mammalian visual system

00:10:46.870 --> 00:10:48.690
and arms and legs and so on

00:10:50.040 --> 00:10:53.480
and therefore become a
rich, complex organism,

00:10:53.480 --> 00:10:56.270
but if you look at that
same genetic endowment

00:10:56.270 --> 00:11:00.030
it prevents you from
developing in other directions.

00:11:00.030 --> 00:11:04.317
There's no kind of experience
which would yield the embryo

00:11:05.810 --> 00:11:08.800
to develop an insect visual system

00:11:08.800 --> 00:11:12.010
or to develop wings instead of arms.

00:11:12.010 --> 00:11:17.010
So the very endowment that
confers richness and complexity

00:11:18.490 --> 00:11:23.490
also sets bounds on what can be attained.

00:11:23.620 --> 00:11:27.480
Now I assume that our cognitive capacities

00:11:27.480 --> 00:11:29.680
are part of the organic world

00:11:29.680 --> 00:11:32.300
therefore they should
have the same properties.

00:11:32.300 --> 00:11:36.845
If they had no built-in
capacity to develop a rich

00:11:36.845 --> 00:11:41.414
and complex structure we
would understand nothing

00:11:41.414 --> 00:11:46.100
just as if your genetic endowment

00:11:46.100 --> 00:11:50.360
did not compel you to
develop arms and legs

00:11:50.360 --> 00:11:54.040
you would just be some kind
of a random ameboid creature

00:11:54.040 --> 00:11:57.640
with no structure at all
so I think it's plausible

00:11:57.640 --> 00:12:00.270
to assume that there are limits,

00:12:00.270 --> 00:12:03.730
and I think we even have some
evidence as to what they are.

00:12:03.730 --> 00:12:06.700
So for example there's a classic moment

00:12:06.700 --> 00:12:10.713
in the history of science
at the time of Newton.

00:12:11.660 --> 00:12:15.918
There was from Galileo to
Newton modern science developed

00:12:15.918 --> 00:12:20.160
on a fundamental assumption
which Newton also accepted,

00:12:20.160 --> 00:12:24.120
namely that the world, the entire universe

00:12:24.120 --> 00:12:28.630
is a mechanical object and
by mechanical they meant

00:12:28.630 --> 00:12:30.660
something like the kinds of artifacts

00:12:30.660 --> 00:12:33.030
that were being developed
by skilled artisans

00:12:33.030 --> 00:12:37.150
all over Europe, the
gears, levers, and so on.

00:12:37.150 --> 00:12:39.820
And their belief was, well the world

00:12:39.820 --> 00:12:42.740
is just a more complex variant of this.

00:12:42.740 --> 00:12:47.740
Newton to his astonishment
and distress proved that there

00:12:49.180 --> 00:12:53.503
are no machines, that there's
interaction without contact.

00:12:54.350 --> 00:12:57.710
His contemporaries like
Leibniz and Huygens

00:12:57.710 --> 00:13:02.580
just dismissed this as
returning to the mysticism

00:13:02.580 --> 00:13:05.880
of the Neo-Scholastics and Newton agreed.

00:13:05.880 --> 00:13:08.227
He said, "It is totally absurd.

00:13:08.227 --> 00:13:11.067
"No person of any scientific intelligence

00:13:11.067 --> 00:13:13.810
"could ever accept this for a moment."

00:13:13.810 --> 00:13:15.330
In fact, he spent the rest of his life

00:13:15.330 --> 00:13:17.760
trying to get around it somehow

00:13:17.760 --> 00:13:20.340
as did many other scientists.

00:13:20.340 --> 00:13:24.100
That was the very criterion
of intelligibility

00:13:24.100 --> 00:13:26.543
for say Galileo or Newton.

00:13:27.690 --> 00:13:31.390
Theory did not produce
an intelligible world

00:13:31.390 --> 00:13:34.090
unless you could duplicate it in a machine

00:13:34.090 --> 00:13:37.550
and he showed you can't,
there are no machines, any.

00:13:37.550 --> 00:13:41.250
Finally after a long
struggle, took a long time

00:13:41.250 --> 00:13:45.250
scientists just accepted
this as common sense,

00:13:45.250 --> 00:13:47.410
but that's a significant moment.

00:13:47.410 --> 00:13:49.370
That means they abandoned the search

00:13:49.370 --> 00:13:54.050
for an intelligible world
and the great philosophers

00:13:54.050 --> 00:13:57.010
of the time understood that very well.

00:13:57.010 --> 00:14:02.010
So for example, David Hume
in his encomium to Newton

00:14:02.330 --> 00:14:05.570
wrote that, who was the
greatest thinker ever and so on.

00:14:05.570 --> 00:14:10.530
He said that he unveiled
many of the secrets of nature

00:14:10.530 --> 00:14:13.007
but by showing the imperfections

00:14:13.007 --> 00:14:17.520
of the mechanical philosophy,
mechanical science

00:14:17.520 --> 00:14:21.250
he left us with, he showed
that there are mysteries

00:14:21.250 --> 00:14:26.250
which ever will remain, and
science just changed its goals.

00:14:26.750 --> 00:14:28.720
It abandoned the mysteries.

00:14:28.720 --> 00:14:31.470
It can't solve it, they'll put it aside.

00:14:31.470 --> 00:14:34.750
We only look for intelligible theories.

00:14:34.750 --> 00:14:36.690
Newton's theories were intelligible

00:14:36.690 --> 00:14:39.120
it's just what they described wasn't.

00:14:39.120 --> 00:14:42.830
Well, Locke said the same thing.

00:14:42.830 --> 00:14:45.500
I think they're basically right and if so

00:14:45.500 --> 00:14:49.740
that showed something about
the limits of human cognition.

00:14:49.740 --> 00:14:54.740
We cannot attain the goal
of understanding the world,

00:14:55.730 --> 00:14:58.440
of finding an intelligible world.

00:14:58.440 --> 00:15:02.573
This mechanical philosophy,
Galileo to Newton,

00:15:03.770 --> 00:15:05.500
there's a good case that can be made that

00:15:05.500 --> 00:15:10.500
that's our instinctive
conception of how things work.

00:15:11.040 --> 00:15:15.720
So if say infants are tested with things

00:15:15.720 --> 00:15:18.700
that if this moves and then this moves

00:15:18.700 --> 00:15:22.100
they kind of invent something
that must be invisible

00:15:22.100 --> 00:15:24.970
that's in between them that's
making them move and so on.

00:15:24.970 --> 00:15:26.580
- [Lex] Yeah, we like physical contact.

00:15:26.580 --> 00:15:28.505
Something about our brain seeks--

00:15:28.505 --> 00:15:31.222
- [Noam] Makes us want a world like then

00:15:31.222 --> 00:15:34.190
just like it wants a world that has

00:15:34.190 --> 00:15:38.030
regular geometric figures
so for example Descartes

00:15:38.030 --> 00:15:41.870
pointed this out that
if you have an infant

00:15:41.870 --> 00:15:46.870
who's never seen a triangle
before and you draw a triangle

00:15:47.358 --> 00:15:52.270
the infant will see a distorted triangle

00:15:52.270 --> 00:15:56.370
not whatever crazy figure
it actually is, you know,

00:15:56.370 --> 00:15:58.430
three lines not coming quite together

00:15:58.430 --> 00:16:00.350
or one of them a little
bit curved and so on.

00:16:00.350 --> 00:16:04.550
We just impose a conception of the world

00:16:04.550 --> 00:16:09.420
in terms of perfect geometric objects.

00:16:09.420 --> 00:16:11.680
It's now been shown that
it goes way beyond that,

00:16:11.680 --> 00:16:15.047
that if you show on a
tachistoscope, let's say,

00:16:16.040 --> 00:16:19.270
a couple of lights
shining, you do it three

00:16:19.270 --> 00:16:22.850
or four times in a row
what people actually see

00:16:22.850 --> 00:16:26.913
is a rigid object in motion
not whatever's there.

00:16:28.230 --> 00:16:31.890
We all know that from a
television set basically.

00:16:31.890 --> 00:16:34.680
- [Lex] So that gives us
hints of potential limits

00:16:34.680 --> 00:16:36.850
to our cognition?
- I think it does,

00:16:36.850 --> 00:16:39.440
but it's a very contested view.

00:16:39.440 --> 00:16:43.900
If you do a poll among scientists
they'll say impossible.

00:16:43.900 --> 00:16:45.483
We can understand anything.

00:16:46.360 --> 00:16:48.640
- [Lex] Let me ask and
give me a chance with this.

00:16:48.640 --> 00:16:52.560
So I just spent a day at a
company called Neuralink,

00:16:52.560 --> 00:16:56.813
and what they do is try
to design what's called

00:16:56.813 --> 00:16:59.610
a brain machine, a brain
computer interface.

00:16:59.610 --> 00:17:03.330
So they try to just do thousands
of readings in the brain,

00:17:03.330 --> 00:17:05.610
be able to read what
the neurons are firing

00:17:05.610 --> 00:17:08.550
and then stimulate back, so two-way.

00:17:08.550 --> 00:17:12.800
Do you think their dream
is to expand the capacity

00:17:12.800 --> 00:17:16.690
of the brain to attain information,

00:17:16.690 --> 00:17:18.180
sort of increase the bandwidth

00:17:18.180 --> 00:17:22.460
at which we can search
Google kind of thing?

00:17:22.460 --> 00:17:26.280
Do you think our cognitive
capacity might be expanded,

00:17:26.280 --> 00:17:29.400
our linguistic capacity,
our ability to reason

00:17:29.400 --> 00:17:33.220
might be expanded by adding
a machine into the picture?

00:17:33.220 --> 00:17:35.660
- [Noam] It can be expanded
in a certain sense,

00:17:35.660 --> 00:17:39.900
but a sense that was known
thousands of years ago.

00:17:39.900 --> 00:17:44.070
A book expands your
cognitive capacity, okay,

00:17:44.070 --> 00:17:46.070
so this could expand it, too.

00:17:46.070 --> 00:17:47.980
- [Lex] But it's not a
fundamental expansion.

00:17:47.980 --> 00:17:51.000
It's not totally new
things could be understood.

00:17:51.000 --> 00:17:53.070
- [Noam] Well, nothing that goes beyond

00:17:53.070 --> 00:17:56.002
our native cognitive capacities

00:17:56.002 --> 00:17:58.670
just like you can't turn the visual system

00:17:58.670 --> 00:18:00.710
into an insect system.

00:18:00.710 --> 00:18:05.710
- [Lex] Well, I mean
the thought is perhaps

00:18:05.730 --> 00:18:07.850
you can't directly but you can map.

00:18:07.850 --> 00:18:12.430
- [Noam] You could be we know
that without this experiment

00:18:12.430 --> 00:18:16.220
you could map what a
bee sees and present it

00:18:16.220 --> 00:18:18.310
in a form so that we could follow it.

00:18:18.310 --> 00:18:20.364
In fact every bee scientist does that.

00:18:20.364 --> 00:18:23.240
- [Lex] Uh-huh, but you
don't think there's something

00:18:23.240 --> 00:18:26.730
greater than bees that we can map

00:18:26.730 --> 00:18:29.730
and then all of a sudden
discover something,

00:18:29.730 --> 00:18:33.830
be able to understand a quantum
world, quantum mechanics,

00:18:33.830 --> 00:18:35.290
be able to start to be able to make sense.

00:18:35.290 --> 00:18:37.800
- [Noam] You can, students at MIT study

00:18:37.800 --> 00:18:40.615
and understand quantum mechanics.

00:18:40.615 --> 00:18:44.000
- [Lex] (laughs) But they
always reduce it to the infant,

00:18:44.000 --> 00:18:46.480
the physical, I mean they
don't really understand--

00:18:46.480 --> 00:18:50.320
- [Noam] Not physical,
that may be another area

00:18:50.320 --> 00:18:52.760
where there's just a
limit to understanding.

00:18:52.760 --> 00:18:54.530
We understand the theories,

00:18:54.530 --> 00:18:58.480
but the world that it describes
doesn't make any sense.

00:18:58.480 --> 00:19:01.510
So you know the experiment,
the Schrodinger's cat

00:19:01.510 --> 00:19:03.750
for example, can understand the theory

00:19:03.750 --> 00:19:05.810
but as Schrodinger pointed out

00:19:05.810 --> 00:19:07.543
it's not an intelligible world.

00:19:09.330 --> 00:19:13.500
One of the reasons why Einstein
was always very skeptical

00:19:13.500 --> 00:19:17.240
about quantum theory, he described himself

00:19:17.240 --> 00:19:21.137
as a classical realist
and wants intelligibility.

00:19:23.070 --> 00:19:26.070
- [Lex] He has something in
common with infants in that way.

00:19:27.470 --> 00:19:32.470
So back to linguistics,
if you could humor me,

00:19:32.670 --> 00:19:35.300
what are the most beautiful
or fascinating aspects

00:19:35.300 --> 00:19:37.740
of language or ideas in linguistics

00:19:37.740 --> 00:19:39.540
or cognitive science that you've seen

00:19:39.540 --> 00:19:42.070
in a lifetime of studying language

00:19:42.070 --> 00:19:44.200
and studying the human mind?

00:19:44.200 --> 00:19:49.200
- [Noam] Well, I think the
deepest property of language

00:19:50.170 --> 00:19:52.880
and puzzling property
that's been discovered

00:19:52.880 --> 00:19:57.230
is what is sometimes called
structure dependence.

00:19:57.230 --> 00:19:59.610
We now understand it pretty well,

00:19:59.610 --> 00:20:01.970
but it was puzzling for a long time.

00:20:01.970 --> 00:20:03.640
I'll give you a concrete example.

00:20:03.640 --> 00:20:08.640
So suppose you say, the
guy who fixed the car

00:20:09.316 --> 00:20:11.910
carefully packed his tools.

00:20:11.910 --> 00:20:15.450
That's ambiguous, he could
fix the car carefully

00:20:15.450 --> 00:20:17.960
or carefully pack his tools.

00:20:17.960 --> 00:20:21.080
Now suppose you put carefully in front.

00:20:21.080 --> 00:20:25.870
Carefully the guy who fixed
the car packed his tools.

00:20:25.870 --> 00:20:29.400
Then it's carefully packed,
not carefully fixed.

00:20:29.400 --> 00:20:32.330
And in fact you do that
even if it makes no sense.

00:20:32.330 --> 00:20:35.150
So suppose you say, carefully the guy

00:20:35.150 --> 00:20:38.173
who fixed the car is tall.

00:20:39.370 --> 00:20:41.900
You have to interpret it
as carefully he's tall

00:20:41.900 --> 00:20:44.270
even though that doesn't make any sense.

00:20:44.270 --> 00:20:46.837
And notice that that's
a very puzzling fact

00:20:46.837 --> 00:20:50.100
because you're relating carefully

00:20:50.100 --> 00:20:53.670
not to the linearly closest verb

00:20:53.670 --> 00:20:57.340
but to the linearly more remote verb.

00:20:57.340 --> 00:21:02.097
Linear closeness is a easy computation,

00:21:02.097 --> 00:21:03.750
but here you're doing a much more,

00:21:03.750 --> 00:21:06.810
what looks like a more
complex computation.

00:21:06.810 --> 00:21:09.520
You're doing something that's taking you

00:21:09.520 --> 00:21:11.913
essentially to the more remote thing,

00:21:13.640 --> 00:21:17.800
it's now if you look at the
actual structure of the sentence

00:21:17.800 --> 00:21:20.720
where the phrases are and so on turns out

00:21:20.720 --> 00:21:24.230
you're picking out the
structurally closest thing,

00:21:24.230 --> 00:21:28.000
but the linearly more remote thing.

00:21:28.000 --> 00:21:32.540
But notice that what's linear
is 100% of what you hear.

00:21:32.540 --> 00:21:33.943
You never hear of structure.

00:21:35.190 --> 00:21:39.280
So what you're doing is and
instantly this is universal.

00:21:39.280 --> 00:21:42.190
All constructions, all languages

00:21:42.190 --> 00:21:45.600
and what we're compelled
to do is carry out

00:21:45.600 --> 00:21:48.720
what looks like the
more complex computation

00:21:48.720 --> 00:21:53.720
on material that we never
hear and we ignore 100%

00:21:54.000 --> 00:21:57.030
of what we hear on the
simplest computation.

00:21:57.030 --> 00:22:00.720
And by now there's even
a neural basis for this

00:22:00.720 --> 00:22:04.060
that's somewhat understood,
and there's good theories

00:22:04.060 --> 00:22:06.660
but none that explain why it's true.

00:22:06.660 --> 00:22:10.661
That's a deep insight
into the surprising nature

00:22:10.661 --> 00:22:13.826
of language with many consequences.

00:22:13.826 --> 00:22:17.317
- [Lex] Let me ask you about
a field of machine learning

00:22:17.317 --> 00:22:20.220
and deep learning, there's
been a lot of progress

00:22:20.220 --> 00:22:23.920
in neural network-based machine learning

00:22:24.920 --> 00:22:26.410
in the recent decade.

00:22:26.410 --> 00:22:30.064
Of course, neural network
research goes back many decades.

00:22:30.064 --> 00:22:30.897
- [Noam] Yeah.

00:22:30.897 --> 00:22:35.610
- [Lex] What do you think are
the limits of deep learning,

00:22:35.610 --> 00:22:38.510
of neural network-based machine learning?

00:22:38.510 --> 00:22:41.160
- [Noam] Well, to give
a real answer to that

00:22:41.160 --> 00:22:44.940
you'd have to understand
the exact processes

00:22:44.940 --> 00:22:47.960
that are taking place, and
those are pretty opaque

00:22:47.960 --> 00:22:50.290
so it's pretty hard to prove a theorem

00:22:50.290 --> 00:22:54.060
about what can be done
and what can't be done.

00:22:54.060 --> 00:22:56.520
But I think it's reasonably clear,

00:22:56.520 --> 00:22:59.220
I mean, putting technicalities aside

00:22:59.220 --> 00:23:04.030
what deep learning is doing
is taking huge numbers

00:23:04.030 --> 00:23:07.770
of examples and finding some patterns.

00:23:07.770 --> 00:23:12.010
Okay, that could be interesting
and in some areas it is

00:23:12.010 --> 00:23:15.090
but we have to ask here
a certain question.

00:23:15.090 --> 00:23:17.883
Is it engineering or is it science?

00:23:17.883 --> 00:23:21.450
Engineering in the sense of
just trying to build something

00:23:21.450 --> 00:23:24.270
that's useful or science in the sense

00:23:24.270 --> 00:23:27.600
that it's trying to understand
something about elements

00:23:27.600 --> 00:23:31.513
of the world so it takes a Google parser.

00:23:31.513 --> 00:23:35.190
We can ask that question, is it useful?

00:23:35.190 --> 00:23:36.900
Yeah, it's pretty useful.

00:23:36.900 --> 00:23:41.900
I use Google Translator
so on engineering grounds

00:23:41.960 --> 00:23:44.923
it's kinda worth having like a bulldozer.

00:23:45.770 --> 00:23:49.050
Does it tell you anything
about human language?

00:23:49.050 --> 00:23:54.050
Zero, nothing, and in
fact it's very striking.

00:23:54.970 --> 00:23:56.820
From the very beginning

00:23:56.820 --> 00:24:00.056
it's just totally remote from science

00:24:00.056 --> 00:24:02.620
so what is a Google parser doing?

00:24:02.620 --> 00:24:05.190
It's taking an enormous text,

00:24:05.190 --> 00:24:08.930
let's say The Wall Street
Journal corpus and asking,

00:24:08.930 --> 00:24:13.930
how close can we come to
getting the right description

00:24:14.150 --> 00:24:16.440
of every sentence in the corpus?

00:24:16.440 --> 00:24:18.550
Well, ever sentence in the corpus

00:24:18.550 --> 00:24:21.131
is essentially an experiment.

00:24:21.131 --> 00:24:25.310
Each sentence that you produce
is an experiment which is,

00:24:25.310 --> 00:24:26.980
am I a grammatical sentence?

00:24:26.980 --> 00:24:30.730
Now the answer is usually
yes so most of the stuff

00:24:30.730 --> 00:24:33.270
in the corpus is grammatical sentences,

00:24:33.270 --> 00:24:36.860
but now ask yourself, is there any science

00:24:36.860 --> 00:24:41.540
which takes random experiments
which are carried out

00:24:41.540 --> 00:24:44.340
for no reason whatsoever and tries

00:24:44.340 --> 00:24:46.540
to find out something from them?

00:24:46.540 --> 00:24:49.680
Like if you're, say, a
chemistry PhD student

00:24:49.680 --> 00:24:51.230
you want to get a thesis can you say,

00:24:51.230 --> 00:24:54.710
well I'm just gonna do a
lot of, mix a lot of things

00:24:54.710 --> 00:24:59.690
together, no purpose, and
maybe I'll find something.

00:24:59.690 --> 00:25:01.640
You'd be laughed out of the department.

00:25:02.490 --> 00:25:06.240
Science tries to find
critical experiments,

00:25:06.240 --> 00:25:09.160
ones that answer some
theoretical question.

00:25:09.160 --> 00:25:13.020
Doesn't care about coverage
of millions of experiments.

00:25:13.020 --> 00:25:16.227
So it just begins by being
very remote from science

00:25:16.227 --> 00:25:20.700
and it continues like
that so the usual question

00:25:20.700 --> 00:25:23.540
that's asked about, say, a Google parser

00:25:23.540 --> 00:25:26.230
is how well does it do, or some parser,

00:25:26.230 --> 00:25:28.370
how well does it do on a corpus?

00:25:28.370 --> 00:25:30.764
But there's another
question that's never asked.

00:25:30.764 --> 00:25:32.950
How well does it do on something

00:25:32.950 --> 00:25:36.120
that violates all the rules of language?

00:25:36.120 --> 00:25:38.770
So for example, take the
structure dependence case

00:25:38.770 --> 00:25:41.670
that I mentioned, suppose
there was a language

00:25:41.670 --> 00:25:46.510
in which you used linear
proximity as the mode

00:25:47.350 --> 00:25:50.090
of interpretation, these deep learning

00:25:50.090 --> 00:25:51.280
would work very easily on that.

00:25:51.280 --> 00:25:54.820
In fact, much more easily
than on an actual language.

00:25:54.820 --> 00:25:56.000
Is that a success?

00:25:56.000 --> 00:25:57.640
No, that's a failure.

00:25:57.640 --> 00:26:00.728
From a scientific point
of view that's a failure.

00:26:00.728 --> 00:26:03.560
It shows that we're not discovering

00:26:03.560 --> 00:26:05.880
the nature of the system at all

00:26:05.880 --> 00:26:07.780
'cause it does just as well or even better

00:26:07.780 --> 00:26:10.777
on things that violate the
structure of the system,

00:26:10.777 --> 00:26:12.750
and it goes on from there.

00:26:12.750 --> 00:26:14.830
It's not an argument against doing it.

00:26:14.830 --> 00:26:17.230
It is useful to have devices like this.

00:26:17.230 --> 00:26:20.670
- [Lex] So yes, neural networks
are kind of approximators

00:26:20.670 --> 00:26:24.410
that look, there's echoes of
the behavioral debates right,

00:26:24.410 --> 00:26:27.620
behavioralism.
- More than echoes.

00:26:27.620 --> 00:26:30.080
Many of the people in deep learning

00:26:30.080 --> 00:26:32.840
say they vindicated.
- (laughs) Yeah.

00:26:32.840 --> 00:26:35.650
- [Noam] Terry Sejnowski for
example in his recent book

00:26:35.650 --> 00:26:38.870
says this vindicates Skinnerian behaviors

00:26:38.870 --> 00:26:41.700
and it doesn't have
anything to do with it.

00:26:41.700 --> 00:26:43.800
- [Lex] Yes, but I think there's something

00:26:44.670 --> 00:26:48.300
actually fundamentally different
when the data set is huge,

00:26:48.300 --> 00:26:51.180
but your point is extremely well taken.

00:26:51.180 --> 00:26:55.410
But do you think we can learn, approximate

00:26:55.410 --> 00:26:58.810
that interesting, complex
structure of language

00:26:58.810 --> 00:27:00.850
with neural networks that will somehow

00:27:00.850 --> 00:27:02.833
help us understand the science?

00:27:03.680 --> 00:27:06.330
- [Noam] It's possible,
I mean, you find patterns

00:27:06.330 --> 00:27:08.730
that you hadn't noticed, let's say.

00:27:08.730 --> 00:27:13.630
Could be, in fact it's very
much like a kind of linguistics

00:27:13.630 --> 00:27:18.630
that's done, what's called
corpus linguistics when you,

00:27:19.200 --> 00:27:22.610
suppose you have some language
where all the speakers

00:27:22.610 --> 00:27:25.140
have died out but you have records.

00:27:25.140 --> 00:27:28.110
So you just look at the records

00:27:28.110 --> 00:27:30.630
and see what you can figure out from that.

00:27:30.630 --> 00:27:33.690
It's much better to have actual speakers

00:27:33.690 --> 00:27:36.090
where you can do critical experiments,

00:27:36.090 --> 00:27:38.540
but if they're all dead you can't do them

00:27:38.540 --> 00:27:40.810
so you have to try to
see what you can find out

00:27:40.810 --> 00:27:43.890
from just looking at
the data that's around.

00:27:43.890 --> 00:27:45.088
You can learn things.

00:27:45.088 --> 00:27:48.400
Anthropology is very much like that.

00:27:48.400 --> 00:27:50.630
You can't do a critical experiment

00:27:50.630 --> 00:27:53.530
on what happened two million years ago

00:27:53.530 --> 00:27:56.550
so you're kinda forced to
take what data's around

00:27:56.550 --> 00:27:59.250
and see what you can figure out from it.

00:27:59.250 --> 00:28:01.440
Okay, it's a serious study.

00:28:01.440 --> 00:28:05.620
- [Lex] So let me venture into
another whole body of work

00:28:05.620 --> 00:28:07.423
and philosophical question.

00:28:08.400 --> 00:28:13.120
You've said that evil in society
arises from institutions,

00:28:13.120 --> 00:28:15.245
not inherently from our nature.

00:28:15.245 --> 00:28:17.840
Do you think most human beings are good,

00:28:17.840 --> 00:28:21.230
they have good intent or
do most have the capacity

00:28:21.230 --> 00:28:24.730
for intentional evil that
depends on their upbringing,

00:28:24.730 --> 00:28:27.320
depends on their environment, on context?

00:28:27.320 --> 00:28:28.153
- [Noam] I wouldn't say

00:28:28.153 --> 00:28:30.143
that they don't arise from our nature.

00:28:31.030 --> 00:28:34.060
Anything we do arises from our nature.

00:28:34.060 --> 00:28:36.750
And the fact that we
have certain institutions

00:28:36.750 --> 00:28:40.560
and not others is one mode

00:28:40.560 --> 00:28:43.740
in which human nature
has expressed itself.

00:28:43.740 --> 00:28:46.300
But as far as we know, human nature

00:28:46.300 --> 00:28:50.260
could yield many different
kinds of institutions.

00:28:50.260 --> 00:28:52.847
The particular ones that have developed

00:28:52.847 --> 00:28:56.980
have to do with historical contingency,

00:28:56.980 --> 00:28:59.183
who conquered whom and that sort of thing,

00:29:00.260 --> 00:29:03.870
then they're not rooted in our nature

00:29:03.870 --> 00:29:06.790
in the sense that they're
essential to our nature

00:29:06.790 --> 00:29:11.420
so it's commonly argued that
these days that something

00:29:11.420 --> 00:29:15.610
like market systems is
just part of our nature,

00:29:15.610 --> 00:29:18.020
but we know from a huge amount of evidence

00:29:18.020 --> 00:29:21.780
that that's not true, there's
all kinds of other structures.

00:29:21.780 --> 00:29:26.270
That's a particular fact of
a moment of modern history.

00:29:26.270 --> 00:29:30.489
Others have argued that the
roots of classical liberalism

00:29:30.489 --> 00:29:34.450
actually argue that
what's called sometimes

00:29:34.450 --> 00:29:37.510
an instinct for freedom, an instinct

00:29:37.510 --> 00:29:42.170
to be free of domination
by illegitimate authority

00:29:42.170 --> 00:29:43.690
is the core of our nature.

00:29:43.690 --> 00:29:45.660
That would be the opposite of this.

00:29:45.660 --> 00:29:48.960
And we don't know, we just
know that human nature

00:29:48.960 --> 00:29:50.733
can accommodate both kinds.

00:29:52.240 --> 00:29:54.930
- [Lex] If you look back at your life,

00:29:54.930 --> 00:29:58.150
is there a moment in
your intellectual life

00:29:58.150 --> 00:30:00.210
or life in general that jumps from memory

00:30:00.210 --> 00:30:02.120
that brought you happiness

00:30:02.120 --> 00:30:04.073
that you would love to relive again?

00:30:05.130 --> 00:30:10.130
- [Noam] Sure, falling
in love, having children.

00:30:10.140 --> 00:30:13.130
- [Lex] What about, so
you have put forward

00:30:13.130 --> 00:30:17.690
into the world a lot of
incredible ideas in linguistics,

00:30:17.690 --> 00:30:22.350
in cognitive science, in terms of ideas

00:30:22.350 --> 00:30:25.953
that just excites you
when it first came to you

00:30:25.953 --> 00:30:28.970
that you love to relive those moments.

00:30:28.970 --> 00:30:31.600
- [Noam] Well, I mean,
when you make a discovery

00:30:32.460 --> 00:30:34.713
about something it's exciting like say

00:30:37.050 --> 00:30:40.550
even the observation
of structure dependence

00:30:40.550 --> 00:30:44.460
and on from that the explanation for it,

00:30:44.460 --> 00:30:49.460
but the major things just
seem like common sense.

00:30:49.510 --> 00:30:53.210
So if you go back to, take your question

00:30:53.210 --> 00:30:55.840
about external and internal language.

00:30:55.840 --> 00:30:58.813
You go back to, say, the 1950s

00:30:58.813 --> 00:31:03.421
almost entirely language is
regarded as an external object,

00:31:03.421 --> 00:31:06.320
something outside the mind.

00:31:06.320 --> 00:31:09.423
It just seemed obvious
that that can't be true.

00:31:10.740 --> 00:31:14.440
Like I said, there's something
about you that determines

00:31:14.440 --> 00:31:18.249
you're talking English
not Swahili or something.

00:31:18.249 --> 00:31:20.330
But that's not really a discovery.

00:31:20.330 --> 00:31:24.150
That's just an observation
of what's transparent.

00:31:24.150 --> 00:31:26.660
You might say it's kind of like

00:31:28.409 --> 00:31:32.490
the 17th century, the
beginnings of modern science

00:31:32.490 --> 00:31:37.150
17th century, they came from being willing

00:31:37.150 --> 00:31:40.440
to be puzzled about things
that seemed obvious.

00:31:40.440 --> 00:31:45.440
So it seems obvious that a heavy
ball of lead'll fall faster

00:31:45.510 --> 00:31:50.380
than a light ball of lead,
but Galileo was not impressed

00:31:50.380 --> 00:31:52.720
by the fact that it seemed obvious.

00:31:52.720 --> 00:31:55.018
so he wanted to know if it's true

00:31:55.018 --> 00:31:59.190
He carried out experiments,
actually thought experiments

00:31:59.190 --> 00:32:01.520
never actually carried
them out which showed

00:32:01.520 --> 00:32:04.216
that it can't be true, you know.

00:32:04.216 --> 00:32:09.216
And out of things like that,
observations of that kind,

00:32:11.110 --> 00:32:14.476
you know, why does a
ball fall to the ground

00:32:14.476 --> 00:32:16.964
instead of rising, let's say?

00:32:16.964 --> 00:32:20.261
It seems obvious till you
start thinking about it

00:32:20.261 --> 00:32:23.950
'cause why does steam rise, let's say.

00:32:23.950 --> 00:32:27.300
And I think the beginnings
of modern linguistics

00:32:27.300 --> 00:32:30.080
roughly in the 50s are kind of like that,

00:32:30.080 --> 00:32:33.670
just being willing to be
puzzled about phenomena

00:32:33.670 --> 00:32:38.050
that looked from some
point of view obvious.

00:32:38.050 --> 00:32:41.370
And for example a kind of doctrine,

00:32:41.370 --> 00:32:44.990
almost official doctrine
of structural linguistics

00:32:44.990 --> 00:32:49.990
in the 50s was that languages
can differ from one another

00:32:50.570 --> 00:32:54.840
in arbitrary ways and
each one has to be studied

00:32:55.770 --> 00:32:58.940
on its own without any presuppositions

00:32:58.940 --> 00:33:02.430
and in fact there were
similar views among biologists

00:33:02.430 --> 00:33:05.910
about the nature of
organisms that each one's,

00:33:05.910 --> 00:33:07.820
they're so different when you look at them

00:33:07.820 --> 00:33:11.000
that you could be almost anything.

00:33:11.000 --> 00:33:13.170
Well in both domains it's been learned

00:33:13.170 --> 00:33:15.560
that it's very far from true.

00:33:15.560 --> 00:33:17.010
There are very narrow constraints

00:33:17.010 --> 00:33:20.653
on what could be an organism
or what could be a language.

00:33:21.630 --> 00:33:26.090
But these are, you know, that's
just the nature of inquiry.

00:33:27.030 --> 00:33:29.400
- [Lex] Science in general, yeah, inquiry.

00:33:29.400 --> 00:33:32.060
So one of the peculiar things

00:33:32.060 --> 00:33:35.290
about us human beings is our mortality.

00:33:35.290 --> 00:33:36.773
Ernest Becker explored it.

00:33:36.773 --> 00:33:40.490
In general do you ponder
the value of mortality?

00:33:40.490 --> 00:33:42.453
Do you think about your own mortality?

00:33:43.470 --> 00:33:46.853
- [Noam] I used to when
I was about 12 years old.

00:33:48.090 --> 00:33:51.940
I wondered, I didn't care
much about my own mortality,

00:33:51.940 --> 00:33:56.410
but I was worried about the
fact that if my consciousness

00:33:56.410 --> 00:34:00.330
disappeared would the
entire universe disappear.

00:34:00.330 --> 00:34:01.610
That was frightening.

00:34:01.610 --> 00:34:03.770
- [Lex] Did you ever find
an answer to that question?

00:34:03.770 --> 00:34:05.920
- [Noam] No, nobody's
ever found an answer,

00:34:05.920 --> 00:34:07.900
but I stopped being bothered by it.

00:34:07.900 --> 00:34:10.420
It's kind of like Woody
Allen in one of his films.

00:34:10.420 --> 00:34:15.120
You may recall he goes to
a shrink when he's a child

00:34:15.120 --> 00:34:17.560
and the shrink asks him,
"What's your problem?"

00:34:17.560 --> 00:34:21.798
He says, "I just learned that
the universe is expanding.

00:34:21.798 --> 00:34:23.236
"I can't handle that."

00:34:23.236 --> 00:34:27.280
- [Lex] (laughs) And
another absurd question is,

00:34:27.280 --> 00:34:32.280
what do you think is the
meaning of our existence here,

00:34:32.630 --> 00:34:36.047
our life on Earth, our
brief little moment in time?

00:34:36.047 --> 00:34:38.947
- [Noam] That's something we
answer by our own activities.

00:34:40.640 --> 00:34:42.380
There's no general answer.

00:34:42.380 --> 00:34:44.523
We determine what the meaning of it is.

00:34:46.640 --> 00:34:48.740
- [Lex] The action determine the meaning.

00:34:48.740 --> 00:34:50.600
- [Noam] Meaning in the
sense of significance

00:34:50.600 --> 00:34:55.420
not meaning in the sense that
chair means this, you know,

00:34:55.420 --> 00:34:58.833
but the significance of your
life is something you create.

00:35:01.090 --> 00:35:02.570
- Noam, thank you so
much for talking today.

00:35:02.570 --> 00:35:05.023
It was a huge honor, thank you so much.

00:35:05.970 --> 00:35:08.570
Thanks for listening to this
conversation with Noam Chomsky,

00:35:08.570 --> 00:35:11.980
and thank you to our
presenting sponsor Cash App.

00:35:11.980 --> 00:35:13.893
Download it, use code LexPodcast.

00:35:14.800 --> 00:35:18.010
You'll get $10 and $10 will go to FIRST,

00:35:18.010 --> 00:35:20.620
a STEM education nonprofit
that inspires hundreds

00:35:20.620 --> 00:35:23.240
of thousands of young minds to learn

00:35:23.240 --> 00:35:26.010
and to dream of engineering our future.

00:35:26.010 --> 00:35:28.660
If you enjoy this podcast
subscribe on YouTube.

00:35:28.660 --> 00:35:30.640
Give us five stars on Apple Podcast,

00:35:30.640 --> 00:35:34.270
support on Patreon, or
connect with me on Twitter.

00:35:34.270 --> 00:35:37.013
Thank you for listening and
hope to see you next time.

