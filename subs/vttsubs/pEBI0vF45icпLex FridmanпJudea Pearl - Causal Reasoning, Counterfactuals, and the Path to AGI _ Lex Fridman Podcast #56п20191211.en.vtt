WEBVTT
Kind: captions
Language: en

00:00:00.130 --> 00:00:03.340
- The following is a
conversion with Judea Pearl,

00:00:03.340 --> 00:00:06.850
professor at UCLA and a
winner of the Turing Award,

00:00:06.850 --> 00:00:10.474
that's generally recognized as
the Nobel Prize of computing.

00:00:10.474 --> 00:00:12.520
He's one of the seminal figures

00:00:12.520 --> 00:00:14.560
in the field of artificial intelligence,

00:00:14.560 --> 00:00:16.760
computer science, and statistics.

00:00:16.760 --> 00:00:20.070
He has developed and championed
probabilistic approaches

00:00:20.070 --> 00:00:22.810
to AI, including Bayesian networks,

00:00:22.810 --> 00:00:26.160
and profound ideas in
causality in general.

00:00:26.160 --> 00:00:29.200
These ideas are important not just to AI,

00:00:29.200 --> 00:00:32.373
but to our understanding
and practice of science.

00:00:32.373 --> 00:00:35.647
But in the field of AI,
the idea of causality,

00:00:35.647 --> 00:00:38.420
cause and effect, to many,

00:00:38.420 --> 00:00:41.020
lie at the core of what
is currently missing

00:00:41.020 --> 00:00:42.200
and what must be developed

00:00:42.200 --> 00:00:45.670
in order to build truly
intelligent systems.

00:00:45.670 --> 00:00:48.100
For this reason, and many others,

00:00:48.100 --> 00:00:50.870
his work is worth returning to often.

00:00:50.870 --> 00:00:54.320
I recommend his most recent
book called "Book of Why"

00:00:54.320 --> 00:00:57.270
that presents key ideas
from a lifetime of work

00:00:57.270 --> 00:01:00.470
in a way that is accessible
to the general public.

00:01:00.470 --> 00:01:03.530
This is the "Artificial
Intelligence Podcast."

00:01:03.530 --> 00:01:05.910
If you enjoy it, subscribe on YouTube,

00:01:05.910 --> 00:01:07.880
give it five stars on Apple Podcast,

00:01:07.880 --> 00:01:10.410
support on Patreon, or
simply connect with me

00:01:10.410 --> 00:01:15.370
on Twitter @lexfridman,
spelled F-R-I-D-M-A-N.

00:01:15.370 --> 00:01:18.240
If you leave a review on
Apple Podcasts especially,

00:01:18.240 --> 00:01:21.010
but also Castbox, or comment on YouTube,

00:01:21.010 --> 00:01:23.420
consider mentioning topics, people, ideas,

00:01:23.420 --> 00:01:25.130
questions, quotes in science, tech,

00:01:25.130 --> 00:01:27.530
and philosophy, you find interesting,

00:01:27.530 --> 00:01:29.610
and I'll read them on this podcast.

00:01:29.610 --> 00:01:31.990
I won't call out names,
but I love comments

00:01:31.990 --> 00:01:33.910
with kindness and thoughtfulness in them,

00:01:33.910 --> 00:01:35.800
so I thought I'd share them with you.

00:01:35.800 --> 00:01:37.880
Someone on YouTube highlighted a quote

00:01:37.880 --> 00:01:40.070
from the conversation with Noam Chomsky

00:01:40.070 --> 00:01:42.840
where he said that the
significance of your life

00:01:42.840 --> 00:01:44.491
is something you create.

00:01:44.491 --> 00:01:46.630
I like this line as well.

00:01:46.630 --> 00:01:49.509
On most days, the
existentialist approach to life

00:01:49.509 --> 00:01:52.957
is one I find liberating and fulfilling.

00:01:52.957 --> 00:01:55.070
I recently started doing ads

00:01:55.070 --> 00:01:56.700
at the end of the introduction.

00:01:56.700 --> 00:01:59.410
I'll do one or two minutes
after introducing the episode

00:01:59.410 --> 00:02:01.140
and never any ads in the middle

00:02:01.140 --> 00:02:03.330
that break the flow of the conversation.

00:02:03.330 --> 00:02:04.780
I hope that works for you

00:02:04.780 --> 00:02:07.753
and doesn't hurt the listening experience.

00:02:07.753 --> 00:02:10.239
This show is presented by Cash App,

00:02:10.239 --> 00:02:13.100
the number one finance
app in the App Store.

00:02:13.100 --> 00:02:15.570
I personally use Cash App
to send money to friends,

00:02:15.570 --> 00:02:17.460
but you can also use it to buy, sell,

00:02:17.460 --> 00:02:20.150
and deposit Bitcoin in just seconds.

00:02:20.150 --> 00:02:22.830
Cash App also has a new investing feature.

00:02:22.830 --> 00:02:25.900
You can buy fractions of
a stock, say $1 worth,

00:02:25.900 --> 00:02:28.070
no matter what the stock price is.

00:02:28.070 --> 00:02:30.760
Broker's services are provided
by Cash App Investing,

00:02:30.760 --> 00:02:33.795
a subsidiary of Square, a member SIPC.

00:02:33.795 --> 00:02:36.650
I'm excited to be working with Cash App

00:02:36.650 --> 00:02:39.970
to support one of my favorite
organizations called FIRST,

00:02:39.970 --> 00:02:43.470
best known for their FIRST
Robotics and LEGO competitions.

00:02:43.470 --> 00:02:45.940
They educate and inspire
hundreds of thousands

00:02:45.940 --> 00:02:48.713
of students in over 110 countries,

00:02:48.713 --> 00:02:51.790
and have a perfect rating
on Charity Navigator,

00:02:51.790 --> 00:02:53.770
which means the donated money is used

00:02:53.770 --> 00:02:55.607
to the maximum effectiveness.

00:02:55.607 --> 00:02:58.730
When you get Cash App from
the App Store or Google Play

00:02:58.730 --> 00:03:02.070
and use code LexPodcast, you'll get $10

00:03:02.070 --> 00:03:05.160
and Cash App will also
donate $10 to FIRST.

00:03:05.160 --> 00:03:07.600
Which, again, is an organization

00:03:07.600 --> 00:03:09.751
that I've personally seen
inspire girls and boys

00:03:09.751 --> 00:03:12.850
to dream of engineering a better world.

00:03:12.850 --> 00:03:16.963
And now, here's my
conversation with Judea Pearl.

00:03:18.130 --> 00:03:19.760
You mentioned in an interview

00:03:19.760 --> 00:03:21.880
that science is not a collection of facts,

00:03:21.880 --> 00:03:25.603
but a constant human struggle
with the mysteries of nature.

00:03:26.440 --> 00:03:27.990
What was the first mystery

00:03:27.990 --> 00:03:30.200
that you can recall that hooked you,

00:03:30.200 --> 00:03:31.437
that captivated your curiosity?

00:03:31.437 --> 00:03:32.650
- Oh, the first mystery.

00:03:32.650 --> 00:03:34.175
That's a good one.

00:03:34.175 --> 00:03:36.751
Yeah, I remember that.

00:03:36.751 --> 00:03:38.529
- [Lex] What was it?

00:03:38.529 --> 00:03:40.029
- I had a fever for three days

00:03:41.065 --> 00:03:45.862
when I learned about Descartes
and a little geometry,

00:03:45.862 --> 00:03:49.930
and I found out that you
can do all the construction

00:03:49.930 --> 00:03:52.375
in geometry using algebra.

00:03:52.375 --> 00:03:54.560
And I couldn't get over it.

00:03:54.560 --> 00:03:56.612
I simply couldn't get out of bed.

00:03:56.612 --> 00:03:58.440
(chuckles)

00:03:58.440 --> 00:04:02.503
- What kinda world does
analytic geometry unlock?

00:04:02.503 --> 00:04:07.503
- Well, it connects algebra
with geometry, okay?

00:04:07.700 --> 00:04:12.416
So, Descartes has the idea
that geometrical construction

00:04:12.416 --> 00:04:15.781
and geometrical theorems and assumptions

00:04:15.781 --> 00:04:19.610
can be articulated in
the language of algebra.

00:04:19.610 --> 00:04:24.445
Which means that all the proofs
that we did in high school

00:04:24.445 --> 00:04:28.660
in trying to prove that
the three bisectors meet

00:04:28.660 --> 00:04:32.914
at one point, and that the (chuckles)

00:04:32.914 --> 00:04:37.914
All this can be proven by
shuffling around notation.

00:04:38.169 --> 00:04:42.483
That was a traumatic experience.

00:04:42.483 --> 00:04:44.510
- (chuckles) Traumatic experience.

00:04:44.510 --> 00:04:45.810
- [Judea] For me, it was, it
was, I'm telling you, right?

00:04:45.810 --> 00:04:47.020
- So it's the connection

00:04:47.020 --> 00:04:49.170
between the different
mathematical disciplines,

00:04:49.170 --> 00:04:50.677
that they all

00:04:50.677 --> 00:04:52.542
- They're not even two
different languages.

00:04:52.542 --> 00:04:54.114
- Languages.
- Yeah.

00:04:54.114 --> 00:04:57.240
- Which mathematic
discipline is most beautiful?

00:04:57.240 --> 00:04:58.660
Is geometry it for you?

00:04:58.660 --> 00:04:59.710
- Both are beautiful.

00:05:00.617 --> 00:05:02.480
They have almost the same power.

00:05:02.480 --> 00:05:04.679
- But there's a visual
element to geometry.

00:05:04.679 --> 00:05:08.150
- The visual element,
it's more transparent.

00:05:08.150 --> 00:05:11.593
But once you get over to algebra then

00:05:11.593 --> 00:05:14.490
linear equations is a straight line.

00:05:14.490 --> 00:05:16.553
This translation is easily absorbed.

00:05:18.282 --> 00:05:23.282
To pass a tangent to a circle, you know,

00:05:23.531 --> 00:05:25.040
you have the basic theorems,

00:05:25.040 --> 00:05:27.820
and you can do it with algebra.

00:05:27.820 --> 00:05:31.630
But the transition from
one to another was really,

00:05:31.630 --> 00:05:34.210
I thought that Descartes was
the greatest mathematician

00:05:34.210 --> 00:05:35.283
of all times.

00:05:36.560 --> 00:05:40.503
- So, if you think of
engineering and mathematics

00:05:41.956 --> 00:05:43.250
as a spectrum--

00:05:43.250 --> 00:05:44.083
- [Judea] Yes.

00:05:44.981 --> 00:05:49.230
- You have walked casually
along this spectrum

00:05:49.230 --> 00:05:51.580
throughout your life.

00:05:51.580 --> 00:05:53.880
You know, a little bit
of engineering and then

00:05:56.276 --> 00:05:59.093
you've done a little bit of
mathematics here and there.

00:05:59.093 --> 00:06:00.040
- A little bit.

00:06:00.040 --> 00:06:04.140
We get a very solid
background in mathematics

00:06:04.140 --> 00:06:07.160
because our teachers were geniuses.

00:06:07.160 --> 00:06:09.800
Our teachers came from
Germany in the 1930s

00:06:09.800 --> 00:06:11.253
running away from Hitler.

00:06:12.350 --> 00:06:15.130
They left their careers
in Heidelberg and Berlin,

00:06:15.130 --> 00:06:17.920
and came to teach high school in Israel.

00:06:17.920 --> 00:06:20.923
And we were the beneficiary
of that experiment.

00:06:22.223 --> 00:06:25.280
When they taught us math, a good way.

00:06:25.280 --> 00:06:27.070
- What's a good way to teach math?

00:06:27.070 --> 00:06:28.263
- [Judea] Theorologically.

00:06:29.120 --> 00:06:29.953
- The people.

00:06:29.953 --> 00:06:33.410
- The people behind the theorems, yeah.

00:06:33.410 --> 00:06:38.410
Their cousins, and their nieces,
(chuckles) and their faces,

00:06:38.580 --> 00:06:41.010
and how they jumped from the bathtub

00:06:41.010 --> 00:06:46.010
when they screamed, "Eureka"
and ran naked in town. (laughs)

00:06:46.090 --> 00:06:49.330
- So you were almost educated
as a historian of math.

00:06:49.330 --> 00:06:52.010
- No, we just got a
glimpse of that history,

00:06:52.010 --> 00:06:56.740
together with the theorem,
so every exercise in math

00:06:56.740 --> 00:06:58.952
was connected with a person,

00:06:58.952 --> 00:07:01.540
and the time of the person,

00:07:01.540 --> 00:07:03.237
the period.

00:07:03.237 --> 00:07:05.680
- [Lex] The period also
mathematically speaking.

00:07:05.680 --> 00:07:07.980
- Mathematically speaking,
yes, not a paradox.

00:07:10.570 --> 00:07:15.570
- Then in university, you had
gone on to do engineering.

00:07:16.280 --> 00:07:19.453
- Yeah. I got a BS in
Engineering at Technion.

00:07:20.720 --> 00:07:24.655
And then I moved here
for graduate school work,

00:07:24.655 --> 00:07:29.655
and I did the engineering in
addition to physics in Rutgers.

00:07:31.950 --> 00:07:35.870
And it combined very
nicely with my thesis,

00:07:35.870 --> 00:07:39.303
which I did in Elsevier
Laboratories in superconductivity.

00:07:40.540 --> 00:07:43.810
- And then somehow thought to switch

00:07:43.810 --> 00:07:48.810
to almost computer science
software, even, not switched,

00:07:49.270 --> 00:07:52.500
but longed to become to get
into software engineering

00:07:52.500 --> 00:07:54.540
a little bit, almost in programming,

00:07:54.540 --> 00:07:56.620
if you can call it that in the 70s.

00:07:56.620 --> 00:07:57.813
There's all these disciplines.

00:07:57.813 --> 00:07:58.646
- Yeah.

00:07:58.646 --> 00:08:00.751
- If you were to pick a favorite,

00:08:00.751 --> 00:08:03.910
in terms of engineering and mathematics,

00:08:03.910 --> 00:08:07.180
which path do you think has more beauty?

00:08:07.180 --> 00:08:08.650
Which path has more power?

00:08:08.650 --> 00:08:10.600
- It's hard to choose, no?

00:08:10.600 --> 00:08:12.660
I enjoy doing physics.

00:08:12.660 --> 00:08:15.885
I even have a vortex named with my name.

00:08:15.885 --> 00:08:20.885
So, I have investment
in immortality. (laughs)

00:08:21.923 --> 00:08:24.340
- So, what is a vortex?

00:08:24.340 --> 00:08:27.040
- Vortex is in superconductivity.

00:08:27.040 --> 00:08:28.220
- In the superconductivity.

00:08:28.220 --> 00:08:30.900
- You have terminal
current swirling around,

00:08:30.900 --> 00:08:34.600
one way or the other, going
to have us throw one or zero,

00:08:34.600 --> 00:08:38.240
for computer that was
we worked on in the 1960

00:08:38.240 --> 00:08:39.930
in Elsevier,

00:08:39.930 --> 00:08:44.100
and I discovered a few nice
phenomena with the vortices.

00:08:44.100 --> 00:08:45.589
You push current and they move.

00:08:45.589 --> 00:08:46.869
- [Lex] So there's a Pearl vortex.

00:08:46.869 --> 00:08:48.989
- A Pearl vortex, why, you can google it.

00:08:48.989 --> 00:08:50.260
(both laugh)

00:08:50.260 --> 00:08:53.570
I didn't know about it,
but the physicist picked up

00:08:53.570 --> 00:08:57.210
on my thesis, on my PhD thesis,

00:08:57.210 --> 00:09:02.210
and it became popular when
thin film superconductors

00:09:03.300 --> 00:09:06.960
became important, for high
temperature superconductors.

00:09:06.960 --> 00:09:10.692
So, they call it "Pearl
vortex" without my knowledge.

00:09:10.692 --> 00:09:11.525
(laughs)

00:09:11.525 --> 00:09:14.486
I discovered it only about 15 years ago.

00:09:14.486 --> 00:09:17.610
- You have footprints
in all of the sciences,

00:09:17.610 --> 00:09:21.000
so let's talk about the
universe for a little bit.

00:09:21.000 --> 00:09:22.920
Is the universe, at the lowest level,

00:09:22.920 --> 00:09:25.077
deterministic or stochastic,

00:09:25.077 --> 00:09:27.440
in your amateur philosophy view?

00:09:27.440 --> 00:09:30.160
Put another way, does God play dice?

00:09:30.160 --> 00:09:33.130
- We know it is stochastic, right?

00:09:33.130 --> 00:09:35.200
- [Lex] Today. Today we
think it is stochastic.

00:09:35.200 --> 00:09:37.530
- Yes, we think

00:09:37.530 --> 00:09:40.150
because we have the Heisenberg
uncertainty principle

00:09:40.150 --> 00:09:44.487
and we have some
experiments to confirm that.

00:09:44.487 --> 00:09:48.000
- All we have is
experiments to confirm it.

00:09:48.000 --> 00:09:49.303
We don't understand why.

00:09:50.430 --> 00:09:51.480
- [Judea] Why is already--

00:09:51.480 --> 00:09:54.397
- You wrote a book about why. (laughs)

00:09:54.397 --> 00:09:56.545
- Yeah, it's a puzzle.

00:09:56.545 --> 00:10:01.545
It's a puzzle that you have
the dice-flipping machine,

00:10:02.420 --> 00:10:07.420
or God, and the result of the flipping,

00:10:08.610 --> 00:10:11.433
propagated with a speed faster
than the speed of light.

00:10:12.363 --> 00:10:14.113
(laughs) We can't explain it, okay?

00:10:15.210 --> 00:10:20.210
But, it only governs
microscopic phenomena.

00:10:21.340 --> 00:10:24.660
- So you don't think of
quantum mechanics as useful

00:10:25.700 --> 00:10:27.646
for understanding the nature of reality?

00:10:27.646 --> 00:10:30.440
- [Judea] No, it's diversionary.

00:10:30.440 --> 00:10:34.560
- So, in your thinking, the world might

00:10:34.560 --> 00:10:36.030
as well be deterministic?

00:10:36.030 --> 00:10:38.530
- The world is deterministic,

00:10:38.530 --> 00:10:42.840
and as far as a new one
firing is concerned,

00:10:42.840 --> 00:10:47.280
it is deterministic to
first approximation.

00:10:47.280 --> 00:10:48.970
- What about free will?

00:10:48.970 --> 00:10:52.970
- Free will is also a nice exercise.

00:10:52.970 --> 00:10:54.980
Free will is an illusion,

00:10:54.980 --> 00:10:57.963
that we AI people are going to solve.

00:10:58.935 --> 00:11:01.703
- So, what do you think, once we solve it,

00:11:01.703 --> 00:11:03.430
that solution will look like?

00:11:03.430 --> 00:11:04.610
Once we put it in the page.

00:11:04.610 --> 00:11:06.310
- The solution will look like,

00:11:06.310 --> 00:11:08.980
first of all it will look like a machine.

00:11:08.980 --> 00:11:12.610
A machine that acts as
though it has free will.

00:11:12.610 --> 00:11:14.280
It communicates with other machines

00:11:14.280 --> 00:11:17.230
as though they have free will,

00:11:17.230 --> 00:11:19.560
and you wouldn't be able
to tell the difference

00:11:19.560 --> 00:11:22.230
between a machine that does and a machine

00:11:22.230 --> 00:11:23.853
that doesn't have free will, eh?

00:11:24.760 --> 00:11:27.550
- So it propagates the
illusion of free will

00:11:27.550 --> 00:11:29.540
amongst the other machines.

00:11:29.540 --> 00:11:33.240
- And faking it is having it, okay?

00:11:33.240 --> 00:11:35.210
That's what Turing test is all about.

00:11:35.210 --> 00:11:37.260
Faking intelligence is intelligence,

00:11:37.260 --> 00:11:41.150
because it's not easy to fake.

00:11:41.150 --> 00:11:42.996
It's very hard to fake,

00:11:42.996 --> 00:11:45.732
and you can only fake if you have it.

00:11:45.732 --> 00:11:50.732
- (laughs) That's such
a beautiful statement.

00:11:51.615 --> 00:11:56.615
(laughs) You can't fake it
if you don't have it, yup.

00:11:59.540 --> 00:12:04.540
So, let's begin at the
beginning, with the probability,

00:12:06.029 --> 00:12:09.370
both philosophically and mathematically,

00:12:09.370 --> 00:12:12.240
what does it mean to say
the probability of something

00:12:12.240 --> 00:12:15.180
happening is 50%?

00:12:15.180 --> 00:12:16.383
What is probability?

00:12:17.220 --> 00:12:19.933
- It's a degree of
uncertainty that an agent has

00:12:19.933 --> 00:12:21.505
about the world.

00:12:21.505 --> 00:12:24.040
- You're still expressing some knowledge

00:12:24.040 --> 00:12:24.873
in that statement.

00:12:24.873 --> 00:12:26.030
- Of course.

00:12:26.030 --> 00:12:29.350
If the probability is 90%,
it's absolutely different kind

00:12:29.350 --> 00:12:32.221
of knowledge than if it is 10%.

00:12:32.221 --> 00:12:35.900
- But it's still not
solid knowledge, it's--

00:12:35.900 --> 00:12:37.673
- It is solid knowledge, by.

00:12:38.550 --> 00:12:42.860
If you tell me that 90% assurance

00:12:42.860 --> 00:12:47.212
smoking will give you
lung cancer in five years,

00:12:47.212 --> 00:12:52.212
versus 10%, it's a piece
of useful knowledge.

00:12:52.430 --> 00:12:55.766
- So this statistical
view of the universe,

00:12:55.766 --> 00:12:57.670
why is it useful?

00:12:57.670 --> 00:13:00.790
So we're swimming in complete uncertainty.

00:13:00.790 --> 00:13:01.840
Most of everything around you--

00:13:01.840 --> 00:13:03.597
- It allows you to predict things

00:13:03.597 --> 00:13:06.150
with a certain probability,

00:13:06.150 --> 00:13:09.143
and computing those
probabilities are very useful.

00:13:10.005 --> 00:13:12.340
That's the whole idea of prediction.

00:13:15.130 --> 00:13:18.240
And you need prediction
to be able to survive.

00:13:18.240 --> 00:13:21.410
If you cannot predict
the future then you just,

00:13:21.410 --> 00:13:25.701
crossing the street would
be extremely fearful.

00:13:25.701 --> 00:13:28.850
- And so you've done a
lot of work in causation,

00:13:28.850 --> 00:13:31.461
so let's think about correlation.

00:13:31.461 --> 00:13:33.948
- I started with probability.

00:13:33.948 --> 00:13:35.670
- You started with probability.

00:13:35.670 --> 00:13:38.820
You've invented the Bayesian networks.

00:13:38.820 --> 00:13:39.653
- [Judea] Yeah.

00:13:40.597 --> 00:13:43.950
- And so, we'll dance back and forth

00:13:43.950 --> 00:13:47.173
between these levels of uncertainty,

00:13:47.173 --> 00:13:49.453
but what is correlation?

00:13:50.430 --> 00:13:54.050
So, probability is something
happening, is something,

00:13:54.050 --> 00:13:56.530
but then there's a bunch
of things happening,

00:13:56.530 --> 00:13:59.580
and sometimes they happen
together sometimes not.

00:13:59.580 --> 00:14:00.820
They're independent or not,

00:14:00.820 --> 00:14:03.690
so how do you think about
correlation of things?

00:14:03.690 --> 00:14:06.310
- Correlation occurs when
two things vary together

00:14:06.310 --> 00:14:09.960
over a very long time, is
one way of measuring it.

00:14:09.960 --> 00:14:12.110
Or, when you have a bunch of variables

00:14:12.110 --> 00:14:15.072
that they all vary cohesively,

00:14:15.072 --> 00:14:18.630
then we have a correlation here,

00:14:18.630 --> 00:14:21.770
and usually when we
think about correlation,

00:14:21.770 --> 00:14:23.563
we really think causation.

00:14:24.450 --> 00:14:27.960
Things cannot be correlation
unless there is a reason

00:14:27.960 --> 00:14:30.330
for them to vary together.

00:14:30.330 --> 00:14:32.100
Why should they vary together?

00:14:32.100 --> 00:14:35.620
If they don't see each other,
why should they vary together?

00:14:35.620 --> 00:14:37.773
- So underlying it somewhere is causation.

00:14:37.773 --> 00:14:39.280
- Yes.

00:14:39.280 --> 00:14:43.210
Hidden in our intuition there
is a notion of causation,

00:14:43.210 --> 00:14:47.643
because we cannot grasp any
other logic except causation.

00:14:48.650 --> 00:14:52.643
- And how does conditional
probability differ

00:14:52.643 --> 00:14:55.276
from causation?

00:14:55.276 --> 00:14:57.980
So, what is conditional probability?

00:14:57.980 --> 00:15:00.630
- Conditional probability
is how things vary

00:15:00.630 --> 00:15:05.070
when one of them stays the same.

00:15:05.070 --> 00:15:09.340
Now, staying the same
means that I have chosen

00:15:09.340 --> 00:15:13.010
to look only at those
incidents where the guy

00:15:13.010 --> 00:15:16.160
has the same value as the previous one.

00:15:16.160 --> 00:15:19.340
It's my choice, as an experimenter,

00:15:19.340 --> 00:15:22.310
so things that are not correlated before

00:15:22.310 --> 00:15:24.290
could become correlated.

00:15:24.290 --> 00:15:26.910
Like for instance, if I have two coins

00:15:26.910 --> 00:15:28.363
which are uncorrelated,

00:15:29.290 --> 00:15:33.820
and I choose only those
flippings experiments

00:15:33.820 --> 00:15:37.050
in which a bell rings,
and the bell rings when

00:15:37.050 --> 00:15:40.810
at least one of them is a tail, okay,

00:15:40.810 --> 00:15:44.410
then suddenly I see correlation
between the two coins,

00:15:44.410 --> 00:15:48.463
because I only looked at the
cases where the bell rang.

00:15:49.340 --> 00:15:51.530
You see, it is my design.

00:15:51.530 --> 00:15:53.720
It is my ignorance essentially,

00:15:53.720 --> 00:15:58.720
with my audacity to
ignore certain incidents,

00:16:01.280 --> 00:16:04.610
I suddenly create a correlation

00:16:04.610 --> 00:16:07.118
where it doesn't exist physically.

00:16:07.118 --> 00:16:08.100
- Right.

00:16:08.100 --> 00:16:11.440
So, you just outlined one of the flaws

00:16:11.440 --> 00:16:14.990
of observing the world and
trying to infer something

00:16:14.990 --> 00:16:16.130
from the math about the world

00:16:16.130 --> 00:16:17.550
from looking at the correlation.

00:16:17.550 --> 00:16:19.010
- I don't look at it as a flaw.

00:16:19.010 --> 00:16:20.423
The world works like that.

00:16:21.278 --> 00:16:26.073
The flaws come if you try
to impose causal logic

00:16:27.512 --> 00:16:32.290
on correlation.

00:16:32.290 --> 00:16:34.750
It doesn't work too well.

00:16:34.750 --> 00:16:36.750
- I mean, but that's exactly what we do.

00:16:38.088 --> 00:16:40.330
That has been the majority
of science, is you--

00:16:40.330 --> 00:16:42.503
- No, the majority of naive science.

00:16:43.800 --> 00:16:45.370
Statisticians know it.

00:16:45.370 --> 00:16:47.900
Statisticians know that if you condition

00:16:47.900 --> 00:16:49.595
on a third variable,

00:16:49.595 --> 00:16:53.830
then you can destroy
or create correlations

00:16:53.830 --> 00:16:55.680
among two other variables.

00:16:55.680 --> 00:16:56.513
They know it.

00:16:56.513 --> 00:16:57.758
It's (speaks foreign language).

00:16:57.758 --> 00:16:59.630
There's nothing surprises them.

00:16:59.630 --> 00:17:02.327
That's why they all dismiss
the systems paradox, look

00:17:02.327 --> 00:17:04.376
"Ah, we know it!"

00:17:04.376 --> 00:17:07.310
They don't know anything
about it. (laughs)

00:17:07.310 --> 00:17:09.730
- Well, there's disciplines
like psychology,

00:17:09.730 --> 00:17:12.910
where all the variables
are hard to account for,

00:17:12.910 --> 00:17:15.260
and so, oftentimes there is a leap

00:17:15.260 --> 00:17:17.849
between correlation to causation.

00:17:17.849 --> 00:17:20.507
- What do you mean, a leap?

00:17:20.507 --> 00:17:24.370
Who is trying to get
causation from correlation?

00:17:24.370 --> 00:17:26.570
There's no one.

00:17:26.570 --> 00:17:28.010
- [Lex] You're not proving causation,

00:17:28.010 --> 00:17:31.720
but you're sort of discussing it,

00:17:31.720 --> 00:17:35.380
implying, sort of hypothesizing
without ability to--

00:17:35.380 --> 00:17:37.200
- Which discipline you have in mind?

00:17:37.200 --> 00:17:40.196
I'll tell you if they are obsolete.

00:17:40.196 --> 00:17:41.274
(Lex laughs)

00:17:41.274 --> 00:17:44.270
Or if they are outdated, or
they're about to get outdated.

00:17:44.270 --> 00:17:45.572
- Yes, yes.

00:17:45.572 --> 00:17:47.571
- [Judea] Oh, yeah, tell me
which ones you have in mind.

00:17:47.571 --> 00:17:48.864
- Well, psychology, you know--

00:17:48.864 --> 00:17:50.683
- [Judea] Psychology, what, SEM?

00:17:50.683 --> 00:17:53.956
- No, no, I was thinking of
applied psychology, studying,

00:17:53.956 --> 00:17:57.290
for example, we work with human behavior

00:17:57.290 --> 00:18:00.410
in semi-autonomous
vehicles, how people behave.

00:18:00.410 --> 00:18:02.610
And you have to conduct these studies

00:18:02.610 --> 00:18:04.340
of people driving cars.

00:18:04.340 --> 00:18:05.580
- Everything starts with the question:

00:18:05.580 --> 00:18:07.860
What is the research question?

00:18:07.860 --> 00:18:09.513
- What is the research question?

00:18:10.480 --> 00:18:12.210
The research question:

00:18:12.210 --> 00:18:17.210
do people fall asleep when
the car is driving itself?

00:18:18.074 --> 00:18:20.600
- Do they fall asleep,

00:18:20.600 --> 00:18:23.200
or do they tend to fall
asleep more frequently

00:18:23.200 --> 00:18:24.033
- [Lex] More frequently

00:18:24.033 --> 00:18:26.020
- than the car not driving itself.

00:18:26.020 --> 00:18:27.070
- [Lex] Not driving itself.

00:18:27.070 --> 00:18:28.520
That's a good question, okay.

00:18:29.707 --> 00:18:33.780
- You put people in the car,
because it's real world.

00:18:33.780 --> 00:18:35.240
You can't conduct an experiment

00:18:35.240 --> 00:18:36.380
where you control everything.

00:18:36.380 --> 00:18:37.890
- [Judea] Why can't you con--

00:18:37.890 --> 00:18:39.326
- You could.

00:18:39.326 --> 00:18:44.260
- [Judea] Turn the
automatic module on and off.

00:18:45.855 --> 00:18:49.013
- Because there's aspects
to it that's unethical,

00:18:52.720 --> 00:18:54.733
because it's testing on public roads.

00:18:56.991 --> 00:19:01.991
The drivers themselves have to
make that choice themselves,

00:19:02.450 --> 00:19:04.483
and so they regulate that.

00:19:05.530 --> 00:19:09.100
So, you just observe when
they drive it autonomously,

00:19:09.100 --> 00:19:10.770
and when they don't.

00:19:10.770 --> 00:19:13.190
- But maybe they turn it
off when they're very tired.

00:19:13.190 --> 00:19:14.590
- [Lex] Yeah, that kind of thing.

00:19:14.590 --> 00:19:16.510
But you don't know those variables.

00:19:16.510 --> 00:19:19.470
- Okay, so you have now
uncontrolled experiment,

00:19:19.470 --> 00:19:20.610
- [Lex] Uncontrolled experiment.

00:19:20.610 --> 00:19:22.944
- When we correct observation of study,

00:19:22.944 --> 00:19:27.210
and when we form the correlation detected,

00:19:27.210 --> 00:19:30.370
we have to infer causal relationship,

00:19:30.370 --> 00:19:33.410
whether it was the automatic piece

00:19:33.410 --> 00:19:36.010
that cause them to fall asleep, or,

00:19:36.010 --> 00:19:41.010
so that is an issue that
is about 120 years old.

00:19:42.894 --> 00:19:44.493
- [Lex] (laughs) Yeah.

00:19:45.500 --> 00:19:48.957
- Oh, I should only go
100 years old, okay?

00:19:48.957 --> 00:19:51.430
- [Lex] (chuckles) Who's counting?

00:19:51.430 --> 00:19:55.290
- Oh, maybe, no, actually I
should say it's 2,000 years old,

00:19:55.290 --> 00:19:57.890
because we have this experiment by Daniel,

00:19:57.890 --> 00:20:00.283
about the Babylonian king,

00:20:03.104 --> 00:20:08.104
that wanted the exiled people from Israel,

00:20:09.260 --> 00:20:14.260
that were taken in exile to
Babylon to serve the king.

00:20:14.740 --> 00:20:18.130
He wanted to serve them
king's food, which was meat,

00:20:18.130 --> 00:20:22.830
and Daniel as a good Jew
couldn't eat non-Kosher food,

00:20:22.830 --> 00:20:26.680
so he asked them to eat vegetarian food.

00:20:26.680 --> 00:20:29.307
But the king's overseers said, "I'm sorry,

00:20:29.307 --> 00:20:33.467
"but if the king sees that
your performance falls

00:20:33.467 --> 00:20:38.467
"below that of other kids,
now, he's going to kill me."

00:20:39.410 --> 00:20:41.647
Daniel said, "Let's make an experiment.

00:20:41.647 --> 00:20:44.267
"Let's take four of us
from Jerusalem, okay?

00:20:44.267 --> 00:20:46.397
"Give us vegetarian food.

00:20:46.397 --> 00:20:50.227
"Let's take the other guys
to eat the king's food,

00:20:50.227 --> 00:20:54.120
"and about a week's time,
we'll test our performance."

00:20:54.120 --> 00:20:57.860
And you know the answer,
because he did the experiment,

00:20:57.860 --> 00:21:01.380
and they were so much
better than the others,

00:21:01.380 --> 00:21:06.380
that the kings nominated them
to super positions, (laughs)

00:21:07.380 --> 00:21:09.763
in his case, so it was a first experiment.

00:21:10.961 --> 00:21:12.790
So that there was a very simple,

00:21:12.790 --> 00:21:15.550
it's also the same research questions.

00:21:15.550 --> 00:21:17.440
We want to know if vegetarian food

00:21:18.432 --> 00:21:22.853
assists or obstructs your mental ability.

00:21:24.740 --> 00:21:29.363
So, the question is a very old one.

00:21:30.500 --> 00:21:35.500
Even Democritus, if I could
discover one cause of things,

00:21:39.142 --> 00:21:42.913
I would rather discuss one
cause than be King of Persia.

00:21:44.220 --> 00:21:49.220
The task of discovering
causes was in the mind

00:21:49.290 --> 00:21:53.530
of ancient people from
many, many years ago.

00:21:53.530 --> 00:21:56.510
But, the mathematics of doing that

00:21:57.420 --> 00:22:00.199
was only developed in the 1920s.

00:22:00.199 --> 00:22:03.493
So, science has left us orphaned.

00:22:04.709 --> 00:22:08.350
Science has not provided
us with the mathematics

00:22:08.350 --> 00:22:13.350
to capture the idea of x causes
y and y does not cause x.

00:22:13.883 --> 00:22:16.580
Because all the question of physics

00:22:16.580 --> 00:22:18.650
are symmetrical, algebraic.

00:22:18.650 --> 00:22:20.703
The equality sign goes both ways.

00:22:21.730 --> 00:22:23.140
- Okay, let's look at machine learning.

00:22:23.140 --> 00:22:26.900
Machine learning today, if you
look at deep neural networks,

00:22:26.900 --> 00:22:31.477
you can think of it as kind
of conditional probability

00:22:31.477 --> 00:22:32.310
estimators.

00:22:32.310 --> 00:22:33.700
- [Judea] Conditional probability.

00:22:33.700 --> 00:22:34.533
Correct.

00:22:35.453 --> 00:22:36.410
Beautiful.

00:22:36.410 --> 00:22:38.375
Well, did you say that?

00:22:38.375 --> 00:22:39.300
- [Lex] What?

00:22:39.300 --> 00:22:41.143
- Conditional probability estimators.

00:22:42.426 --> 00:22:44.926
None of the machine learning
people clobbered you?

00:22:46.137 --> 00:22:46.970
(laughs)
Attacked you?

00:22:49.440 --> 00:22:52.450
- Most people, and this is
why today's conversation

00:22:52.450 --> 00:22:53.600
I think is interesting is,

00:22:53.600 --> 00:22:55.290
most people would agree with you.

00:22:55.290 --> 00:22:58.710
There's certain aspects that
are just effective today,

00:22:58.710 --> 00:23:01.682
but we're going to hit a wall,
and there's a lot of ideas,

00:23:01.682 --> 00:23:03.580
I think you're very right,

00:23:03.580 --> 00:23:06.503
that we're going to have to
return to, about causality.

00:23:07.588 --> 00:23:10.734
Let's try to explore it.

00:23:10.734 --> 00:23:12.130
- Okay.

00:23:12.130 --> 00:23:13.210
- Let's even take a step back.

00:23:13.210 --> 00:23:15.323
You invented Bayesian networks,

00:23:17.430 --> 00:23:21.330
that look awfully a lot
like they express something

00:23:21.330 --> 00:23:24.073
like causation, but they
don't, not necessarily.

00:23:25.320 --> 00:23:28.288
So, how do we turn Bayesian networks

00:23:28.288 --> 00:23:30.860
into expressing causation?

00:23:30.860 --> 00:23:33.719
How do we build causal networks?

00:23:33.719 --> 00:23:36.510
A causes B, B causes C.

00:23:36.510 --> 00:23:38.850
How do we start to infer
that kind of thing?

00:23:38.850 --> 00:23:41.500
- We start by asking ourselves question:

00:23:41.500 --> 00:23:46.370
what are the factors that
would determine the value of x?

00:23:46.370 --> 00:23:51.290
X could be blood pressure, death, hunger.

00:23:52.614 --> 00:23:56.080
- But these are hypotheses
that we propose--

00:23:56.080 --> 00:23:59.090
- Hypotheses, everything
which has to do with causality

00:23:59.090 --> 00:24:00.823
comes from a theory.

00:24:02.007 --> 00:24:06.873
The difference is only how
you interrogate the theory

00:24:06.873 --> 00:24:09.123
that you have in your mind.

00:24:10.940 --> 00:24:13.920
- So it still needs the
human expert to propose--

00:24:13.920 --> 00:24:14.957
- Right.

00:24:14.957 --> 00:24:19.957
They need the human expert
to specify the initial model.

00:24:21.010 --> 00:24:24.070
Initial model could be very qualitative.

00:24:24.070 --> 00:24:27.060
Just who listens to whom?

00:24:27.060 --> 00:24:30.870
By whom listens I mean one
variable listens to the other.

00:24:30.870 --> 00:24:34.333
So, I say okay, the tide
is listening to the moon,

00:24:36.140 --> 00:24:41.140
and not to the rooster
crow, okay, and so forth.

00:24:43.150 --> 00:24:46.003
This is our understanding of
the world in which we live,

00:24:46.890 --> 00:24:51.128
scientific understanding of reality.

00:24:51.128 --> 00:24:55.240
We have to start there,
because if we don't know how

00:24:55.240 --> 00:24:58.600
to handle cause and effect relationship,

00:24:58.600 --> 00:25:02.980
when we do have a model, and
we certainly do not know how

00:25:02.980 --> 00:25:05.440
to handle it when we don't have a model,

00:25:05.440 --> 00:25:07.450
so that starts first.

00:25:07.450 --> 00:25:12.450
An AI slogan is presentation
first, discovery second.

00:25:12.462 --> 00:25:16.924
But, if I give you all the
information that you need,

00:25:16.924 --> 00:25:19.301
can you do anything useful with it?

00:25:19.301 --> 00:25:21.560
That is the first, representation.

00:25:21.560 --> 00:25:22.580
How do you represent it?

00:25:22.580 --> 00:25:24.620
I give you all the knowledge in the world.

00:25:24.620 --> 00:25:25.820
How do you represent it?

00:25:26.970 --> 00:25:30.077
When you represent it, I ask you,

00:25:30.077 --> 00:25:33.230
can you infer x or y or z?

00:25:33.230 --> 00:25:35.290
Can you answer certain queries?

00:25:35.290 --> 00:25:36.940
Is it complex?

00:25:36.940 --> 00:25:38.800
Is it polynomial?

00:25:38.800 --> 00:25:42.070
All the computer science exercises, we do,

00:25:42.070 --> 00:25:47.070
once you give me a
representation for my knowledge.

00:25:47.290 --> 00:25:49.582
Then you can ask me, now that I understand

00:25:49.582 --> 00:25:52.570
how to represent things,
how do I discover them?

00:25:52.570 --> 00:25:54.063
It's a secondary thing.

00:25:55.006 --> 00:25:57.090
- I should echo the statement

00:25:57.090 --> 00:26:02.090
that mathematics in much of
the machine learning world

00:26:02.215 --> 00:26:06.320
has not considered
causation, that A causes B.

00:26:06.320 --> 00:26:08.190
Just in anything.

00:26:08.190 --> 00:26:13.190
That seems like a non-obvious thing

00:26:15.390 --> 00:26:18.300
that you think we would
have really acknowledged it,

00:26:18.300 --> 00:26:19.260
but we haven't.

00:26:19.260 --> 00:26:21.060
So we have to put that on the table.

00:26:21.920 --> 00:26:23.620
Knowledge,

00:26:23.620 --> 00:26:28.450
How hard is it to create a
knowledge from which to work?

00:26:28.450 --> 00:26:31.300
- In certain area, it's easy,

00:26:31.300 --> 00:26:36.300
because we have only four
or five major variables.

00:26:36.863 --> 00:26:41.583
An epidemiologist or an
economist can put them down.

00:26:42.544 --> 00:26:47.544
The minimum wage,
unemployment, policy xyz,

00:26:51.400 --> 00:26:54.320
and start collecting data,

00:26:54.320 --> 00:26:59.213
and quantify the parameters
that were left unquantified,

00:27:00.220 --> 00:27:01.543
with initial knowledge.

00:27:02.561 --> 00:27:07.561
That's the routine work that you find

00:27:07.630 --> 00:27:12.630
in experimental psychology,
in economics, everywhere.

00:27:12.960 --> 00:27:16.570
In health science, that's a routine thing.

00:27:16.570 --> 00:27:19.630
But I should emphasize, you should start

00:27:19.630 --> 00:27:21.020
with the research question.

00:27:21.020 --> 00:27:24.870
What do you want to estimate?

00:27:24.870 --> 00:27:27.470
Once you have that, you
have to have a language

00:27:27.470 --> 00:27:30.170
of expressing what you want to estimate.

00:27:30.170 --> 00:27:31.292
You think it's easy?

00:27:31.292 --> 00:27:32.750
No.

00:27:32.750 --> 00:27:34.900
- So we can talk about
two things, I think.

00:27:35.830 --> 00:27:40.830
One is how the science of
causation is very useful

00:27:44.016 --> 00:27:47.530
for answering certain questions,

00:27:47.530 --> 00:27:50.430
and then the other is how do
we create intelligent systems

00:27:51.280 --> 00:27:53.630
that need to reason with causation?

00:27:53.630 --> 00:27:56.210
So if my research question
is how do I pick up

00:27:56.210 --> 00:27:58.713
this water bottle from the table?

00:27:59.822 --> 00:28:04.822
All the knowledge that is
required to be able to do that,

00:28:04.967 --> 00:28:07.090
how do we construct that knowledge base?

00:28:07.090 --> 00:28:11.050
Do we return back to the problem

00:28:11.050 --> 00:28:13.610
that we didn't solve in the
80s with expert systems?

00:28:13.610 --> 00:28:15.460
Do we have to solve that problem,

00:28:15.460 --> 00:28:17.883
of automated construction of knowledge?

00:28:19.237 --> 00:28:24.237
You're talking about the
task of eliciting knowledge

00:28:24.800 --> 00:28:25.633
from an expert.

00:28:26.600 --> 00:28:28.624
- Task of eliciting
knowledge from an expert,

00:28:28.624 --> 00:28:31.090
or self discovery of more knowledge,

00:28:31.090 --> 00:28:33.562
more and more knowledge.

00:28:33.562 --> 00:28:37.090
So, automating the building of knowledge

00:28:37.090 --> 00:28:38.620
as much as possible.

00:28:38.620 --> 00:28:42.430
- It's a different game,
in the causal domain,

00:28:42.430 --> 00:28:46.500
because essentially it is the same thing.

00:28:46.500 --> 00:28:48.700
You have to start with some knowledge,

00:28:48.700 --> 00:28:51.540
and you're trying to enrich it.

00:28:51.540 --> 00:28:56.500
But you don't enrich it
by asking for more rules.

00:28:56.500 --> 00:28:58.990
You enrich it by asking for the data.

00:28:58.990 --> 00:29:01.810
To look at the data, and quantifying,

00:29:01.810 --> 00:29:05.563
and ask queries that you
couldn't answer when you started.

00:29:06.520 --> 00:29:11.520
You couldn't because the
question is quite complex,

00:29:11.970 --> 00:29:16.970
and it's not within the
capability of ordinary cognition,

00:29:18.810 --> 00:29:22.383
of ordinary person, ordinary
expert even, to answer.

00:29:23.270 --> 00:29:25.832
- So what kind of questions
do you think we can start

00:29:25.832 --> 00:29:27.030
to answer?

00:29:27.030 --> 00:29:29.830
- Even a simple, I suppose, yeah. (laughs)

00:29:29.830 --> 00:29:31.280
I start with easy one.

00:29:31.280 --> 00:29:32.113
- [Lex] Let's do it.

00:29:32.113 --> 00:29:35.963
- Okay, what's the effect
of a drug on recovery?

00:29:36.912 --> 00:29:41.673
Was it the aspirin that caused
my headache to be cured,

00:29:41.673 --> 00:29:44.690
or was it the television program,

00:29:44.690 --> 00:29:46.273
or the good news I received?

00:29:47.182 --> 00:29:49.960
This is already, see,
it's a difficult question

00:29:49.960 --> 00:29:52.713
because it's: find the cause from effect.

00:29:53.730 --> 00:29:56.241
The easy one is find effect from cause.

00:29:56.241 --> 00:29:57.780
- That's right.

00:29:57.780 --> 00:29:59.490
So first you construct a model saying

00:29:59.490 --> 00:30:01.300
that this an important research question.

00:30:01.300 --> 00:30:02.850
This is an important question.

00:30:02.850 --> 00:30:04.330
Then you--

00:30:04.330 --> 00:30:05.540
- I didn't construct a model yet.

00:30:05.540 --> 00:30:07.210
I just said it's important question.

00:30:07.210 --> 00:30:08.924
- Important question.

00:30:08.924 --> 00:30:12.320
- And the first exercise is,
express it mathematically.

00:30:12.320 --> 00:30:13.840
What do you want to prove?

00:30:13.840 --> 00:30:17.040
Like, if I tell you
what will be the effect

00:30:17.040 --> 00:30:18.780
of taking this drug?

00:30:18.780 --> 00:30:21.360
Okay, you have to say that in mathematics.

00:30:21.360 --> 00:30:22.532
How do you say that?

00:30:22.532 --> 00:30:23.590
- Yes.

00:30:23.590 --> 00:30:25.510
- [Judea] Can you write down the question.

00:30:25.510 --> 00:30:26.423
Not the answer.

00:30:27.740 --> 00:30:31.459
I want to find the effect
of a drug on my headache.

00:30:31.459 --> 00:30:32.702
- Right.

00:30:32.702 --> 00:30:34.160
- [Judea] Write it down, write it down.

00:30:34.160 --> 00:30:35.960
That's where the do-calculus
comes in. (laughs)

00:30:35.960 --> 00:30:37.081
- [Judea] Yes.

00:30:37.081 --> 00:30:38.290
The do-operator, the do-operator.

00:30:38.290 --> 00:30:40.120
- Do-operator, yeah.

00:30:40.120 --> 00:30:40.953
Which is nice.

00:30:40.953 --> 00:30:43.340
It's the difference between
association and intervention.

00:30:43.340 --> 00:30:45.800
Very beautifully sort of constructed.

00:30:45.800 --> 00:30:48.060
- Yeah, so we have a do-operator.

00:30:48.060 --> 00:30:50.530
So, the do-calculus connected--

00:30:50.530 --> 00:30:55.530
and the do-operator itself,
connects the operation of doing

00:30:55.610 --> 00:30:57.551
to something that we can see.

00:30:57.551 --> 00:30:58.710
- Right.

00:30:58.710 --> 00:31:01.770
So as opposed to the purely observing,

00:31:01.770 --> 00:31:05.940
you're making the choice
to change a variable--

00:31:05.940 --> 00:31:08.120
- That's what it expresses.

00:31:08.120 --> 00:31:11.492
And then, the way that we interpret it,

00:31:11.492 --> 00:31:15.460
the mechanism by which we take your query,

00:31:15.460 --> 00:31:18.680
and we translate it into
something that we can work with,

00:31:18.680 --> 00:31:21.090
is by giving it semantics,

00:31:21.090 --> 00:31:23.380
saying that you have a model of the world,

00:31:23.380 --> 00:31:26.880
and you cut off all the
incoming arrows into x,

00:31:26.880 --> 00:31:30.730
and you're looking now in the
modified, mutilated model,

00:31:30.730 --> 00:31:33.690
you ask for the probability of y.

00:31:33.690 --> 00:31:36.400
That is interpretation of doing x,

00:31:36.400 --> 00:31:40.270
because by doing things,
you've liberated them

00:31:40.270 --> 00:31:45.240
from all influences that
acted upon them earlier,

00:31:45.240 --> 00:31:49.272
and you subject them to the
tyranny of your muscles.

00:31:49.272 --> 00:31:53.210
- So you (chuckles) you
remove all the questions

00:31:53.210 --> 00:31:55.770
about causality by doing them.

00:31:55.770 --> 00:31:59.090
- So there is one level of questions.

00:31:59.090 --> 00:32:01.950
Answer questions about what
will happen if you do things.

00:32:01.950 --> 00:32:03.360
If you do, if you drink the coffee,

00:32:03.360 --> 00:32:05.520
or if you take the aspirin.

00:32:05.520 --> 00:32:06.726
- [Judea] Right.

00:32:06.726 --> 00:32:10.970
- So how do we get the
doing data? (laughs)

00:32:10.970 --> 00:32:15.678
- Hah. Now the question is,
if you cannot run experiments,

00:32:15.678 --> 00:32:20.678
right, then we have to rely
on observation and study.

00:32:21.010 --> 00:32:22.610
- So first we could, sorry to interrupt,

00:32:22.610 --> 00:32:24.450
we could run an experiment,

00:32:24.450 --> 00:32:26.970
where we do something,
where we drink the coffee,

00:32:26.970 --> 00:32:29.282
and the do-operator allows you

00:32:29.282 --> 00:32:31.830
to sort of be systematic
about expressing that.

00:32:31.830 --> 00:32:34.630
- To imagine how the
experiment will look like

00:32:34.630 --> 00:32:37.780
even though we cannot
physically and technologically

00:32:37.780 --> 00:32:38.810
conduct it.

00:32:38.810 --> 00:32:40.640
I'll give you an example.

00:32:40.640 --> 00:32:43.140
What is the effect of blood
pressure on mortality?

00:32:44.643 --> 00:32:47.400
I cannot go down into your vein

00:32:47.400 --> 00:32:49.440
and change your blood pressure.

00:32:49.440 --> 00:32:51.639
But I can ask the question,

00:32:51.639 --> 00:32:55.130
which means I can have
a model of your body.

00:32:55.130 --> 00:33:00.130
I can imagine how the
blood pressure change

00:33:02.470 --> 00:33:04.770
will affect your mortality.

00:33:04.770 --> 00:33:05.603
How?

00:33:05.603 --> 00:33:09.770
I go into the model, and
I conduct this surgery,

00:33:09.770 --> 00:33:12.120
about the blood pressure,

00:33:12.120 --> 00:33:15.510
even though physically I cannot do it.

00:33:15.510 --> 00:33:19.800
- Let me ask the quantum
mechanics question.

00:33:19.800 --> 00:33:22.579
Does the doing change the observation?

00:33:22.579 --> 00:33:27.407
Meaning, the surgery of
changing the blood pressure--

00:33:27.407 --> 00:33:31.750
- No, the surgery is very delicate.

00:33:34.855 --> 00:33:36.260
- [Lex] It's very delicate.

00:33:36.260 --> 00:33:37.870
Infinitely delicate. (laughs)

00:33:37.870 --> 00:33:39.373
- Incisive and delicate,

00:33:40.591 --> 00:33:45.591
which means, do-x means
I'm going to touch only x.

00:33:46.043 --> 00:33:47.283
- [Lex] Only x.

00:33:48.919 --> 00:33:50.230
- Directly into x.

00:33:50.230 --> 00:33:52.950
So, that means that I change only things

00:33:56.353 --> 00:34:00.017
which depend on x, by
virtue of x changing.

00:34:00.017 --> 00:34:00.850
But I don't depend things
which are not depend on x.

00:34:02.273 --> 00:34:04.020
Like, I wouldn't change
your sex, or your age.

00:34:04.020 --> 00:34:06.930
I just change your blood pressure, okay?

00:34:06.930 --> 00:34:10.010
- So, in the case of
blood pressure, it may be

00:34:10.010 --> 00:34:12.860
difficult or impossible to
construct such an experiment.

00:34:12.860 --> 00:34:14.980
- No, but physically, yes.

00:34:14.980 --> 00:34:16.570
But hypothetically no.

00:34:16.570 --> 00:34:17.590
- [Lex] Hypothetically no.

00:34:17.590 --> 00:34:20.770
- If we had a model, that
is what the model is for.

00:34:20.770 --> 00:34:24.670
So, you conduct surgeries on the models.

00:34:24.670 --> 00:34:26.910
You take it apart, put it back.

00:34:26.910 --> 00:34:28.920
That's the idea for model.

00:34:28.920 --> 00:34:31.650
It's the idea of thinking
counterfactually, imagining,

00:34:31.650 --> 00:34:35.170
and that idea of creativity.

00:34:35.170 --> 00:34:37.798
- So by constructing
that model you can start

00:34:37.798 --> 00:34:42.798
to infer if the blood
pressure leads to mortality,

00:34:44.318 --> 00:34:47.400
which increases or decreases, whi--

00:34:47.400 --> 00:34:48.590
- I construct a model.

00:34:48.590 --> 00:34:50.690
I still cannot answer it.

00:34:50.690 --> 00:34:53.850
I have to see if I have enough
information in the model

00:34:53.850 --> 00:34:58.360
that would allow me to find
out the effects of intervention

00:34:58.360 --> 00:35:03.360
from an uninterventional
study, from a hands-off study.

00:35:03.881 --> 00:35:06.156
- [Lex] So what's needed--

00:35:06.156 --> 00:35:11.156
- We need to have assumptions
about who affects whom.

00:35:12.935 --> 00:35:16.430
If the graph has a certain property,

00:35:16.430 --> 00:35:17.263
the answer is

00:35:17.263 --> 00:35:20.580
"yes, you can get it from
observational study."

00:35:20.580 --> 00:35:23.780
If the graph is too mushy bushy bushy,

00:35:23.780 --> 00:35:25.720
the answer is, "no, you cannot."

00:35:25.720 --> 00:35:29.490
Then you need to find
either different kind

00:35:29.490 --> 00:35:32.470
of observation that
you haven't considered,

00:35:32.470 --> 00:35:34.223
or one experiment.

00:35:35.130 --> 00:35:38.920
- So, basically, that puts
a lot of pressure on you

00:35:38.920 --> 00:35:41.890
to encode wisdom into that graph.

00:35:41.890 --> 00:35:43.180
- Correct.

00:35:43.180 --> 00:35:47.251
But you don't have to encode
more than what you know.

00:35:47.251 --> 00:35:48.170
God forbid.

00:35:48.170 --> 00:35:51.410
The economists are doing that.

00:35:51.410 --> 00:35:52.900
They call identifying assumptions.

00:35:52.900 --> 00:35:55.180
They put assumptions,
even they don't prevail

00:35:55.180 --> 00:35:56.583
in the world, they put assumptions

00:35:56.583 --> 00:35:59.242
so they can identify things.

00:35:59.242 --> 00:36:00.550
- Yes, beautifully put.

00:36:00.550 --> 00:36:04.243
But, the problem is you don't
know what you don't know.

00:36:04.243 --> 00:36:07.164
- You know what you don't know,

00:36:07.164 --> 00:36:10.390
because if you don't know,
you say it's possible

00:36:11.770 --> 00:36:16.386
that x affect the traffic tomorrow.

00:36:16.386 --> 00:36:18.720
It's possible.

00:36:18.720 --> 00:36:20.940
You put down an arrow
which says it's possible.

00:36:20.940 --> 00:36:23.970
Every arrow in the graph
says it's possible.

00:36:23.970 --> 00:36:27.174
- [Lex] So there's not a
significant cost to adding arrows,

00:36:27.174 --> 00:36:30.509
- The more arrow you add--

00:36:30.509 --> 00:36:31.789
- [Lex] The better.

00:36:31.789 --> 00:36:34.610
- The less likely you
are to identify things

00:36:34.610 --> 00:36:36.160
from purely observational data.

00:36:37.700 --> 00:36:39.583
So if the whole world is bushy,

00:36:40.519 --> 00:36:44.667
and everybody effect everybody else,

00:36:44.667 --> 00:36:48.843
the answer is-- you can
answer it ahead of time.

00:36:48.843 --> 00:36:53.843
I cannot answer my query
from observational data.

00:36:54.250 --> 00:36:55.673
I have to go to experiments.

00:36:56.670 --> 00:36:59.189
- So, you talk about machine
learning as essentially

00:36:59.189 --> 00:37:03.180
learning by association, or
reasoning by association,

00:37:03.180 --> 00:37:07.140
and this do-calculus is
allowing for intervention.

00:37:07.140 --> 00:37:08.286
I like that word.

00:37:08.286 --> 00:37:12.400
You also talk about counterfactuals.

00:37:12.400 --> 00:37:13.233
- Yeah.

00:37:13.233 --> 00:37:15.900
- And trying to sort of
understand the difference

00:37:15.900 --> 00:37:18.343
between counterfactuals and intervention,

00:37:19.680 --> 00:37:22.390
first of all, what is counterfactuals,

00:37:22.390 --> 00:37:25.716
and why are they useful?

00:37:25.716 --> 00:37:29.700
Why are they especially useful

00:37:29.700 --> 00:37:34.510
as opposed to just reasoning
what effect actions have?

00:37:34.510 --> 00:37:38.220
- Well, counterfactual
contains what we know

00:37:38.220 --> 00:37:40.260
will equal explanations.

00:37:40.260 --> 00:37:41.991
- Can you give an
example of what kind of--

00:37:41.991 --> 00:37:45.240
- If I tell you that acting
one way affects something else,

00:37:45.240 --> 00:37:47.279
I didn't explain anything yet.

00:37:47.279 --> 00:37:52.279
But if I ask you, was it the
aspirin that cure my headache,

00:37:54.610 --> 00:37:58.700
I'm asking for explanation:
what cure my headache?

00:37:58.700 --> 00:38:03.700
And putting a finger on
aspirin, provide explanation.

00:38:04.690 --> 00:38:08.200
It was the aspirin that was responsible

00:38:08.200 --> 00:38:11.233
for your headache going away.

00:38:11.233 --> 00:38:14.470
If you didn't take the aspirin,

00:38:14.470 --> 00:38:16.020
you will still have a headache.

00:38:16.020 --> 00:38:20.227
- So by saying, "If I didn't take aspirin,

00:38:20.227 --> 00:38:21.220
"I would have a headache,"

00:38:21.220 --> 00:38:24.047
you're thereby saying,
"The aspirin is the thing

00:38:24.047 --> 00:38:26.000
"that removed the headache."

00:38:26.000 --> 00:38:30.146
- Yes, but you have to have
another point of information.

00:38:30.146 --> 00:38:34.181
I took the aspirin, and
my headache is gone.

00:38:34.181 --> 00:38:36.430
It's very important information.

00:38:36.430 --> 00:38:38.897
Now we're reasoning backward, and I say,

00:38:38.897 --> 00:38:40.550
"Was it the aspirin?"

00:38:40.550 --> 00:38:41.438
- Yeah.

00:38:41.438 --> 00:38:44.134
By considering what would have happened

00:38:44.134 --> 00:38:47.073
if everything is the same,
but I didn't take aspirin.

00:38:47.073 --> 00:38:47.906
- That's right.

00:38:47.906 --> 00:38:50.748
So we know that things
took place, you know?

00:38:50.748 --> 00:38:52.293
Joe killed Schmo.

00:38:53.199 --> 00:38:58.199
And Schmo would be alive
had Joe not used his gun.

00:38:58.976 --> 00:39:02.090
Okay, so that is the counterfactual.

00:39:02.090 --> 00:39:04.347
It had a confliction.

00:39:04.347 --> 00:39:06.680
It had a conflict here, or clash

00:39:06.680 --> 00:39:11.653
between observed fact
-- he did shoot, okay --

00:39:13.620 --> 00:39:16.630
and the hypothetical predicate,

00:39:16.630 --> 00:39:18.840
which says, had he not shot.

00:39:18.840 --> 00:39:21.580
You have a clash, a logical clash,

00:39:21.580 --> 00:39:23.860
that cannot exist together.

00:39:23.860 --> 00:39:24.950
That's counterfactual,

00:39:24.950 --> 00:39:28.330
and that is the source of our explanation

00:39:28.330 --> 00:39:33.330
of the idea of responsibility,
regret, and free will.

00:39:33.762 --> 00:39:35.995
- Yes, it certainly seems,

00:39:35.995 --> 00:39:39.038
that's the highest level
of reasoning, right?

00:39:39.038 --> 00:39:39.871
Counterfactual.

00:39:39.871 --> 00:39:41.930
- [Judea] Yes, and physicists
do it all the time.

00:39:41.930 --> 00:39:42.800
- Who does it all the time?

00:39:42.800 --> 00:39:44.471
- [Judea] Physicists.

00:39:44.471 --> 00:39:45.746
- Physicists.

00:39:45.746 --> 00:39:47.780
- In every equation of physics,

00:39:47.780 --> 00:39:49.610
you have Hooke's law,

00:39:49.610 --> 00:39:52.270
and you put one kilogram on the spring,

00:39:52.270 --> 00:39:54.740
and the spring is one meter,

00:39:54.740 --> 00:39:58.337
and you say, "Had this
weight been two kilograms,

00:39:58.337 --> 00:40:00.487
"the spring would have
been twice as long."

00:40:01.416 --> 00:40:05.610
It's not a problem for
physicists to say that.

00:40:05.610 --> 00:40:10.264
Instead with mathematics, it
is in the form of an equation,

00:40:10.264 --> 00:40:15.264
equating the weight,
proportionality constant,

00:40:16.121 --> 00:40:18.439
and the length of the spring.

00:40:18.439 --> 00:40:23.320
We don't have the assymetry
in the equation of physics,

00:40:23.320 --> 00:40:26.860
although every physicist
thinks counterfactually.

00:40:26.860 --> 00:40:31.160
Ask high school kids, had the
weight been three kilograms,

00:40:31.160 --> 00:40:33.410
what would be the length of the spring?

00:40:33.410 --> 00:40:35.200
They can answer it immediately,

00:40:35.200 --> 00:40:38.940
because they do the counterfactual
processing in their mind,

00:40:38.940 --> 00:40:42.310
and then they put it into
equation, algebraic equation,

00:40:42.310 --> 00:40:43.809
and they solve it.

00:40:43.809 --> 00:40:45.760
But a robot cannot do that.

00:40:45.760 --> 00:40:50.760
- How do you make a robot
learn these relationships?

00:40:50.915 --> 00:40:53.260
- Why use the word "learn?"

00:40:53.260 --> 00:40:55.790
Suppose you tell him, can you do it?

00:40:55.790 --> 00:40:58.808
Before you go learning,
you have to ask yourself,

00:40:58.808 --> 00:40:59.641
suppose I give all the information.

00:40:59.641 --> 00:41:04.641
Can the robot perform a task
that I ask him to perform?

00:41:05.600 --> 00:41:09.557
Can he reason and say,
"No, it wasn't the aspirin.

00:41:09.557 --> 00:41:13.929
"It was the good news we
received on the phone."

00:41:13.929 --> 00:41:18.929
- Right, because, well,
unless the robot had a model,

00:41:19.130 --> 00:41:22.285
a causal model of the world.

00:41:22.285 --> 00:41:23.983
- [Judea] Right, right.

00:41:23.983 --> 00:41:26.037
- I'm sorry I have to linger on this--

00:41:26.037 --> 00:41:27.965
- [Judea] But now we have to
linger, and we have to say,

00:41:27.965 --> 00:41:29.120
"How do we do it?"

00:41:29.120 --> 00:41:29.953
- How do we build it?

00:41:29.953 --> 00:41:31.376
- [Judea] Yes.

00:41:31.376 --> 00:41:32.510
- How do we build a causal model

00:41:34.123 --> 00:41:36.710
without a team of human
experts running around--

00:41:36.710 --> 00:41:39.192
- No, why did you go
to learning right away?

00:41:39.192 --> 00:41:41.671
You are too much involved with learning.

00:41:41.671 --> 00:41:42.504
- Because I like babies.

00:41:42.504 --> 00:41:43.877
Babies learn fast, and
I'm trying to figure out

00:41:43.877 --> 00:41:45.180
how they do it.

00:41:45.180 --> 00:41:46.212
- Good.

00:41:46.212 --> 00:41:47.700
That's another question:

00:41:47.700 --> 00:41:49.150
How do the babies come out

00:41:49.150 --> 00:41:51.820
with the counterfactual
model of the world?

00:41:51.820 --> 00:41:53.670
And babies do that.

00:41:53.670 --> 00:41:56.574
They know how to play in the crib.

00:41:56.574 --> 00:41:59.134
They know which balls hits another one,

00:41:59.134 --> 00:42:04.134
and they learn it by playful manipulation

00:42:04.598 --> 00:42:06.905
of the world.

00:42:06.905 --> 00:42:10.610
Their simple world involves
all these toys and balls

00:42:10.610 --> 00:42:12.580
and chimes (laughs)

00:42:12.580 --> 00:42:17.280
but if you think about
it, it's a complex world.

00:42:17.280 --> 00:42:19.919
- We take for granted how complicated--

00:42:19.919 --> 00:42:23.770
- And the kids do it by
playful manipulation,

00:42:23.770 --> 00:42:28.770
plus parent guidance,
peer wisdom, and heresay.

00:42:30.459 --> 00:42:34.943
They meet each other, and they say,

00:42:34.943 --> 00:42:38.950
"You shouldn't have
taken my toy." (laughs)

00:42:38.950 --> 00:42:39.783
- Right,

00:42:40.850 --> 00:42:43.590
and these multiple sources of information,

00:42:43.590 --> 00:42:45.227
they're able to integrate.

00:42:45.227 --> 00:42:49.010
So, the challenge is
about how to integrate,

00:42:49.010 --> 00:42:52.670
how to form these causal relationships

00:42:52.670 --> 00:42:54.120
from different sources of data.

00:42:54.120 --> 00:42:55.020
- [Judea] Correct.

00:42:56.633 --> 00:43:01.633
- So, how much causal
information is required

00:43:02.494 --> 00:43:06.820
to be able to play in the
crib with different objects?

00:43:06.820 --> 00:43:08.320
- I don't know.

00:43:08.320 --> 00:43:11.390
I haven't experimented
with the crib. (chuckles)

00:43:11.390 --> 00:43:12.620
- [Lex] Okay, not a crib--

00:43:12.620 --> 00:43:14.180
- I know, it's a very interesting--

00:43:14.180 --> 00:43:16.950
- Manipulating physical
objects on this very,

00:43:16.950 --> 00:43:20.641
opening the pages of
a book, all the tasks,

00:43:20.641 --> 00:43:24.772
physical manipulation
tasks, do you have a sense?

00:43:24.772 --> 00:43:28.070
Because my sense is the world
is extremely complicated.

00:43:28.070 --> 00:43:29.470
- Extremely complicated.

00:43:29.470 --> 00:43:31.300
I agree and I don't
know how to organize it,

00:43:31.300 --> 00:43:34.690
because I've been spoiled by easy problems

00:43:34.690 --> 00:43:38.490
such as cancer and death, okay? (laughs)

00:43:38.490 --> 00:43:41.670
- [Lex] First we have to start trying to--

00:43:41.670 --> 00:43:43.660
- No, but it's easy, easy in the sense

00:43:43.660 --> 00:43:47.030
that you have only 20 variables,

00:43:47.030 --> 00:43:49.193
and they are just variables.

00:43:49.193 --> 00:43:51.530
They are not mechanics, okay?

00:43:51.530 --> 00:43:52.363
It's easy.

00:43:52.363 --> 00:43:53.640
You just put them on the graph

00:43:53.640 --> 00:43:57.503
and they speak to you. (laughs)

00:43:57.503 --> 00:44:00.612
- [Lex] And you're providing a methodology

00:44:00.612 --> 00:44:01.895
for letting them speak.

00:44:01.895 --> 00:44:04.865
- I'm working only in the abstract.

00:44:04.865 --> 00:44:08.279
The abstract is knowledge
in, knowledge out,

00:44:08.279 --> 00:44:10.974
data in between.

00:44:10.974 --> 00:44:15.110
- Now, can we take a
leap to trying to learn,

00:44:15.110 --> 00:44:20.110
when it's not 20 variables
but 20 million variables,

00:44:20.159 --> 00:44:23.657
trying to learn causation in this world.

00:44:23.657 --> 00:44:26.297
Not learn, but somehow construct models.

00:44:26.297 --> 00:44:28.247
I mean, it seems like you would only have

00:44:28.247 --> 00:44:30.064
to be able to learn,

00:44:30.064 --> 00:44:34.957
because constructing it
manually would be too difficult.

00:44:34.957 --> 00:44:36.887
Do you have ideas of--

00:44:36.887 --> 00:44:41.240
- I think it's a matter
of combining simple models

00:44:41.240 --> 00:44:44.582
from many, many sources,
from many, many disciplines.

00:44:44.582 --> 00:44:47.444
And many metaphors.

00:44:47.444 --> 00:44:51.018
Metaphors are the basis
of human intelligence.

00:44:51.018 --> 00:44:54.080
- Yeah, so how do you
think about a metaphor

00:44:54.080 --> 00:44:56.190
in terms of its use in human intelligence?

00:44:56.190 --> 00:45:00.373
- Metaphors is an expert system.

00:45:02.084 --> 00:45:07.084
It's mapping problem with
which you are not familiar,

00:45:09.620 --> 00:45:13.840
to a problem with which you are familiar.

00:45:13.840 --> 00:45:16.010
Like I give you a great example.

00:45:16.010 --> 00:45:21.010
The Greek believed that
the sky is an opaque sheer.

00:45:22.280 --> 00:45:27.230
It's not really infinite
space; it's an opaque sheer,

00:45:27.230 --> 00:45:32.100
and the stars are holes
poked in the sheer,

00:45:32.100 --> 00:45:34.650
through which you see the eternal light.

00:45:34.650 --> 00:45:37.000
It was a metaphor, why?

00:45:37.000 --> 00:45:41.408
Because they understand how
you poke holes in sheers.

00:45:41.408 --> 00:45:45.204
They were not familiar
with infinite space.

00:45:45.204 --> 00:45:50.204
And we are walking on a shell of a turtle,

00:45:51.794 --> 00:45:54.570
and if you get too close to the edge,

00:45:54.570 --> 00:45:57.374
you're going to fall down
to Hades, or wherever, yeah.

00:45:57.374 --> 00:46:00.081
That's a metaphor.

00:46:00.081 --> 00:46:01.619
It's not true.

00:46:01.619 --> 00:46:06.619
But these kind of metaphor
enabled Eratosthenes

00:46:07.102 --> 00:46:10.119
to measure the radius of the Earth,

00:46:10.119 --> 00:46:12.547
because he said, "Come on.

00:46:12.547 --> 00:46:14.738
"If we are walking on a turtle shell,

00:46:14.738 --> 00:46:19.393
"then the ray of light
coming to this place

00:46:19.393 --> 00:46:22.987
"will be different angle
than coming to this place.

00:46:22.987 --> 00:46:23.987
"I know the distance.

00:46:23.987 --> 00:46:26.357
"I'll measure the two angles,

00:46:26.357 --> 00:46:31.357
"and then I have the radius
of the shell of the turtle."

00:46:32.421 --> 00:46:34.896
And he did.

00:46:34.896 --> 00:46:39.540
And his measurement was very close

00:46:39.540 --> 00:46:42.343
to the measurements we have today.

00:46:43.270 --> 00:46:48.270
It was, what, 6,700
kilometers, was the Earth?

00:46:51.292 --> 00:46:54.936
That's something that would not occur

00:46:54.936 --> 00:46:59.810
to a Babylonian astronomer,

00:46:59.810 --> 00:47:01.923
even though the Babylonian experiments

00:47:01.923 --> 00:47:04.650
were the machine learning
people of the time.

00:47:04.650 --> 00:47:08.003
They fit curves, and they
could predict the eclipse

00:47:08.003 --> 00:47:13.003
of the moon much more
accurately than the Greek,

00:47:13.159 --> 00:47:15.246
because they fit curves.

00:47:15.246 --> 00:47:19.270
That's a different metaphor,

00:47:19.270 --> 00:47:20.610
something that you're familiar with,

00:47:20.610 --> 00:47:21.833
a game, a turtle shell.

00:47:23.166 --> 00:47:27.550
What does it mean, if you are familiar?

00:47:27.550 --> 00:47:31.280
Familiar means that answers
to certain questions

00:47:31.280 --> 00:47:33.500
are explicit.

00:47:33.500 --> 00:47:35.610
You don't have to derive them.

00:47:35.610 --> 00:47:37.580
- And they were made explicit

00:47:37.580 --> 00:47:40.450
because somewhere in the
past you've constructed

00:47:40.450 --> 00:47:42.251
a model of that--

00:47:42.251 --> 00:47:46.210
- You're familiar with,
so the child is familiar

00:47:46.210 --> 00:47:47.913
with billiard balls.

00:47:47.913 --> 00:47:49.910
So the child could predict that

00:47:49.910 --> 00:47:52.292
if you let loose of one ball,

00:47:52.292 --> 00:47:54.223
the other one will bounce off.

00:47:55.100 --> 00:48:00.100
You attain that by familiarity.

00:48:00.210 --> 00:48:02.940
Familiarity is answering questions,

00:48:02.940 --> 00:48:05.579
and you store the answer explicitly.

00:48:05.579 --> 00:48:08.050
You don't have to derive it.

00:48:08.050 --> 00:48:09.680
So this is idea for metaphor.

00:48:09.680 --> 00:48:11.670
All our life, all our intelligence,

00:48:11.670 --> 00:48:13.460
is built around metaphors,

00:48:13.460 --> 00:48:16.280
mapping from the
unfamiliar to the familiar,

00:48:16.280 --> 00:48:20.618
but the marriage between
the two is a tough thing,

00:48:20.618 --> 00:48:24.790
which we haven't yet been
able to algorithmatize.

00:48:24.790 --> 00:48:29.330
- So, you think of that
process of using metaphor

00:48:29.330 --> 00:48:31.739
to leap from one place to another.

00:48:31.739 --> 00:48:33.899
We can call it reasoning.

00:48:33.899 --> 00:48:35.900
Is it a kind of reasoning?

00:48:35.900 --> 00:48:37.746
- [Judea] It is a reasoning
by metaphor, but--

00:48:37.746 --> 00:48:39.510
- Reasoning by metaphor.

00:48:39.510 --> 00:48:42.792
Do you think of that as learning?

00:48:42.792 --> 00:48:46.144
So, learning is a
popular terminology today

00:48:46.144 --> 00:48:47.720
in a narrow sense.

00:48:47.720 --> 00:48:49.710
- [Judea] It is, it is definitely.

00:48:49.710 --> 00:48:51.734
- So you may not-- you're right.

00:48:51.734 --> 00:48:53.840
- It's one of the most important learning,

00:48:53.840 --> 00:48:57.680
taking something which
theoretically is derivable,

00:48:57.680 --> 00:49:01.750
and store it in accessible format.

00:49:01.750 --> 00:49:05.633
I'll give you an example: chess, okay?

00:49:06.667 --> 00:49:11.667
Finding the winning starting
move in chess is hard.

00:49:16.393 --> 00:49:20.673
But there is an answer.

00:49:20.673 --> 00:49:24.530
Either there is a winning move
for white, or there isn't,

00:49:24.530 --> 00:49:25.713
or it is a draw.

00:49:26.860 --> 00:49:31.130
So, the answer to that is available

00:49:31.130 --> 00:49:32.580
through the rule of the game.

00:49:33.574 --> 00:49:35.500
But we don't know the answer.

00:49:35.500 --> 00:49:38.400
So what does a chess master
have that we don't have?

00:49:38.400 --> 00:49:41.820
He has stored explicitly an evaluation

00:49:41.820 --> 00:49:45.067
of certain complex pattern of the board.

00:49:45.067 --> 00:49:49.060
We don't have it,
ordinary people, like me.

00:49:49.060 --> 00:49:51.000
I don't know about you.

00:49:51.000 --> 00:49:52.850
I'm not a chess master.

00:49:52.850 --> 00:49:57.625
So for me I have to derive
things that for him is explicit.

00:49:57.625 --> 00:50:02.042
He has seen it before, or he
has seen the pattern before,

00:50:02.042 --> 00:50:04.583
or similar patterns before,

00:50:04.583 --> 00:50:08.607
and he generalizes, and says,

00:50:08.607 --> 00:50:11.187
"Don't move; it's a dangerous move."

00:50:12.761 --> 00:50:15.560
- It's just that, not
in the game of chess,

00:50:15.560 --> 00:50:18.622
but in the game of billiard balls

00:50:18.622 --> 00:50:22.460
we humans are able to initially
derive very effectively

00:50:22.460 --> 00:50:25.130
and then reason by
metaphor very effectively,

00:50:25.130 --> 00:50:27.200
and we make it look so easy,

00:50:27.200 --> 00:50:28.750
and it makes one wonder

00:50:28.750 --> 00:50:31.283
how hard is it to build it in a machine?

00:50:32.878 --> 00:50:37.878
In your sense, (laughs)
how far away are we

00:50:37.929 --> 00:50:39.720
to be able to construct--

00:50:39.720 --> 00:50:40.970
- I don't know.

00:50:40.970 --> 00:50:43.327
I'm not a futurist.

00:50:43.327 --> 00:50:48.327
All I can tell you is that we
are making tremendous progress

00:50:48.450 --> 00:50:52.170
in the causal reasoning domain.

00:50:52.170 --> 00:50:57.170
Something that I even dare
to call it a revolution,

00:50:59.020 --> 00:51:00.690
the causal revolution,

00:51:00.690 --> 00:51:05.690
because what we have achieved
in the past three decades

00:51:07.290 --> 00:51:12.290
is something that dwarf
everything that was derived

00:51:12.970 --> 00:51:15.450
in the entire history.

00:51:15.450 --> 00:51:16.840
- So there's an excitement

00:51:16.840 --> 00:51:20.254
about current machine
learning methodologies,

00:51:20.254 --> 00:51:23.980
and there's really important
good work you're doing

00:51:23.980 --> 00:51:26.433
in causal inference.

00:51:27.433 --> 00:51:32.433
Where do these worlds collide,
and what does that look like?

00:51:34.118 --> 00:51:38.750
- First they gotta work
without collisions. (laughs)

00:51:38.750 --> 00:51:40.917
It's got to work in harmony.

00:51:40.917 --> 00:51:41.800
- [Lex] Harmony.

00:51:41.800 --> 00:51:46.800
- The human is going to
jumpstart the exercise

00:51:48.580 --> 00:51:53.373
by providing qualitative,
noncommitting models

00:51:55.100 --> 00:51:57.477
of how the universe works,

00:51:57.477 --> 00:52:02.477
how reality, the domain
of discourse, works.

00:52:03.147 --> 00:52:06.070
The machine is going to
take over from that point

00:52:06.070 --> 00:52:09.002
of view, and derive whatever the calculus

00:52:09.002 --> 00:52:11.285
says can be derived,

00:52:11.285 --> 00:52:15.415
namely, quantitative
answer to our questions.

00:52:15.415 --> 00:52:18.470
These are complex questions.

00:52:18.470 --> 00:52:21.250
I'll give you some examples
of complex questions,

00:52:21.250 --> 00:52:26.250
that boggle your mind
if you think about it.

00:52:27.175 --> 00:52:32.175
You take the results of
studies in diverse population,

00:52:33.288 --> 00:52:35.830
under diverse conditions,

00:52:35.830 --> 00:52:40.760
and you infer the cause
effect of a new population

00:52:40.760 --> 00:52:45.200
which doesn't even resemble
any of the ones studied.

00:52:45.200 --> 00:52:48.320
You do that by do-calculus.

00:52:48.320 --> 00:52:52.670
You do that by generalizing
from one study to another.

00:52:52.670 --> 00:52:54.700
See, what's common there too?

00:52:54.700 --> 00:52:57.040
What is different?

00:52:57.040 --> 00:53:01.220
Let's ignore the differences
and pull out the commonality.

00:53:01.220 --> 00:53:06.190
And you do it over maybe 100
hospitals around the world.

00:53:06.190 --> 00:53:11.190
From that, you can get
really mileage from big data.

00:53:12.159 --> 00:53:15.080
It's not only that you have many samples;

00:53:15.080 --> 00:53:17.853
you have many sources of data.

00:53:18.750 --> 00:53:21.500
- So that's a really
powerful thing, I think,

00:53:21.500 --> 00:53:23.737
especially for medical applications.

00:53:23.737 --> 00:53:25.860
Cure cancer, right?

00:53:25.860 --> 00:53:28.580
That's how, from data,
you can cure cancer.

00:53:28.580 --> 00:53:30.110
So we're talking about causation,

00:53:30.110 --> 00:53:34.589
which is the temporal
relationships between things.

00:53:34.589 --> 00:53:36.326
- Not only temporal.

00:53:36.326 --> 00:53:38.903
It was structural and temporal.

00:53:38.903 --> 00:53:43.903
Temporal precedence by itself
cannot replace causation.

00:53:45.593 --> 00:53:50.363
- Is temporal precedence the
arrow of time in physics?

00:53:50.363 --> 00:53:52.679
- [Judea] Yeah, it's important, necessary.

00:53:52.679 --> 00:53:53.512
- It's important.

00:53:53.512 --> 00:53:54.345
- [Judea] Yes.

00:53:54.345 --> 00:53:55.790
- Is it?

00:53:55.790 --> 00:53:59.945
- Yes, I've never seen a
cause propagate backwards.

00:53:59.945 --> 00:54:03.498
- But if we use the word cause,

00:54:03.498 --> 00:54:07.120
but there's relationships
that are timeless.

00:54:07.120 --> 00:54:10.420
I suppose that's still
forward an arrow of time.

00:54:10.420 --> 00:54:14.288
But, are there relationships,
logical relationships,

00:54:14.288 --> 00:54:17.012
that fit into the structure?

00:54:17.012 --> 00:54:22.012
- [Judea] Sure. All do-calculus
is logical relationships.

00:54:22.020 --> 00:54:23.850
- That doesn't require a temporal.

00:54:23.850 --> 00:54:25.210
It has just the condition

00:54:25.210 --> 00:54:28.610
that you're not traveling back in time.

00:54:28.610 --> 00:54:31.230
- [Judea] Yes, correct.

00:54:31.230 --> 00:54:33.920
- So it's really a generalization,

00:54:33.920 --> 00:54:37.494
a powerful generalization, of what--

00:54:37.494 --> 00:54:40.038
- [Judea] Of boolean logic.

00:54:40.038 --> 00:54:41.760
- Yeah, boolean logic.

00:54:41.760 --> 00:54:42.593
- [Judea] Yes.

00:54:43.510 --> 00:54:47.320
- That is sort of simply
put, and allows us

00:54:47.320 --> 00:54:52.320
to reason about the order
of events, the source--

00:54:54.477 --> 00:54:55.670
- Not about, between.

00:54:55.670 --> 00:54:58.080
But not deriving the order of events.

00:54:58.080 --> 00:55:01.400
We are given cause effect relationships.

00:55:01.400 --> 00:55:06.400
They ought to be obeying the
time precedence relationship.

00:55:08.950 --> 00:55:10.000
We are given that,

00:55:10.000 --> 00:55:11.720
and now that we ask questions

00:55:11.720 --> 00:55:14.320
about other causal relationships,

00:55:14.320 --> 00:55:17.890
that could be derived
from the initial ones,

00:55:17.890 --> 00:55:20.574
but were not given to us explicitly.

00:55:20.574 --> 00:55:25.574
Like the case of the
firing squad I gave you

00:55:25.843 --> 00:55:28.947
in the first chapter and I ask,

00:55:28.947 --> 00:55:33.330
"What if rifleman A declined to shoot?

00:55:33.330 --> 00:55:36.665
Would the prisoner still be dead?

00:55:36.665 --> 00:55:41.550
To decline to shoot, it means
that he disobeyed orders.

00:55:42.536 --> 00:55:47.536
The rule of the games were that
he is an obedient marksman.

00:55:50.684 --> 00:55:52.317
That's how you start.

00:55:52.317 --> 00:55:53.570
That's the initial order,

00:55:53.570 --> 00:55:56.570
but now you ask question
about breaking the rules.

00:55:56.570 --> 00:56:00.028
What if he decided not
to pull the trigger,

00:56:00.028 --> 00:56:02.188
because became a pacifist?

00:56:02.188 --> 00:56:06.050
You and I can answer that.

00:56:06.050 --> 00:56:09.270
The other rifleman would have
hit and killed him, okay?

00:56:09.270 --> 00:56:10.670
I want a machine to do that.

00:56:12.054 --> 00:56:14.154
Is it so hard to ask a machine to do that?

00:56:15.004 --> 00:56:16.883
It's such a simple task.

00:56:17.750 --> 00:56:19.654
But they have to have a calculus for that.

00:56:19.654 --> 00:56:21.210
- Yes, yeah.

00:56:21.210 --> 00:56:24.380
But the curiosity, the
natural curiosity for me, is

00:56:24.380 --> 00:56:28.010
that yes, you're absolutely
correct and important,

00:56:28.010 --> 00:56:31.130
and it's hard to believe
that we haven't done this

00:56:31.130 --> 00:56:35.420
seriously, extensively,
already a long time ago.

00:56:35.420 --> 00:56:37.040
So, this is really important work,

00:56:37.040 --> 00:56:38.653
but I also want to know,

00:56:39.717 --> 00:56:43.140
maybe you can philosophize
about how hard is it to learn.

00:56:43.140 --> 00:56:44.460
- Look, let's assume learning.

00:56:44.460 --> 00:56:45.685
We want learning, okay?

00:56:45.685 --> 00:56:46.690
- We want to learn.

00:56:46.690 --> 00:56:47.523
- So what do we do?

00:56:47.523 --> 00:56:52.320
We put a learning machine
that watches execution trials

00:56:52.320 --> 00:56:57.260
in many countries, in many
(laughs) locations, okay?

00:56:57.260 --> 00:57:01.080
All the machine can learn
is to see shot or not shot.

00:57:01.080 --> 00:57:02.930
Dead, not dead.

00:57:02.930 --> 00:57:06.533
A court issued an order or
didn't, okay, just the fact.

00:57:07.380 --> 00:57:10.170
For the fact, you don't
know who listens to whom.

00:57:10.170 --> 00:57:13.770
You don't know that the condemned person

00:57:13.770 --> 00:57:15.320
listens to the bullets,

00:57:15.320 --> 00:57:19.546
that the bullets are listening
to the captain, okay?

00:57:19.546 --> 00:57:24.340
All we hear is one command,
two shots, dead, okay?

00:57:24.340 --> 00:57:29.340
A triple of variables:
yes, no, yes, no, okay.

00:57:29.519 --> 00:57:31.750
From that you can learn
who listens to whom?

00:57:31.750 --> 00:57:34.010
And you can answer the question? No.

00:57:34.010 --> 00:57:35.260
- Definitively, no.

00:57:35.260 --> 00:57:39.150
But don't you think you
can start proposing ideas

00:57:39.150 --> 00:57:41.201
for humans to review?

00:57:41.201 --> 00:57:44.096
You want machine to learn it,
all right, you want a robot.

00:57:44.096 --> 00:57:49.096
So robot is watching trials
like that, 200 trials,

00:57:50.191 --> 00:57:52.610
and then he has to answer the question,

00:57:52.610 --> 00:57:56.930
what if rifleman A
refrained from shooting.

00:57:56.930 --> 00:57:59.697
- [Lex] Yeah. So how do we do that?

00:57:59.697 --> 00:58:03.660
- (laughs) That's exactly my point.

00:58:03.660 --> 00:58:06.150
If looking at the facts
don't give you the strings

00:58:06.150 --> 00:58:08.010
behind the facts--
- Absolutely,

00:58:08.010 --> 00:58:11.890
but so you think of machine learning,

00:58:11.890 --> 00:58:13.307
as it's currently defined,

00:58:13.307 --> 00:58:17.630
as only something that looks
at the facts and tries to--

00:58:17.630 --> 00:58:19.676
- [Judea] Right now they
only look at the facts.

00:58:19.676 --> 00:58:22.724
- Yeah, so is there a way
to modify, in your sense--

00:58:22.724 --> 00:58:25.170
- [Judea] Yeah, playful manipulation

00:58:25.170 --> 00:58:26.428
- Playful manipulation.

00:58:26.428 --> 00:58:29.020
Doing the interventionist kind of things.

00:58:29.020 --> 00:58:31.170
- But it could be at random.

00:58:31.170 --> 00:58:34.560
For instance, the
rifleman is sick that day,

00:58:34.560 --> 00:58:37.290
or he just vomits, or whatever.

00:58:37.290 --> 00:58:40.921
So, we can observe this unexpected event,

00:58:40.921 --> 00:58:43.630
which introduced noise.

00:58:43.630 --> 00:58:46.990
The noise still have
to be random to be able

00:58:46.990 --> 00:58:51.700
to relate it to randomized experiments,

00:58:51.700 --> 00:58:55.520
and then you have observational studies,

00:58:55.520 --> 00:58:59.648
from which to infer the
strings behind the facts.

00:58:59.648 --> 00:59:02.391
It's doable to a certain extent.

00:59:02.391 --> 00:59:06.310
But now that we're
expert in what you can do

00:59:06.310 --> 00:59:07.700
once you have a model,

00:59:07.700 --> 00:59:10.695
we can reason back and say
what kind of data you need

00:59:10.695 --> 00:59:12.641
to build a model.

00:59:12.641 --> 00:59:13.620
- Got it.

00:59:13.620 --> 00:59:16.880
So, I know you're not a futurist,

00:59:16.880 --> 00:59:19.244
but are you excited?

00:59:19.244 --> 00:59:21.909
Have you, when you look back at your life,

00:59:21.909 --> 00:59:25.850
longed for the idea of creating
a human level intelligence--

00:59:25.850 --> 00:59:28.021
- Well, yeah, I'm driven by that.

00:59:28.021 --> 00:59:32.718
All my life I'm driven
just by one thing. (laughs)

00:59:32.718 --> 00:59:34.950
But I go slowly.

00:59:34.950 --> 00:59:39.084
I go from what I know, to
the next step incrementally.

00:59:39.084 --> 00:59:41.667
- So, without imagining what
the end goal looks like,

00:59:41.667 --> 00:59:44.000
do you imagine--

00:59:44.000 --> 00:59:47.434
- The end goal is going to be a machine

00:59:47.434 --> 00:59:50.887
that can answer sophisticated questions:

00:59:50.887 --> 00:59:55.237
counterfactuals, regret,
compassion, responsibility,

00:59:56.334 --> 00:59:57.923
and free will.

00:59:59.420 --> 01:00:01.640
- So what is a good test?

01:00:01.640 --> 01:00:04.090
Is a Turing test a reasonable test?

01:00:04.090 --> 01:00:06.763
- A Turing test of free
will doesn't exist yet.

01:00:07.623 --> 01:00:08.456
There's not--

01:00:08.456 --> 01:00:11.180
- [Lex] How would you
test free will? That's a--

01:00:11.180 --> 01:00:13.797
- So far we know only one
thing, merely (laughs)

01:00:13.797 --> 01:00:17.680
if robots can communicate,

01:00:17.680 --> 01:00:21.183
with reward and punishment
among themselves,

01:00:22.023 --> 01:00:25.470
and hitting each other on the wrists,

01:00:25.470 --> 01:00:27.420
and say "You shouldn't have done that."

01:00:28.316 --> 01:00:32.525
Playing better soccer
because they can do that.

01:00:32.525 --> 01:00:35.970
- [Lex] What do you mean,
because they can do that?

01:00:35.970 --> 01:00:37.824
- Because they can
communicate among themselves.

01:00:37.824 --> 01:00:39.450
- [Lex] Because of the communication,

01:00:39.450 --> 01:00:41.266
they can do the soccer.

01:00:41.266 --> 01:00:44.000
- Because they communicate like
us, rewards and punishment,

01:00:44.000 --> 01:00:46.710
yes, you didn't pass
the ball the right time,

01:00:46.710 --> 01:00:48.370
and so forth;

01:00:48.370 --> 01:00:51.570
therefore you're going to sit
on the bench for the next two,

01:00:51.570 --> 01:00:53.680
if they start communicating like that,

01:00:53.680 --> 01:00:56.420
the question is, will
they play better soccer?

01:00:56.420 --> 01:00:57.916
As opposed to what?

01:00:57.916 --> 01:00:59.710
As opposed to what they do now?

01:00:59.710 --> 01:01:04.710
Without this ability to reason
about reward and punishment.

01:01:05.050 --> 01:01:06.470
Responsibility.

01:01:06.470 --> 01:01:09.007
- And counterfactuals.

01:01:09.007 --> 01:01:11.740
- So far, I can only
think about communication.

01:01:11.740 --> 01:01:15.430
- Communication, and not
necessarily in natural language,

01:01:15.430 --> 01:01:16.750
but just communication.

01:01:16.750 --> 01:01:17.640
- Just communication,

01:01:17.640 --> 01:01:22.040
and that's important to have
a quick and effective means

01:01:22.040 --> 01:01:24.130
of communicating knowledge.

01:01:24.130 --> 01:01:26.530
If the coach tells you you
should have passed the ball,

01:01:26.530 --> 01:01:28.810
ping, he conveys so much knowledge to you

01:01:28.810 --> 01:01:30.550
as opposed to what?

01:01:30.550 --> 01:01:33.500
Go down and change your software, right.

01:01:33.500 --> 01:01:35.370
That's the alternative.

01:01:35.370 --> 01:01:37.770
But the coach doesn't know your software.

01:01:37.770 --> 01:01:39.660
So how can a coach tell you

01:01:39.660 --> 01:01:41.600
you should have passed the ball?

01:01:41.600 --> 01:01:44.330
But, our language is very effective:

01:01:44.330 --> 01:01:45.650
you should have passed the ball.

01:01:45.650 --> 01:01:47.090
You know your software.

01:01:47.090 --> 01:01:49.607
You tweak the right module, okay,

01:01:49.607 --> 01:01:51.707
and next time you don't do it.

01:01:51.707 --> 01:01:53.610
- Now that's for playing soccer,

01:01:53.610 --> 01:01:55.499
where the rules are well defined.

01:01:55.499 --> 01:01:56.937
- No, no, no, they're not well defined.

01:01:56.937 --> 01:01:58.870
When you should pass the ball--

01:01:58.870 --> 01:02:01.102
- Is not well defined.

01:02:01.102 --> 01:02:02.202
- No, it's very noisy.

01:02:03.650 --> 01:02:06.427
Yes, you have to do it
under pressure (laughs)

01:02:06.427 --> 01:02:07.890
- It's art.

01:02:07.890 --> 01:02:11.080
But in terms of aligning values

01:02:11.080 --> 01:02:14.831
between computers and humans,

01:02:14.831 --> 01:02:19.831
do you think this cause
and effect type of thinking

01:02:20.270 --> 01:02:24.670
is important to align the
values, morals, ethics

01:02:24.670 --> 01:02:26.460
under which machines make decisions.

01:02:26.460 --> 01:02:31.246
Is the cause effect where
the two can come together?

01:02:31.246 --> 01:02:34.320
- Cause effect is necessary component

01:02:34.320 --> 01:02:37.470
to build an ethical machine,

01:02:37.470 --> 01:02:40.510
because the machine has to empathize,

01:02:40.510 --> 01:02:42.690
to understand what's good for you,

01:02:42.690 --> 01:02:46.694
to build a model of you, as a recipient.

01:02:46.694 --> 01:02:48.980
We should be very much--

01:02:48.980 --> 01:02:50.940
What is compassion?

01:02:50.940 --> 01:02:55.940
The imagine that you
suffer pain as much as me.

01:02:56.030 --> 01:02:57.060
- [Lex] As much as me.

01:02:57.060 --> 01:03:00.320
- I do have already a
model of myself, right?

01:03:00.320 --> 01:03:02.830
So it's very easy for
me to map you to mine.

01:03:02.830 --> 01:03:04.660
I don't have to rebuild a model.

01:03:04.660 --> 01:03:06.950
It's much easier to say,
"Ah, you're like me."

01:03:06.950 --> 01:03:09.886
Okay, therefore, I will
not hit you, okay? (laughs)

01:03:09.886 --> 01:03:12.100
- And the machine has to imagine,

01:03:12.100 --> 01:03:14.030
has to try to fake to be human.

01:03:14.030 --> 01:03:17.870
Essentially so you can imagine
that you're like me, right?

01:03:17.870 --> 01:03:20.840
- Whoa, whoa, whoa, who is me?

01:03:20.840 --> 01:03:24.230
That's further; that's consciousness.

01:03:24.230 --> 01:03:26.417
They have a model of yourself.

01:03:26.417 --> 01:03:28.160
Where do you get this model?

01:03:28.160 --> 01:03:32.410
You look at yourself as if you
are part of the environment.

01:03:32.410 --> 01:03:35.470
If you build a model of
yourself versus the environment,

01:03:35.470 --> 01:03:38.187
then you can say, "I need
to have a model of myself.

01:03:38.187 --> 01:03:41.850
"I have abilities; I have
desires, and so forth," okay?

01:03:41.850 --> 01:03:44.380
I have a blueprint of myself, though,

01:03:44.380 --> 01:03:47.500
not a full detail, though,
because I cannot get

01:03:47.500 --> 01:03:49.260
the whole thing problem,

01:03:49.260 --> 01:03:50.750
but I have a blueprint.

01:03:50.750 --> 01:03:54.270
So at that level of a
blueprint, I can modify things.

01:03:54.270 --> 01:03:56.517
I can look at myself
in the mirror and say,

01:03:56.517 --> 01:03:59.167
"Hmm, if I tweak this model,

01:03:59.167 --> 01:04:01.580
"I'm going to perform differently."

01:04:01.580 --> 01:04:05.780
That is what we mean
by free will. (laughs)

01:04:05.780 --> 01:04:07.642
- And consciousness.

01:04:07.642 --> 01:04:10.440
What do you think is consciousness?

01:04:10.440 --> 01:04:13.100
Is it simply self awareness,
including yourself

01:04:13.100 --> 01:04:14.745
into the model of the world?

01:04:14.745 --> 01:04:16.081
- That's right.

01:04:16.081 --> 01:04:19.640
Some people tell me no, this
is only part of consciousness,

01:04:19.640 --> 01:04:21.470
and then they start telling
what they really mean

01:04:21.470 --> 01:04:23.170
by consciousness, and I lose them.

01:04:24.720 --> 01:04:28.713
For me, consciousness
is having a blueprint

01:04:28.713 --> 01:04:31.106
of your software.

01:04:31.106 --> 01:04:36.025
- Do you have concerns
about the future of AI,

01:04:36.025 --> 01:04:39.680
all the different trajectories
of all the research?

01:04:39.680 --> 01:04:40.750
- [Judea] Yes.

01:04:40.750 --> 01:04:43.300
- Where's your hope
where the movement heads?

01:04:43.300 --> 01:04:44.560
Where are your concerns?

01:04:44.560 --> 01:04:45.790
- I'm concerned,

01:04:45.790 --> 01:04:49.293
because I know we are
building a new species

01:04:49.293 --> 01:04:51.877
that has the capability of exceeding us,

01:04:54.503 --> 01:04:56.753
exceeding our capabilities,

01:04:58.126 --> 01:05:03.126
and can breed itself and take
over the world, absolutely.

01:05:03.590 --> 01:05:07.680
It's a new species; it is uncontrolled.

01:05:07.680 --> 01:05:09.700
We don't know the degree
to which we control it.

01:05:09.700 --> 01:05:12.660
We don't even understand what it means,

01:05:12.660 --> 01:05:15.233
to be able to control this new species.

01:05:16.207 --> 01:05:18.300
So, I'm concerned.

01:05:18.300 --> 01:05:21.120
I don't have anything to add to that

01:05:21.120 --> 01:05:25.012
because it's such a
gray area, that unknown.

01:05:25.012 --> 01:05:27.763
It never happened in history.

01:05:28.938 --> 01:05:33.515
The only time it happened in history,

01:05:33.515 --> 01:05:35.907
was evolution with the human being.

01:05:35.907 --> 01:05:36.740
- [Lex] Right.

01:05:36.740 --> 01:05:41.088
- And it was very
successful, was it? (laughs)

01:05:41.088 --> 01:05:42.750
Some people say it was a great success.

01:05:42.750 --> 01:05:46.120
- For us, it was, but a
few people along the way,

01:05:46.120 --> 01:05:49.380
yeah, a few creatures along
the way would not agree.

01:05:49.380 --> 01:05:53.120
So, just because it's such a gray area,

01:05:53.120 --> 01:05:55.020
there's nothing else to say.

01:05:55.020 --> 01:05:56.840
- [Judea] We have a sample of one.

01:05:56.840 --> 01:05:58.160
- Sample of one.

01:05:58.160 --> 01:05:59.060
- [Judea] It's us.

01:06:00.369 --> 01:06:04.812
- Some people would look
at you, and say, yeah

01:06:04.812 --> 01:06:09.812
but we were looking to
you to help us make sure

01:06:10.340 --> 01:06:11.263
that sample two works out okay.

01:06:11.263 --> 01:06:12.096
- Correct.

01:06:13.336 --> 01:06:15.000
Actually we have more
than a sample of one.

01:06:15.000 --> 01:06:15.850
We have theories.

01:06:17.230 --> 01:06:20.780
And that's good; we don't
need to be statisticians.

01:06:20.780 --> 01:06:25.480
So, sample of one doesn't
mean poverty of knowledge.

01:06:25.480 --> 01:06:26.500
It's not.

01:06:26.500 --> 01:06:30.600
Sample of one plus theory,
conjecture or theory,

01:06:30.600 --> 01:06:34.430
of what could happen, that we do have.

01:06:34.430 --> 01:06:39.412
But I really feel helpless in
contributing to this argument,

01:06:39.412 --> 01:06:41.613
because I know so little,

01:06:42.762 --> 01:06:46.245
and my imagination is limited,

01:06:46.245 --> 01:06:49.553
and I know how much I don't know,

01:06:51.523 --> 01:06:54.847
but I'm concerned.

01:06:54.847 --> 01:06:57.180
- You were born and raised in Israel.

01:06:57.180 --> 01:06:59.310
- [Judea] Born and raised in Israel, yes.

01:06:59.310 --> 01:07:04.310
- And later served in the
Israel military defense forces.

01:07:04.673 --> 01:07:08.536
- In the Israel Defense Force.

01:07:08.536 --> 01:07:12.811
- What did you learn from that experience?

01:07:12.811 --> 01:07:15.957
- From that experience? (laughs)

01:07:15.957 --> 01:07:18.160
- [Lex] There's a
kibbutz in there as well.

01:07:18.160 --> 01:07:21.124
- Yes, because I was in a NAHAL,

01:07:21.124 --> 01:07:25.628
which is a combination
of agricultural work

01:07:25.628 --> 01:07:28.610
and military service.

01:07:28.610 --> 01:07:31.250
I was an idealist.

01:07:31.250 --> 01:07:34.250
I wanted to be a member of the kibbutz

01:07:34.250 --> 01:07:36.240
throughout my life,

01:07:36.240 --> 01:07:38.283
and to live a communal life,

01:07:39.630 --> 01:07:44.630
and so I prepared myself for that.

01:07:44.925 --> 01:07:49.925
Slowly, slowly I wanted
a greater challenge.

01:07:50.304 --> 01:07:55.304
- So, that's a far world away, both in t--

01:07:55.494 --> 01:07:58.588
But I learned from that, what a kidada.

01:07:58.588 --> 01:08:00.772
It was a miracle

01:08:00.772 --> 01:08:05.772
It was a miracle that
I served in the 1950s.

01:08:06.313 --> 01:08:09.483
I don't know how we survived.

01:08:10.369 --> 01:08:13.743
The country was under austerity.

01:08:14.847 --> 01:08:19.847
It tripled its population
from 600,000 to 1.8 million

01:08:21.500 --> 01:08:23.370
when I finished college.

01:08:23.370 --> 01:08:24.903
No one went hungry.

01:08:26.203 --> 01:08:28.073
Austerity, yes.

01:08:28.980 --> 01:08:33.070
When you wanted to make
an omelet in a restaurant,

01:08:33.930 --> 01:08:35.623
you had to bring your own egg.

01:08:37.879 --> 01:08:42.879
And the imprisoned people
from bringing the food

01:08:43.760 --> 01:08:48.685
from the farming area, from
the villages, to the city.

01:08:48.685 --> 01:08:50.823
But no one went hungry,

01:08:52.090 --> 01:08:57.090
and I always add to that:
higher education did not suffer

01:08:57.920 --> 01:08:59.843
any budget cuts.

01:08:59.843 --> 01:09:04.843
They still invested in me, in
my wife, in our generation.

01:09:05.480 --> 01:09:08.093
To get the best education that they could.

01:09:09.730 --> 01:09:13.687
So I'm really grateful for the progenity,

01:09:13.687 --> 01:09:17.910
and I'm trying to pay back now.

01:09:17.910 --> 01:09:22.910
It's a miracle that we
survived the war of 1948.

01:09:22.950 --> 01:09:26.323
They were so close to a second genocide.

01:09:27.300 --> 01:09:30.200
It was all planned. (laughs)

01:09:30.200 --> 01:09:32.220
But we survived it by a miracle,

01:09:32.220 --> 01:09:36.100
and then the second miracle
that not many people talk about,

01:09:36.100 --> 01:09:39.950
the next phase, how no one went hungry,

01:09:39.950 --> 01:09:44.020
and the country managed
to triple its population.

01:09:44.020 --> 01:09:45.330
You know what it means
to triple population?

01:09:45.330 --> 01:09:50.260
Imagine United States going
from, what, 350 million

01:09:50.260 --> 01:09:53.405
to (laugh) unbelievable.

01:09:53.405 --> 01:09:56.727
- This is a really
tense part of the world.

01:09:56.727 --> 01:09:58.786
It's a complicated part of the world,

01:09:58.786 --> 01:10:00.773
Israel and all around.

01:10:01.840 --> 01:10:06.840
Religion is at the core
of that complexity,

01:10:07.285 --> 01:10:09.087
or one of the components--

01:10:09.087 --> 01:10:12.690
Religion is a strong motivating course

01:10:12.690 --> 01:10:16.530
for many, many people
in the Middle East, yes.

01:10:16.530 --> 01:10:21.063
- In your view, looking back,
is religion good for society?

01:10:22.058 --> 01:10:26.013
- That's a good question
for robotics, you know?

01:10:26.013 --> 01:10:28.346
- [Lex] There's echoes of that question.

01:10:28.346 --> 01:10:31.073
- Should we equip robot
with religious beliefs?

01:10:32.310 --> 01:10:34.700
Suppose we find out, or we agree,

01:10:34.700 --> 01:10:37.950
that religion is a good thing,
it will keep you in line.

01:10:37.950 --> 01:10:42.650
Should we give the robot
the metaphor of a god?

01:10:42.650 --> 01:10:46.523
As a metaphor, the robot
will get it without us, also.

01:10:47.400 --> 01:10:51.020
Why? Because a robot
will reason by metaphor.

01:10:51.020 --> 01:10:56.020
And what is the most primitive
metaphor a child grows with?

01:10:57.687 --> 01:11:02.687
Mother smile, father teaching,

01:11:02.970 --> 01:11:05.443
father image and mother image, that's God.

01:11:06.490 --> 01:11:09.367
So, whether you want it or not, (laughs)

01:11:09.367 --> 01:11:12.950
the robot will, assuming
the robot is going

01:11:12.950 --> 01:11:14.820
to have a mother and a father.

01:11:14.820 --> 01:11:16.410
It may only have program, though,

01:11:16.410 --> 01:11:21.000
which doesn't supply
warmth and discipline.

01:11:21.000 --> 01:11:22.490
Well, discipline it does.

01:11:22.490 --> 01:11:26.093
So, the robot will have
a model of the trainer.

01:11:26.944 --> 01:11:29.340
And everything that happens in the world,

01:11:29.340 --> 01:11:32.340
cosmology and so on, is going to be mapped

01:11:32.340 --> 01:11:34.900
into the programmer. (laughs)

01:11:34.900 --> 01:11:36.433
That's God.

01:11:37.795 --> 01:11:42.420
- The thing that represents
the origin for everything

01:11:42.420 --> 01:11:43.390
for that robot.

01:11:43.390 --> 01:11:46.370
- [Judea] It's the most
primitive relationship.

01:11:46.370 --> 01:11:48.570
- So it's going to
arrive there by metaphor.

01:11:49.639 --> 01:11:53.180
And so the question is
if overall that metaphor

01:11:53.180 --> 01:11:55.803
has served us well, as humans.

01:11:55.803 --> 01:11:58.050
- I really don't know.

01:11:58.050 --> 01:11:59.853
I think it did,

01:11:59.853 --> 01:12:03.333
but as long as you keep in
mind it is only a metaphor.

01:12:03.333 --> 01:12:05.180
(laughs)

01:12:05.180 --> 01:12:10.180
- So, if you think we can,
can we talk about your son?

01:12:11.018 --> 01:12:13.290
- [Judea] Yes, yes.

01:12:13.290 --> 01:12:15.110
- Can you tell his story?

01:12:15.110 --> 01:12:17.200
- [Judea] His story, well--

01:12:17.200 --> 01:12:18.033
- Daniel.

01:12:18.033 --> 01:12:19.033
- His story is known.

01:12:20.450 --> 01:12:25.450
He was abducted in Pakistan,
by al-Quaeda driven sect,

01:12:27.050 --> 01:12:31.541
and under various pretenses.

01:12:31.541 --> 01:12:35.330
I don't even pay attention
to what the pretense was.

01:12:35.330 --> 01:12:40.330
Originally they wanted to
have United States deliver

01:12:43.229 --> 01:12:46.880
some promised airplanes, I--

01:12:46.880 --> 01:12:48.957
It was all made up, you know,

01:12:48.957 --> 01:12:53.313
all these demands were bogus.

01:12:54.330 --> 01:12:56.404
I don't know, really,

01:12:56.404 --> 01:13:00.120
but eventually he was executed,

01:13:00.120 --> 01:13:02.073
in front of a camera.

01:13:03.720 --> 01:13:06.846
- At the core of that
is hate and intolerance.

01:13:06.846 --> 01:13:09.902
- At the core, yes, absolutely, yes.

01:13:09.902 --> 01:13:14.902
We don't really appreciate
the depth of the hate

01:13:17.001 --> 01:13:19.201
with which billions of
peoples are educated.

01:13:24.981 --> 01:13:27.580
We don't understand it.

01:13:27.580 --> 01:13:29.380
I just listened recently

01:13:30.550 --> 01:13:33.963
to what they teach you
in Mogadishu. (laughs)

01:13:37.813 --> 01:13:41.619
When the war does stop,

01:13:41.619 --> 01:13:44.926
and the tap,

01:13:44.926 --> 01:13:48.660
we knew exactly who did it.

01:13:48.660 --> 01:13:49.493
The Jews.

01:13:49.493 --> 01:13:50.326
- [Lex] The Jews.

01:13:51.483 --> 01:13:54.063
We didn't know how,
but we knew who did it.

01:13:54.969 --> 01:13:58.110
We don't appreciate what it means to us.

01:13:58.110 --> 01:14:00.480
The depth is unbelievable.

01:14:00.480 --> 01:14:04.683
- Do you think all of
us are capable of evil,

01:14:06.618 --> 01:14:09.870
and the education, the indoctrination,

01:14:09.870 --> 01:14:11.662
is really what creates evil?

01:14:11.662 --> 01:14:13.613
- Absolutely we are capable of evil.

01:14:13.613 --> 01:14:16.393
If you are indoctrinated
sufficiently long,

01:14:17.420 --> 01:14:18.553
and in depth,

01:14:18.553 --> 01:14:23.553
we are capable of ISIS,
we are capable of Nazism,

01:14:24.083 --> 01:14:25.883
yes, we are.

01:14:26.760 --> 01:14:30.500
But the question is whether
we, after we have gone

01:14:30.500 --> 01:14:32.850
through some Western education,

01:14:32.850 --> 01:14:35.720
and we learn that everything
is really relative,

01:14:35.720 --> 01:14:37.700
that there is no absolute God.

01:14:37.700 --> 01:14:40.130
He's only a belief in God.

01:14:40.130 --> 01:14:43.550
Whether we are capable,
now, of being transformed,

01:14:43.550 --> 01:14:47.297
under certain circumstances,
to become brutal.

01:14:48.965 --> 01:14:50.323
- [Lex] Yeah.

01:14:50.323 --> 01:14:53.070
- That is a qu-- I'm worried about it,

01:14:53.070 --> 01:14:57.133
because some people say yes,
given the right circumstances,

01:14:58.809 --> 01:15:00.807
given the bad economical crisis.

01:15:03.650 --> 01:15:07.988
You are capable of doing it,
too, and that worries me.

01:15:07.988 --> 01:15:10.533
I want to believe that I'm not capable.

01:15:12.750 --> 01:15:14.610
- Seven years after Daniel's death,

01:15:14.610 --> 01:15:16.840
you wrote an article at
the Wall Street Journal

01:15:16.840 --> 01:15:19.680
titled "Daniel Pearl and
the Normalization of Evil."

01:15:19.680 --> 01:15:20.513
- [Judea] Yes.

01:15:20.513 --> 01:15:23.100
- What was your message back then,

01:15:23.100 --> 01:15:27.600
and how did it change
today, over the years?

01:15:27.600 --> 01:15:28.853
- I lost.

01:15:30.630 --> 01:15:32.080
- [Lex] What was the message?

01:15:32.080 --> 01:15:36.453
- The message was that we
are not treating terrorism

01:15:39.525 --> 01:15:41.446
as a taboo.

01:15:41.446 --> 01:15:46.446
We are treating it as a bargaining
device that is accepted.

01:15:47.220 --> 01:15:52.220
People have grievance, and
they go and bomb restaurants.

01:15:53.162 --> 01:15:55.300
It's normal.

01:15:55.300 --> 01:15:58.173
Look, you're even not
surprised when I tell you that.

01:15:59.230 --> 01:16:02.637
Twenty years ago you say,
"What? For grievance you go

01:16:02.637 --> 01:16:04.630
"and blow a restaurant?"

01:16:04.630 --> 01:16:07.264
Today it's become normalized.

01:16:07.264 --> 01:16:09.713
The banalisation of evil.

01:16:10.782 --> 01:16:15.782
And we have created that to
ourselves, by normalizing it,

01:16:16.630 --> 01:16:21.273
by making it part of political life.

01:16:24.000 --> 01:16:26.823
It's a political debate.

01:16:27.770 --> 01:16:32.770
Every terrorist yesterday
becomes a freedom fighter today

01:16:34.065 --> 01:16:36.660
and tomorrow is become a terrorist again.

01:16:36.660 --> 01:16:37.850
It's switchable.

01:16:38.789 --> 01:16:42.320
- [Lex] And so, we should call
out evil when there's evil.

01:16:43.380 --> 01:16:46.220
- If we don't want to be part of it.

01:16:46.220 --> 01:16:47.999
- [Lex] Become it.

01:16:47.999 --> 01:16:52.330
- Yeah, if we want to
separate good from evil,

01:16:52.330 --> 01:16:54.180
that's one of the first things, that,

01:16:56.160 --> 01:16:57.847
in the Garden of Eden, remember?

01:16:57.847 --> 01:17:02.847
The first thing that God tells them was

01:17:02.847 --> 01:17:04.987
"Hey, you want some knowledge?

01:17:04.987 --> 01:17:07.377
"Here is the tree of good and evil."

01:17:08.249 --> 01:17:11.819
- So this evil touched
your life personally.

01:17:11.819 --> 01:17:16.819
Does your heart have anger,
sadness, or is it hope?

01:17:17.090 --> 01:17:22.090
- Look, I see some beautiful
people coming from Pakistan.

01:17:25.524 --> 01:17:29.470
I see beautiful people everywhere.

01:17:29.470 --> 01:17:34.470
But I see horrible propagation
of evil in this country, too.

01:17:38.406 --> 01:17:43.406
It shows you how populistic
slogans can catch the mind

01:17:44.630 --> 01:17:47.023
of the best intellectuals.

01:17:48.250 --> 01:17:50.130
- Today is Father's Day.

01:17:50.130 --> 01:17:51.928
- [Judea] I didn't know that.

01:17:51.928 --> 01:17:56.928
- Yeah, what's a fond
memory you have of Daniel?

01:17:57.761 --> 01:18:01.589
- Oh, many good memories remains.

01:18:01.589 --> 01:18:03.943
He was my mentor.

01:18:06.150 --> 01:18:11.150
He had a sense of balance
that I didn't have. (laughs)

01:18:12.192 --> 01:18:14.453
- [Lex] Yeah.

01:18:15.360 --> 01:18:17.563
- He saw the beauty in every person.

01:18:19.480 --> 01:18:22.080
He was not as emotional as I am,

01:18:22.080 --> 01:18:26.260
more looking things in perspective.

01:18:26.260 --> 01:18:29.380
He really liked every person.

01:18:29.380 --> 01:18:31.580
He really grew up with the idea

01:18:31.580 --> 01:18:36.580
that a foreigner is a
reason for curiosity,

01:18:38.340 --> 01:18:39.923
not for fear.

01:18:41.835 --> 01:18:44.965
This one time we went in Berkeley,

01:18:44.965 --> 01:18:48.451
and a homeless came out
from some dark alley

01:18:48.451 --> 01:18:50.846
and said, "Hey man, can you spare a dime?"

01:18:50.846 --> 01:18:54.510
(Judea gasps) I retreated
back, you know, two feet back,

01:18:54.510 --> 01:18:57.283
and Danny just hugged him
and say "Here's a dime.

01:18:58.479 --> 01:19:01.279
"Enjoy yourself. Maybe you
want some money to take a bus

01:19:03.617 --> 01:19:04.487
"or whatever."

01:19:05.360 --> 01:19:06.640
Where did he get it?

01:19:06.640 --> 01:19:07.473
Not from me.

01:19:08.428 --> 01:19:10.510
(both laugh)

01:19:10.510 --> 01:19:12.480
- Do you have advice for young minds today

01:19:12.480 --> 01:19:16.240
dreaming about creating,
as you have dreamt,

01:19:16.240 --> 01:19:17.920
creating intelligent systems?

01:19:17.920 --> 01:19:21.440
What is the best way to arrive
at new break-through ideas

01:19:21.440 --> 01:19:23.870
and carry them through
the fire of criticism

01:19:23.870 --> 01:19:27.263
and past conventional ideas?

01:19:27.263 --> 01:19:29.643
- Ask your questions.

01:19:31.251 --> 01:19:36.251
Really, your questions are never dumb.

01:19:37.720 --> 01:19:40.750
And solve them your own way. (laughs)

01:19:40.750 --> 01:19:42.733
And don't take "no" for an answer.

01:19:44.015 --> 01:19:48.410
If they're really dumb,
you'll find out quickly,

01:19:48.410 --> 01:19:50.320
by trial and error, to see

01:19:50.320 --> 01:19:52.460
that they're not leading any place.

01:19:52.460 --> 01:19:57.460
But follow them, and try to
understand things your way.

01:19:59.500 --> 01:20:01.620
That is my advice.

01:20:01.620 --> 01:20:04.020
I don't know if it's going to help anyone.

01:20:04.020 --> 01:20:05.770
- [Lex] No, that's brilliantly put.

01:20:07.145 --> 01:20:09.770
- There's a lot of inertia
in science, in academia.

01:20:14.082 --> 01:20:17.493
It is slowing down science.

01:20:18.610 --> 01:20:21.360
- Yeah, those two words, "your way,"

01:20:21.360 --> 01:20:22.623
that's a powerful thing.

01:20:23.580 --> 01:20:26.120
It's against inertia, potentially.

01:20:26.120 --> 01:20:28.728
- [Judea] Against your professor.

01:20:28.728 --> 01:20:30.470
(Lex laughs)

01:20:30.470 --> 01:20:33.410
- I wrote "The Book of Why" in order

01:20:33.410 --> 01:20:35.970
to democratize common sense.

01:20:35.970 --> 01:20:37.793
- [Lex] Yeah. (laughs)

01:20:38.690 --> 01:20:43.690
- In order to instill
rebellious spirits in students,

01:20:44.928 --> 01:20:49.928
so they wouldn't wait until the
professor gets things right.

01:20:50.095 --> 01:20:52.512
(both laugh)

01:20:53.398 --> 01:20:56.620
- [Lex] So you wrote the
manifesto of the rebellion

01:20:56.620 --> 01:20:58.260
against the professor. (laughs)

01:20:58.260 --> 01:21:00.400
- [Judea] Against the professor, yes.

01:21:00.400 --> 01:21:02.820
- So looking back at
your life of research,

01:21:02.820 --> 01:21:06.910
what ideas do you hope ripple
through the next many decades?

01:21:06.910 --> 01:21:10.056
What do you hope your legacy will be?

01:21:10.056 --> 01:21:14.017
I already have a tombstone carved.

01:21:15.021 --> 01:21:17.438
(both laugh)

01:21:20.220 --> 01:21:21.550
- Oh, boy.

01:21:21.550 --> 01:21:24.643
- The fundamental law of counterfactuals.

01:21:25.860 --> 01:21:30.548
That's what it-- it's a simple equation.

01:21:30.548 --> 01:21:34.483
Put a counterfactual in
terms of a model surgery.

01:21:35.570 --> 01:21:38.020
That's it, because everything
follows from there.

01:21:39.419 --> 01:21:43.819
If you get that, all the rest.

01:21:43.819 --> 01:21:45.985
I can die in peace,

01:21:45.985 --> 01:21:49.089
and my student can derive all my knowledge

01:21:49.089 --> 01:21:51.940
by mathematical means.

01:21:51.940 --> 01:21:53.113
- The rest follows.

01:21:54.061 --> 01:21:56.470
Thank you so much for talking today.

01:21:56.470 --> 01:21:57.620
I really appreciate it.

01:21:58.815 --> 01:22:01.515
- My thank you for being so
attentive and instigating.

01:22:02.442 --> 01:22:03.900
(both laugh)

01:22:03.900 --> 01:22:04.850
- We did it.

01:22:04.850 --> 01:22:05.710
- We did it.

01:22:05.710 --> 01:22:07.540
- [Lex] The coffee helped.

01:22:07.540 --> 01:22:11.320
Thanks for listening to this
conversation with Judea Pearl.

01:22:11.320 --> 01:22:14.260
And thank you to our
presenting sponsor, Cash App.

01:22:14.260 --> 01:22:16.103
Download it, use code LexPodcast.

01:22:17.190 --> 01:22:20.120
You'll get $10, and $10 will go to FIRST,

01:22:20.120 --> 01:22:23.200
a STEM education nonprofit
that inspires hundreds

01:22:23.200 --> 01:22:25.780
of thousands of young minds to learn

01:22:25.780 --> 01:22:28.350
and to dream of engineering our future.

01:22:28.350 --> 01:22:31.110
If you enjoy this podcast,
subscribe on YouTube,

01:22:31.110 --> 01:22:34.360
give it five stars on Apple
Podcast, support on Patreon,

01:22:34.360 --> 01:22:36.870
or simply connect with me on Twitter.

01:22:36.870 --> 01:22:39.320
And now, let me leave you
with some words of wisdom

01:22:39.320 --> 01:22:41.070
from Judea Pearl.

01:22:41.070 --> 01:22:44.020
You cannot answer a question
that you cannot ask,

01:22:44.020 --> 01:22:47.393
and you cannot ask a question
that you have no words for.

01:22:48.850 --> 01:22:51.853
Thank you for listening, and
hope to see you next time.

